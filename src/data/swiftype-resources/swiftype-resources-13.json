{
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses": [
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-09-27T02:29:38Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.64569,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android <em>application</em> <em>licenses</em>",
        "sections": "Android <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Android <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-09-27T02:30:32Z",
      "updated_at": "2021-05-05T16:26:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Analytics MIT Copyright © 2016 Segment.io, Inc. CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me LoginManagerSDK New Relic License © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.64555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS <em>application</em> <em>licenses</em>",
        "sections": "tvOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic for TV <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.59708,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "sections": "Android SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the Android SDK for <em>mobile</em> monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License"
      },
      "id": "603e9eb628ccbc117beba796"
    }
  ],
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 407.67654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS <em>application</em> <em>licenses</em>",
        "sections": "iOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic iOS <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-09-27T02:29:38Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.64569,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android <em>application</em> <em>licenses</em>",
        "sections": "Android <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Android <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.59708,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "sections": "Android SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the Android SDK for <em>mobile</em> monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License"
      },
      "id": "603e9eb628ccbc117beba796"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/apm-agent-sdk-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-26T18:55:38Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.67319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-26T18:53:42Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.47758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/c-sdk-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-26T18:55:38Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.67319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-26T18:53:42Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.47758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-26T18:55:38Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.67319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-09-26T18:54:48Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.34903,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/java-agent-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-26T18:55:38Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.67319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-26T18:53:42Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.47758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-26T18:55:38Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.67319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-26T18:53:42Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.47758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.699,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-26T18:55:38Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.67319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-26T18:53:42Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.47758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-resource-provider-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.699,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-26T18:55:38Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.67319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-26T18:53:42Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.47758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69885,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-26T18:53:42Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.47758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-09-26T18:54:48Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.34903,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/nodejs-agent-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69885,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-26T18:55:38Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.67319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-26T18:53:42Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.47758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/php-agent-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-26T18:55:38Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.67319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-26T18:53:42Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.47758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-26T18:55:38Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.67319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-26T18:53:42Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.47758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/ruby-agent-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69852,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-09-26T18:55:38Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.67319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-09-26T18:53:42Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.47758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-browser/browser-agent-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.28503,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "New Relic Browser licenses",
        "UI tier"
      ],
      "title": "New Relic Browser licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Browser"
      ],
      "external_id": "b308c950e31570ee201237a88bfb8891da10a23c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-browser/new-relic-browser-licenses/",
      "published_at": "2021-09-26T18:58:39Z",
      "updated_at": "2021-03-16T04:45:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Browser. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. UI tier Library License DataStax Cassandra Java Driver Apache 2.0 d3 BSD Finagle Apache 2.0 gulp-rename MIT Jackson Apache 2.0 nee ISC nscala-time Apache 2.0 photocopy ISC Rapture Apache 2.0 React Apache 2.0 require.dir MIT Scrooge Apache 2.0 slf4j MIT snappy-java Apache 2.0 TwitterServer Apache 2.0 Typesafe Config Apache 2.0",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 180.30757,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>Browser</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>Browser</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> <em>Browser</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. UI tier Library License DataStax"
      },
      "id": "603ece91e7b9d2c9d02a07c2"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.4718,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-browser/new-relic-browser-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.28485,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Browser agent licenses"
      ],
      "title": "Browser agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Browser"
      ],
      "external_id": "9fac9d2d566767575f22d9458e49410063a83406",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-browser/browser-agent-licenses/",
      "published_at": "2021-09-26T18:56:34Z",
      "updated_at": "2021-03-16T04:45:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Browser agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Browserify MIT Episodes Apache 2.0 Lo-Dash MIT TraceKit MIT",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.89839,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> agent <em>licenses</em>",
        "sections": "<em>Browser</em> agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> <em>Browser</em> agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Browserify MIT Episodes Apache 2.0 Lo-Dash MIT TraceKit MIT"
      },
      "id": "603eb41ce7b9d298012a080a"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.4718,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-edition": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Developer Program Resources"
      ],
      "title": "Developer Program Resources",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Developer edition"
      ],
      "external_id": "8a2f08905c7dcd10e50e975783ca3cf0071324c0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-program-resources/",
      "published_at": "2021-09-26T18:59:33Z",
      "updated_at": "2021-03-13T03:24:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer, you are eligible to participate in New Relic’s Developer Program. Additional information and resources are available at New Relic’s Developer Program site. By downloading, accessing, or using the developer resources (including the CLI), you agree that usage of the developer resources is pursuant to the New Relic Developers Terms and Conditions and that you have the authority to bind your organization. Such terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not use these developer resources. If your use of the New Relic developer resources are covered under a separate agreement, the above does not apply to you.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Developer</em> Program Resources",
        "sections": "<em>Developer</em> Program Resources",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer, you are eligible to participate in <em>New</em> <em>Relic</em>’s <em>Developer</em> Program. Additional information and resources are available at <em>New</em> <em>Relic</em>’s <em>Developer</em> Program site. By downloading, accessing, or using the <em>developer</em> resources (including the CLI), you agree that usage of the <em>developer</em> resources"
      },
      "id": "6044e7bb196a676d20960f4d"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.59703,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-program-resources": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69818,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Developer edition",
        "Terms"
      ],
      "title": "Developer edition",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Developer edition"
      ],
      "external_id": "60bc94afd677817a7b7fd7dd471c537090a9f711",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-edition/",
      "published_at": "2021-09-26T18:56:35Z",
      "updated_at": "2021-03-13T02:26:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All new accounts (outside Japan) created on or after July 30, 2020 are on the New Relic One pricing plan and have the newer New Relic One user model as described here. If (i) your account was created prior to July 30, 2020; or (ii) you are a current New Relic K.K. customer (Japan): in addition to the New Relic Pre-release policy, use of the Developer Edition of New Relic to the extent it is available is also subject to the following terms: Terms Non-production use only Up to $500 per month in total product usage across the New Relic platform Up to 2 users",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.90392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Developer</em> <em>edition</em>",
        "sections": "<em>Developer</em> <em>edition</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " to the <em>New</em> <em>Relic</em> Pre-release policy, use of the <em>Developer</em> <em>Edition</em> of <em>New</em> <em>Relic</em> to the extent it is available is also subject to the following terms: Terms Non-production use only Up to $500 per month in total <em>product</em> usage across the <em>New</em> <em>Relic</em> platform Up to 2 users"
      },
      "id": "604506b9e7b9d22d115799c8"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.59702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-infrastructure/new-relic-infrastructure-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.2847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.47179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.03404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-insights/new-relic-insights-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.28455,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.47179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.03404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-logs/logs-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.10638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logs</em> plugin <em>licenses</em>",
        "sections": "<em>Logs</em> plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " used for <em>New</em> <em>Relic</em> <em>Logs</em>, see <em>Logs</em> <em>licenses</em>. Plugins for <em>Logs</em> The following <em>licenses</em> are for the plugins used to connects your <em>log</em> data with <em>New</em> <em>Relic</em> <em>Logs</em>. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 <em>New</em> <em>Relic</em>, Inc. Fluentd Library License Copyright Fluentd Apache"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.59702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Logs licenses",
        "Logs"
      ],
      "title": "Logs licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "229757bf0e3d8f3518533b11a059b9e4516e4699",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-licenses/",
      "published_at": "2021-09-26T19:01:50Z",
      "updated_at": "2021-03-16T04:46:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for the New Relic Logs plugins, see Logs plugin licenses. Logs axios MIT Copyright © 2014-present Matt Zabriskie Babel-plugin-transform-runtime MIT Copyright © 2014-present Sebastian McKenzie and other contributors Classnames MIT Copyright © 2018 Jed Watson Downshift MIT Copyright © 2017 PayPal Fuzzy-search ISC Copyright © 2016, Wouter Rutgers Immer MIT Copyright © 2017 Michel Weststrate Lodash MIT Copyright © JS Foundation and other contributors Lodash.debounce MIT Copyright © JS Foundation and other contributors Moment MIT Copyright © JS Foundation and other contributors Node-sass MIT Copyright © 2013-2016 Andrew Nesbitt Prop-types MIT Copyright © 2013-present, Facebook, Inc. React MIT Copyright © Facebook, Inc. and its affiliates. React-dom MIT Copyright © Facebook, Inc. and its affiliates. React-highlight-words MIT Copyright © 2015 Treasure Data React-json-view MIT Copyright © 2015 Mac Gainor React-popper MIT Copyright © 2018 React Popper authors React-redux MIT Copyright © 2015-present Dan Abramov React-select MIT Copyright © 2018 Jed Watson React-tooltip MIT Copyright © 2015 Wang Zixiao Redux MIT Copyright © 2015-present Dan Abramov Redux-logger MIT Copyright © 2016 Eugene Rodionov Redux-saga MIT Copyright © 2015 Yassine Elouafi Reselect MIT Copyright © 2015-2018 Reselect Contributors Shortid MIT Copyright © Dylan Greene Snyk Apache License 2.0 Copyright © 2015 Snyk Ltd. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.40971,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logs</em> <em>licenses</em>",
        "sections": "<em>Logs</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> <em>Logs</em> plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea57b28ccbce04ceba77a"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.59702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "iOS SDK for mobile monitoring licenses"
      ],
      "title": "iOS SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "71d2df4a922b6728230da4b4e8241f2d458ea66c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/ios-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-27T02:38:32Z",
      "updated_at": "2021-07-22T01:04:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the iOS SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apple Reachability Apple Reachability JSON++ MIT mod-pbxproj BSD-3 PLCrashReporter MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.04974,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "sections": "iOS SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the iOS SDK for <em>mobile</em> monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Apple"
      },
      "id": "60450cfde7b9d2c9eb5799c3"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-09-27T02:29:38Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.87169,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-mobile/ios-sdk-new-relic-mobile-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.02608,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "sections": "Android SDK for <em>mobile</em> monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the Android SDK for <em>mobile</em> monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License"
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-09-27T02:29:38Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.87169,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.6977,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.597,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.53246,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-plugins/plugins-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.6977,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.4043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs <em>plugin</em> <em>licenses</em>",
        "sections": "Logs <em>plugin</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs <em>plugins</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Logs licenses",
        "Logs"
      ],
      "title": "Logs licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "229757bf0e3d8f3518533b11a059b9e4516e4699",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-licenses/",
      "published_at": "2021-09-26T19:01:50Z",
      "updated_at": "2021-03-16T04:46:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for the New Relic Logs plugins, see Logs plugin licenses. Logs axios MIT Copyright © 2014-present Matt Zabriskie Babel-plugin-transform-runtime MIT Copyright © 2014-present Sebastian McKenzie and other contributors Classnames MIT Copyright © 2018 Jed Watson Downshift MIT Copyright © 2017 PayPal Fuzzy-search ISC Copyright © 2016, Wouter Rutgers Immer MIT Copyright © 2017 Michel Weststrate Lodash MIT Copyright © JS Foundation and other contributors Lodash.debounce MIT Copyright © JS Foundation and other contributors Moment MIT Copyright © JS Foundation and other contributors Node-sass MIT Copyright © 2013-2016 Andrew Nesbitt Prop-types MIT Copyright © 2013-present, Facebook, Inc. React MIT Copyright © Facebook, Inc. and its affiliates. React-dom MIT Copyright © Facebook, Inc. and its affiliates. React-highlight-words MIT Copyright © 2015 Treasure Data React-json-view MIT Copyright © 2015 Mac Gainor React-popper MIT Copyright © 2018 React Popper authors React-redux MIT Copyright © 2015-present Dan Abramov React-select MIT Copyright © 2018 Jed Watson React-tooltip MIT Copyright © 2015 Wang Zixiao Redux MIT Copyright © 2015-present Dan Abramov Redux-logger MIT Copyright © 2016 Eugene Rodionov Redux-saga MIT Copyright © 2015 Yassine Elouafi Reselect MIT Copyright © 2015-2018 Reselect Contributors Shortid MIT Copyright © Dylan Greene Snyk Apache License 2.0 Copyright © 2015 Snyk Ltd. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.95903,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs <em>licenses</em>",
        "sections": "Logs <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " used for the <em>New</em> <em>Relic</em> Logs <em>plugins</em>, see Logs <em>plugin</em> <em>licenses</em>. Logs axios MIT Copyright © 2014-present Matt Zabriskie Babel-<em>plugin</em>-transform-runtime MIT Copyright © 2014-present Sebastian McKenzie and other contributors Classnames MIT Copyright © 2018 Jed Watson Downshift MIT Copyright © 2017 PayPal"
      },
      "id": "603ea57b28ccbce04ceba77a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-synthetics/new-relic-synthetics-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Android SDK for mobile monitoring licenses"
      ],
      "title": "Android SDK for mobile monitoring licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-08-21T08:48:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for mobile monitoring. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.59698,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for mobile monitoring <em>licenses</em>",
        "sections": "Android SDK for mobile monitoring <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-09-26T19:02:31Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.53246,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/annotate-logs-logs-context-using-apm-agent-apis": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-27T15:54:46Z",
      "updated_at": "2021-09-27T15:54:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.2542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET <em>agent</em> connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.30609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>New</em> <em>Relic</em> tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your <em>agent</em> to see contextual <em>log</em> data, such as distributed"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-27T15:10:14Z",
      "updated_at": "2021-09-27T15:10:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.26596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring <em>agent</em>. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure <em>agent</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/c-sdk-configure-logs-context": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-27T15:54:46Z",
      "updated_at": "2021-09-27T15:54:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 448.6869,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Java: Configure logs in context",
        "Set up your Java app",
        "Dropwizard 1.3 or higher",
        "java.util.logging",
        "java.util.logging classpath additions",
        "Log4j 1.x",
        "Log4j 2.x",
        "Logback version 1.2.0 or higher",
        "Spring and Springboot",
        "View logs in UI",
        "What's next?"
      ],
      "title": "Java: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "59255e4b759113c33c56c041bc7376f06de7fe45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/java-configure-logs-context-all/",
      "published_at": "2021-09-26T18:28:11Z",
      "updated_at": "2021-09-01T04:08:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Java agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Java app To enable logs in context for APM apps monitored by Java: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Java agent version. Use Java agent version 5.6.0 or higher for logs in context. Enable the JVM argument -javaagent, and enable distributed tracing. Configure logs in context for Java to enrich your log data, using any of the following extensions as applicable. If you use Spring or Spring Boot and aren't sure which extension you need, see our Spring documentation. Dropwizard 1.3 or higher We offer a Dropwizard extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with the DropWizard extension: Make sure you have the Dropwizard 1.3 or higher package installed and working on your application. Use the original Dropwizard appenders and logging factory installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Dropwizard 1.3 extension as applicable: Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:dropwizard:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>dropwizard</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your Dropwizard .yaml configuration file with a newrelic-json layout, replacing the currently used type: console or type: file with either type: newrelic-console or type: newrelic-file as appropriate. For example: logging: appenders: - type: newrelic-console # Add the two lines below if you don't have a layout specified on the appender. # If you have a layout, remove all parameters to the layout and set the type. layout: type: newrelic-json Copy The New Relic Dropwizard extension also supports a log-format layout type that uses the standard Dropwizard logging. For testing purposes, you can change the type of the layout with a one-line change: logging: appenders: - type: newrelic-file # This format will be ignored by the newrelic-json layout, but used by the log-format layout. logFormat: \"%date{ISO8601} %c %-5p: %m trace.id=%mdc{trace.id} span.id=%mdc{span.id}%n\" layout: # type: newrelic-json type: log-format Copy java.util.logging We offer a java.util.logging extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the java.util.logging extension: Make sure you have the java.util.logging package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the java.util.logging extension as applicable. If you can't edit these files, you can instead add the jars directly to the application classpath. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:jul:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>jul</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Check if your logging file's handlers property is set to something other than NewRelicMemoryHandler. Look for a line listing the root logger's handlers, like this: handlers = java.util.logging.FileHandler Copy Update your logging properties file to set the root logger's handler to NewRelicMemoryHandler so it intercepts messages destined for another handler: handlers = com.newrelic.logging.jul.NewRelicMemoryHandler Copy Configure the NewRelicMemoryHandler by setting the target to the handler that was previously assigned to the root logger, so it captures data New Relic needs on the thread the log message is coming from: com.newrelic.logging.jul.NewRelicMemoryHandler.target = java.util.logging.FileHandler Copy Use a NewRelicFormatter for the final handler. Update your logging properties file to set the formatter property like the following example. Make sure the handler where you set the formatter is the target handler from the previous step (java.util.logging.FileHandler in this example). java.util.logging.FileHandler.formatter = com.newrelic.logging.jul. NewRelicFormatter Copy The New Relic log format is JSON with telemetry metadata we use to correlate transactions and logs together. Currently we do not support any customization of that format. Once complete, JSON is logged instead of text. The JSON should be formatted as single objects, one per line, and should contain fields like log.level and thread.name. The trace.id, which is required for logs in context, should only have a value for log messages that occur within a transaction. java.util.logging classpath additions The most direct way to get the logs-in-context extensions is to add these dependencies to Maven's pom.xml or Gradle's build.gradle. This allows the packaging tools to pick up the correct dependencies. If you can't edit these files, you can instead add the jars directly to the application classpath for your logging framework's configuration. Before you modify the classpath: Enable the JVM argument -javaagent on your app's Java agent. Verify which logging framework the application is using. Make sure you are able to change your logging framework's configuration. Add the following three jars to the classpath if they aren't already present. Generally, we recommend taking the latest versions published on Maven Central. Group ID com.newrelic.logging and Artifact ID: Select the artifact named after your application's logging framework in Maven. Group ID com.fasterxml.jackson.core and Artifact ID: Use jackson-core. Group ID com.newrelic.agent.java and Artifact ID: Use newrelic-api. Log4j 1.x We offer a Log4j 1.x extension extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 1.x extension, you must configure the Log4j extension in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Make sure you have the Log4j 1.x package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 1.x extension as applicable. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/>: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension: <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Log4j 2.x We offer a Log4j 2.x extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 2.x extension: Make sure you have the Log4j 2.x or Logs4j 2 binding package installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 2.x extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you're using a properties file, add packages=com.newrelic.logging.log4j2. Add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you're using a properties file, only change the layout.type: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, skip this step. If you added a new appender, add <AppenderRef/> within <Root> to use this appender. Use the ref attribute to refer to appender name you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you're using a properties file and added a new appender, add: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Logback version 1.2.0 or higher We offer a Logback extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with Logback: Make sure you have Logback version 1.2.0 or higher and the New Relic Java agent version 5.6.0 or higher installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Logback extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing <encoder> element. If you're logging to the console (stdout/stderr), look for ConsoleAppender and replace: <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you're logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the first appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. Then list any other appenders after the NewRelicAsyncAppender in the <root> list. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Here are examples of an updated logging .xml file for the Logback extension. You can also see a working example in GitHub. Single console appender example Example configuration file after adding in the logging extension information: <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two console appenders example This example sends New Relic logging to a file, but still sends standard logging to the console: <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Spring and Springboot We offer extensions for current versions of Spring and Spring Boot. If you already know the logging library, you can skip directly to that documentation: java.util.logging log4j 1 log4j 2 logback The extensions support default configurations only on Spring Boot 2.0 and higher. With Spring Boot: Here are tips to determine which logging library you have: If you have spring-boot-starter-log4j2 in your dependencies, you're using log4j 2.x. Refer to the Spring Boot log4j 2.x documentation for basic configuration, and the New Relic log4j 2 extension for customizing your configuration. If you're using Spring Boot but not the starter-log4j2, you're using logback by default. Refer to Spring Boot logback documentation for basic configuration, and the New Relic logback extension for customizing your configuration. With Spring (but not Spring Boot): Spring 5 or higher: Spring implements a bridge to other logging libraries that will automatically find them. However, those individual libraries must be configured and explicitly included in your project dependencies. To identify your logging dependency, consult your Gradle, Maven, or other build tool's dependency tree. Then follow the procedures to configure logs in context for your Java app with that extension. Spring 4 or lower: Spring version 4 and lower uses Apache Commons Logging for its bridge. Refer to the Spring documentation for information on configuring its bridge. View logs in UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.88223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Java agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your Java app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efca3e7b9d2f718b6f223"
    },
    {
      "sections": [
        "Configure logs in context with APM agents",
        "See the root cause of issues across your platform",
        "Basic process to enable logs in context",
        "API and other options",
        "What's next?"
      ],
      "title": "Configure logs in context with APM agents",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "f8ebd94136bca8ad2279d6f1170f3f6848a51ebc",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents/",
      "published_at": "2021-09-27T02:40:10Z",
      "updated_at": "2021-08-27T07:09:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you need to correlate log data with other telemetry data, enable logs in context in New Relic. Logs in context adds metadata that links your logs with related APM data, like errors or distributed traces, or your platform performance data from infrastructure monitoring in New Relic One. See the root cause of issues across your platform By bringing all of your application and infrastructure data together in a single solution, you can get to the root cause of issues faster. Logs in context help you quickly see meaningful patterns and trends. The following diagram shows the lifecycle of a log message, from enrichment with agent metadata (contextual logging), to formatting and forwarding the log data to New Relic: This diagram illustrates the flow of log messages through New Relic. Don't spend extra time trying to narrow down all your logs from different parts of your platform. Instead, enable logs in context to see the exact log lines you need to identify and resolve a problem. Basic process to enable logs in context The process to enable logs in context is basically the same, regardless of which APM agent you use to monitor your application: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Update to a supported APM agent version for your app, and enable distributed tracing. Configure logs in context for your APM agent or for your infrastructure monitoring agent. View your logs within the context of your apps or infrastructure in New Relic One. The main differences in this procedure are which log appenders you can use to extend and enrich your log data, and how to configure the log appender you select for your APM agent. For detailed information, see the logs-in-context procedures for: C SDK Go Java .NET Node.js PHP Python Ruby Infrastructure monitoring agent API and other options If our logging solutions don't meet your needs, you can use other options to send your log data to New Relic: Logging extensions via agent API calls HTTP endpoint via our Log API Syslog protocols via TCP endpoint (useful for CDNs, hardware devices, or managed services) What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.30203,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " logging in <em>New</em> <em>Relic</em>. This includes configuring a supported <em>log</em> forwarder that collects your application <em>logs</em> and extends the metadata that is forwarded to <em>New</em> <em>Relic</em>. Update to a supported APM agent version for your app, and <em>enable</em> distributed tracing. <em>Configure</em> <em>logs</em> in <em>context</em> for your APM agent"
      },
      "id": "603ea62e196a6749f8a83dc9"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-27T15:54:46Z",
      "updated_at": "2021-09-27T15:54:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 448.6869,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Java: Configure logs in context",
        "Set up your Java app",
        "Dropwizard 1.3 or higher",
        "java.util.logging",
        "java.util.logging classpath additions",
        "Log4j 1.x",
        "Log4j 2.x",
        "Logback version 1.2.0 or higher",
        "Spring and Springboot",
        "View logs in UI",
        "What's next?"
      ],
      "title": "Java: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "59255e4b759113c33c56c041bc7376f06de7fe45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/java-configure-logs-context-all/",
      "published_at": "2021-09-26T18:28:11Z",
      "updated_at": "2021-09-01T04:08:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Java agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Java app To enable logs in context for APM apps monitored by Java: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Java agent version. Use Java agent version 5.6.0 or higher for logs in context. Enable the JVM argument -javaagent, and enable distributed tracing. Configure logs in context for Java to enrich your log data, using any of the following extensions as applicable. If you use Spring or Spring Boot and aren't sure which extension you need, see our Spring documentation. Dropwizard 1.3 or higher We offer a Dropwizard extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with the DropWizard extension: Make sure you have the Dropwizard 1.3 or higher package installed and working on your application. Use the original Dropwizard appenders and logging factory installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Dropwizard 1.3 extension as applicable: Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:dropwizard:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>dropwizard</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your Dropwizard .yaml configuration file with a newrelic-json layout, replacing the currently used type: console or type: file with either type: newrelic-console or type: newrelic-file as appropriate. For example: logging: appenders: - type: newrelic-console # Add the two lines below if you don't have a layout specified on the appender. # If you have a layout, remove all parameters to the layout and set the type. layout: type: newrelic-json Copy The New Relic Dropwizard extension also supports a log-format layout type that uses the standard Dropwizard logging. For testing purposes, you can change the type of the layout with a one-line change: logging: appenders: - type: newrelic-file # This format will be ignored by the newrelic-json layout, but used by the log-format layout. logFormat: \"%date{ISO8601} %c %-5p: %m trace.id=%mdc{trace.id} span.id=%mdc{span.id}%n\" layout: # type: newrelic-json type: log-format Copy java.util.logging We offer a java.util.logging extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the java.util.logging extension: Make sure you have the java.util.logging package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the java.util.logging extension as applicable. If you can't edit these files, you can instead add the jars directly to the application classpath. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:jul:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>jul</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Check if your logging file's handlers property is set to something other than NewRelicMemoryHandler. Look for a line listing the root logger's handlers, like this: handlers = java.util.logging.FileHandler Copy Update your logging properties file to set the root logger's handler to NewRelicMemoryHandler so it intercepts messages destined for another handler: handlers = com.newrelic.logging.jul.NewRelicMemoryHandler Copy Configure the NewRelicMemoryHandler by setting the target to the handler that was previously assigned to the root logger, so it captures data New Relic needs on the thread the log message is coming from: com.newrelic.logging.jul.NewRelicMemoryHandler.target = java.util.logging.FileHandler Copy Use a NewRelicFormatter for the final handler. Update your logging properties file to set the formatter property like the following example. Make sure the handler where you set the formatter is the target handler from the previous step (java.util.logging.FileHandler in this example). java.util.logging.FileHandler.formatter = com.newrelic.logging.jul. NewRelicFormatter Copy The New Relic log format is JSON with telemetry metadata we use to correlate transactions and logs together. Currently we do not support any customization of that format. Once complete, JSON is logged instead of text. The JSON should be formatted as single objects, one per line, and should contain fields like log.level and thread.name. The trace.id, which is required for logs in context, should only have a value for log messages that occur within a transaction. java.util.logging classpath additions The most direct way to get the logs-in-context extensions is to add these dependencies to Maven's pom.xml or Gradle's build.gradle. This allows the packaging tools to pick up the correct dependencies. If you can't edit these files, you can instead add the jars directly to the application classpath for your logging framework's configuration. Before you modify the classpath: Enable the JVM argument -javaagent on your app's Java agent. Verify which logging framework the application is using. Make sure you are able to change your logging framework's configuration. Add the following three jars to the classpath if they aren't already present. Generally, we recommend taking the latest versions published on Maven Central. Group ID com.newrelic.logging and Artifact ID: Select the artifact named after your application's logging framework in Maven. Group ID com.fasterxml.jackson.core and Artifact ID: Use jackson-core. Group ID com.newrelic.agent.java and Artifact ID: Use newrelic-api. Log4j 1.x We offer a Log4j 1.x extension extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 1.x extension, you must configure the Log4j extension in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Make sure you have the Log4j 1.x package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 1.x extension as applicable. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/>: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension: <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Log4j 2.x We offer a Log4j 2.x extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 2.x extension: Make sure you have the Log4j 2.x or Logs4j 2 binding package installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 2.x extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you're using a properties file, add packages=com.newrelic.logging.log4j2. Add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you're using a properties file, only change the layout.type: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, skip this step. If you added a new appender, add <AppenderRef/> within <Root> to use this appender. Use the ref attribute to refer to appender name you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you're using a properties file and added a new appender, add: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Logback version 1.2.0 or higher We offer a Logback extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with Logback: Make sure you have Logback version 1.2.0 or higher and the New Relic Java agent version 5.6.0 or higher installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Logback extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing <encoder> element. If you're logging to the console (stdout/stderr), look for ConsoleAppender and replace: <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you're logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the first appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. Then list any other appenders after the NewRelicAsyncAppender in the <root> list. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Here are examples of an updated logging .xml file for the Logback extension. You can also see a working example in GitHub. Single console appender example Example configuration file after adding in the logging extension information: <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two console appenders example This example sends New Relic logging to a file, but still sends standard logging to the console: <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Spring and Springboot We offer extensions for current versions of Spring and Spring Boot. If you already know the logging library, you can skip directly to that documentation: java.util.logging log4j 1 log4j 2 logback The extensions support default configurations only on Spring Boot 2.0 and higher. With Spring Boot: Here are tips to determine which logging library you have: If you have spring-boot-starter-log4j2 in your dependencies, you're using log4j 2.x. Refer to the Spring Boot log4j 2.x documentation for basic configuration, and the New Relic log4j 2 extension for customizing your configuration. If you're using Spring Boot but not the starter-log4j2, you're using logback by default. Refer to Spring Boot logback documentation for basic configuration, and the New Relic logback extension for customizing your configuration. With Spring (but not Spring Boot): Spring 5 or higher: Spring implements a bridge to other logging libraries that will automatically find them. However, those individual libraries must be configured and explicitly included in your project dependencies. To identify your logging dependency, consult your Gradle, Maven, or other build tool's dependency tree. Then follow the procedures to configure logs in context for your Java app with that extension. Spring 4 or lower: Spring version 4 and lower uses Apache Commons Logging for its bridge. Refer to the Spring documentation for information on configuring its bridge. View logs in UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.88223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Java agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your Java app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efca3e7b9d2f718b6f223"
    },
    {
      "sections": [
        "C SDK: Configure logs in context"
      ],
      "title": "C SDK: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "b4e0747855dd10d05a7ead1d4504beba3f218723",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/c-sdk-configure-logs-context/",
      "published_at": "2021-09-26T19:06:13Z",
      "updated_at": "2021-08-26T05:33:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream services. To enable distributed tracing for apps monitored by the C SDK, install or update to the latest C SDK version. Distributed tracing requires C SDK version 1.1.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.8766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the <em>Log</em> API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream"
      },
      "id": "6127279b28ccbcf0c6f2618d"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-go": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-27T15:54:46Z",
      "updated_at": "2021-09-27T15:54:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 272.8522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Use APM agent APIs with logs in context",
        "APM agent trace metadata and linking metadata APIs",
        "Resources for correctly annotating logs"
      ],
      "title": "Use APM agent APIs with logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context with agent APIs"
      ],
      "external_id": "6dc4fff9bde0b7d49285cb8a7f16ba1dfc91f939",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/annotate-logs-logs-context-using-apm-agent-apis/",
      "published_at": "2021-09-27T15:21:48Z",
      "updated_at": "2021-09-26T11:16:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To correlate log data with other telemetry data, such as errors and distributed traces in APM, you can use our logs in context solutions. If your logging framework is not available with our existing logs in context solutions, you can configure your logging libraries by using API calls to annotate your logs. APM agent trace metadata and linking metadata APIs To get properly annotated logs for logs in context, use the following API calls for your APM agent. These APIs pass the required trace metadata and linking metadata to link your log data to other New Relic data. APM agent APIs: APM agent API calls C SDK (n/a) See our Log API documentation. Go GetTraceMetadata GetLinkingMetadata Java getTraceMetadata getLinkingMetadata .NET TraceMetadata GetLinkingMetadata Node.js newrelic.getTraceMetadata newrelic.getLinkingMetadata PHP newrelic_get_trace_metadata newrelic_get_linking_metadata Python get_linking_metadata Ruby linking_metadata current_trace_id current_span_id Resources for correctly annotating logs For more information about using the trace metadata and linking metadata APIs to annotate logs for logs in context, review the APM agent specifications in GitHub. These specifications include the required fields and properly formatted output. Also, review the source code for our own logs in context extensions to see how we use these APIs: C SDK: n/a Go: Logrus extension Java: Log4j2 extension .NET: Serilog extension Node.js: Winston extension Python: Streamhandler example PHP: Monolog extension Ruby: logging.rb extension",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.54337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use APM agent APIs with <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Use APM agent APIs with <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " your <em>logs</em>. APM agent trace metadata and linking metadata APIs To get properly annotated <em>logs</em> for <em>logs</em> in <em>context</em>, use the following API calls for your APM agent. These APIs pass the required trace metadata and linking metadata to link your <em>log</em> data to other <em>New</em> <em>Relic</em> data. APM agent APIs: APM agent"
      },
      "id": "61505693196a670394b70d61"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.66873,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-nodejs": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-27T15:54:46Z",
      "updated_at": "2021-09-27T15:54:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.25385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Use APM agent APIs with logs in context",
        "APM agent trace metadata and linking metadata APIs",
        "Resources for correctly annotating logs"
      ],
      "title": "Use APM agent APIs with logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context with agent APIs"
      ],
      "external_id": "6dc4fff9bde0b7d49285cb8a7f16ba1dfc91f939",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/annotate-logs-logs-context-using-apm-agent-apis/",
      "published_at": "2021-09-27T15:21:48Z",
      "updated_at": "2021-09-26T11:16:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To correlate log data with other telemetry data, such as errors and distributed traces in APM, you can use our logs in context solutions. If your logging framework is not available with our existing logs in context solutions, you can configure your logging libraries by using API calls to annotate your logs. APM agent trace metadata and linking metadata APIs To get properly annotated logs for logs in context, use the following API calls for your APM agent. These APIs pass the required trace metadata and linking metadata to link your log data to other New Relic data. APM agent APIs: APM agent API calls C SDK (n/a) See our Log API documentation. Go GetTraceMetadata GetLinkingMetadata Java getTraceMetadata getLinkingMetadata .NET TraceMetadata GetLinkingMetadata Node.js newrelic.getTraceMetadata newrelic.getLinkingMetadata PHP newrelic_get_trace_metadata newrelic_get_linking_metadata Python get_linking_metadata Ruby linking_metadata current_trace_id current_span_id Resources for correctly annotating logs For more information about using the trace metadata and linking metadata APIs to annotate logs for logs in context, review the APM agent specifications in GitHub. These specifications include the required fields and properly formatted output. Also, review the source code for our own logs in context extensions to see how we use these APIs: C SDK: n/a Go: Logrus extension Java: Log4j2 extension .NET: Serilog extension Node.js: Winston extension Python: Streamhandler example PHP: Monolog extension Ruby: logging.rb extension",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.21002,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use APM agent APIs with <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Use APM agent APIs with <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " include the required fields and properly formatted output. Also, review the source code for our own <em>logs</em> in <em>context</em> extensions to see how we use these APIs: C SDK: n&#x2F;a Go: Logrus extension Java: <em>Log</em>4j2 extension .NET: Serilog extension <em>Node.js</em>: Winston extension Python: Streamhandler example PHP: Monolog extension Ruby: logging.rb extension"
      },
      "id": "61505693196a670394b70d61"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.30582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-php": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-27T15:54:46Z",
      "updated_at": "2021-09-27T15:54:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.25366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Use APM agent APIs with logs in context",
        "APM agent trace metadata and linking metadata APIs",
        "Resources for correctly annotating logs"
      ],
      "title": "Use APM agent APIs with logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context with agent APIs"
      ],
      "external_id": "6dc4fff9bde0b7d49285cb8a7f16ba1dfc91f939",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/annotate-logs-logs-context-using-apm-agent-apis/",
      "published_at": "2021-09-27T15:21:48Z",
      "updated_at": "2021-09-26T11:16:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To correlate log data with other telemetry data, such as errors and distributed traces in APM, you can use our logs in context solutions. If your logging framework is not available with our existing logs in context solutions, you can configure your logging libraries by using API calls to annotate your logs. APM agent trace metadata and linking metadata APIs To get properly annotated logs for logs in context, use the following API calls for your APM agent. These APIs pass the required trace metadata and linking metadata to link your log data to other New Relic data. APM agent APIs: APM agent API calls C SDK (n/a) See our Log API documentation. Go GetTraceMetadata GetLinkingMetadata Java getTraceMetadata getLinkingMetadata .NET TraceMetadata GetLinkingMetadata Node.js newrelic.getTraceMetadata newrelic.getLinkingMetadata PHP newrelic_get_trace_metadata newrelic_get_linking_metadata Python get_linking_metadata Ruby linking_metadata current_trace_id current_span_id Resources for correctly annotating logs For more information about using the trace metadata and linking metadata APIs to annotate logs for logs in context, review the APM agent specifications in GitHub. These specifications include the required fields and properly formatted output. Also, review the source code for our own logs in context extensions to see how we use these APIs: C SDK: n/a Go: Logrus extension Java: Log4j2 extension .NET: Serilog extension Node.js: Winston extension Python: Streamhandler example PHP: Monolog extension Ruby: logging.rb extension",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.2099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use APM agent APIs with <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Use APM agent APIs with <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " your <em>logs</em>. APM agent trace metadata and linking metadata APIs To get properly annotated <em>logs</em> for <em>logs</em> in <em>context</em>, use the following API calls for your APM agent. These APIs pass the required trace metadata and linking metadata to link your <em>log</em> data to other <em>New</em> <em>Relic</em> data. APM agent APIs: APM agent"
      },
      "id": "61505693196a670394b70d61"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.3057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-python": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-27T15:54:46Z",
      "updated_at": "2021-09-27T15:54:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.2535,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Use APM agent APIs with logs in context",
        "APM agent trace metadata and linking metadata APIs",
        "Resources for correctly annotating logs"
      ],
      "title": "Use APM agent APIs with logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context with agent APIs"
      ],
      "external_id": "6dc4fff9bde0b7d49285cb8a7f16ba1dfc91f939",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/annotate-logs-logs-context-using-apm-agent-apis/",
      "published_at": "2021-09-27T15:21:48Z",
      "updated_at": "2021-09-26T11:16:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To correlate log data with other telemetry data, such as errors and distributed traces in APM, you can use our logs in context solutions. If your logging framework is not available with our existing logs in context solutions, you can configure your logging libraries by using API calls to annotate your logs. APM agent trace metadata and linking metadata APIs To get properly annotated logs for logs in context, use the following API calls for your APM agent. These APIs pass the required trace metadata and linking metadata to link your log data to other New Relic data. APM agent APIs: APM agent API calls C SDK (n/a) See our Log API documentation. Go GetTraceMetadata GetLinkingMetadata Java getTraceMetadata getLinkingMetadata .NET TraceMetadata GetLinkingMetadata Node.js newrelic.getTraceMetadata newrelic.getLinkingMetadata PHP newrelic_get_trace_metadata newrelic_get_linking_metadata Python get_linking_metadata Ruby linking_metadata current_trace_id current_span_id Resources for correctly annotating logs For more information about using the trace metadata and linking metadata APIs to annotate logs for logs in context, review the APM agent specifications in GitHub. These specifications include the required fields and properly formatted output. Also, review the source code for our own logs in context extensions to see how we use these APIs: C SDK: n/a Go: Logrus extension Java: Log4j2 extension .NET: Serilog extension Node.js: Winston extension Python: Streamhandler example PHP: Monolog extension Ruby: logging.rb extension",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.20976,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use APM agent APIs with <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Use APM agent APIs with <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " your <em>logs</em>. APM agent trace metadata and linking metadata APIs To get properly annotated <em>logs</em> for <em>logs</em> in <em>context</em>, use the following API calls for your APM agent. These APIs pass the required trace metadata and linking metadata to link your <em>log</em> data to other <em>New</em> <em>Relic</em> data. APM agent APIs: APM agent"
      },
      "id": "61505693196a670394b70d61"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.30556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-ruby": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-27T15:54:46Z",
      "updated_at": "2021-09-27T15:54:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.2535,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Use APM agent APIs with logs in context",
        "APM agent trace metadata and linking metadata APIs",
        "Resources for correctly annotating logs"
      ],
      "title": "Use APM agent APIs with logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context with agent APIs"
      ],
      "external_id": "6dc4fff9bde0b7d49285cb8a7f16ba1dfc91f939",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/annotate-logs-logs-context-using-apm-agent-apis/",
      "published_at": "2021-09-27T15:21:48Z",
      "updated_at": "2021-09-26T11:16:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To correlate log data with other telemetry data, such as errors and distributed traces in APM, you can use our logs in context solutions. If your logging framework is not available with our existing logs in context solutions, you can configure your logging libraries by using API calls to annotate your logs. APM agent trace metadata and linking metadata APIs To get properly annotated logs for logs in context, use the following API calls for your APM agent. These APIs pass the required trace metadata and linking metadata to link your log data to other New Relic data. APM agent APIs: APM agent API calls C SDK (n/a) See our Log API documentation. Go GetTraceMetadata GetLinkingMetadata Java getTraceMetadata getLinkingMetadata .NET TraceMetadata GetLinkingMetadata Node.js newrelic.getTraceMetadata newrelic.getLinkingMetadata PHP newrelic_get_trace_metadata newrelic_get_linking_metadata Python get_linking_metadata Ruby linking_metadata current_trace_id current_span_id Resources for correctly annotating logs For more information about using the trace metadata and linking metadata APIs to annotate logs for logs in context, review the APM agent specifications in GitHub. These specifications include the required fields and properly formatted output. Also, review the source code for our own logs in context extensions to see how we use these APIs: C SDK: n/a Go: Logrus extension Java: Log4j2 extension .NET: Serilog extension Node.js: Winston extension Python: Streamhandler example PHP: Monolog extension Ruby: logging.rb extension",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.20976,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use APM agent APIs with <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Use APM agent APIs with <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " your <em>logs</em>. APM agent trace metadata and linking metadata APIs To get properly annotated <em>logs</em> for <em>logs</em> in <em>context</em>, use the following API calls for your APM agent. These APIs pass the required trace metadata and linking metadata to link your <em>log</em> data to other <em>New</em> <em>Relic</em> data. APM agent APIs: APM agent"
      },
      "id": "61505693196a670394b70d61"
    },
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.30556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/java-configure-logs-context-all": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "1a1f97cbefe7280d8e526a23826bdd0fa70a5bd7",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all/",
      "published_at": "2021-09-27T15:54:46Z",
      "updated_at": "2021-09-27T15:54:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 448.68576,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Configure logs in context with APM agents",
        "See the root cause of issues across your platform",
        "Basic process to enable logs in context",
        "API and other options",
        "What's next?"
      ],
      "title": "Configure logs in context with APM agents",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "f8ebd94136bca8ad2279d6f1170f3f6848a51ebc",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents/",
      "published_at": "2021-09-27T02:40:10Z",
      "updated_at": "2021-08-27T07:09:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you need to correlate log data with other telemetry data, enable logs in context in New Relic. Logs in context adds metadata that links your logs with related APM data, like errors or distributed traces, or your platform performance data from infrastructure monitoring in New Relic One. See the root cause of issues across your platform By bringing all of your application and infrastructure data together in a single solution, you can get to the root cause of issues faster. Logs in context help you quickly see meaningful patterns and trends. The following diagram shows the lifecycle of a log message, from enrichment with agent metadata (contextual logging), to formatting and forwarding the log data to New Relic: This diagram illustrates the flow of log messages through New Relic. Don't spend extra time trying to narrow down all your logs from different parts of your platform. Instead, enable logs in context to see the exact log lines you need to identify and resolve a problem. Basic process to enable logs in context The process to enable logs in context is basically the same, regardless of which APM agent you use to monitor your application: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Update to a supported APM agent version for your app, and enable distributed tracing. Configure logs in context for your APM agent or for your infrastructure monitoring agent. View your logs within the context of your apps or infrastructure in New Relic One. The main differences in this procedure are which log appenders you can use to extend and enrich your log data, and how to configure the log appender you select for your APM agent. For detailed information, see the logs-in-context procedures for: C SDK Go Java .NET Node.js PHP Python Ruby Infrastructure monitoring agent API and other options If our logging solutions don't meet your needs, you can use other options to send your log data to New Relic: Logging extensions via agent API calls HTTP endpoint via our Log API Syslog protocols via TCP endpoint (useful for CDNs, hardware devices, or managed services) What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.30197,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " logging in <em>New</em> <em>Relic</em>. This includes configuring a supported <em>log</em> forwarder that collects your application <em>logs</em> and extends the metadata that is forwarded to <em>New</em> <em>Relic</em>. Update to a supported APM agent version for your app, and <em>enable</em> distributed tracing. <em>Configure</em> <em>logs</em> in <em>context</em> for your APM agent"
      },
      "id": "603ea62e196a6749f8a83dc9"
    },
    {
      "sections": [
        "C SDK: Configure logs in context"
      ],
      "title": "C SDK: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "b4e0747855dd10d05a7ead1d4504beba3f218723",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/c-sdk-configure-logs-context/",
      "published_at": "2021-09-26T19:06:13Z",
      "updated_at": "2021-08-26T05:33:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream services. To enable distributed tracing for apps monitored by the C SDK, install or update to the latest C SDK version. Distributed tracing requires C SDK version 1.1.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.87653,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the <em>Log</em> API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream"
      },
      "id": "6127279b28ccbcf0c6f2618d"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/net-configure-logs-context-all": [
    {
      "sections": [
        "Java: Configure logs in context",
        "Set up your Java app",
        "Dropwizard 1.3 or higher",
        "java.util.logging",
        "java.util.logging classpath additions",
        "Log4j 1.x",
        "Log4j 2.x",
        "Logback version 1.2.0 or higher",
        "Spring and Springboot",
        "View logs in UI",
        "What's next?"
      ],
      "title": "Java: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "59255e4b759113c33c56c041bc7376f06de7fe45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/java-configure-logs-context-all/",
      "published_at": "2021-09-26T18:28:11Z",
      "updated_at": "2021-09-01T04:08:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Java agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Java app To enable logs in context for APM apps monitored by Java: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Java agent version. Use Java agent version 5.6.0 or higher for logs in context. Enable the JVM argument -javaagent, and enable distributed tracing. Configure logs in context for Java to enrich your log data, using any of the following extensions as applicable. If you use Spring or Spring Boot and aren't sure which extension you need, see our Spring documentation. Dropwizard 1.3 or higher We offer a Dropwizard extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with the DropWizard extension: Make sure you have the Dropwizard 1.3 or higher package installed and working on your application. Use the original Dropwizard appenders and logging factory installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Dropwizard 1.3 extension as applicable: Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:dropwizard:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>dropwizard</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your Dropwizard .yaml configuration file with a newrelic-json layout, replacing the currently used type: console or type: file with either type: newrelic-console or type: newrelic-file as appropriate. For example: logging: appenders: - type: newrelic-console # Add the two lines below if you don't have a layout specified on the appender. # If you have a layout, remove all parameters to the layout and set the type. layout: type: newrelic-json Copy The New Relic Dropwizard extension also supports a log-format layout type that uses the standard Dropwizard logging. For testing purposes, you can change the type of the layout with a one-line change: logging: appenders: - type: newrelic-file # This format will be ignored by the newrelic-json layout, but used by the log-format layout. logFormat: \"%date{ISO8601} %c %-5p: %m trace.id=%mdc{trace.id} span.id=%mdc{span.id}%n\" layout: # type: newrelic-json type: log-format Copy java.util.logging We offer a java.util.logging extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the java.util.logging extension: Make sure you have the java.util.logging package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the java.util.logging extension as applicable. If you can't edit these files, you can instead add the jars directly to the application classpath. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:jul:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>jul</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Check if your logging file's handlers property is set to something other than NewRelicMemoryHandler. Look for a line listing the root logger's handlers, like this: handlers = java.util.logging.FileHandler Copy Update your logging properties file to set the root logger's handler to NewRelicMemoryHandler so it intercepts messages destined for another handler: handlers = com.newrelic.logging.jul.NewRelicMemoryHandler Copy Configure the NewRelicMemoryHandler by setting the target to the handler that was previously assigned to the root logger, so it captures data New Relic needs on the thread the log message is coming from: com.newrelic.logging.jul.NewRelicMemoryHandler.target = java.util.logging.FileHandler Copy Use a NewRelicFormatter for the final handler. Update your logging properties file to set the formatter property like the following example. Make sure the handler where you set the formatter is the target handler from the previous step (java.util.logging.FileHandler in this example). java.util.logging.FileHandler.formatter = com.newrelic.logging.jul. NewRelicFormatter Copy The New Relic log format is JSON with telemetry metadata we use to correlate transactions and logs together. Currently we do not support any customization of that format. Once complete, JSON is logged instead of text. The JSON should be formatted as single objects, one per line, and should contain fields like log.level and thread.name. The trace.id, which is required for logs in context, should only have a value for log messages that occur within a transaction. java.util.logging classpath additions The most direct way to get the logs-in-context extensions is to add these dependencies to Maven's pom.xml or Gradle's build.gradle. This allows the packaging tools to pick up the correct dependencies. If you can't edit these files, you can instead add the jars directly to the application classpath for your logging framework's configuration. Before you modify the classpath: Enable the JVM argument -javaagent on your app's Java agent. Verify which logging framework the application is using. Make sure you are able to change your logging framework's configuration. Add the following three jars to the classpath if they aren't already present. Generally, we recommend taking the latest versions published on Maven Central. Group ID com.newrelic.logging and Artifact ID: Select the artifact named after your application's logging framework in Maven. Group ID com.fasterxml.jackson.core and Artifact ID: Use jackson-core. Group ID com.newrelic.agent.java and Artifact ID: Use newrelic-api. Log4j 1.x We offer a Log4j 1.x extension extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 1.x extension, you must configure the Log4j extension in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Make sure you have the Log4j 1.x package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 1.x extension as applicable. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/>: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension: <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Log4j 2.x We offer a Log4j 2.x extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 2.x extension: Make sure you have the Log4j 2.x or Logs4j 2 binding package installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 2.x extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you're using a properties file, add packages=com.newrelic.logging.log4j2. Add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you're using a properties file, only change the layout.type: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, skip this step. If you added a new appender, add <AppenderRef/> within <Root> to use this appender. Use the ref attribute to refer to appender name you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you're using a properties file and added a new appender, add: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Logback version 1.2.0 or higher We offer a Logback extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with Logback: Make sure you have Logback version 1.2.0 or higher and the New Relic Java agent version 5.6.0 or higher installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Logback extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing <encoder> element. If you're logging to the console (stdout/stderr), look for ConsoleAppender and replace: <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you're logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the first appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. Then list any other appenders after the NewRelicAsyncAppender in the <root> list. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Here are examples of an updated logging .xml file for the Logback extension. You can also see a working example in GitHub. Single console appender example Example configuration file after adding in the logging extension information: <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two console appenders example This example sends New Relic logging to a file, but still sends standard logging to the console: <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Spring and Springboot We offer extensions for current versions of Spring and Spring Boot. If you already know the logging library, you can skip directly to that documentation: java.util.logging log4j 1 log4j 2 logback The extensions support default configurations only on Spring Boot 2.0 and higher. With Spring Boot: Here are tips to determine which logging library you have: If you have spring-boot-starter-log4j2 in your dependencies, you're using log4j 2.x. Refer to the Spring Boot log4j 2.x documentation for basic configuration, and the New Relic log4j 2 extension for customizing your configuration. If you're using Spring Boot but not the starter-log4j2, you're using logback by default. Refer to Spring Boot logback documentation for basic configuration, and the New Relic logback extension for customizing your configuration. With Spring (but not Spring Boot): Spring 5 or higher: Spring implements a bridge to other logging libraries that will automatically find them. However, those individual libraries must be configured and explicitly included in your project dependencies. To identify your logging dependency, consult your Gradle, Maven, or other build tool's dependency tree. Then follow the procedures to configure logs in context for your Java app with that extension. Spring 4 or lower: Spring version 4 and lower uses Apache Commons Logging for its bridge. Refer to the Spring documentation for information on configuring its bridge. View logs in UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.88214,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Java agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your Java app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efca3e7b9d2f718b6f223"
    },
    {
      "sections": [
        "Configure logs in context with APM agents",
        "See the root cause of issues across your platform",
        "Basic process to enable logs in context",
        "API and other options",
        "What's next?"
      ],
      "title": "Configure logs in context with APM agents",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "f8ebd94136bca8ad2279d6f1170f3f6848a51ebc",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents/",
      "published_at": "2021-09-27T02:40:10Z",
      "updated_at": "2021-08-27T07:09:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you need to correlate log data with other telemetry data, enable logs in context in New Relic. Logs in context adds metadata that links your logs with related APM data, like errors or distributed traces, or your platform performance data from infrastructure monitoring in New Relic One. See the root cause of issues across your platform By bringing all of your application and infrastructure data together in a single solution, you can get to the root cause of issues faster. Logs in context help you quickly see meaningful patterns and trends. The following diagram shows the lifecycle of a log message, from enrichment with agent metadata (contextual logging), to formatting and forwarding the log data to New Relic: This diagram illustrates the flow of log messages through New Relic. Don't spend extra time trying to narrow down all your logs from different parts of your platform. Instead, enable logs in context to see the exact log lines you need to identify and resolve a problem. Basic process to enable logs in context The process to enable logs in context is basically the same, regardless of which APM agent you use to monitor your application: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Update to a supported APM agent version for your app, and enable distributed tracing. Configure logs in context for your APM agent or for your infrastructure monitoring agent. View your logs within the context of your apps or infrastructure in New Relic One. The main differences in this procedure are which log appenders you can use to extend and enrich your log data, and how to configure the log appender you select for your APM agent. For detailed information, see the logs-in-context procedures for: C SDK Go Java .NET Node.js PHP Python Ruby Infrastructure monitoring agent API and other options If our logging solutions don't meet your needs, you can use other options to send your log data to New Relic: Logging extensions via agent API calls HTTP endpoint via our Log API Syslog protocols via TCP endpoint (useful for CDNs, hardware devices, or managed services) What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.30197,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " logging in <em>New</em> <em>Relic</em>. This includes configuring a supported <em>log</em> forwarder that collects your application <em>logs</em> and extends the metadata that is forwarded to <em>New</em> <em>Relic</em>. Update to a supported APM agent version for your app, and <em>enable</em> distributed tracing. <em>Configure</em> <em>logs</em> in <em>context</em> for your APM agent"
      },
      "id": "603ea62e196a6749f8a83dc9"
    },
    {
      "sections": [
        "C SDK: Configure logs in context"
      ],
      "title": "C SDK: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "b4e0747855dd10d05a7ead1d4504beba3f218723",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/c-sdk-configure-logs-context/",
      "published_at": "2021-09-26T19:06:13Z",
      "updated_at": "2021-08-26T05:33:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream services. To enable distributed tracing for apps monitored by the C SDK, install or update to the latest C SDK version. Distributed tracing requires C SDK version 1.1.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.87653,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the <em>Log</em> API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream"
      },
      "id": "6127279b28ccbcf0c6f2618d"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-firelens-plugin-log-forwarding": [
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.29657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-27T15:10:14Z",
      "updated_at": "2021-09-27T15:10:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.22766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward logs and activity logs from Azure",
        "Requirements",
        "Use the Azure Resource Manager (ARM) template",
        "View log data",
        "Send logs from Azure resources",
        "Azure Activity Logs",
        "What's next?"
      ],
      "title": "Forward logs and activity logs from Azure",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "Azure",
        "Cloud logs"
      ],
      "external_id": "154d5c9a60899bf708548c0fec6a59c0836a9c74",
      "image": "https://docs.newrelic.com/static/da32e66650336026701ab338f5afbb60/5f1d2/azure-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/azure-log-forwarding/",
      "published_at": "2021-09-27T15:16:25Z",
      "updated_at": "2021-09-26T11:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Azure Resources Manager (ARM) template provided by New Relic One helps you: Set up Azure to forward logs from EventHub to New Relic One. Set up Azure Activity Logs forwarding to New Relic One through EventHub. The setup process is almost the same for both use cases, but take a look at step 9 if you want to forward Azure Activity Logs to New Relic. On the other hand, the template is idempotent. You can start forwarding logs from EventHub and then re-run the same template to configure Azure Activity Logs forwarding by completing step 9 listed below. Requirements A New Relic license key. Use the Azure Resource Manager (ARM) template Login to New Relic Logs and click Add more data sources on the top right of the page. Under Log ingestion, click on the tile. Select the account you want to send the logs from the selector, and click Continue. Click Generate API Key and copy the generated API Key. Click Deploy to Azure and a new tab will be open with the ARM template loaded in Azure. Select the Resource Group in which you want to create the necessary resources, and a Region. In the New Relic License Key field, paste the previously copied API Key. Ensure the New Relic One endpoint set is the one corresponding to your account. Optionally, set to true the Azure Activity Logs you want to forward from the following list: Administrative Azure Activity Logs Alert Azure Activity Logs Autoscale Azure Activity Logs Policy Azure Activity Logs Recommendation Azure Activity Logs Resource Health Azure Activity Logs Security Azure Activity Logs Service Health Azure Activity Logs Click Review + create, review the data you've inserted, and click Create. View log data Once logs are streaming you can view them using: New Relic Logs - Search for plugin.type:\"azure\" if you have more logs sources and want to check only the ones coming from Azure. New Relic tools for running NRQL queries. For example, you can run a query like: SELECT * FROM Log Copy If you want to only query for logs coming from Azure, run the following query: SELECT * FROM Log where plugin.type='azure' Copy Send logs from Azure resources By default, this template only configures the needed function and resources to forward logs to New Relic One. We can also configure the activity logs to be forwarded, but there isn't a default log forwarding from your Azure resources. If you want to forward logs from any resource that produces them, you need to configure it by creating a diagnostic setting for the given resource. As an example, if you have a function running on Azure and you want to forward the logs to New Relic One, you'll need to configure a diagnostic setting to forward the logs to the configure EventHub. Read how to create diagnostic settings to send platform logs and metrics to different destinations. Azure Activity Logs Activating the Azure Activity Logs forwarding is optional and it provides: More visibility of your Azure resources Activity of the Azure resources Information about performed actions Events and their timestamps The user who performed an action, if applicable These logs allow your company to have more control over the resources, be aware of wrong or unintentional changes on your resources and even unexpected actions. You can read more about this kind of event on the Azure Activity Log event schema. What's next? Now that you've enabled Logs, you can: Take a look at how the New Relic One ARM template and Azure function works in the newrelic-azure-functions repository. Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.9403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "sections": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " the Azure Resource Manager (ARM) template Login to <em>New</em> <em>Relic</em> <em>Logs</em> and click Add more data sources on the top right of the page. Under <em>Log</em> ingestion, click on the tile. Select the account you want to send the <em>logs</em> from the selector, and click Continue. Click Generate API Key and copy the generated"
      },
      "id": "6150545de7b9d2ae518de37f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs": [
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.29657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-27T15:10:14Z",
      "updated_at": "2021-09-27T15:10:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.22766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward logs and activity logs from Azure",
        "Requirements",
        "Use the Azure Resource Manager (ARM) template",
        "View log data",
        "Send logs from Azure resources",
        "Azure Activity Logs",
        "What's next?"
      ],
      "title": "Forward logs and activity logs from Azure",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "Azure",
        "Cloud logs"
      ],
      "external_id": "154d5c9a60899bf708548c0fec6a59c0836a9c74",
      "image": "https://docs.newrelic.com/static/da32e66650336026701ab338f5afbb60/5f1d2/azure-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/azure-log-forwarding/",
      "published_at": "2021-09-27T15:16:25Z",
      "updated_at": "2021-09-26T11:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Azure Resources Manager (ARM) template provided by New Relic One helps you: Set up Azure to forward logs from EventHub to New Relic One. Set up Azure Activity Logs forwarding to New Relic One through EventHub. The setup process is almost the same for both use cases, but take a look at step 9 if you want to forward Azure Activity Logs to New Relic. On the other hand, the template is idempotent. You can start forwarding logs from EventHub and then re-run the same template to configure Azure Activity Logs forwarding by completing step 9 listed below. Requirements A New Relic license key. Use the Azure Resource Manager (ARM) template Login to New Relic Logs and click Add more data sources on the top right of the page. Under Log ingestion, click on the tile. Select the account you want to send the logs from the selector, and click Continue. Click Generate API Key and copy the generated API Key. Click Deploy to Azure and a new tab will be open with the ARM template loaded in Azure. Select the Resource Group in which you want to create the necessary resources, and a Region. In the New Relic License Key field, paste the previously copied API Key. Ensure the New Relic One endpoint set is the one corresponding to your account. Optionally, set to true the Azure Activity Logs you want to forward from the following list: Administrative Azure Activity Logs Alert Azure Activity Logs Autoscale Azure Activity Logs Policy Azure Activity Logs Recommendation Azure Activity Logs Resource Health Azure Activity Logs Security Azure Activity Logs Service Health Azure Activity Logs Click Review + create, review the data you've inserted, and click Create. View log data Once logs are streaming you can view them using: New Relic Logs - Search for plugin.type:\"azure\" if you have more logs sources and want to check only the ones coming from Azure. New Relic tools for running NRQL queries. For example, you can run a query like: SELECT * FROM Log Copy If you want to only query for logs coming from Azure, run the following query: SELECT * FROM Log where plugin.type='azure' Copy Send logs from Azure resources By default, this template only configures the needed function and resources to forward logs to New Relic One. We can also configure the activity logs to be forwarded, but there isn't a default log forwarding from your Azure resources. If you want to forward logs from any resource that produces them, you need to configure it by creating a diagnostic setting for the given resource. As an example, if you have a function running on Azure and you want to forward the logs to New Relic One, you'll need to configure a diagnostic setting to forward the logs to the configure EventHub. Read how to create diagnostic settings to send platform logs and metrics to different destinations. Azure Activity Logs Activating the Azure Activity Logs forwarding is optional and it provides: More visibility of your Azure resources Activity of the Azure resources Information about performed actions Events and their timestamps The user who performed an action, if applicable These logs allow your company to have more control over the resources, be aware of wrong or unintentional changes on your resources and even unexpected actions. You can read more about this kind of event on the Azure Activity Log event schema. What's next? Now that you've enabled Logs, you can: Take a look at how the New Relic One ARM template and Azure function works in the newrelic-azure-functions repository. Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.9403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "sections": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " the Azure Resource Manager (ARM) template Login to <em>New</em> <em>Relic</em> <em>Logs</em> and click Add more data sources on the top right of the page. Under <em>Log</em> ingestion, click on the tile. Select the account you want to send the <em>logs</em> from the selector, and click Continue. Click Generate API Key and copy the generated"
      },
      "id": "6150545de7b9d2ae518de37f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-logs-s3": [
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.29633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-27T15:10:14Z",
      "updated_at": "2021-09-27T15:10:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.22742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward logs and activity logs from Azure",
        "Requirements",
        "Use the Azure Resource Manager (ARM) template",
        "View log data",
        "Send logs from Azure resources",
        "Azure Activity Logs",
        "What's next?"
      ],
      "title": "Forward logs and activity logs from Azure",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "Azure",
        "Cloud logs"
      ],
      "external_id": "154d5c9a60899bf708548c0fec6a59c0836a9c74",
      "image": "https://docs.newrelic.com/static/da32e66650336026701ab338f5afbb60/5f1d2/azure-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/azure-log-forwarding/",
      "published_at": "2021-09-27T15:16:25Z",
      "updated_at": "2021-09-26T11:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Azure Resources Manager (ARM) template provided by New Relic One helps you: Set up Azure to forward logs from EventHub to New Relic One. Set up Azure Activity Logs forwarding to New Relic One through EventHub. The setup process is almost the same for both use cases, but take a look at step 9 if you want to forward Azure Activity Logs to New Relic. On the other hand, the template is idempotent. You can start forwarding logs from EventHub and then re-run the same template to configure Azure Activity Logs forwarding by completing step 9 listed below. Requirements A New Relic license key. Use the Azure Resource Manager (ARM) template Login to New Relic Logs and click Add more data sources on the top right of the page. Under Log ingestion, click on the tile. Select the account you want to send the logs from the selector, and click Continue. Click Generate API Key and copy the generated API Key. Click Deploy to Azure and a new tab will be open with the ARM template loaded in Azure. Select the Resource Group in which you want to create the necessary resources, and a Region. In the New Relic License Key field, paste the previously copied API Key. Ensure the New Relic One endpoint set is the one corresponding to your account. Optionally, set to true the Azure Activity Logs you want to forward from the following list: Administrative Azure Activity Logs Alert Azure Activity Logs Autoscale Azure Activity Logs Policy Azure Activity Logs Recommendation Azure Activity Logs Resource Health Azure Activity Logs Security Azure Activity Logs Service Health Azure Activity Logs Click Review + create, review the data you've inserted, and click Create. View log data Once logs are streaming you can view them using: New Relic Logs - Search for plugin.type:\"azure\" if you have more logs sources and want to check only the ones coming from Azure. New Relic tools for running NRQL queries. For example, you can run a query like: SELECT * FROM Log Copy If you want to only query for logs coming from Azure, run the following query: SELECT * FROM Log where plugin.type='azure' Copy Send logs from Azure resources By default, this template only configures the needed function and resources to forward logs to New Relic One. We can also configure the activity logs to be forwarded, but there isn't a default log forwarding from your Azure resources. If you want to forward logs from any resource that produces them, you need to configure it by creating a diagnostic setting for the given resource. As an example, if you have a function running on Azure and you want to forward the logs to New Relic One, you'll need to configure a diagnostic setting to forward the logs to the configure EventHub. Read how to create diagnostic settings to send platform logs and metrics to different destinations. Azure Activity Logs Activating the Azure Activity Logs forwarding is optional and it provides: More visibility of your Azure resources Activity of the Azure resources Information about performed actions Events and their timestamps The user who performed an action, if applicable These logs allow your company to have more control over the resources, be aware of wrong or unintentional changes on your resources and even unexpected actions. You can read more about this kind of event on the Azure Activity Log event schema. What's next? Now that you've enabled Logs, you can: Take a look at how the New Relic One ARM template and Azure function works in the newrelic-azure-functions repository. Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.94012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "sections": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " the Azure Resource Manager (ARM) template Login to <em>New</em> <em>Relic</em> <em>Logs</em> and click Add more data sources on the top right of the page. Under <em>Log</em> ingestion, click on the tile. Select the account you want to send the <em>logs</em> from the selector, and click Continue. Click Generate API Key and copy the generated"
      },
      "id": "6150545de7b9d2ae518de37f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/azure-log-forwarding": [
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 370.30054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-27T15:10:14Z",
      "updated_at": "2021-09-27T15:10:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 370.23087,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-27T15:49:32Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.05347,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/enable-log-management-new-relic": [
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.2961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-27T15:10:14Z",
      "updated_at": "2021-09-27T15:10:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.22717,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward logs and activity logs from Azure",
        "Requirements",
        "Use the Azure Resource Manager (ARM) template",
        "View log data",
        "Send logs from Azure resources",
        "Azure Activity Logs",
        "What's next?"
      ],
      "title": "Forward logs and activity logs from Azure",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "Azure",
        "Cloud logs"
      ],
      "external_id": "154d5c9a60899bf708548c0fec6a59c0836a9c74",
      "image": "https://docs.newrelic.com/static/da32e66650336026701ab338f5afbb60/5f1d2/azure-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/azure-log-forwarding/",
      "published_at": "2021-09-27T15:16:25Z",
      "updated_at": "2021-09-26T11:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Azure Resources Manager (ARM) template provided by New Relic One helps you: Set up Azure to forward logs from EventHub to New Relic One. Set up Azure Activity Logs forwarding to New Relic One through EventHub. The setup process is almost the same for both use cases, but take a look at step 9 if you want to forward Azure Activity Logs to New Relic. On the other hand, the template is idempotent. You can start forwarding logs from EventHub and then re-run the same template to configure Azure Activity Logs forwarding by completing step 9 listed below. Requirements A New Relic license key. Use the Azure Resource Manager (ARM) template Login to New Relic Logs and click Add more data sources on the top right of the page. Under Log ingestion, click on the tile. Select the account you want to send the logs from the selector, and click Continue. Click Generate API Key and copy the generated API Key. Click Deploy to Azure and a new tab will be open with the ARM template loaded in Azure. Select the Resource Group in which you want to create the necessary resources, and a Region. In the New Relic License Key field, paste the previously copied API Key. Ensure the New Relic One endpoint set is the one corresponding to your account. Optionally, set to true the Azure Activity Logs you want to forward from the following list: Administrative Azure Activity Logs Alert Azure Activity Logs Autoscale Azure Activity Logs Policy Azure Activity Logs Recommendation Azure Activity Logs Resource Health Azure Activity Logs Security Azure Activity Logs Service Health Azure Activity Logs Click Review + create, review the data you've inserted, and click Create. View log data Once logs are streaming you can view them using: New Relic Logs - Search for plugin.type:\"azure\" if you have more logs sources and want to check only the ones coming from Azure. New Relic tools for running NRQL queries. For example, you can run a query like: SELECT * FROM Log Copy If you want to only query for logs coming from Azure, run the following query: SELECT * FROM Log where plugin.type='azure' Copy Send logs from Azure resources By default, this template only configures the needed function and resources to forward logs to New Relic One. We can also configure the activity logs to be forwarded, but there isn't a default log forwarding from your Azure resources. If you want to forward logs from any resource that produces them, you need to configure it by creating a diagnostic setting for the given resource. As an example, if you have a function running on Azure and you want to forward the logs to New Relic One, you'll need to configure a diagnostic setting to forward the logs to the configure EventHub. Read how to create diagnostic settings to send platform logs and metrics to different destinations. Azure Activity Logs Activating the Azure Activity Logs forwarding is optional and it provides: More visibility of your Azure resources Activity of the Azure resources Information about performed actions Events and their timestamps The user who performed an action, if applicable These logs allow your company to have more control over the resources, be aware of wrong or unintentional changes on your resources and even unexpected actions. You can read more about this kind of event on the Azure Activity Log event schema. What's next? Now that you've enabled Logs, you can: Take a look at how the New Relic One ARM template and Azure function works in the newrelic-azure-functions repository. Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.93994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "sections": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " the Azure Resource Manager (ARM) template Login to <em>New</em> <em>Relic</em> <em>Logs</em> and click Add more data sources on the top right of the page. Under <em>Log</em> ingestion, click on the tile. Select the account you want to send the <em>logs</em> from the selector, and click Continue. Click Generate API Key and copy the generated"
      },
      "id": "6150545de7b9d2ae518de37f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/fluent-bit-plugin-log-forwarding": [
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.2961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-27T15:10:14Z",
      "updated_at": "2021-09-27T15:10:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.22717,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward logs and activity logs from Azure",
        "Requirements",
        "Use the Azure Resource Manager (ARM) template",
        "View log data",
        "Send logs from Azure resources",
        "Azure Activity Logs",
        "What's next?"
      ],
      "title": "Forward logs and activity logs from Azure",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "Azure",
        "Cloud logs"
      ],
      "external_id": "154d5c9a60899bf708548c0fec6a59c0836a9c74",
      "image": "https://docs.newrelic.com/static/da32e66650336026701ab338f5afbb60/5f1d2/azure-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/azure-log-forwarding/",
      "published_at": "2021-09-27T15:16:25Z",
      "updated_at": "2021-09-26T11:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Azure Resources Manager (ARM) template provided by New Relic One helps you: Set up Azure to forward logs from EventHub to New Relic One. Set up Azure Activity Logs forwarding to New Relic One through EventHub. The setup process is almost the same for both use cases, but take a look at step 9 if you want to forward Azure Activity Logs to New Relic. On the other hand, the template is idempotent. You can start forwarding logs from EventHub and then re-run the same template to configure Azure Activity Logs forwarding by completing step 9 listed below. Requirements A New Relic license key. Use the Azure Resource Manager (ARM) template Login to New Relic Logs and click Add more data sources on the top right of the page. Under Log ingestion, click on the tile. Select the account you want to send the logs from the selector, and click Continue. Click Generate API Key and copy the generated API Key. Click Deploy to Azure and a new tab will be open with the ARM template loaded in Azure. Select the Resource Group in which you want to create the necessary resources, and a Region. In the New Relic License Key field, paste the previously copied API Key. Ensure the New Relic One endpoint set is the one corresponding to your account. Optionally, set to true the Azure Activity Logs you want to forward from the following list: Administrative Azure Activity Logs Alert Azure Activity Logs Autoscale Azure Activity Logs Policy Azure Activity Logs Recommendation Azure Activity Logs Resource Health Azure Activity Logs Security Azure Activity Logs Service Health Azure Activity Logs Click Review + create, review the data you've inserted, and click Create. View log data Once logs are streaming you can view them using: New Relic Logs - Search for plugin.type:\"azure\" if you have more logs sources and want to check only the ones coming from Azure. New Relic tools for running NRQL queries. For example, you can run a query like: SELECT * FROM Log Copy If you want to only query for logs coming from Azure, run the following query: SELECT * FROM Log where plugin.type='azure' Copy Send logs from Azure resources By default, this template only configures the needed function and resources to forward logs to New Relic One. We can also configure the activity logs to be forwarded, but there isn't a default log forwarding from your Azure resources. If you want to forward logs from any resource that produces them, you need to configure it by creating a diagnostic setting for the given resource. As an example, if you have a function running on Azure and you want to forward the logs to New Relic One, you'll need to configure a diagnostic setting to forward the logs to the configure EventHub. Read how to create diagnostic settings to send platform logs and metrics to different destinations. Azure Activity Logs Activating the Azure Activity Logs forwarding is optional and it provides: More visibility of your Azure resources Activity of the Azure resources Information about performed actions Events and their timestamps The user who performed an action, if applicable These logs allow your company to have more control over the resources, be aware of wrong or unintentional changes on your resources and even unexpected actions. You can read more about this kind of event on the Azure Activity Log event schema. What's next? Now that you've enabled Logs, you can: Take a look at how the New Relic One ARM template and Azure function works in the newrelic-azure-functions repository. Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.93994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "sections": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " the Azure Resource Manager (ARM) template Login to <em>New</em> <em>Relic</em> <em>Logs</em> and click Add more data sources on the top right of the page. Under <em>Log</em> ingestion, click on the tile. Select the account you want to send the <em>logs</em> from the selector, and click Continue. Click Generate API Key and copy the generated"
      },
      "id": "6150545de7b9d2ae518de37f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/fluentd-plugin-log-forwarding": [
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.2959,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-27T15:10:14Z",
      "updated_at": "2021-09-27T15:10:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.22696,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward logs and activity logs from Azure",
        "Requirements",
        "Use the Azure Resource Manager (ARM) template",
        "View log data",
        "Send logs from Azure resources",
        "Azure Activity Logs",
        "What's next?"
      ],
      "title": "Forward logs and activity logs from Azure",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "Azure",
        "Cloud logs"
      ],
      "external_id": "154d5c9a60899bf708548c0fec6a59c0836a9c74",
      "image": "https://docs.newrelic.com/static/da32e66650336026701ab338f5afbb60/5f1d2/azure-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/azure-log-forwarding/",
      "published_at": "2021-09-27T15:16:25Z",
      "updated_at": "2021-09-26T11:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Azure Resources Manager (ARM) template provided by New Relic One helps you: Set up Azure to forward logs from EventHub to New Relic One. Set up Azure Activity Logs forwarding to New Relic One through EventHub. The setup process is almost the same for both use cases, but take a look at step 9 if you want to forward Azure Activity Logs to New Relic. On the other hand, the template is idempotent. You can start forwarding logs from EventHub and then re-run the same template to configure Azure Activity Logs forwarding by completing step 9 listed below. Requirements A New Relic license key. Use the Azure Resource Manager (ARM) template Login to New Relic Logs and click Add more data sources on the top right of the page. Under Log ingestion, click on the tile. Select the account you want to send the logs from the selector, and click Continue. Click Generate API Key and copy the generated API Key. Click Deploy to Azure and a new tab will be open with the ARM template loaded in Azure. Select the Resource Group in which you want to create the necessary resources, and a Region. In the New Relic License Key field, paste the previously copied API Key. Ensure the New Relic One endpoint set is the one corresponding to your account. Optionally, set to true the Azure Activity Logs you want to forward from the following list: Administrative Azure Activity Logs Alert Azure Activity Logs Autoscale Azure Activity Logs Policy Azure Activity Logs Recommendation Azure Activity Logs Resource Health Azure Activity Logs Security Azure Activity Logs Service Health Azure Activity Logs Click Review + create, review the data you've inserted, and click Create. View log data Once logs are streaming you can view them using: New Relic Logs - Search for plugin.type:\"azure\" if you have more logs sources and want to check only the ones coming from Azure. New Relic tools for running NRQL queries. For example, you can run a query like: SELECT * FROM Log Copy If you want to only query for logs coming from Azure, run the following query: SELECT * FROM Log where plugin.type='azure' Copy Send logs from Azure resources By default, this template only configures the needed function and resources to forward logs to New Relic One. We can also configure the activity logs to be forwarded, but there isn't a default log forwarding from your Azure resources. If you want to forward logs from any resource that produces them, you need to configure it by creating a diagnostic setting for the given resource. As an example, if you have a function running on Azure and you want to forward the logs to New Relic One, you'll need to configure a diagnostic setting to forward the logs to the configure EventHub. Read how to create diagnostic settings to send platform logs and metrics to different destinations. Azure Activity Logs Activating the Azure Activity Logs forwarding is optional and it provides: More visibility of your Azure resources Activity of the Azure resources Information about performed actions Events and their timestamps The user who performed an action, if applicable These logs allow your company to have more control over the resources, be aware of wrong or unintentional changes on your resources and even unexpected actions. You can read more about this kind of event on the Azure Activity Log event schema. What's next? Now that you've enabled Logs, you can: Take a look at how the New Relic One ARM template and Azure function works in the newrelic-azure-functions repository. Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.93973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "sections": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " the Azure Resource Manager (ARM) template Login to <em>New</em> <em>Relic</em> <em>Logs</em> and click Add more data sources on the top right of the page. Under <em>Log</em> ingestion, click on the tile. Select the account you want to send the <em>logs</em> from the selector, and click Continue. Click Generate API Key and copy the generated"
      },
      "id": "6150545de7b9d2ae518de37f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent": [
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.2959,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "Forward logs and activity logs from Azure",
        "Requirements",
        "Use the Azure Resource Manager (ARM) template",
        "View log data",
        "Send logs from Azure resources",
        "Azure Activity Logs",
        "What's next?"
      ],
      "title": "Forward logs and activity logs from Azure",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "Azure",
        "Cloud logs"
      ],
      "external_id": "154d5c9a60899bf708548c0fec6a59c0836a9c74",
      "image": "https://docs.newrelic.com/static/da32e66650336026701ab338f5afbb60/5f1d2/azure-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/azure-log-forwarding/",
      "published_at": "2021-09-27T15:16:25Z",
      "updated_at": "2021-09-26T11:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Azure Resources Manager (ARM) template provided by New Relic One helps you: Set up Azure to forward logs from EventHub to New Relic One. Set up Azure Activity Logs forwarding to New Relic One through EventHub. The setup process is almost the same for both use cases, but take a look at step 9 if you want to forward Azure Activity Logs to New Relic. On the other hand, the template is idempotent. You can start forwarding logs from EventHub and then re-run the same template to configure Azure Activity Logs forwarding by completing step 9 listed below. Requirements A New Relic license key. Use the Azure Resource Manager (ARM) template Login to New Relic Logs and click Add more data sources on the top right of the page. Under Log ingestion, click on the tile. Select the account you want to send the logs from the selector, and click Continue. Click Generate API Key and copy the generated API Key. Click Deploy to Azure and a new tab will be open with the ARM template loaded in Azure. Select the Resource Group in which you want to create the necessary resources, and a Region. In the New Relic License Key field, paste the previously copied API Key. Ensure the New Relic One endpoint set is the one corresponding to your account. Optionally, set to true the Azure Activity Logs you want to forward from the following list: Administrative Azure Activity Logs Alert Azure Activity Logs Autoscale Azure Activity Logs Policy Azure Activity Logs Recommendation Azure Activity Logs Resource Health Azure Activity Logs Security Azure Activity Logs Service Health Azure Activity Logs Click Review + create, review the data you've inserted, and click Create. View log data Once logs are streaming you can view them using: New Relic Logs - Search for plugin.type:\"azure\" if you have more logs sources and want to check only the ones coming from Azure. New Relic tools for running NRQL queries. For example, you can run a query like: SELECT * FROM Log Copy If you want to only query for logs coming from Azure, run the following query: SELECT * FROM Log where plugin.type='azure' Copy Send logs from Azure resources By default, this template only configures the needed function and resources to forward logs to New Relic One. We can also configure the activity logs to be forwarded, but there isn't a default log forwarding from your Azure resources. If you want to forward logs from any resource that produces them, you need to configure it by creating a diagnostic setting for the given resource. As an example, if you have a function running on Azure and you want to forward the logs to New Relic One, you'll need to configure a diagnostic setting to forward the logs to the configure EventHub. Read how to create diagnostic settings to send platform logs and metrics to different destinations. Azure Activity Logs Activating the Azure Activity Logs forwarding is optional and it provides: More visibility of your Azure resources Activity of the Azure resources Information about performed actions Events and their timestamps The user who performed an action, if applicable These logs allow your company to have more control over the resources, be aware of wrong or unintentional changes on your resources and even unexpected actions. You can read more about this kind of event on the Azure Activity Log event schema. What's next? Now that you've enabled Logs, you can: Take a look at how the New Relic One ARM template and Azure function works in the newrelic-azure-functions repository. Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.93973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "sections": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " the Azure Resource Manager (ARM) template Login to <em>New</em> <em>Relic</em> <em>Logs</em> and click Add more data sources on the top right of the page. Under <em>Log</em> ingestion, click on the tile. Select the account you want to send the <em>logs</em> from the selector, and click Continue. Click Generate API Key and copy the generated"
      },
      "id": "6150545de7b9d2ae518de37f"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-27T15:49:32Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 285.92767,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-27T15:10:14Z",
      "updated_at": "2021-09-27T15:10:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.22675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward logs and activity logs from Azure",
        "Requirements",
        "Use the Azure Resource Manager (ARM) template",
        "View log data",
        "Send logs from Azure resources",
        "Azure Activity Logs",
        "What's next?"
      ],
      "title": "Forward logs and activity logs from Azure",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "Azure",
        "Cloud logs"
      ],
      "external_id": "154d5c9a60899bf708548c0fec6a59c0836a9c74",
      "image": "https://docs.newrelic.com/static/da32e66650336026701ab338f5afbb60/5f1d2/azure-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/azure-log-forwarding/",
      "published_at": "2021-09-27T15:16:25Z",
      "updated_at": "2021-09-26T11:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Azure Resources Manager (ARM) template provided by New Relic One helps you: Set up Azure to forward logs from EventHub to New Relic One. Set up Azure Activity Logs forwarding to New Relic One through EventHub. The setup process is almost the same for both use cases, but take a look at step 9 if you want to forward Azure Activity Logs to New Relic. On the other hand, the template is idempotent. You can start forwarding logs from EventHub and then re-run the same template to configure Azure Activity Logs forwarding by completing step 9 listed below. Requirements A New Relic license key. Use the Azure Resource Manager (ARM) template Login to New Relic Logs and click Add more data sources on the top right of the page. Under Log ingestion, click on the tile. Select the account you want to send the logs from the selector, and click Continue. Click Generate API Key and copy the generated API Key. Click Deploy to Azure and a new tab will be open with the ARM template loaded in Azure. Select the Resource Group in which you want to create the necessary resources, and a Region. In the New Relic License Key field, paste the previously copied API Key. Ensure the New Relic One endpoint set is the one corresponding to your account. Optionally, set to true the Azure Activity Logs you want to forward from the following list: Administrative Azure Activity Logs Alert Azure Activity Logs Autoscale Azure Activity Logs Policy Azure Activity Logs Recommendation Azure Activity Logs Resource Health Azure Activity Logs Security Azure Activity Logs Service Health Azure Activity Logs Click Review + create, review the data you've inserted, and click Create. View log data Once logs are streaming you can view them using: New Relic Logs - Search for plugin.type:\"azure\" if you have more logs sources and want to check only the ones coming from Azure. New Relic tools for running NRQL queries. For example, you can run a query like: SELECT * FROM Log Copy If you want to only query for logs coming from Azure, run the following query: SELECT * FROM Log where plugin.type='azure' Copy Send logs from Azure resources By default, this template only configures the needed function and resources to forward logs to New Relic One. We can also configure the activity logs to be forwarded, but there isn't a default log forwarding from your Azure resources. If you want to forward logs from any resource that produces them, you need to configure it by creating a diagnostic setting for the given resource. As an example, if you have a function running on Azure and you want to forward the logs to New Relic One, you'll need to configure a diagnostic setting to forward the logs to the configure EventHub. Read how to create diagnostic settings to send platform logs and metrics to different destinations. Azure Activity Logs Activating the Azure Activity Logs forwarding is optional and it provides: More visibility of your Azure resources Activity of the Azure resources Information about performed actions Events and their timestamps The user who performed an action, if applicable These logs allow your company to have more control over the resources, be aware of wrong or unintentional changes on your resources and even unexpected actions. You can read more about this kind of event on the Azure Activity Log event schema. What's next? Now that you've enabled Logs, you can: Take a look at how the New Relic One ARM template and Azure function works in the newrelic-azure-functions repository. Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.93954,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "sections": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " the Azure Resource Manager (ARM) template Login to <em>New</em> <em>Relic</em> <em>Logs</em> and click Add more data sources on the top right of the page. Under <em>Log</em> ingestion, click on the tile. Select the account you want to send the <em>logs</em> from the selector, and click Continue. Click Generate API Key and copy the generated"
      },
      "id": "6150545de7b9d2ae518de37f"
    },
    {
      "sections": [
        "Stream logs using Kinesis Data Firehose",
        "Compatibility and requirements",
        "Create the delivery stream for New Relic",
        "Configure your stream to send logs to EU accounts",
        "View log data",
        "What's next?"
      ],
      "title": "Stream logs using Kinesis Data Firehose",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a7a552710c45f3a3dfec71b9fe0661c8db8ae014",
      "image": "https://docs.newrelic.com/static/ef38529dfbd5e54cbe001c347c5f528b/c1b63/3rd-party-firehose.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose/",
      "published_at": "2021-09-27T15:49:32Z",
      "updated_at": "2021-09-20T19:23:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your logs to New Relic using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to enable this integration. Compatibility and requirements To forward logs to New Relic using Kinesis Data Firehose, you need a New Relic license key. Create the delivery stream for New Relic When creating an Amazon Kinesis Data Firehose delivery stream, you can select New Relic as the destination: In the AWS Management Console, go to Amazon Kinesis. Select Kinesis Data Firehose and click Create delivery stream. Enter a name for the stream and select your data source. When selecting the destination, click Third-party partner and then New Relic. Under HTTP endpoint URL, select New Relic logs - US from the drop-down. Note: To send your logs to the EU, complete the remaining steps, then proceed to the send logs to EU accounts section. Paste your license key in the API key field. Configure and review the remaining settings. Configure your stream to send logs to EU accounts Complete the steps above to create your delivery stream. Once your stream has been created, navigate to the Kinesis Console and click Delivery streams. Click on the name of your newly created delivery stream, and select the Configuration tab. Click the Edit button next to the Destination settings section. Update the value for HTTP endpoint URL to our Firehose endpoint for EU accounts: https://aws-api.eu.newrelic.com/firehose/v1 Copy Click Save changes to ensure your stream is updated. Our EU endpoint will be selectable from the AWS Kinesis console soon. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 285.92758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>logs</em> using Kinesis Data Firehose",
        "sections": "Create the delivery stream for <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can send your <em>logs</em> to <em>New</em> <em>Relic</em> using Amazon Kinesis Data Firehose, a service which can stream data in real time to a variety of destinations, including our platform. Here we explain how to <em>enable</em> this integration. Compatibility and requirements To forward <em>logs</em> to <em>New</em> <em>Relic</em> using Kinesis Data"
      },
      "id": "603e96be64441f41584e8858"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/kubernetes-plugin-log-forwarding": [
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.29565,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-27T15:10:14Z",
      "updated_at": "2021-09-27T15:10:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.22675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward logs and activity logs from Azure",
        "Requirements",
        "Use the Azure Resource Manager (ARM) template",
        "View log data",
        "Send logs from Azure resources",
        "Azure Activity Logs",
        "What's next?"
      ],
      "title": "Forward logs and activity logs from Azure",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "Azure",
        "Cloud logs"
      ],
      "external_id": "154d5c9a60899bf708548c0fec6a59c0836a9c74",
      "image": "https://docs.newrelic.com/static/da32e66650336026701ab338f5afbb60/5f1d2/azure-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/azure-log-forwarding/",
      "published_at": "2021-09-27T15:16:25Z",
      "updated_at": "2021-09-26T11:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Azure Resources Manager (ARM) template provided by New Relic One helps you: Set up Azure to forward logs from EventHub to New Relic One. Set up Azure Activity Logs forwarding to New Relic One through EventHub. The setup process is almost the same for both use cases, but take a look at step 9 if you want to forward Azure Activity Logs to New Relic. On the other hand, the template is idempotent. You can start forwarding logs from EventHub and then re-run the same template to configure Azure Activity Logs forwarding by completing step 9 listed below. Requirements A New Relic license key. Use the Azure Resource Manager (ARM) template Login to New Relic Logs and click Add more data sources on the top right of the page. Under Log ingestion, click on the tile. Select the account you want to send the logs from the selector, and click Continue. Click Generate API Key and copy the generated API Key. Click Deploy to Azure and a new tab will be open with the ARM template loaded in Azure. Select the Resource Group in which you want to create the necessary resources, and a Region. In the New Relic License Key field, paste the previously copied API Key. Ensure the New Relic One endpoint set is the one corresponding to your account. Optionally, set to true the Azure Activity Logs you want to forward from the following list: Administrative Azure Activity Logs Alert Azure Activity Logs Autoscale Azure Activity Logs Policy Azure Activity Logs Recommendation Azure Activity Logs Resource Health Azure Activity Logs Security Azure Activity Logs Service Health Azure Activity Logs Click Review + create, review the data you've inserted, and click Create. View log data Once logs are streaming you can view them using: New Relic Logs - Search for plugin.type:\"azure\" if you have more logs sources and want to check only the ones coming from Azure. New Relic tools for running NRQL queries. For example, you can run a query like: SELECT * FROM Log Copy If you want to only query for logs coming from Azure, run the following query: SELECT * FROM Log where plugin.type='azure' Copy Send logs from Azure resources By default, this template only configures the needed function and resources to forward logs to New Relic One. We can also configure the activity logs to be forwarded, but there isn't a default log forwarding from your Azure resources. If you want to forward logs from any resource that produces them, you need to configure it by creating a diagnostic setting for the given resource. As an example, if you have a function running on Azure and you want to forward the logs to New Relic One, you'll need to configure a diagnostic setting to forward the logs to the configure EventHub. Read how to create diagnostic settings to send platform logs and metrics to different destinations. Azure Activity Logs Activating the Azure Activity Logs forwarding is optional and it provides: More visibility of your Azure resources Activity of the Azure resources Information about performed actions Events and their timestamps The user who performed an action, if applicable These logs allow your company to have more control over the resources, be aware of wrong or unintentional changes on your resources and even unexpected actions. You can read more about this kind of event on the Azure Activity Log event schema. What's next? Now that you've enabled Logs, you can: Take a look at how the New Relic One ARM template and Azure function works in the newrelic-azure-functions repository. Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.93954,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "sections": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " the Azure Resource Manager (ARM) template Login to <em>New</em> <em>Relic</em> <em>Logs</em> and click Add more data sources on the top right of the page. Under <em>Log</em> ingestion, click on the tile. Select the account you want to send the <em>logs</em> from the selector, and click Continue. Click Generate API Key and copy the generated"
      },
      "id": "6150545de7b9d2ae518de37f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding": [
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.29565,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-27T15:10:14Z",
      "updated_at": "2021-09-27T15:10:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.22675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward logs and activity logs from Azure",
        "Requirements",
        "Use the Azure Resource Manager (ARM) template",
        "View log data",
        "Send logs from Azure resources",
        "Azure Activity Logs",
        "What's next?"
      ],
      "title": "Forward logs and activity logs from Azure",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "Azure",
        "Cloud logs"
      ],
      "external_id": "154d5c9a60899bf708548c0fec6a59c0836a9c74",
      "image": "https://docs.newrelic.com/static/da32e66650336026701ab338f5afbb60/5f1d2/azure-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/azure-log-forwarding/",
      "published_at": "2021-09-27T15:16:25Z",
      "updated_at": "2021-09-26T11:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Azure Resources Manager (ARM) template provided by New Relic One helps you: Set up Azure to forward logs from EventHub to New Relic One. Set up Azure Activity Logs forwarding to New Relic One through EventHub. The setup process is almost the same for both use cases, but take a look at step 9 if you want to forward Azure Activity Logs to New Relic. On the other hand, the template is idempotent. You can start forwarding logs from EventHub and then re-run the same template to configure Azure Activity Logs forwarding by completing step 9 listed below. Requirements A New Relic license key. Use the Azure Resource Manager (ARM) template Login to New Relic Logs and click Add more data sources on the top right of the page. Under Log ingestion, click on the tile. Select the account you want to send the logs from the selector, and click Continue. Click Generate API Key and copy the generated API Key. Click Deploy to Azure and a new tab will be open with the ARM template loaded in Azure. Select the Resource Group in which you want to create the necessary resources, and a Region. In the New Relic License Key field, paste the previously copied API Key. Ensure the New Relic One endpoint set is the one corresponding to your account. Optionally, set to true the Azure Activity Logs you want to forward from the following list: Administrative Azure Activity Logs Alert Azure Activity Logs Autoscale Azure Activity Logs Policy Azure Activity Logs Recommendation Azure Activity Logs Resource Health Azure Activity Logs Security Azure Activity Logs Service Health Azure Activity Logs Click Review + create, review the data you've inserted, and click Create. View log data Once logs are streaming you can view them using: New Relic Logs - Search for plugin.type:\"azure\" if you have more logs sources and want to check only the ones coming from Azure. New Relic tools for running NRQL queries. For example, you can run a query like: SELECT * FROM Log Copy If you want to only query for logs coming from Azure, run the following query: SELECT * FROM Log where plugin.type='azure' Copy Send logs from Azure resources By default, this template only configures the needed function and resources to forward logs to New Relic One. We can also configure the activity logs to be forwarded, but there isn't a default log forwarding from your Azure resources. If you want to forward logs from any resource that produces them, you need to configure it by creating a diagnostic setting for the given resource. As an example, if you have a function running on Azure and you want to forward the logs to New Relic One, you'll need to configure a diagnostic setting to forward the logs to the configure EventHub. Read how to create diagnostic settings to send platform logs and metrics to different destinations. Azure Activity Logs Activating the Azure Activity Logs forwarding is optional and it provides: More visibility of your Azure resources Activity of the Azure resources Information about performed actions Events and their timestamps The user who performed an action, if applicable These logs allow your company to have more control over the resources, be aware of wrong or unintentional changes on your resources and even unexpected actions. You can read more about this kind of event on the Azure Activity Log event schema. What's next? Now that you've enabled Logs, you can: Take a look at how the New Relic One ARM template and Azure function works in the newrelic-azure-functions repository. Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.93954,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "sections": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " the Azure Resource Manager (ARM) template Login to <em>New</em> <em>Relic</em> <em>Logs</em> and click Add more data sources on the top right of the page. Under <em>Log</em> ingestion, click on the tile. Select the account you want to send the <em>logs</em> from the selector, and click Continue. Click Generate API Key and copy the generated"
      },
      "id": "6150545de7b9d2ae518de37f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose": [
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.2954,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-27T15:10:14Z",
      "updated_at": "2021-09-27T15:10:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.2265,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward logs and activity logs from Azure",
        "Requirements",
        "Use the Azure Resource Manager (ARM) template",
        "View log data",
        "Send logs from Azure resources",
        "Azure Activity Logs",
        "What's next?"
      ],
      "title": "Forward logs and activity logs from Azure",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "Azure",
        "Cloud logs"
      ],
      "external_id": "154d5c9a60899bf708548c0fec6a59c0836a9c74",
      "image": "https://docs.newrelic.com/static/da32e66650336026701ab338f5afbb60/5f1d2/azure-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/azure-log-forwarding/",
      "published_at": "2021-09-27T15:16:25Z",
      "updated_at": "2021-09-26T11:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Azure Resources Manager (ARM) template provided by New Relic One helps you: Set up Azure to forward logs from EventHub to New Relic One. Set up Azure Activity Logs forwarding to New Relic One through EventHub. The setup process is almost the same for both use cases, but take a look at step 9 if you want to forward Azure Activity Logs to New Relic. On the other hand, the template is idempotent. You can start forwarding logs from EventHub and then re-run the same template to configure Azure Activity Logs forwarding by completing step 9 listed below. Requirements A New Relic license key. Use the Azure Resource Manager (ARM) template Login to New Relic Logs and click Add more data sources on the top right of the page. Under Log ingestion, click on the tile. Select the account you want to send the logs from the selector, and click Continue. Click Generate API Key and copy the generated API Key. Click Deploy to Azure and a new tab will be open with the ARM template loaded in Azure. Select the Resource Group in which you want to create the necessary resources, and a Region. In the New Relic License Key field, paste the previously copied API Key. Ensure the New Relic One endpoint set is the one corresponding to your account. Optionally, set to true the Azure Activity Logs you want to forward from the following list: Administrative Azure Activity Logs Alert Azure Activity Logs Autoscale Azure Activity Logs Policy Azure Activity Logs Recommendation Azure Activity Logs Resource Health Azure Activity Logs Security Azure Activity Logs Service Health Azure Activity Logs Click Review + create, review the data you've inserted, and click Create. View log data Once logs are streaming you can view them using: New Relic Logs - Search for plugin.type:\"azure\" if you have more logs sources and want to check only the ones coming from Azure. New Relic tools for running NRQL queries. For example, you can run a query like: SELECT * FROM Log Copy If you want to only query for logs coming from Azure, run the following query: SELECT * FROM Log where plugin.type='azure' Copy Send logs from Azure resources By default, this template only configures the needed function and resources to forward logs to New Relic One. We can also configure the activity logs to be forwarded, but there isn't a default log forwarding from your Azure resources. If you want to forward logs from any resource that produces them, you need to configure it by creating a diagnostic setting for the given resource. As an example, if you have a function running on Azure and you want to forward the logs to New Relic One, you'll need to configure a diagnostic setting to forward the logs to the configure EventHub. Read how to create diagnostic settings to send platform logs and metrics to different destinations. Azure Activity Logs Activating the Azure Activity Logs forwarding is optional and it provides: More visibility of your Azure resources Activity of the Azure resources Information about performed actions Events and their timestamps The user who performed an action, if applicable These logs allow your company to have more control over the resources, be aware of wrong or unintentional changes on your resources and even unexpected actions. You can read more about this kind of event on the Azure Activity Log event schema. What's next? Now that you've enabled Logs, you can: Take a look at how the New Relic One ARM template and Azure function works in the newrelic-azure-functions repository. Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.93936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "sections": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " the Azure Resource Manager (ARM) template Login to <em>New</em> <em>Relic</em> <em>Logs</em> and click Add more data sources on the top right of the page. Under <em>Log</em> ingestion, click on the tile. Select the account you want to send the <em>logs</em> from the selector, and click Continue. Click Generate API Key and copy the generated"
      },
      "id": "6150545de7b9d2ae518de37f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding": [
    {
      "sections": [
        "Stream Logs from Heroku",
        "Requirements",
        "Important",
        "Create a Heroku Syslog drain",
        "Register a Heroku Syslog drain",
        "View log data",
        "What's next?"
      ],
      "title": "Stream Logs from Heroku",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "f039eeeca1321a36ca291d262ce0a97401039313",
      "image": "https://docs.newrelic.com/static/d6e93beb130138749c5299a6bc2149bc/d38a6/heroku-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding/",
      "published_at": "2021-09-27T15:15:12Z",
      "updated_at": "2021-09-27T15:15:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can stream your Heroku logs to New Relic using Heroku's built-in Logplex router. In this page, we explain how to stream logs to New Relic using Heroku Syslog drains. Requirements Important Currently, our Heroku Syslog endpoint only supports accounts in our US data center. Ensure the following before configuring log forwarding from Heroku: Your New Relic user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream logs from, replacing YOUR_APP_NAME with the name of your Heroku application. $ heroku drains:add syslog+tls://newrelic.syslog.nr-data.net:6515 -a YOUR_APP_NAME Copy Run the following command and copy the Heroku Syslog drain token from the token attribute: $ heroku drains -a YOUR_APP_NAME--json Copy { \"addon\": null, \"created_at\": \"2018-12-04T00:59:46Z\", \"id\": \"906262a4-e151-45d2-b35a-a2dc0ea9e688\", \"token\": \"d.f14da5dc-106b-468d-b1bd-bed0ed9fa1e7\", \"updated_at\": \"2018-12-04T00:59:47Z\", \"url\": \"syslog+tls://newrelic.syslog.nr-data.net:6515 } Copy Register a Heroku Syslog drain Next, you'll need to register your newly created Heroku Syslog drain in New Relic: Login to New Relic Logs and click Add more data sources. Click the Heroku tile under Log ingestion. Choose the New Relic account to stream your Heroku application logs to and click Continue. Paste your newly created Heroku drain token in the Heroku drain token field. Click Add Heroku drain log to complete registration. Important Heroku doesn't currently support customizing the format of logs sent from Logplex. For more information, check Heroku's documentation on their log format. View log data Once logs are streaming you can view them using: New Relic Logs New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.29517,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Stream <em>Logs</em> from Heroku",
        "sections": "Stream <em>Logs</em> from Heroku",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " before configuring <em>log</em> forwarding from Heroku: Your <em>New</em> <em>Relic</em> user account has the Admin role assigned to it. Create a Heroku Syslog drain Download and install the Heroku CLI. Use the Heroku CLI to create a Syslog drain and attach it to the application you want to stream <em>logs</em> from, replacing"
      },
      "id": "60506f58196a677d432d1622"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-09-27T15:10:14Z",
      "updated_at": "2021-09-27T15:10:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: If you haven't already, create a New Relic account. It's free, forever. Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarder in the infrastructure agent for arm architecture, meanwhile check this post with the steps you can follow. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding Important Fluent Bit's tail plugin does not support network drives. If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.22626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. <em>Enable</em> <em>log</em> forwarding using the infrastructure agent"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward logs and activity logs from Azure",
        "Requirements",
        "Use the Azure Resource Manager (ARM) template",
        "View log data",
        "Send logs from Azure resources",
        "Azure Activity Logs",
        "What's next?"
      ],
      "title": "Forward logs and activity logs from Azure",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "Azure",
        "Cloud logs"
      ],
      "external_id": "154d5c9a60899bf708548c0fec6a59c0836a9c74",
      "image": "https://docs.newrelic.com/static/da32e66650336026701ab338f5afbb60/5f1d2/azure-tile.png",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/azure-log-forwarding/",
      "published_at": "2021-09-27T15:16:25Z",
      "updated_at": "2021-09-26T11:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Azure Resources Manager (ARM) template provided by New Relic One helps you: Set up Azure to forward logs from EventHub to New Relic One. Set up Azure Activity Logs forwarding to New Relic One through EventHub. The setup process is almost the same for both use cases, but take a look at step 9 if you want to forward Azure Activity Logs to New Relic. On the other hand, the template is idempotent. You can start forwarding logs from EventHub and then re-run the same template to configure Azure Activity Logs forwarding by completing step 9 listed below. Requirements A New Relic license key. Use the Azure Resource Manager (ARM) template Login to New Relic Logs and click Add more data sources on the top right of the page. Under Log ingestion, click on the tile. Select the account you want to send the logs from the selector, and click Continue. Click Generate API Key and copy the generated API Key. Click Deploy to Azure and a new tab will be open with the ARM template loaded in Azure. Select the Resource Group in which you want to create the necessary resources, and a Region. In the New Relic License Key field, paste the previously copied API Key. Ensure the New Relic One endpoint set is the one corresponding to your account. Optionally, set to true the Azure Activity Logs you want to forward from the following list: Administrative Azure Activity Logs Alert Azure Activity Logs Autoscale Azure Activity Logs Policy Azure Activity Logs Recommendation Azure Activity Logs Resource Health Azure Activity Logs Security Azure Activity Logs Service Health Azure Activity Logs Click Review + create, review the data you've inserted, and click Create. View log data Once logs are streaming you can view them using: New Relic Logs - Search for plugin.type:\"azure\" if you have more logs sources and want to check only the ones coming from Azure. New Relic tools for running NRQL queries. For example, you can run a query like: SELECT * FROM Log Copy If you want to only query for logs coming from Azure, run the following query: SELECT * FROM Log where plugin.type='azure' Copy Send logs from Azure resources By default, this template only configures the needed function and resources to forward logs to New Relic One. We can also configure the activity logs to be forwarded, but there isn't a default log forwarding from your Azure resources. If you want to forward logs from any resource that produces them, you need to configure it by creating a diagnostic setting for the given resource. As an example, if you have a function running on Azure and you want to forward the logs to New Relic One, you'll need to configure a diagnostic setting to forward the logs to the configure EventHub. Read how to create diagnostic settings to send platform logs and metrics to different destinations. Azure Activity Logs Activating the Azure Activity Logs forwarding is optional and it provides: More visibility of your Azure resources Activity of the Azure resources Information about performed actions Events and their timestamps The user who performed an action, if applicable These logs allow your company to have more control over the resources, be aware of wrong or unintentional changes on your resources and even unexpected actions. You can read more about this kind of event on the Azure Activity Log event schema. What's next? Now that you've enabled Logs, you can: Take a look at how the New Relic One ARM template and Azure function works in the newrelic-azure-functions repository. Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.93915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "sections": "Forward <em>logs</em> and activity <em>logs</em> from Azure",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " the Azure Resource Manager (ARM) template Login to <em>New</em> <em>Relic</em> <em>Logs</em> and click Add more data sources on the top right of the page. Under <em>Log</em> ingestion, click on the tile. Select the account you want to send the <em>logs</em> from the selector, and click Continue. Click Generate API Key and copy the generated"
      },
      "id": "6150545de7b9d2ae518de37f"
    }
  ],
  "/docs/logs/index": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 85.39317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Logs</em>",
        "body": "<em>Log</em> patterns are the fastest way to discover value in <em>log</em> data without searching. <em>Log</em> data is high volume telemetry with a low value per individual record. Searching can quickly lead to <em>logs</em> that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 85.33899,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logstash</em> example",
        "tags": "<em>Logs</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> data into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> UI, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-09-27T15:34:21Z",
      "updated_at": "2021-09-26T02:25:03Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.16373,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Logs</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    }
  ],
  "/docs/logs/log-management/get-started/get-started-log-management": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.94292,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " limits on memory and CPU resources when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you <em>get</em>. For more information, see our documentation about parsing limits. <em>Get</em> <em>started</em> To <em>start</em> examining patterns: Go to one.newrelic.com &gt; <em>Logs</em>, and use the account picker"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-09-27T15:34:21Z",
      "updated_at": "2021-09-26T02:25:03Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.6156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.8981,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logstash</em> example",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common <em>log</em> formats have well-established parsing rules already created for them. To <em>get</em> the benefit of built-in parsing rules, add the logtype attribute when forwarding <em>logs</em>"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/get-started/new-relics-log-management-security-privacy": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.94278,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " limits on memory and CPU resources when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you <em>get</em>. For more information, see our documentation about parsing limits. <em>Get</em> <em>started</em> To <em>start</em> examining patterns: Go to one.newrelic.com &gt; <em>Logs</em>, and use the account picker"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-09-27T15:34:21Z",
      "updated_at": "2021-09-26T02:25:03Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.61551,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.89798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logstash</em> example",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common <em>log</em> formats have well-established parsing rules already created for them. To <em>get</em> the benefit of built-in parsing rules, add the logtype attribute when forwarding <em>logs</em>"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/log-api/introduction-log-api": [
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.40314,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logs</em> <em>API</em> example",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " more about using the <em>Logs</em> <em>API</em>. POST &#x2F;<em>log</em>&#x2F;v1 HTTP&#x2F;1.1 Host: <em>log</em>-<em>api</em>.newrelic.com Content-Type: application&#x2F;json X-License-Key: YOUR_LICENSE_KEY Accept: *&#x2F;* Content-Length: 133 { &quot;timestamp&quot;: TIMESTAMP_IN_UNIX_EPOCH, &quot;message&quot;: &quot;User &#x27;xyz&#x27; logged in&quot;, &quot;logtype&quot;: &quot;accesslogs&quot;, &quot;service&quot;: &quot;login-service"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Use APM agent APIs with logs in context",
        "APM agent trace metadata and linking metadata APIs",
        "Resources for correctly annotating logs"
      ],
      "title": "Use APM agent APIs with logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context with agent APIs"
      ],
      "external_id": "6dc4fff9bde0b7d49285cb8a7f16ba1dfc91f939",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/annotate-logs-logs-context-using-apm-agent-apis/",
      "published_at": "2021-09-27T15:21:48Z",
      "updated_at": "2021-09-26T11:16:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To correlate log data with other telemetry data, such as errors and distributed traces in APM, you can use our logs in context solutions. If your logging framework is not available with our existing logs in context solutions, you can configure your logging libraries by using API calls to annotate your logs. APM agent trace metadata and linking metadata APIs To get properly annotated logs for logs in context, use the following API calls for your APM agent. These APIs pass the required trace metadata and linking metadata to link your log data to other New Relic data. APM agent APIs: APM agent API calls C SDK (n/a) See our Log API documentation. Go GetTraceMetadata GetLinkingMetadata Java getTraceMetadata getLinkingMetadata .NET TraceMetadata GetLinkingMetadata Node.js newrelic.getTraceMetadata newrelic.getLinkingMetadata PHP newrelic_get_trace_metadata newrelic_get_linking_metadata Python get_linking_metadata Ruby linking_metadata current_trace_id current_span_id Resources for correctly annotating logs For more information about using the trace metadata and linking metadata APIs to annotate logs for logs in context, review the APM agent specifications in GitHub. These specifications include the required fields and properly formatted output. Also, review the source code for our own logs in context extensions to see how we use these APIs: C SDK: n/a Go: Logrus extension Java: Log4j2 extension .NET: Serilog extension Node.js: Winston extension Python: Streamhandler example PHP: Monolog extension Ruby: logging.rb extension",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.02338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use APM agent <em>APIs</em> with <em>logs</em> in context",
        "sections": "Use APM agent <em>APIs</em> with <em>logs</em> in context",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": "To correlate <em>log</em> data with other telemetry data, such as errors and distributed traces in APM, you can use our <em>logs</em> in context solutions. If your logging framework is not available with our existing <em>logs</em> in context solutions, you can configure your logging libraries by using <em>API</em> calls to annotate"
      },
      "id": "61505693196a670394b70d61"
    },
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-09-27T15:34:21Z",
      "updated_at": "2021-09-26T02:25:03Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.23251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    }
  ],
  "/docs/logs/log-management/log-api/log-event-data": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.1796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> <em>data</em> with patterns",
        "sections": "Discover value in <em>log</em> <em>data</em> with patterns",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " off in your <em>Log</em> <em>management</em> Patterns <em>UI</em>, click the Configure Patterns button and enable it. If you don&#x27;t see patterns within 30 minutes of enabling the feature, there may be a lack of <em>data</em> with a message attribute for the system to create a pattern from it. <em>Log</em> patterns Limitations"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.9663,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Find data in long logs (blobs)",
        "How blobs work",
        "Tip",
        "Query your data for blobs",
        "Data retention for long logs"
      ],
      "title": "Find data in long logs (blobs)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "0f8c586e5227c95813221647e6a9c2e01c7044a5",
      "image": "https://docs.newrelic.com/static/25249afab9ba5695a0764e676d14dfb3/c1b63/log-blob-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/long-logs-blobs/",
      "published_at": "2021-09-27T15:26:43Z",
      "updated_at": "2021-09-26T11:16:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Extensive log data can help you troubleshoot issues. But what if an attribute in your log contains thousands of characters? How much of this data can New Relic store? And how can you find useful information in all this data? How blobs work For long string value that are longer than can be stored in NRDB (4,094 characters), we split the storage of the long string into three pieces: The first 4,094 characters are stored in Log event field with the same name So a long message value would have its first 4,094 characters stored in a message field. The next 128,000 UTF-8 bytes of the string are stored in a \"blob\" field with the name with newrelic.ext. prepended So a long message value would have characters past the first 4,094 characters stored in a newrelic.ext.message field as a \"blob\" The actual number of characters stored depends on the UTF-8 representation of the characters. UTF-8 represents Unicode characters as one to four bytes, so we will store anywhere between 32,000 and 128,000 characters past the first 4,094 characters. Any characters past 4,094 characters plus 128,000 bytes are dropped and not stored. So the long message field would be stored as: message: <first 4,094 characters as a string> newrelic.ext.message: <next 128,000 bytes as a 'blob'> Copy Tip You can search the first 4,094 characters of a string attribute. You can also create alerts for the first 4,094 characters. However, since 'blob' storage is not searchable, text beyond the first 4,094 characters is not searchable or alertable. Query your data for blobs To query for any log data in New Relic, run the following query: SELECT * FROM Log Copy To expand the blob data, run the following query, using message or any other attribute. Be sure to enclose the blob's attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM Log Copy To query extended blob data in your logs, be sure to include backticks in your attribute's blob syntax. This expands the data in the blob so you can see (but not search) it. For example, New Relic returns: { \"message\": <first 4,094 characters> \"newrelic.ext.message\": <the next 128,000 bytes as Base64> \"another-attribute\": <first 4,094 characters> \"newrelic.ext.another-attribute\": <the next 128,000 bytes as Base64> } Copy The Logs UI automatically stitches the original value back together when looking at the Log Detail View. When querying using NRQL directly, you need to manually stitch the information together by Decoding the Base64 of the newrelic.ext. attribute value Converting the resulting UTF-8 into a string Appending that string to the first 4,094 characters in the \"main\" attribute Data retention for long logs NRDB retains your blob records for a month. If you have existing long log messages stored as LogExtendedRecord, that data will also continue to be available for a month in NRDB. After a month passes, no more new LogExtendedRecord attributes will be created. They will all be stored in NRDB as blobs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.8667,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "sections": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ": SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM <em>Log</em> Copy To query extended blob <em>data</em> in your <em>logs</em>, be sure to include backticks in your attribute&#x27;s blob syntax. This expands the <em>data</em> in the blob so you can see (but not search) it. For example"
      },
      "id": "6150569228ccbcf314f21423"
    }
  ],
  "/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic": [
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.40298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logs</em> <em>API</em> example",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " more about using the <em>Logs</em> <em>API</em>. POST &#x2F;<em>log</em>&#x2F;v1 HTTP&#x2F;1.1 Host: <em>log</em>-<em>api</em>.newrelic.com Content-Type: application&#x2F;json X-License-Key: YOUR_LICENSE_KEY Accept: *&#x2F;* Content-Length: 133 { &quot;timestamp&quot;: TIMESTAMP_IN_UNIX_EPOCH, &quot;message&quot;: &quot;User &#x27;xyz&#x27; logged in&quot;, &quot;logtype&quot;: &quot;accesslogs&quot;, &quot;service&quot;: &quot;login-service"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Use APM agent APIs with logs in context",
        "APM agent trace metadata and linking metadata APIs",
        "Resources for correctly annotating logs"
      ],
      "title": "Use APM agent APIs with logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context with agent APIs"
      ],
      "external_id": "6dc4fff9bde0b7d49285cb8a7f16ba1dfc91f939",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/annotate-logs-logs-context-using-apm-agent-apis/",
      "published_at": "2021-09-27T15:21:48Z",
      "updated_at": "2021-09-26T11:16:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To correlate log data with other telemetry data, such as errors and distributed traces in APM, you can use our logs in context solutions. If your logging framework is not available with our existing logs in context solutions, you can configure your logging libraries by using API calls to annotate your logs. APM agent trace metadata and linking metadata APIs To get properly annotated logs for logs in context, use the following API calls for your APM agent. These APIs pass the required trace metadata and linking metadata to link your log data to other New Relic data. APM agent APIs: APM agent API calls C SDK (n/a) See our Log API documentation. Go GetTraceMetadata GetLinkingMetadata Java getTraceMetadata getLinkingMetadata .NET TraceMetadata GetLinkingMetadata Node.js newrelic.getTraceMetadata newrelic.getLinkingMetadata PHP newrelic_get_trace_metadata newrelic_get_linking_metadata Python get_linking_metadata Ruby linking_metadata current_trace_id current_span_id Resources for correctly annotating logs For more information about using the trace metadata and linking metadata APIs to annotate logs for logs in context, review the APM agent specifications in GitHub. These specifications include the required fields and properly formatted output. Also, review the source code for our own logs in context extensions to see how we use these APIs: C SDK: n/a Go: Logrus extension Java: Log4j2 extension .NET: Serilog extension Node.js: Winston extension Python: Streamhandler example PHP: Monolog extension Ruby: logging.rb extension",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.02328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use APM agent <em>APIs</em> with <em>logs</em> in context",
        "sections": "Use APM agent <em>APIs</em> with <em>logs</em> in context",
        "tags": "Enable <em>log</em> <em>management</em> in New Relic",
        "body": "To correlate <em>log</em> data with other telemetry data, such as errors and distributed traces in APM, you can use our <em>logs</em> in context solutions. If your logging framework is not available with our existing <em>logs</em> in context solutions, you can configure your logging libraries by using <em>API</em> calls to annotate"
      },
      "id": "61505693196a670394b70d61"
    },
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-09-27T15:34:21Z",
      "updated_at": "2021-09-26T02:25:03Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.23242,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    }
  ],
  "/docs/logs/log-management/troubleshooting/find-issues-cause-or-impact-surrounding-logs": [
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-09-27T15:34:21Z",
      "updated_at": "2021-09-26T02:25:03Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.80304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    },
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.48474,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ", the <em>log</em> patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. <em>Troubleshoot</em> <em>log</em> messages that haven&#x27;t been clustered into a pattern Use the <em>Logs</em> with no pattern tab in the <em>Log</em>"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.95477,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logstash</em> example",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> data into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> UI, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/troubleshooting/json-message-not-parsed": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.48474,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ", the <em>log</em> patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. <em>Troubleshoot</em> <em>log</em> messages that haven&#x27;t been clustered into a pattern Use the <em>Logs</em> with no pattern tab in the <em>Log</em>"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.95477,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logstash</em> example",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> data into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> UI, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Log event data",
        "Data storage",
        "Restrictions"
      ],
      "title": "Log event data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "bb497c607e526a0880c748715bdf4d0f7b82ba35",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/log-event-data/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-26T11:16:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log events are records stored like any other event sent to New Relic. At a minimum the record should include: timestamp: an integer representing Unix epoch milliseconds At least one attribute containing data, like a message field Typically logs have a message field and level or severity, but we do not have fixed requirements for what you can send to New Relic. Data storage Log records are stored by default in the Log event type. You can create additional event types by defining a custom data partition in Logs. The resulting types will always be prefaced with Log_. For detailed information, see our data partitions documentation. Attributes: Maximum attributes: 255 Name: maximum 255 characters Searchable value: The first 4,094 characters of data stored in an attribute can be queried directly in the UI. Additional storage: Any attribute with more than 4,094 characters will have up to 128KB of data stored in a \"blob\" in the New Relic backend. Blob storage is not searchable, but you can access data stored in blobs in the New Relic One UI. Data beyond 128KB will be truncated. Restrictions Some specific attributes have additional restrictions: Attribute Restrictions accountId This is a reserved attribute name. If it is included, it will be dropped during ingest. eventType This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid entity.name entity.type These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information, see our documentation about entity synthesis. timestamp This value must be an integer representing milliseconds since Unix epoch (seconds since epoch is also supported). Payloads with timestamps older than 48 hours may be dropped.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.76103,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Log</em> event data",
        "sections": "<em>Log</em> event data",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "<em>Log</em> events are records stored like any other event sent to New Relic. At a minimum the record should include: timestamp: an integer representing Unix epoch milliseconds At least one attribute containing data, like a message field Typically <em>logs</em> have a message field and level or severity, but we do"
      },
      "id": "61505692196a6706bbb70d49"
    }
  ],
  "/docs/logs/log-management/troubleshooting/log-message-truncated": [
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-09-27T15:34:21Z",
      "updated_at": "2021-09-26T02:25:03Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.80292,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    },
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.48462,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ", the <em>log</em> patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. <em>Troubleshoot</em> <em>log</em> messages that haven&#x27;t been clustered into a pattern Use the <em>Logs</em> with no pattern tab in the <em>Log</em>"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.95465,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logstash</em> example",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> data into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> UI, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/troubleshooting/no-log-data-appears-ui": [
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-09-27T15:34:21Z",
      "updated_at": "2021-09-26T02:25:03Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.80292,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    },
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.48462,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ", the <em>log</em> patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. <em>Troubleshoot</em> <em>log</em> messages that haven&#x27;t been clustered into a pattern Use the <em>Logs</em> with no pattern tab in the <em>Log</em>"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.95465,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logstash</em> example",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> data into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> UI, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/troubleshooting/view-log-messages-real-time-live-tail": [
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-09-27T15:34:21Z",
      "updated_at": "2021-09-26T02:25:03Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.8028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key-value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    },
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.48447,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ", the <em>log</em> patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. <em>Troubleshoot</em> <em>log</em> messages that haven&#x27;t been clustered into a pattern Use the <em>Logs</em> with no pattern tab in the <em>Log</em>"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.9545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logstash</em> example",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> data into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> UI, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/ui-data/built-log-parsing-rulesets": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.17896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> <em>data</em> with patterns",
        "sections": "Discover value in <em>log</em> <em>data</em> with patterns",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " off in your <em>Log</em> <em>management</em> Patterns <em>UI</em>, click the Configure Patterns button and enable it. If you don&#x27;t see patterns within 30 minutes of enabling the feature, there may be a lack of <em>data</em> with a message attribute for the system to create a pattern from it. <em>Log</em> patterns Limitations"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.96564,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Find data in long logs (blobs)",
        "How blobs work",
        "Tip",
        "Query your data for blobs",
        "Data retention for long logs"
      ],
      "title": "Find data in long logs (blobs)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "0f8c586e5227c95813221647e6a9c2e01c7044a5",
      "image": "https://docs.newrelic.com/static/25249afab9ba5695a0764e676d14dfb3/c1b63/log-blob-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/long-logs-blobs/",
      "published_at": "2021-09-27T15:26:43Z",
      "updated_at": "2021-09-26T11:16:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Extensive log data can help you troubleshoot issues. But what if an attribute in your log contains thousands of characters? How much of this data can New Relic store? And how can you find useful information in all this data? How blobs work For long string value that are longer than can be stored in NRDB (4,094 characters), we split the storage of the long string into three pieces: The first 4,094 characters are stored in Log event field with the same name So a long message value would have its first 4,094 characters stored in a message field. The next 128,000 UTF-8 bytes of the string are stored in a \"blob\" field with the name with newrelic.ext. prepended So a long message value would have characters past the first 4,094 characters stored in a newrelic.ext.message field as a \"blob\" The actual number of characters stored depends on the UTF-8 representation of the characters. UTF-8 represents Unicode characters as one to four bytes, so we will store anywhere between 32,000 and 128,000 characters past the first 4,094 characters. Any characters past 4,094 characters plus 128,000 bytes are dropped and not stored. So the long message field would be stored as: message: <first 4,094 characters as a string> newrelic.ext.message: <next 128,000 bytes as a 'blob'> Copy Tip You can search the first 4,094 characters of a string attribute. You can also create alerts for the first 4,094 characters. However, since 'blob' storage is not searchable, text beyond the first 4,094 characters is not searchable or alertable. Query your data for blobs To query for any log data in New Relic, run the following query: SELECT * FROM Log Copy To expand the blob data, run the following query, using message or any other attribute. Be sure to enclose the blob's attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM Log Copy To query extended blob data in your logs, be sure to include backticks in your attribute's blob syntax. This expands the data in the blob so you can see (but not search) it. For example, New Relic returns: { \"message\": <first 4,094 characters> \"newrelic.ext.message\": <the next 128,000 bytes as Base64> \"another-attribute\": <first 4,094 characters> \"newrelic.ext.another-attribute\": <the next 128,000 bytes as Base64> } Copy The Logs UI automatically stitches the original value back together when looking at the Log Detail View. When querying using NRQL directly, you need to manually stitch the information together by Decoding the Base64 of the newrelic.ext. attribute value Converting the resulting UTF-8 into a string Appending that string to the first 4,094 characters in the \"main\" attribute Data retention for long logs NRDB retains your blob records for a month. If you have existing long log messages stored as LogExtendedRecord, that data will also continue to be available for a month in NRDB. After a month passes, no more new LogExtendedRecord attributes will be created. They will all be stored in NRDB as blobs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.8662,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "sections": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ": SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM <em>Log</em> Copy To query extended blob <em>data</em> in your <em>logs</em>, be sure to include backticks in your attribute&#x27;s blob syntax. This expands the <em>data</em> in the blob so you can see (but not search) it. For example"
      },
      "id": "6150569228ccbcf314f21423"
    }
  ],
  "/docs/logs/log-management/ui-data/data-partitions": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.17874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> <em>data</em> with patterns",
        "sections": "Discover value in <em>log</em> <em>data</em> with patterns",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " off in your <em>Log</em> <em>management</em> Patterns <em>UI</em>, click the Configure Patterns button and enable it. If you don&#x27;t see patterns within 30 minutes of enabling the feature, there may be a lack of <em>data</em> with a message attribute for the system to create a pattern from it. <em>Log</em> patterns Limitations"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.96545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Find data in long logs (blobs)",
        "How blobs work",
        "Tip",
        "Query your data for blobs",
        "Data retention for long logs"
      ],
      "title": "Find data in long logs (blobs)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "0f8c586e5227c95813221647e6a9c2e01c7044a5",
      "image": "https://docs.newrelic.com/static/25249afab9ba5695a0764e676d14dfb3/c1b63/log-blob-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/long-logs-blobs/",
      "published_at": "2021-09-27T15:26:43Z",
      "updated_at": "2021-09-26T11:16:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Extensive log data can help you troubleshoot issues. But what if an attribute in your log contains thousands of characters? How much of this data can New Relic store? And how can you find useful information in all this data? How blobs work For long string value that are longer than can be stored in NRDB (4,094 characters), we split the storage of the long string into three pieces: The first 4,094 characters are stored in Log event field with the same name So a long message value would have its first 4,094 characters stored in a message field. The next 128,000 UTF-8 bytes of the string are stored in a \"blob\" field with the name with newrelic.ext. prepended So a long message value would have characters past the first 4,094 characters stored in a newrelic.ext.message field as a \"blob\" The actual number of characters stored depends on the UTF-8 representation of the characters. UTF-8 represents Unicode characters as one to four bytes, so we will store anywhere between 32,000 and 128,000 characters past the first 4,094 characters. Any characters past 4,094 characters plus 128,000 bytes are dropped and not stored. So the long message field would be stored as: message: <first 4,094 characters as a string> newrelic.ext.message: <next 128,000 bytes as a 'blob'> Copy Tip You can search the first 4,094 characters of a string attribute. You can also create alerts for the first 4,094 characters. However, since 'blob' storage is not searchable, text beyond the first 4,094 characters is not searchable or alertable. Query your data for blobs To query for any log data in New Relic, run the following query: SELECT * FROM Log Copy To expand the blob data, run the following query, using message or any other attribute. Be sure to enclose the blob's attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM Log Copy To query extended blob data in your logs, be sure to include backticks in your attribute's blob syntax. This expands the data in the blob so you can see (but not search) it. For example, New Relic returns: { \"message\": <first 4,094 characters> \"newrelic.ext.message\": <the next 128,000 bytes as Base64> \"another-attribute\": <first 4,094 characters> \"newrelic.ext.another-attribute\": <the next 128,000 bytes as Base64> } Copy The Logs UI automatically stitches the original value back together when looking at the Log Detail View. When querying using NRQL directly, you need to manually stitch the information together by Decoding the Base64 of the newrelic.ext. attribute value Converting the resulting UTF-8 into a string Appending that string to the first 4,094 characters in the \"main\" attribute Data retention for long logs NRDB retains your blob records for a month. If you have existing long log messages stored as LogExtendedRecord, that data will also continue to be available for a month in NRDB. After a month passes, no more new LogExtendedRecord attributes will be created. They will all be stored in NRDB as blobs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.86603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "sections": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ": SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM <em>Log</em> Copy To query extended blob <em>data</em> in your <em>logs</em>, be sure to include backticks in your attribute&#x27;s blob syntax. This expands the <em>data</em> in the blob so you can see (but not search) it. For example"
      },
      "id": "6150569228ccbcf314f21423"
    }
  ],
  "/docs/logs/log-management/ui-data/drop-data-drop-filter-rules": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.17874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> <em>data</em> with patterns",
        "sections": "Discover value in <em>log</em> <em>data</em> with patterns",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " off in your <em>Log</em> <em>management</em> Patterns <em>UI</em>, click the Configure Patterns button and enable it. If you don&#x27;t see patterns within 30 minutes of enabling the feature, there may be a lack of <em>data</em> with a message attribute for the system to create a pattern from it. <em>Log</em> patterns Limitations"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.96545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Find data in long logs (blobs)",
        "How blobs work",
        "Tip",
        "Query your data for blobs",
        "Data retention for long logs"
      ],
      "title": "Find data in long logs (blobs)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "0f8c586e5227c95813221647e6a9c2e01c7044a5",
      "image": "https://docs.newrelic.com/static/25249afab9ba5695a0764e676d14dfb3/c1b63/log-blob-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/long-logs-blobs/",
      "published_at": "2021-09-27T15:26:43Z",
      "updated_at": "2021-09-26T11:16:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Extensive log data can help you troubleshoot issues. But what if an attribute in your log contains thousands of characters? How much of this data can New Relic store? And how can you find useful information in all this data? How blobs work For long string value that are longer than can be stored in NRDB (4,094 characters), we split the storage of the long string into three pieces: The first 4,094 characters are stored in Log event field with the same name So a long message value would have its first 4,094 characters stored in a message field. The next 128,000 UTF-8 bytes of the string are stored in a \"blob\" field with the name with newrelic.ext. prepended So a long message value would have characters past the first 4,094 characters stored in a newrelic.ext.message field as a \"blob\" The actual number of characters stored depends on the UTF-8 representation of the characters. UTF-8 represents Unicode characters as one to four bytes, so we will store anywhere between 32,000 and 128,000 characters past the first 4,094 characters. Any characters past 4,094 characters plus 128,000 bytes are dropped and not stored. So the long message field would be stored as: message: <first 4,094 characters as a string> newrelic.ext.message: <next 128,000 bytes as a 'blob'> Copy Tip You can search the first 4,094 characters of a string attribute. You can also create alerts for the first 4,094 characters. However, since 'blob' storage is not searchable, text beyond the first 4,094 characters is not searchable or alertable. Query your data for blobs To query for any log data in New Relic, run the following query: SELECT * FROM Log Copy To expand the blob data, run the following query, using message or any other attribute. Be sure to enclose the blob's attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM Log Copy To query extended blob data in your logs, be sure to include backticks in your attribute's blob syntax. This expands the data in the blob so you can see (but not search) it. For example, New Relic returns: { \"message\": <first 4,094 characters> \"newrelic.ext.message\": <the next 128,000 bytes as Base64> \"another-attribute\": <first 4,094 characters> \"newrelic.ext.another-attribute\": <the next 128,000 bytes as Base64> } Copy The Logs UI automatically stitches the original value back together when looking at the Log Detail View. When querying using NRQL directly, you need to manually stitch the information together by Decoding the Base64 of the newrelic.ext. attribute value Converting the resulting UTF-8 into a string Appending that string to the first 4,094 characters in the \"main\" attribute Data retention for long logs NRDB retains your blob records for a month. If you have existing long log messages stored as LogExtendedRecord, that data will also continue to be available for a month in NRDB. After a month passes, no more new LogExtendedRecord attributes will be created. They will all be stored in NRDB as blobs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.86603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "sections": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ": SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM <em>Log</em> Copy To query extended blob <em>data</em> in your <em>logs</em>, be sure to include backticks in your attribute&#x27;s blob syntax. This expands the <em>data</em> in the blob so you can see (but not search) it. For example"
      },
      "id": "6150569228ccbcf314f21423"
    }
  ],
  "/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns": [
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.9652,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Find data in long logs (blobs)",
        "How blobs work",
        "Tip",
        "Query your data for blobs",
        "Data retention for long logs"
      ],
      "title": "Find data in long logs (blobs)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "0f8c586e5227c95813221647e6a9c2e01c7044a5",
      "image": "https://docs.newrelic.com/static/25249afab9ba5695a0764e676d14dfb3/c1b63/log-blob-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/long-logs-blobs/",
      "published_at": "2021-09-27T15:26:43Z",
      "updated_at": "2021-09-26T11:16:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Extensive log data can help you troubleshoot issues. But what if an attribute in your log contains thousands of characters? How much of this data can New Relic store? And how can you find useful information in all this data? How blobs work For long string value that are longer than can be stored in NRDB (4,094 characters), we split the storage of the long string into three pieces: The first 4,094 characters are stored in Log event field with the same name So a long message value would have its first 4,094 characters stored in a message field. The next 128,000 UTF-8 bytes of the string are stored in a \"blob\" field with the name with newrelic.ext. prepended So a long message value would have characters past the first 4,094 characters stored in a newrelic.ext.message field as a \"blob\" The actual number of characters stored depends on the UTF-8 representation of the characters. UTF-8 represents Unicode characters as one to four bytes, so we will store anywhere between 32,000 and 128,000 characters past the first 4,094 characters. Any characters past 4,094 characters plus 128,000 bytes are dropped and not stored. So the long message field would be stored as: message: <first 4,094 characters as a string> newrelic.ext.message: <next 128,000 bytes as a 'blob'> Copy Tip You can search the first 4,094 characters of a string attribute. You can also create alerts for the first 4,094 characters. However, since 'blob' storage is not searchable, text beyond the first 4,094 characters is not searchable or alertable. Query your data for blobs To query for any log data in New Relic, run the following query: SELECT * FROM Log Copy To expand the blob data, run the following query, using message or any other attribute. Be sure to enclose the blob's attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM Log Copy To query extended blob data in your logs, be sure to include backticks in your attribute's blob syntax. This expands the data in the blob so you can see (but not search) it. For example, New Relic returns: { \"message\": <first 4,094 characters> \"newrelic.ext.message\": <the next 128,000 bytes as Base64> \"another-attribute\": <first 4,094 characters> \"newrelic.ext.another-attribute\": <the next 128,000 bytes as Base64> } Copy The Logs UI automatically stitches the original value back together when looking at the Log Detail View. When querying using NRQL directly, you need to manually stitch the information together by Decoding the Base64 of the newrelic.ext. attribute value Converting the resulting UTF-8 into a string Appending that string to the first 4,094 characters in the \"main\" attribute Data retention for long logs NRDB retains your blob records for a month. If you have existing long log messages stored as LogExtendedRecord, that data will also continue to be available for a month in NRDB. After a month passes, no more new LogExtendedRecord attributes will be created. They will all be stored in NRDB as blobs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.86588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "sections": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ": SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM <em>Log</em> Copy To query extended blob <em>data</em> in your <em>logs</em>, be sure to include backticks in your attribute&#x27;s blob syntax. This expands the <em>data</em> in the blob so you can see (but not search) it. For example"
      },
      "id": "6150569228ccbcf314f21423"
    },
    {
      "sections": [
        "Log event data",
        "Data storage",
        "Restrictions"
      ],
      "title": "Log event data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "bb497c607e526a0880c748715bdf4d0f7b82ba35",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/log-event-data/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-26T11:16:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log events are records stored like any other event sent to New Relic. At a minimum the record should include: timestamp: an integer representing Unix epoch milliseconds At least one attribute containing data, like a message field Typically logs have a message field and level or severity, but we do not have fixed requirements for what you can send to New Relic. Data storage Log records are stored by default in the Log event type. You can create additional event types by defining a custom data partition in Logs. The resulting types will always be prefaced with Log_. For detailed information, see our data partitions documentation. Attributes: Maximum attributes: 255 Name: maximum 255 characters Searchable value: The first 4,094 characters of data stored in an attribute can be queried directly in the UI. Additional storage: Any attribute with more than 4,094 characters will have up to 128KB of data stored in a \"blob\" in the New Relic backend. Blob storage is not searchable, but you can access data stored in blobs in the New Relic One UI. Data beyond 128KB will be truncated. Restrictions Some specific attributes have additional restrictions: Attribute Restrictions accountId This is a reserved attribute name. If it is included, it will be dropped during ingest. eventType This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid entity.name entity.type These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information, see our documentation about entity synthesis. timestamp This value must be an integer representing milliseconds since Unix epoch (seconds since epoch is also supported). Payloads with timestamps older than 48 hours may be dropped.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.86588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Log</em> event <em>data</em>",
        "sections": "<em>Log</em> event <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "<em>Log</em> events are records stored like any other event sent to New Relic. At a minimum the record should include: timestamp: an integer representing Unix epoch milliseconds At least one attribute containing <em>data</em>, like a message field Typically <em>logs</em> have a message field and level or severity, but we do"
      },
      "id": "61505692196a6706bbb70d49"
    }
  ],
  "/docs/logs/log-management/ui-data/long-logs-blobs": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.17853,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> <em>data</em> with patterns",
        "sections": "Discover value in <em>log</em> <em>data</em> with patterns",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " off in your <em>Log</em> <em>management</em> Patterns <em>UI</em>, click the Configure Patterns button and enable it. If you don&#x27;t see patterns within 30 minutes of enabling the feature, there may be a lack of <em>data</em> with a message attribute for the system to create a pattern from it. <em>Log</em> patterns Limitations"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.9652,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Log event data",
        "Data storage",
        "Restrictions"
      ],
      "title": "Log event data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "bb497c607e526a0880c748715bdf4d0f7b82ba35",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/log-event-data/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-26T11:16:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log events are records stored like any other event sent to New Relic. At a minimum the record should include: timestamp: an integer representing Unix epoch milliseconds At least one attribute containing data, like a message field Typically logs have a message field and level or severity, but we do not have fixed requirements for what you can send to New Relic. Data storage Log records are stored by default in the Log event type. You can create additional event types by defining a custom data partition in Logs. The resulting types will always be prefaced with Log_. For detailed information, see our data partitions documentation. Attributes: Maximum attributes: 255 Name: maximum 255 characters Searchable value: The first 4,094 characters of data stored in an attribute can be queried directly in the UI. Additional storage: Any attribute with more than 4,094 characters will have up to 128KB of data stored in a \"blob\" in the New Relic backend. Blob storage is not searchable, but you can access data stored in blobs in the New Relic One UI. Data beyond 128KB will be truncated. Restrictions Some specific attributes have additional restrictions: Attribute Restrictions accountId This is a reserved attribute name. If it is included, it will be dropped during ingest. eventType This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid entity.name entity.type These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information, see our documentation about entity synthesis. timestamp This value must be an integer representing milliseconds since Unix epoch (seconds since epoch is also supported). Payloads with timestamps older than 48 hours may be dropped.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.86588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Log</em> event <em>data</em>",
        "sections": "<em>Log</em> event <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "<em>Log</em> events are records stored like any other event sent to New Relic. At a minimum the record should include: timestamp: an integer representing Unix epoch milliseconds At least one attribute containing <em>data</em>, like a message field Typically <em>logs</em> have a message field and level or severity, but we do"
      },
      "id": "61505692196a6706bbb70d49"
    }
  ],
  "/docs/logs/log-management/ui-data/parsing": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.1783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> <em>data</em> with patterns",
        "sections": "Discover value in <em>log</em> <em>data</em> with patterns",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " off in your <em>Log</em> <em>management</em> Patterns <em>UI</em>, click the Configure Patterns button and enable it. If you don&#x27;t see patterns within 30 minutes of enabling the feature, there may be a lack of <em>data</em> with a message attribute for the system to create a pattern from it. <em>Log</em> patterns Limitations"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Find data in long logs (blobs)",
        "How blobs work",
        "Tip",
        "Query your data for blobs",
        "Data retention for long logs"
      ],
      "title": "Find data in long logs (blobs)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "0f8c586e5227c95813221647e6a9c2e01c7044a5",
      "image": "https://docs.newrelic.com/static/25249afab9ba5695a0764e676d14dfb3/c1b63/log-blob-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/long-logs-blobs/",
      "published_at": "2021-09-27T15:26:43Z",
      "updated_at": "2021-09-26T11:16:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Extensive log data can help you troubleshoot issues. But what if an attribute in your log contains thousands of characters? How much of this data can New Relic store? And how can you find useful information in all this data? How blobs work For long string value that are longer than can be stored in NRDB (4,094 characters), we split the storage of the long string into three pieces: The first 4,094 characters are stored in Log event field with the same name So a long message value would have its first 4,094 characters stored in a message field. The next 128,000 UTF-8 bytes of the string are stored in a \"blob\" field with the name with newrelic.ext. prepended So a long message value would have characters past the first 4,094 characters stored in a newrelic.ext.message field as a \"blob\" The actual number of characters stored depends on the UTF-8 representation of the characters. UTF-8 represents Unicode characters as one to four bytes, so we will store anywhere between 32,000 and 128,000 characters past the first 4,094 characters. Any characters past 4,094 characters plus 128,000 bytes are dropped and not stored. So the long message field would be stored as: message: <first 4,094 characters as a string> newrelic.ext.message: <next 128,000 bytes as a 'blob'> Copy Tip You can search the first 4,094 characters of a string attribute. You can also create alerts for the first 4,094 characters. However, since 'blob' storage is not searchable, text beyond the first 4,094 characters is not searchable or alertable. Query your data for blobs To query for any log data in New Relic, run the following query: SELECT * FROM Log Copy To expand the blob data, run the following query, using message or any other attribute. Be sure to enclose the blob's attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM Log Copy To query extended blob data in your logs, be sure to include backticks in your attribute's blob syntax. This expands the data in the blob so you can see (but not search) it. For example, New Relic returns: { \"message\": <first 4,094 characters> \"newrelic.ext.message\": <the next 128,000 bytes as Base64> \"another-attribute\": <first 4,094 characters> \"newrelic.ext.another-attribute\": <the next 128,000 bytes as Base64> } Copy The Logs UI automatically stitches the original value back together when looking at the Log Detail View. When querying using NRQL directly, you need to manually stitch the information together by Decoding the Base64 of the newrelic.ext. attribute value Converting the resulting UTF-8 into a string Appending that string to the first 4,094 characters in the \"main\" attribute Data retention for long logs NRDB retains your blob records for a month. If you have existing long log messages stored as LogExtendedRecord, that data will also continue to be available for a month in NRDB. After a month passes, no more new LogExtendedRecord attributes will be created. They will all be stored in NRDB as blobs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.86572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "sections": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ": SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM <em>Log</em> Copy To query extended blob <em>data</em> in your <em>logs</em>, be sure to include backticks in your attribute&#x27;s blob syntax. This expands the <em>data</em> in the blob so you can see (but not search) it. For example"
      },
      "id": "6150569228ccbcf314f21423"
    },
    {
      "sections": [
        "Log event data",
        "Data storage",
        "Restrictions"
      ],
      "title": "Log event data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "bb497c607e526a0880c748715bdf4d0f7b82ba35",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/log-event-data/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-26T11:16:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log events are records stored like any other event sent to New Relic. At a minimum the record should include: timestamp: an integer representing Unix epoch milliseconds At least one attribute containing data, like a message field Typically logs have a message field and level or severity, but we do not have fixed requirements for what you can send to New Relic. Data storage Log records are stored by default in the Log event type. You can create additional event types by defining a custom data partition in Logs. The resulting types will always be prefaced with Log_. For detailed information, see our data partitions documentation. Attributes: Maximum attributes: 255 Name: maximum 255 characters Searchable value: The first 4,094 characters of data stored in an attribute can be queried directly in the UI. Additional storage: Any attribute with more than 4,094 characters will have up to 128KB of data stored in a \"blob\" in the New Relic backend. Blob storage is not searchable, but you can access data stored in blobs in the New Relic One UI. Data beyond 128KB will be truncated. Restrictions Some specific attributes have additional restrictions: Attribute Restrictions accountId This is a reserved attribute name. If it is included, it will be dropped during ingest. eventType This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid entity.name entity.type These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information, see our documentation about entity synthesis. timestamp This value must be an integer representing milliseconds since Unix epoch (seconds since epoch is also supported). Payloads with timestamps older than 48 hours may be dropped.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.86572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Log</em> event <em>data</em>",
        "sections": "<em>Log</em> event <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "<em>Log</em> events are records stored like any other event sent to New Relic. At a minimum the record should include: timestamp: an integer representing Unix epoch milliseconds At least one attribute containing <em>data</em>, like a message field Typically <em>logs</em> have a message field and level or severity, but we do"
      },
      "id": "61505692196a6706bbb70d49"
    }
  ],
  "/docs/logs/log-management/ui-data/query-syntax-logs": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.1783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> <em>data</em> with patterns",
        "sections": "Discover value in <em>log</em> <em>data</em> with patterns",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " off in your <em>Log</em> <em>management</em> Patterns <em>UI</em>, click the Configure Patterns button and enable it. If you don&#x27;t see patterns within 30 minutes of enabling the feature, there may be a lack of <em>data</em> with a message attribute for the system to create a pattern from it. <em>Log</em> patterns Limitations"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.96503,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Find data in long logs (blobs)",
        "How blobs work",
        "Tip",
        "Query your data for blobs",
        "Data retention for long logs"
      ],
      "title": "Find data in long logs (blobs)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "0f8c586e5227c95813221647e6a9c2e01c7044a5",
      "image": "https://docs.newrelic.com/static/25249afab9ba5695a0764e676d14dfb3/c1b63/log-blob-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/long-logs-blobs/",
      "published_at": "2021-09-27T15:26:43Z",
      "updated_at": "2021-09-26T11:16:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Extensive log data can help you troubleshoot issues. But what if an attribute in your log contains thousands of characters? How much of this data can New Relic store? And how can you find useful information in all this data? How blobs work For long string value that are longer than can be stored in NRDB (4,094 characters), we split the storage of the long string into three pieces: The first 4,094 characters are stored in Log event field with the same name So a long message value would have its first 4,094 characters stored in a message field. The next 128,000 UTF-8 bytes of the string are stored in a \"blob\" field with the name with newrelic.ext. prepended So a long message value would have characters past the first 4,094 characters stored in a newrelic.ext.message field as a \"blob\" The actual number of characters stored depends on the UTF-8 representation of the characters. UTF-8 represents Unicode characters as one to four bytes, so we will store anywhere between 32,000 and 128,000 characters past the first 4,094 characters. Any characters past 4,094 characters plus 128,000 bytes are dropped and not stored. So the long message field would be stored as: message: <first 4,094 characters as a string> newrelic.ext.message: <next 128,000 bytes as a 'blob'> Copy Tip You can search the first 4,094 characters of a string attribute. You can also create alerts for the first 4,094 characters. However, since 'blob' storage is not searchable, text beyond the first 4,094 characters is not searchable or alertable. Query your data for blobs To query for any log data in New Relic, run the following query: SELECT * FROM Log Copy To expand the blob data, run the following query, using message or any other attribute. Be sure to enclose the blob's attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM Log Copy To query extended blob data in your logs, be sure to include backticks in your attribute's blob syntax. This expands the data in the blob so you can see (but not search) it. For example, New Relic returns: { \"message\": <first 4,094 characters> \"newrelic.ext.message\": <the next 128,000 bytes as Base64> \"another-attribute\": <first 4,094 characters> \"newrelic.ext.another-attribute\": <the next 128,000 bytes as Base64> } Copy The Logs UI automatically stitches the original value back together when looking at the Log Detail View. When querying using NRQL directly, you need to manually stitch the information together by Decoding the Base64 of the newrelic.ext. attribute value Converting the resulting UTF-8 into a string Appending that string to the first 4,094 characters in the \"main\" attribute Data retention for long logs NRDB retains your blob records for a month. If you have existing long log messages stored as LogExtendedRecord, that data will also continue to be available for a month in NRDB. After a month passes, no more new LogExtendedRecord attributes will be created. They will all be stored in NRDB as blobs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.86572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "sections": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ": SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM <em>Log</em> Copy To query extended blob <em>data</em> in your <em>logs</em>, be sure to include backticks in your attribute&#x27;s blob syntax. This expands the <em>data</em> in the blob so you can see (but not search) it. For example"
      },
      "id": "6150569228ccbcf314f21423"
    }
  ],
  "/docs/logs/log-management/ui-data/use-logs-ui": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-09-27T15:28:12Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.1781,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> <em>data</em> with patterns",
        "sections": "Discover value in <em>log</em> <em>data</em> with patterns",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " off in your <em>Log</em> <em>management</em> Patterns <em>UI</em>, click the Configure Patterns button and enable it. If you don&#x27;t see patterns within 30 minutes of enabling the feature, there may be a lack of <em>data</em> with a message attribute for the system to create a pattern from it. <em>Log</em> patterns Limitations"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rulesets",
        "List of built-in rulesets",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-09-27T15:11:31Z",
      "updated_at": "2021-09-27T15:11:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attribute/value pairs. You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. New Relic parses log data according to rules. Learn how logs parsing works, how to use built-in rules, and how to create custom rules. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in ruleset to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rulesets Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rulesets The following logtype attribute values map to a standard parsing rulesets. See Built-in parsing rules to learn what fields are parsed for each rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 335.96478,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attribute&#x2F;value pairs. You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. From the left nav in the <em>Logs</em> <em>UI</em>, select Parsing, then create your own custom parsing"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Find data in long logs (blobs)",
        "How blobs work",
        "Tip",
        "Query your data for blobs",
        "Data retention for long logs"
      ],
      "title": "Find data in long logs (blobs)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "0f8c586e5227c95813221647e6a9c2e01c7044a5",
      "image": "https://docs.newrelic.com/static/25249afab9ba5695a0764e676d14dfb3/c1b63/log-blob-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/long-logs-blobs/",
      "published_at": "2021-09-27T15:26:43Z",
      "updated_at": "2021-09-26T11:16:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Extensive log data can help you troubleshoot issues. But what if an attribute in your log contains thousands of characters? How much of this data can New Relic store? And how can you find useful information in all this data? How blobs work For long string value that are longer than can be stored in NRDB (4,094 characters), we split the storage of the long string into three pieces: The first 4,094 characters are stored in Log event field with the same name So a long message value would have its first 4,094 characters stored in a message field. The next 128,000 UTF-8 bytes of the string are stored in a \"blob\" field with the name with newrelic.ext. prepended So a long message value would have characters past the first 4,094 characters stored in a newrelic.ext.message field as a \"blob\" The actual number of characters stored depends on the UTF-8 representation of the characters. UTF-8 represents Unicode characters as one to four bytes, so we will store anywhere between 32,000 and 128,000 characters past the first 4,094 characters. Any characters past 4,094 characters plus 128,000 bytes are dropped and not stored. So the long message field would be stored as: message: <first 4,094 characters as a string> newrelic.ext.message: <next 128,000 bytes as a 'blob'> Copy Tip You can search the first 4,094 characters of a string attribute. You can also create alerts for the first 4,094 characters. However, since 'blob' storage is not searchable, text beyond the first 4,094 characters is not searchable or alertable. Query your data for blobs To query for any log data in New Relic, run the following query: SELECT * FROM Log Copy To expand the blob data, run the following query, using message or any other attribute. Be sure to enclose the blob's attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM Log Copy To query extended blob data in your logs, be sure to include backticks in your attribute's blob syntax. This expands the data in the blob so you can see (but not search) it. For example, New Relic returns: { \"message\": <first 4,094 characters> \"newrelic.ext.message\": <the next 128,000 bytes as Base64> \"another-attribute\": <first 4,094 characters> \"newrelic.ext.another-attribute\": <the next 128,000 bytes as Base64> } Copy The Logs UI automatically stitches the original value back together when looking at the Log Detail View. When querying using NRQL directly, you need to manually stitch the information together by Decoding the Base64 of the newrelic.ext. attribute value Converting the resulting UTF-8 into a string Appending that string to the first 4,094 characters in the \"main\" attribute Data retention for long logs NRDB retains your blob records for a month. If you have existing long log messages stored as LogExtendedRecord, that data will also continue to be available for a month in NRDB. After a month passes, no more new LogExtendedRecord attributes will be created. They will all be stored in NRDB as blobs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.86554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "sections": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ": SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM <em>Log</em> Copy To query extended blob <em>data</em> in your <em>logs</em>, be sure to include backticks in your attribute&#x27;s blob syntax. This expands the <em>data</em> in the blob so you can see (but not search) it. For example"
      },
      "id": "6150569228ccbcf314f21423"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/android-app/android-app-ui": [
    {
      "sections": [
        "Introduction to New Relic Android app",
        "Requirements",
        "Install New Relic's mobile app",
        "View New Relic data",
        "New Relic product details",
        "Synthetics data",
        "Alerts",
        "Mobile app monitoring",
        "Details on setting time range",
        "Data privacy"
      ],
      "title": "Introduction to New Relic Android app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "ff8415c00363a49eaa062f4b0b13c795b4717ea5",
      "image": "https://docs.newrelic.com/static/ea914fce17844b32fdabefd60efc457e/e5166/navigation_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app/",
      "published_at": "2021-09-26T18:35:20Z",
      "updated_at": "2021-09-14T07:28:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's Android app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install New Relic's mobile app You can install the New Relic Android app from the Google Play Store or learn more from the New Relic website. Follow standard procedures to install any Android app, then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or user authentication steps may be required. View New Relic data To view details of your apps monitored by New Relic, select a product from the app's main menu. See below for details on how to use specific features of the app: New Relic product details The New Relic Android app includes data about these features: APM metrics, both real-time and historical data, including health maps. Select the transaction icon to see detailed transaction metrics, or an Overview chart to view summary charts of your top five transactions. Select the icon to filter by labels and categories. Browser monitoring metrics, including average page load time, Apdex, average throughput, and more. Infrastructure monitoring. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Synthetics data You can use the Android app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. To view more detailed charts, select the caret icon. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen. To view them, tap the alert event. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile app monitoring If you have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Details on setting time range When viewing an application or host, you can change the visible time frame with the time picker. To move back and forth across the timeline, scrub the New Relic charts. To change the duration of the visible time slice, select the clock icon. To specify an end time other than now, slide the toggle from Ending Now to Custom Date. To save your changes and refresh the chart data, select the clock icon again. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.44962,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em> <em>Android</em> <em>app</em>",
        "sections": "Install <em>New</em> <em>Relic&#x27;s</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s <em>Android</em> <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. Requirements Requirements include: <em>Android</em> 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install <em>New</em> <em>Relic</em>&#x27;s <em>mobile</em>"
      },
      "id": "604415e0196a67ff23960f46"
    },
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-09-29T01:39:46Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.1422,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "sections": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s iPhone and iPad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> iOS <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s iOS <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-09-26T22:37:56Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.10027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for authentication. <em>Android</em> <em>app</em> users will also see a notification message. Important The authentication email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app": [
    {
      "sections": [
        "Android app UI",
        "Pages",
        "Time range",
        "New Relic Synthetics",
        "Alerts",
        "Mobile apps",
        "For more help"
      ],
      "title": "Android app UI",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "8918a5a2454491a91421c55e26501a0e3f64cd3a",
      "image": "https://docs.newrelic.com/static/fc97ade0bbdbdef58b89495a0d91b734/edd00/deployment-markers_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/android-app-ui/",
      "published_at": "2021-09-29T01:40:58Z",
      "updated_at": "2021-09-14T07:28:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The UI for the New Relic Android app provides functionality similar to the standard user interface, with customized details for mobile users. Pages To view details of your New Relic apps, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The New Relic Android app includes: APM metrics, both real-time and historical data, including health maps. And, select the transaction icon for detailed transaction metrics, or an Overview Charts to view summary charts of your top five transactions. New Relic Infrastructure utilization. New Relic Plugins, including a list of their components or instances, and their charts and current values from the plugin's Summary. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Select the filter icon to filter by labels and categories. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. Note: New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the time picker icon in the top right of the page (the 7D in the screenshot). This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth in the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). New Relic Synthetics You can use the Android app to view your New Relic Synthetics data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen and can be viewed by tapping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile apps If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. For more help Additional documentation resources include: New Relic Android app (compatibility, requirements, installation) Android authentication (procedures to add or remove users, and for the users to authenticate with their Android device)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.52542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Android</em> <em>app</em> UI",
        "sections": "<em>Mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The UI for the <em>New</em> <em>Relic</em> <em>Android</em> <em>app</em> provides functionality similar to the standard user interface, with customized details for <em>mobile</em> users. Pages To view details of your <em>New</em> <em>Relic</em> <em>apps</em>, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The <em>New</em>"
      },
      "id": "6044181d28ccbc9a522c60a5"
    },
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-09-29T01:39:46Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.14217,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "sections": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s iPhone and iPad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> iOS <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s iOS <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-09-26T22:37:56Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.10027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for authentication. <em>Android</em> <em>app</em> users will also see a notification message. Important The authentication email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps": [
    {
      "sections": [
        "User settings and authentication",
        "User authentication",
        "User settings",
        "Sign in with additional username",
        "Switch between accounts",
        "Remove or re-add a user name"
      ],
      "title": "User settings and authentication",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "0b40ac4c2e769279d25d0ebb2ea77cebda8d8ea7",
      "image": "https://docs.newrelic.com/static/88ff328efc4a127601923bc728fea229/8c557/device-ipad-switch-user.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/user-settings-authentication/",
      "published_at": "2021-09-26T18:36:19Z",
      "updated_at": "2021-05-16T06:27:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This explains how to authenticate your New Relic mobile app account, and how to add users to or remove them from your mobile device. User authentication Depending on your New Relic account, additional installation or authentication steps may be required when you install the New Relic mobile app. New Relic account Additional requirements New users If you do not already have a New Relic account: From your desktop web browser, create a New Relic account. Install your application with the appropriate New Relic agent. As part of new account setup, you will receive an email with a password reset link. The password reset link expires after 20 minutes for mobile apps. Existing New Relic users No additional requirements; your applications, hosts, installed plugins, and key transactions automatically appear after you sign in. Users with New Relic partner accounts Depending on the partner, you may need to complete a different authentication process. Azure Store users: Due to the deep integration between Azure Storefront and New Relic, Azure Storefront users cannot access their accounts on the New Relic Android or iOS apps. Users with SAML-SSO enabled accounts When you sign in to the New Relic mobile app, your session automatically redirects to your web browser. From there you can sign in to your New Relic SAML-SSO account. If you see any errors when using SAML-SSO accounts on your mobile device, verify that you are able to sign in to one.newrelic.com with a desktop web browser. If no, contact your administrator. If yes, get support at support.newrelic.com. User settings After you sign in, all New Relic accounts and applications associated with the user appear automatically. Sign in with additional username Follow the procedure for your mobile device. Mobile device To sign in to the app with an additional user name: Android To switch users: Log out from the Android device: Main menu > (selected username) > Logout > Confirm. Log in with a new account. iPhone From the app menu, select your account name, then select the Users menu. From the Users menu, select the plus icon. Sign in with the additional username. iPad To access the Users menu: Select the user icon or slide right. From the Users menu, select the plus icon. Sign in with the additional username. Switch between accounts To switch between accounts associated with your username: From the Users menu, select the user name. Select the account name. Remove or re-add a user name To remove a specific username from this device: From the Users menu, select Logout. To remove a user from this device, select the user's red minus icon. Select the user's Log out icon. To add a user again, sign in with that username again. Select the user icon or slide right to show the New Relic iPad app's Users menu.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.18936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User settings <em>and</em> <em>authentication</em>",
        "sections": "User settings <em>and</em> <em>authentication</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "This explains how to authenticate your <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em> account, and how to add users to or remove them from your <em>mobile</em> device. User <em>authentication</em> Depending on your <em>New</em> <em>Relic</em> account, additional installation or <em>authentication</em> steps may be required when you install the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>"
      },
      "id": "604415a728ccbc8fb52c6068"
    },
    {
      "sections": [
        "Troubleshoot SSO accounts using mobile devices",
        "No user name or password",
        "Errors after signing in",
        "Reauthentication problems"
      ],
      "title": "Troubleshoot SSO accounts using mobile devices",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "9ebb373182ce5fea83ba5a6baa03b2c7bccf0174",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/troubleshoot-sso-accounts-using-mobile-devices/",
      "published_at": "2021-09-26T18:35:19Z",
      "updated_at": "2021-05-16T06:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Typically when you sign in to the New Relic mobile app, your session redirects automatically to your web browser. From there you can sign in to your New Relic account. Here are troubleshooting tips if you have problems using the New Relic mobile app with your SAML-SSO enabled account. No user name or password You may not have a user name or password for New Relic because some SAML providers will overwrite your password, or because your administrator has not sent you this information. In these situations: From the mobile app's Log in, select the I don't have a password link. Use your mobile device to open your email account. From your email account, retrieve the New Relic authentication email within 20 minutes. Select the Authenticate button or the link below it in the email. Errors after signing in If you see any errors after successfully signing in to your SSO provider with your mobile device, verify that you are able to sign in to one.newrelic.com with a desktop web browser. If no, contact your administrator. If yes, get support at support.newrelic.com. Reauthentication problems If you are using reauthentication on a SAML-SSO account, you must log in to your default account. (All other accounts will be grayed out.) If you attempt to switch to a grayed-out account, an error message will appear, explaining this is currently not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.18912,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot SSO accounts using <em>mobile</em> devices",
        "sections": "Troubleshoot SSO accounts using <em>mobile</em> devices",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "Typically when you sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, your session redirects automatically to your web browser. From there you can sign in to your <em>New</em> <em>Relic</em> account. Here are troubleshooting tips if you have problems using the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em> with your SAML-SSO enabled account. No user name"
      },
      "id": "604415e0196a67fc3f960f42"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-09-26T22:37:56Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.66801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for <em>authentication</em>. Android <em>app</em> users will also see a notification message. Important The <em>authentication</em> email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/troubleshoot-sso-accounts-using-mobile-devices": [
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-09-26T18:35:19Z",
      "updated_at": "2021-07-09T12:24:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.05725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " channel to the <em>alert</em> policy. View <em>alert</em> incident details The notification automatically appears on your device&#x27;s lock screen. To start the <em>New</em> <em>Relic</em> <em>app</em>: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the <em>New</em> <em>Relic</em> <em>app</em>&#x27;s <em>Alerts</em> menu, select"
      },
      "id": "603e9efd64441f19a14e88ab"
    },
    {
      "sections": [
        "User settings and authentication",
        "User authentication",
        "User settings",
        "Sign in with additional username",
        "Switch between accounts",
        "Remove or re-add a user name"
      ],
      "title": "User settings and authentication",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "0b40ac4c2e769279d25d0ebb2ea77cebda8d8ea7",
      "image": "https://docs.newrelic.com/static/88ff328efc4a127601923bc728fea229/8c557/device-ipad-switch-user.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/user-settings-authentication/",
      "published_at": "2021-09-26T18:36:19Z",
      "updated_at": "2021-05-16T06:27:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This explains how to authenticate your New Relic mobile app account, and how to add users to or remove them from your mobile device. User authentication Depending on your New Relic account, additional installation or authentication steps may be required when you install the New Relic mobile app. New Relic account Additional requirements New users If you do not already have a New Relic account: From your desktop web browser, create a New Relic account. Install your application with the appropriate New Relic agent. As part of new account setup, you will receive an email with a password reset link. The password reset link expires after 20 minutes for mobile apps. Existing New Relic users No additional requirements; your applications, hosts, installed plugins, and key transactions automatically appear after you sign in. Users with New Relic partner accounts Depending on the partner, you may need to complete a different authentication process. Azure Store users: Due to the deep integration between Azure Storefront and New Relic, Azure Storefront users cannot access their accounts on the New Relic Android or iOS apps. Users with SAML-SSO enabled accounts When you sign in to the New Relic mobile app, your session automatically redirects to your web browser. From there you can sign in to your New Relic SAML-SSO account. If you see any errors when using SAML-SSO accounts on your mobile device, verify that you are able to sign in to one.newrelic.com with a desktop web browser. If no, contact your administrator. If yes, get support at support.newrelic.com. User settings After you sign in, all New Relic accounts and applications associated with the user appear automatically. Sign in with additional username Follow the procedure for your mobile device. Mobile device To sign in to the app with an additional user name: Android To switch users: Log out from the Android device: Main menu > (selected username) > Logout > Confirm. Log in with a new account. iPhone From the app menu, select your account name, then select the Users menu. From the Users menu, select the plus icon. Sign in with the additional username. iPad To access the Users menu: Select the user icon or slide right. From the Users menu, select the plus icon. Sign in with the additional username. Switch between accounts To switch between accounts associated with your username: From the Users menu, select the user name. Select the account name. Remove or re-add a user name To remove a specific username from this device: From the Users menu, select Logout. To remove a user from this device, select the user's red minus icon. Select the user's Log out icon. To add a user again, sign in with that username again. Select the user icon or slide right to show the New Relic iPad app's Users menu.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.18936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User settings <em>and</em> <em>authentication</em>",
        "sections": "User settings <em>and</em> <em>authentication</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "This explains how to authenticate your <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em> account, and how to add users to or remove them from your <em>mobile</em> device. User <em>authentication</em> Depending on your <em>New</em> <em>Relic</em> account, additional installation or <em>authentication</em> steps may be required when you install the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>"
      },
      "id": "604415a728ccbc8fb52c6068"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-09-26T22:37:56Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.66801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for <em>authentication</em>. Android <em>app</em> users will also see a notification message. Important The <em>authentication</em> email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/user-settings-authentication": [
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-09-26T18:35:19Z",
      "updated_at": "2021-07-09T12:24:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.05725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " channel to the <em>alert</em> policy. View <em>alert</em> incident details The notification automatically appears on your device&#x27;s lock screen. To start the <em>New</em> <em>Relic</em> <em>app</em>: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the <em>New</em> <em>Relic</em> <em>app</em>&#x27;s <em>Alerts</em> menu, select"
      },
      "id": "603e9efd64441f19a14e88ab"
    },
    {
      "sections": [
        "Troubleshoot SSO accounts using mobile devices",
        "No user name or password",
        "Errors after signing in",
        "Reauthentication problems"
      ],
      "title": "Troubleshoot SSO accounts using mobile devices",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "9ebb373182ce5fea83ba5a6baa03b2c7bccf0174",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/troubleshoot-sso-accounts-using-mobile-devices/",
      "published_at": "2021-09-26T18:35:19Z",
      "updated_at": "2021-05-16T06:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Typically when you sign in to the New Relic mobile app, your session redirects automatically to your web browser. From there you can sign in to your New Relic account. Here are troubleshooting tips if you have problems using the New Relic mobile app with your SAML-SSO enabled account. No user name or password You may not have a user name or password for New Relic because some SAML providers will overwrite your password, or because your administrator has not sent you this information. In these situations: From the mobile app's Log in, select the I don't have a password link. Use your mobile device to open your email account. From your email account, retrieve the New Relic authentication email within 20 minutes. Select the Authenticate button or the link below it in the email. Errors after signing in If you see any errors after successfully signing in to your SSO provider with your mobile device, verify that you are able to sign in to one.newrelic.com with a desktop web browser. If no, contact your administrator. If yes, get support at support.newrelic.com. Reauthentication problems If you are using reauthentication on a SAML-SSO account, you must log in to your default account. (All other accounts will be grayed out.) If you attempt to switch to a grayed-out account, an error message will appear, explaining this is currently not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.18912,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot SSO accounts using <em>mobile</em> devices",
        "sections": "Troubleshoot SSO accounts using <em>mobile</em> devices",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "Typically when you sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, your session redirects automatically to your web browser. From there you can sign in to your <em>New</em> <em>Relic</em> account. Here are troubleshooting tips if you have problems using the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em> with your SAML-SSO enabled account. No user name"
      },
      "id": "604415e0196a67fc3f960f42"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-09-26T22:37:56Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.66801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for <em>authentication</em>. Android <em>app</em> users will also see a notification message. Important The <em>authentication</em> email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/ios-app/install-new-relic-ios-mobile-app": [
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-09-29T01:39:46Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 317.11035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> to <em>iOS</em> <em>mobile</em> <em>app</em>",
        "sections": "<em>Introduction</em> to <em>iOS</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s <em>i</em>Phone and <em>i</em>Pad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> <em>iOS</em> <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s <em>iOS</em> <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.26843,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>iOS</em> <em>application</em> licenses",
        "sections": "<em>iOS</em> <em>application</em> licenses",
        "tags": "<em>Mobile</em> <em>app</em> licenses",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> <em>iOS</em> <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-09-26T18:35:19Z",
      "updated_at": "2021-07-09T12:24:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.94652,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": ": Android From your Android device&#x27;s Settings, select <em>Apps</em>, then select the <em>New</em> <em>Relic</em> <em>app</em>. Select Uninstall. Continue with the steps to reinstall the <em>New</em> <em>Relic</em> <em>app</em>. <em>iOS</em> From your <em>iOS</em> home screen, tap and hold the <em>New</em> <em>Relic</em> icon until it shakes. To delete the <em>app</em>, select the X icon. Continue"
      },
      "id": "603e9efd64441f19a14e88ab"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-09-27T15:25:25Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.26828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>iOS</em> <em>application</em> licenses",
        "sections": "<em>iOS</em> <em>application</em> licenses",
        "tags": "<em>Mobile</em> <em>app</em> licenses",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> <em>iOS</em> <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Install the New Relic iOS mobile app",
        "Compatibility and requirements",
        "Installation"
      ],
      "title": "Install the New Relic iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "a33650792e7ba24040db9a65d8d7fbb25c341d18",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/install-new-relic-ios-mobile-app/",
      "published_at": "2021-09-26T18:36:19Z",
      "updated_at": "2021-03-13T04:04:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This section provides information about compatibility and requirements, basic instructions on how to install and configure the New Relic iPhone and iPad apps, and links to more detailed information. Compatibility and requirements The New Relic iOS app allows you to view your New Relic applications, Infrastructure data, plugins you have installed from Plugin Central, key transactions, Synthetics monitors, and alerts from an Apple iPhone or iPad. Product requirements include: iOS 7 or higher iPhone users: iPhone 4S or higher iPad users: iPad 2 or higher You can also use an iPod touch, although resolution may be different. Installation You can install the New Relic app from the App Store or learn more from the New Relic website. Follow standard procedures to install any iOS app, and then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or authentication steps may be required. For more information, see User settings and authentication.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.89496,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>New</em> <em>Relic</em> <em>iOS</em> <em>mobile</em> <em>app</em>",
        "sections": "<em>Install</em> the <em>New</em> <em>Relic</em> <em>iOS</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "This section provides information about compatibility and requirements, basic instructions on how to install and configure the <em>New</em> <em>Relic</em> <em>i</em>Phone and <em>i</em>Pad <em>apps</em>, and links to more detailed information. Compatibility and requirements The <em>New</em> <em>Relic</em> <em>iOS</em> <em>app</em> allows you to view your <em>New</em> <em>Relic</em> applications"
      },
      "id": "60441616196a67b070960f2b"
    },
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-09-26T18:35:19Z",
      "updated_at": "2021-07-09T12:24:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.94652,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": ": Android From your Android device&#x27;s Settings, select <em>Apps</em>, then select the <em>New</em> <em>Relic</em> <em>app</em>. Select Uninstall. Continue with the steps to reinstall the <em>New</em> <em>Relic</em> <em>app</em>. <em>iOS</em> From your <em>iOS</em> home screen, tap and hold the <em>New</em> <em>Relic</em> icon until it shakes. To delete the <em>app</em>, select the X icon. Continue"
      },
      "id": "603e9efd64441f19a14e88ab"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/tvos-app/introduction-apple-tv-app": [
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-09-29T01:39:46Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.1421,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "sections": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s iPhone and iPad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> iOS <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s iOS <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Introduction to New Relic Android app",
        "Requirements",
        "Install New Relic's mobile app",
        "View New Relic data",
        "New Relic product details",
        "Synthetics data",
        "Alerts",
        "Mobile app monitoring",
        "Details on setting time range",
        "Data privacy"
      ],
      "title": "Introduction to New Relic Android app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "ff8415c00363a49eaa062f4b0b13c795b4717ea5",
      "image": "https://docs.newrelic.com/static/ea914fce17844b32fdabefd60efc457e/e5166/navigation_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app/",
      "published_at": "2021-09-26T18:35:20Z",
      "updated_at": "2021-09-14T07:28:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's Android app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install New Relic's mobile app You can install the New Relic Android app from the Google Play Store or learn more from the New Relic website. Follow standard procedures to install any Android app, then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or user authentication steps may be required. View New Relic data To view details of your apps monitored by New Relic, select a product from the app's main menu. See below for details on how to use specific features of the app: New Relic product details The New Relic Android app includes data about these features: APM metrics, both real-time and historical data, including health maps. Select the transaction icon to see detailed transaction metrics, or an Overview chart to view summary charts of your top five transactions. Select the icon to filter by labels and categories. Browser monitoring metrics, including average page load time, Apdex, average throughput, and more. Infrastructure monitoring. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Synthetics data You can use the Android app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. To view more detailed charts, select the caret icon. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen. To view them, tap the alert event. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile app monitoring If you have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Details on setting time range When viewing an application or host, you can change the visible time frame with the time picker. To move back and forth across the timeline, scrub the New Relic charts. To change the duration of the visible time slice, select the clock icon. To specify an end time other than now, slide the toggle from Ending Now to Custom Date. To save your changes and refresh the chart data, select the clock icon again. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.13936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em> Android <em>app</em>",
        "sections": "Install <em>New</em> <em>Relic&#x27;s</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s Android <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install <em>New</em> <em>Relic</em>&#x27;s <em>mobile</em>"
      },
      "id": "604415e0196a67ff23960f46"
    },
    {
      "sections": [
        "Android app UI",
        "Pages",
        "Time range",
        "New Relic Synthetics",
        "Alerts",
        "Mobile apps",
        "For more help"
      ],
      "title": "Android app UI",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "8918a5a2454491a91421c55e26501a0e3f64cd3a",
      "image": "https://docs.newrelic.com/static/fc97ade0bbdbdef58b89495a0d91b734/edd00/deployment-markers_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/android-app-ui/",
      "published_at": "2021-09-29T01:40:58Z",
      "updated_at": "2021-09-14T07:28:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The UI for the New Relic Android app provides functionality similar to the standard user interface, with customized details for mobile users. Pages To view details of your New Relic apps, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The New Relic Android app includes: APM metrics, both real-time and historical data, including health maps. And, select the transaction icon for detailed transaction metrics, or an Overview Charts to view summary charts of your top five transactions. New Relic Infrastructure utilization. New Relic Plugins, including a list of their components or instances, and their charts and current values from the plugin's Summary. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Select the filter icon to filter by labels and categories. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. Note: New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the time picker icon in the top right of the page (the 7D in the screenshot). This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth in the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). New Relic Synthetics You can use the Android app to view your New Relic Synthetics data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen and can be viewed by tapping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile apps If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. For more help Additional documentation resources include: New Relic Android app (compatibility, requirements, installation) Android authentication (procedures to add or remove users, and for the users to authenticate with their Android device)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.13933,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android <em>app</em> UI",
        "sections": "<em>Mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The UI for the <em>New</em> <em>Relic</em> Android <em>app</em> provides functionality similar to the standard user interface, with customized details for <em>mobile</em> users. Pages To view details of your <em>New</em> <em>Relic</em> <em>apps</em>, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The <em>New</em>"
      },
      "id": "6044181d28ccbc9a522c60a5"
    }
  ],
  "/docs/mobile-crash-rest-api-v1": [
    {
      "sections": [
        "Working with the New Relic REST API (v1) (deprecated)",
        "Important"
      ],
      "title": "Working with the New Relic REST API (v1) (deprecated)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v1 deprecated",
        "New Relic REST API v1"
      ],
      "external_id": "9cb0f38eb95a8757624ddb63298ff9a32e1176e7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v1-deprecated/new-relic-rest-api-v1/working-new-relic-rest-api-v1-deprecated/",
      "published_at": "2021-09-27T04:39:45Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Currently New Relic supports two versions of the REST API. Version 1 is deprecated and has been replaced with the newer v2. No termination date has been announced. However, no further development or modifications are being made to v1. Important Start new projects by referring to Getting started with API v2 and the New Relic REST API v2 examples. Also, begin migrating your v1 scripts to their v2 equivalent. To use the REST API v1 in any way, your API key is required. Then, from the command line, you can use: curl -gH \"x-api-key:REPLACE_WITH_YOUR_API_KEY\" 'ENDPOINT_URL' Copy OR wget -qO- --header \"x-api-key:REPLACE_WITH_YOUR_API_KEY\" 'ENDPOINT_URL' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.28296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Working with the New Relic <em>REST</em> <em>API</em> (<em>v1</em>) (deprecated)",
        "sections": "Working with the New Relic <em>REST</em> <em>API</em> (<em>v1</em>) (deprecated)",
        "tags": "<em>REST</em> <em>API</em> <em>v1</em> deprecated",
        "body": "Currently New Relic supports two versions of the <em>REST</em> <em>API</em>. Version <em>1</em> is deprecated and has been replaced with the newer <em>v</em>2. No termination date has been announced. However, no further development or modifications are being made to <em>v1</em>. Important Start new projects by referring to Getting started"
      },
      "id": "6043ff97e7b9d20358579a0d"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Important",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "OTLP API",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-27T14:43:39Z",
      "updated_at": "2021-09-27T14:43:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. Important The AWS CloudWatch Metric Streams integration is not currently FedRAMP compliant. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. OTLP API To ensure FedRAMP compliance when using the OTLP API, instead of sending to the US OTLP API endpoint of https://otlp.nr-data.net:4317, send data to https://gov-otlp.nr-data.net:4317. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. To enable FedRAMP compliance for Infinite Tracing, you would create a new FedRAMP compliant trace observer from the New Relic Edge app.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 329.93655,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Mobile</em> monitoring agents",
        "body": "-data.net:4317. Metric <em>API</em> To ensure FedRAMP compliance when using the Metric <em>API</em>, instead of sending metric data to the default Metric <em>API</em> endpoint of https:&#x2F;&#x2F;metric-<em>api</em>.newrelic.com&#x2F;metric&#x2F;<em>v1</em>, it must be sent to https:&#x2F;&#x2F;gov-metric-<em>api</em>.newrelic.com&#x2F;metric&#x2F;<em>v1</em>. The Metric <em>API</em> can be used directly"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "API examples for SLA reports",
        "Tip",
        "Browser metrics for SLAs",
        "App server metrics for SLAs",
        "Tips for collecting metrics",
        "Examples",
        "REST API v2 commands",
        "Browser load time and page view count (v2)",
        "App response time and request count (v2)",
        "Apdex SLA data (v2)",
        "REST API v1 commands (deprecated)",
        "Browser load time and page view count (v1)",
        "App response time and request count (v1)",
        "Apdex SLA data (v1)",
        "Analyze your data"
      ],
      "title": "API examples for SLA reports",
      "type": "docs",
      "tags": [
        "APM",
        "Reports",
        "Service level agreements"
      ],
      "external_id": "3b4dafc002932fc100b6375a3ae87b01350d57fc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/reports/service-level-agreements/api-examples-sla-reports/",
      "published_at": "2021-09-26T15:30:18Z",
      "updated_at": "2021-09-14T10:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic stores SLA data forever for eligible accounts, so you can use the New Relic REST API to generate service level agreement reports over any time period. For example, you can create SLA reports going back more than 12 days, weeks, or months. Tip Access to this feature depends on your subscription level. Browser metrics for SLAs Browser metrics for the End user tier are available only if you have installed the browser agent. Browser (End user tier) SLA metric name:value (and formula) Page Views thousands EndUser : call_count Load time sec EndUser : average_response_time Apdex EndUser/Apdex : score % Satisfied EndUser/Apdex : s divided by EndUser : call_count % Tolerating EndUser/Apdex : t divided by Enduser : call_count % Frustrated EndUser/Apdex : f divided by Enduser : call_count App server metrics for SLAs Here are the SLA metrics for application servers. App server SLA metric name:value (and formula) Requests millions HttpDispatcher : call_count (scaled appropriately) Resp. time ms HttpDispatcher : average_response_time (multiplied by 1000) Apdex Apdex : score % Satisfied Apdex : s divided by Apdex : count % Tolerating Apdex : t divided by Apdex : count % Frustrated Apdex : f divided by Apdex : count Tips for collecting metrics Here are some tips for planning which metrics to collect. SLA tips Comments Requirements When using the cURL command examples, be sure to replace the placeholder text with your account ID, an API key, and the application ID. Time ranges You are not limited to standard day, week, or month time ranges. For example, you can extract metric data for a \"holiday weekend\" from 12/23 to 12/26 or \"the 20 minutes after our site had problems\" or whatever other period interests you. UTC XML time format You must specify the time in UTC XML format, so be sure to adjust for your time zone compared to UTC. For example, New Relic starts at 16:00:00 on the day before the selected data, since New Relic headquarters are in UTC-8. Summary reports When requesting metrics to use with summary reports, include the query string parameter summarize=true (v2) or summary=1 (v1) as shown in the examples. Scaled statistics Your report has some statistics that are scaled in the SLA reports in New Relic's user interface. New Relic changes the scale of page views in your report to show small numbers. Depending on your traffic, typically it might be displayed in thousands, millions, or billions. Recommendation: To avoid a string of zeroes, divide this number appropriately for your own purposes. End user statistics End user statistics will reflect only the calls in which the agent gathered browser data. For example, end user stats may not appear in situations such as: Browser types Clients (they might have disabled the JavaScript agent, or blocked traffic to New Relic sites for JavaScript code's location Transactions not in one of those categories, in case the page load did not complete for any reason This is why there are fewer (sometimes many fewer) page views in the End User (browser) data section than in the App server data section. Examples The following sections contain code examples to acquire the data for values described above for the Daily (24hr) SLA statistics in the default GMT/UTC time zone. Adjust the from= and to= for your time range as desired. There are syntactical differences between New Relic's REST API v2 and v1. The examples show how to use each. REST API v2 commands Browser load time and page view count (v2) To obtain the browser (EndUser/RUM) load time and page view count for v2, from the command line, type: curl -X GET \"https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.xml\"\\ -H \"Api-Key:$API_KEY\" -i \\ -d 'names[]=EndUser&values[]=call_count&values[]=average_response_time&from=2014-06-09T00:00:00+00:00&to=2014-06-09T23:00:00+00:00&summarize=true' Copy In Ruby: require 'rubygems' require 'curb' response = Curl::Easy.http_get(\"https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.xml?names[]=EndUser&values[]=call_count&values[]=average_response_time&from=2012-01-01T00:00:00+00:00&to=2012-01-08T00:00:00+00:00&summarize=true\") do |curl| curl.headers[\"api-key\"] = \"$API_KEY\" curl.header_in_body=true end puts response.body_str Copy App response time and request count (v2) To obtain the Application response time and request count for v2, from the command line, type: curl -X GET \"https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.xml\" \\ -H \"Api-Key:$API_KEY\" -i \\ -d 'names[]=HttpDispatcher&values[]=average_response_time&values[]=call_count&from=2014-06-09T00:00:00+00:00&to=2014-06-09T23:00:00+00:00&summarize=true' Copy In Ruby: require 'rubygems' require 'curb' response = Curl::Easy.http_get(\"https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.xml?names[]=HttpDispatcher&values[]=average_response_time&values[]=call_count&from=2012-01-01T00:00:00+00:00&to=2012-01-08T00:00:00+00:00&summarize=true\") do |curl| curl.headers[\"api-key\"] = \"$API_KEY\" curl.header_in_body=true end puts response.body_str Copy Apdex SLA data (v2) To obtain the Apdex related data for v2, from the command line, type: curl -X GET \"https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.xml\" \\ -H \"Api-Key:$API_KEY\" -i \\ -d 'names[]=Apdex&names[]=EndUser/Apdex&from=2014-06-09T00:00:00+00:00&to=2014-06-09T23:00:00+00:00&summarize=true' Copy In Ruby: require 'rubygems' require 'curb' response = Curl::Easy.http_get(\"https://api.newrelic.com/v2/applications/$APP_ID/metrics/data.xml?names[]=EndUser/Apdex&from=2012-01-01T00:00:00+00:00&to=2012-01-08T00:00:00+00:00&summarize=true\") do |curl| curl.headers[\"api-key\"] = \"$API_KEY\" curl.header_in_body=true end puts response.body_str Copy REST API v1 commands (deprecated) REST API v1 is deprecated. Browser load time and page view count (v1) To obtain the browser (EndUser/RUM) load time and page view count for v1, from the command line, type: curl -gH \"api-key:$API_KEY\" \"https://api.newrelic.com/api/v1/accounts/$ACCOUNT_ID/applications/$APP_ID/data.xml?metrics[]=EndUser&field=call_count&field=average_response_time&summary=1&begin=2012-01-01T00:00:00Z&end=2012-01-08T00:00:00Z\" Copy In Ruby: require 'rubygems' require 'curb' response = Curl::Easy.perform(\"https://api.newrelic.com/api/v1/accounts/$ACCOUNT_ID/applications/$APP_ID/data.xml?metrics[]=EndUser&field=call_count&field=average_response_time&summary=1&begin=2012-01-01T00:00:00Z&end=2012-01-08T00:00:00Z\") do |curl| curl.headers[\"api-key\"] = \"$API_KEY\" end puts response.body_str Copy App response time and request count (v1) To obtain the Application response time and request count for v1, from the command line, type: curl -gH \"api-key:$API_KEY\" \"https://api.newrelic.com/api/v1/accounts/$ACCOUNT_ID/applications/$APP_ID/data.xml?metrics[]=HttpDispatcher&field=average_response_time&field=call_count&summary=1&begin=2012-01-01T00:00:00Z&end=2012-01-08T00:00:00Z\" Copy In Ruby: require 'rubygems' require 'curb' response = Curl::Easy.perform(\"https://api.newrelic.com/api/v1/accounts/$ACCOUNT_ID/applications/$APP_ID/data.xml?metrics[]=HttpDispatcher&field=average_response_time&field=call_count&summary=1&begin=2012-01-01T00:00:00Z&end=2012-01-08T00:00:00Z\") do |curl| curl.headers[\"api-key\"] = \"$API_KEY\" end puts response.body_str Copy Apdex SLA data (v1) To obtain the Apdex related data for v1, from the command line, type: curl -gH \"api-key:$API_KEY\" \"https://api.newrelic.com/api/v1/accounts/$ACCOUNT_ID/applications/$APP_ID/data.xml?metrics[]=Apdex&metrics[]=EndUser/Apdex&summary=1&begin=2012-01-01T00:00:00Z&end=2012-01-08T00:00:00Z\" Copy In Ruby: require 'rubygems' require 'curb' response = Curl::Easy.perform(\"https://api.newrelic.com/api/v1/accounts/$ACCOUNT_ID/applications/$APP_ID/data.xml?metrics[]=Apdex&metrics[]=EndUser/Apdex&summary=1&begin=2012-01-01T00:00:00Z&end=2012-01-08T00:00:00Z\") do |curl| curl.headers[\"api-key\"] = \"$API_KEY\" end puts response.body_str Copy Analyze your data APM includes several reports in the user interface. To gather, analyze, and visualize data about your software in other formats, use dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.05164,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>API</em> examples for SLA reports",
        "sections": "<em>REST</em> <em>API</em> <em>v1</em> commands (deprecated)",
        "body": " range as desired. There are syntactical differences between New Relic&#x27;s <em>REST</em> <em>API</em> <em>v</em>2 and <em>v1</em>. The examples show how to use each. <em>REST</em> <em>API</em> <em>v</em>2 commands Browser load time and page view count (<em>v</em>2) To obtain the browser (EndUser&#x2F;RUM) load time and page view count for <em>v</em>2, from the command line, type: curl"
      },
      "id": "603ebe82196a67631fa83dd7"
    }
  ],
  "/docs/mobile-monitoring/index": [
    {
      "sections": [
        "Upload dSYM files",
        "Automatic script",
        "Identify missing dSYMs",
        "Upload dSYM files through the mobile monitoring UI",
        "Manually upload dSYM files",
        "Via Python script (agent versions 6.0.0 or higher)",
        "Via command line",
        "Troubleshooting",
        "Auto-upload failure",
        "Missing dSYMs"
      ],
      "title": "Upload dSYM files",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Configuration"
      ],
      "external_id": "3655f49cf0e1ae693de0f8ea45bf4e5e6437e399",
      "image": "https://docs.newrelic.com/static/5c859575f391fbb1eaa18243a8c97000/8c557/Screen-Shot-2014-09-23-at-11.30.35-AM_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/configuration/upload-dsyms-bitcode-apps/",
      "published_at": "2021-09-27T15:06:37Z",
      "updated_at": "2021-09-27T15:06:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your app's dSYM files are stored in Xcode's dSYM archive path folder. This is the folder where the iOS agent gets the dSYM files that are used to symbolicate your crash reports. New Relic provides a post-build script as part of the iOS agent's install process and the tvOS agent's install process. This script automatically uploads your app's dSYM files. Automatic script The script automatically uploads dSYM files only for release builds. Non-release builds must upload their files either manually or through the mobile monitoring UI. Bitcode-enabled apps have their dSYM files generated by Apple. You must download the dSYM files for Bitcode-enabled apps from Apple and upload them to New Relic. If you see unreadable machine code in the Crashes page, your dSYM files may not be uploaded correctly. In some cases, you may need to manually upload dSYM files. The automatic script uses Python 2. As of October 2019 with macOS 10.15 (Catalina), Python won't be installed by default. If you're using the automatic script (recommended), you may need to manually install Python 2. If you're using Homebrew, see Python on Homebrew. Identify missing dSYMs When a Bitcode-enabled app is uploaded to Apple for App Store review or ad-hoc distribution, dSYMs need to be manually downloaded from Apple and uploaded to New Relic to allow the mobile crash reports to be properly symbolicated. These dSYMs can be downloaded through the archives organizer in Xcode within several minutes of uploading the app. In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you'll see three indicators in the mobile monitoring UI: Banner notification: A banner warning appears on the Crash report page. The warning reads: We were unable to locate your dsym. Copy Upload prompt: From the Crash type summary page you will be automatically prompted to upload a dSYM file if it is missing. Machine code: The crash stack trace on the Crash report page displays machine code and not a human-readable error message. Upload dSYM files through the mobile monitoring UI You can easily upload your dSYM files directly from the New Relic One UI. The maximum file size is 600 MB. To upload your dSYM files: Go to one.newrelic.com and click Mobile. Then select your app from the list. View Crash analysis. Select a specific crash from the Crash types list. Click Upload dSYM. You can either drag and drop your dSYMs directly, or select the file form your computer. Manually upload dSYM files In some circumstances, New Relic's automatic upload of dSYM files may fail. If a dSYM upload is attempted and fails, it creates a build error with a detailed message. For example, if there's a network failure and the dSYM upload isn't completed, Xcode will report an error. For additional information about how New Relic handles dSYM uploads, see New Relic's Online Technical Community. If the automatic upload fails, you can manually upload your dSYM file. If you have multiple dSYM files, they can be within a single zip with a maximum file size of 600 MB. The YOUR_NEW_RELIC_APPLICATION_TOKEN value in the commands below is the same key used for +[NewRelic startWithApplicationToken:] (in Objective-C) or NewRelic.start(withApplicationToken:) (in Swift). To manually upload your dSYM files: Via Python script (agent versions 6.0.0 or higher) In iOS agent versions 6.0.0 or higher, the agent includes a Python script that automatically processes and uploads symbols. You can call this script from the command line: NewRelicAgent.framework/Resources/generateMap.py \"DSYM_ARCHIVE_PATH\" \"YOUR_NEW_RELIC_APPLICATION_TOKEN\" Copy Via command line To manually upload individual dSYM files from the command line: Zip up your dSYM file or files using the following command. Replace ~ /ZIPPED_DSYM_PATH with your new dSYM archive path and file name (for example, Users/my-name/desktop). Also replace ~ /dSYM_PATH with your existing dSYM file path. /usr/bin/zip --recurse-paths --quiet \"~/ZIPPED_DSYM_PATH\" \"~/dSYM_PATH\" Copy Upload the dSYM zip file using the following command: For US accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.newrelic.com/symbol Copy For EU accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.eu01.nr-data.net/symbol Copy Troubleshooting Auto-upload failure If a dSYM auto-upload failed, the Report Navigator may have a fully formed cURL command. You can use this cURL command to reattempt an upload. Depending on the error, you may also need to follow some of the dSYM manual upload steps. Here is an example of a successful dSYM upload in the Report Navigator: Example: A successful dSYM upload in the Report Navigator. Missing dSYMs If dSYM files are missing, you may need to check Xcode build settings to ensure the file is being generated. Frameworks which are built locally have separate build settings and may need to be updated as well. Build settings: Debug Information Format : Dwarf with dSYM File Deployment Postprocessing: Yes Strip Linked Product: Yes Strip Debug Symbols During Copy : Yes Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 481.08087,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Upload dSYM files through the <em>mobile</em> <em>monitoring</em> UI",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": ". This script automatically uploads your app&#x27;s dSYM files. Automatic script The script automatically uploads dSYM files only for release builds. Non-release builds must upload their files either manually or through the <em>mobile</em> <em>monitoring</em> UI. Bitcode-enabled apps have their dSYM files generated by Apple"
      },
      "id": "60441960e7b9d24f705799ca"
    },
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-26T22:36:15Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 472.23883,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map page for <em>mobile</em> apps (deprecated)",
        "sections": "Map page for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map page, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "setMaxEventPoolSize (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set maximum size of event pool to 1000"
      ],
      "title": "setMaxEventPoolSize (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "16019f6e7ab593733c87c9dc1831ff9ffa11dbb8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-pool-size/",
      "published_at": "2021-09-27T15:51:59Z",
      "updated_at": "2021-09-27T15:51:59Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, mobile monitoring collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method controls the maximum size of the event pool stored in the memory until the next harvest cycle. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. This method lets you override the maximum size of that event pool. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. The default value for the event harvest cycle is 600 seconds. See also setMaxEventBufferTime(), which lets you change the length of the event harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxSize int Required. Maximum size of event pool. Return values Returns true if it succeeds, or false if it doesn't. Examples Set maximum size of event pool to 1000 boolean poolSizeSet = NewRelic.setMaxEventPoolSize(1000); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 402.23114,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, <em>mobile</em> <em>monitoring</em> collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method"
      },
      "id": "603ea0ea28ccbce4f4eba760"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/crash-analysis-group-filter-your-crashes": [
    {
      "sections": [
        "Upload dSYM files",
        "Automatic script",
        "Identify missing dSYMs",
        "Upload dSYM files through the mobile monitoring UI",
        "Manually upload dSYM files",
        "Via Python script (agent versions 6.0.0 or higher)",
        "Via command line",
        "Troubleshooting",
        "Auto-upload failure",
        "Missing dSYMs"
      ],
      "title": "Upload dSYM files",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Configuration"
      ],
      "external_id": "3655f49cf0e1ae693de0f8ea45bf4e5e6437e399",
      "image": "https://docs.newrelic.com/static/5c859575f391fbb1eaa18243a8c97000/8c557/Screen-Shot-2014-09-23-at-11.30.35-AM_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/configuration/upload-dsyms-bitcode-apps/",
      "published_at": "2021-09-27T15:06:37Z",
      "updated_at": "2021-09-27T15:06:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your app's dSYM files are stored in Xcode's dSYM archive path folder. This is the folder where the iOS agent gets the dSYM files that are used to symbolicate your crash reports. New Relic provides a post-build script as part of the iOS agent's install process and the tvOS agent's install process. This script automatically uploads your app's dSYM files. Automatic script The script automatically uploads dSYM files only for release builds. Non-release builds must upload their files either manually or through the mobile monitoring UI. Bitcode-enabled apps have their dSYM files generated by Apple. You must download the dSYM files for Bitcode-enabled apps from Apple and upload them to New Relic. If you see unreadable machine code in the Crashes page, your dSYM files may not be uploaded correctly. In some cases, you may need to manually upload dSYM files. The automatic script uses Python 2. As of October 2019 with macOS 10.15 (Catalina), Python won't be installed by default. If you're using the automatic script (recommended), you may need to manually install Python 2. If you're using Homebrew, see Python on Homebrew. Identify missing dSYMs When a Bitcode-enabled app is uploaded to Apple for App Store review or ad-hoc distribution, dSYMs need to be manually downloaded from Apple and uploaded to New Relic to allow the mobile crash reports to be properly symbolicated. These dSYMs can be downloaded through the archives organizer in Xcode within several minutes of uploading the app. In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you'll see three indicators in the mobile monitoring UI: Banner notification: A banner warning appears on the Crash report page. The warning reads: We were unable to locate your dsym. Copy Upload prompt: From the Crash type summary page you will be automatically prompted to upload a dSYM file if it is missing. Machine code: The crash stack trace on the Crash report page displays machine code and not a human-readable error message. Upload dSYM files through the mobile monitoring UI You can easily upload your dSYM files directly from the New Relic One UI. The maximum file size is 600 MB. To upload your dSYM files: Go to one.newrelic.com and click Mobile. Then select your app from the list. View Crash analysis. Select a specific crash from the Crash types list. Click Upload dSYM. You can either drag and drop your dSYMs directly, or select the file form your computer. Manually upload dSYM files In some circumstances, New Relic's automatic upload of dSYM files may fail. If a dSYM upload is attempted and fails, it creates a build error with a detailed message. For example, if there's a network failure and the dSYM upload isn't completed, Xcode will report an error. For additional information about how New Relic handles dSYM uploads, see New Relic's Online Technical Community. If the automatic upload fails, you can manually upload your dSYM file. If you have multiple dSYM files, they can be within a single zip with a maximum file size of 600 MB. The YOUR_NEW_RELIC_APPLICATION_TOKEN value in the commands below is the same key used for +[NewRelic startWithApplicationToken:] (in Objective-C) or NewRelic.start(withApplicationToken:) (in Swift). To manually upload your dSYM files: Via Python script (agent versions 6.0.0 or higher) In iOS agent versions 6.0.0 or higher, the agent includes a Python script that automatically processes and uploads symbols. You can call this script from the command line: NewRelicAgent.framework/Resources/generateMap.py \"DSYM_ARCHIVE_PATH\" \"YOUR_NEW_RELIC_APPLICATION_TOKEN\" Copy Via command line To manually upload individual dSYM files from the command line: Zip up your dSYM file or files using the following command. Replace ~ /ZIPPED_DSYM_PATH with your new dSYM archive path and file name (for example, Users/my-name/desktop). Also replace ~ /dSYM_PATH with your existing dSYM file path. /usr/bin/zip --recurse-paths --quiet \"~/ZIPPED_DSYM_PATH\" \"~/dSYM_PATH\" Copy Upload the dSYM zip file using the following command: For US accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.newrelic.com/symbol Copy For EU accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.eu01.nr-data.net/symbol Copy Troubleshooting Auto-upload failure If a dSYM auto-upload failed, the Report Navigator may have a fully formed cURL command. You can use this cURL command to reattempt an upload. Depending on the error, you may also need to follow some of the dSYM manual upload steps. Here is an example of a successful dSYM upload in the Report Navigator: Example: A successful dSYM upload in the Report Navigator. Missing dSYMs If dSYM files are missing, you may need to check Xcode build settings to ensure the file is being generated. Frameworks which are built locally have separate build settings and may need to be updated as well. Build settings: Debug Information Format : Dwarf with dSYM File Deployment Postprocessing: Yes Strip Linked Product: Yes Strip Debug Symbols During Copy : Yes Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.51004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Upload dSYM files through the <em>mobile</em> <em>monitoring</em> <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": ". In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you&#x27;ll see three indicators in the <em>mobile</em> <em>monitoring</em> <em>UI</em>: Banner notification: A banner warning appears on the <em>Crash</em> report page. The warning reads: We were unable to locate your dsym. Copy"
      },
      "id": "60441960e7b9d24f705799ca"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-09-27T03:00:13Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.46378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-09-27T02:59:21Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.45244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes": [
    {
      "sections": [
        "Upload dSYM files",
        "Automatic script",
        "Identify missing dSYMs",
        "Upload dSYM files through the mobile monitoring UI",
        "Manually upload dSYM files",
        "Via Python script (agent versions 6.0.0 or higher)",
        "Via command line",
        "Troubleshooting",
        "Auto-upload failure",
        "Missing dSYMs"
      ],
      "title": "Upload dSYM files",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Configuration"
      ],
      "external_id": "3655f49cf0e1ae693de0f8ea45bf4e5e6437e399",
      "image": "https://docs.newrelic.com/static/5c859575f391fbb1eaa18243a8c97000/8c557/Screen-Shot-2014-09-23-at-11.30.35-AM_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/configuration/upload-dsyms-bitcode-apps/",
      "published_at": "2021-09-27T15:06:37Z",
      "updated_at": "2021-09-27T15:06:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your app's dSYM files are stored in Xcode's dSYM archive path folder. This is the folder where the iOS agent gets the dSYM files that are used to symbolicate your crash reports. New Relic provides a post-build script as part of the iOS agent's install process and the tvOS agent's install process. This script automatically uploads your app's dSYM files. Automatic script The script automatically uploads dSYM files only for release builds. Non-release builds must upload their files either manually or through the mobile monitoring UI. Bitcode-enabled apps have their dSYM files generated by Apple. You must download the dSYM files for Bitcode-enabled apps from Apple and upload them to New Relic. If you see unreadable machine code in the Crashes page, your dSYM files may not be uploaded correctly. In some cases, you may need to manually upload dSYM files. The automatic script uses Python 2. As of October 2019 with macOS 10.15 (Catalina), Python won't be installed by default. If you're using the automatic script (recommended), you may need to manually install Python 2. If you're using Homebrew, see Python on Homebrew. Identify missing dSYMs When a Bitcode-enabled app is uploaded to Apple for App Store review or ad-hoc distribution, dSYMs need to be manually downloaded from Apple and uploaded to New Relic to allow the mobile crash reports to be properly symbolicated. These dSYMs can be downloaded through the archives organizer in Xcode within several minutes of uploading the app. In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you'll see three indicators in the mobile monitoring UI: Banner notification: A banner warning appears on the Crash report page. The warning reads: We were unable to locate your dsym. Copy Upload prompt: From the Crash type summary page you will be automatically prompted to upload a dSYM file if it is missing. Machine code: The crash stack trace on the Crash report page displays machine code and not a human-readable error message. Upload dSYM files through the mobile monitoring UI You can easily upload your dSYM files directly from the New Relic One UI. The maximum file size is 600 MB. To upload your dSYM files: Go to one.newrelic.com and click Mobile. Then select your app from the list. View Crash analysis. Select a specific crash from the Crash types list. Click Upload dSYM. You can either drag and drop your dSYMs directly, or select the file form your computer. Manually upload dSYM files In some circumstances, New Relic's automatic upload of dSYM files may fail. If a dSYM upload is attempted and fails, it creates a build error with a detailed message. For example, if there's a network failure and the dSYM upload isn't completed, Xcode will report an error. For additional information about how New Relic handles dSYM uploads, see New Relic's Online Technical Community. If the automatic upload fails, you can manually upload your dSYM file. If you have multiple dSYM files, they can be within a single zip with a maximum file size of 600 MB. The YOUR_NEW_RELIC_APPLICATION_TOKEN value in the commands below is the same key used for +[NewRelic startWithApplicationToken:] (in Objective-C) or NewRelic.start(withApplicationToken:) (in Swift). To manually upload your dSYM files: Via Python script (agent versions 6.0.0 or higher) In iOS agent versions 6.0.0 or higher, the agent includes a Python script that automatically processes and uploads symbols. You can call this script from the command line: NewRelicAgent.framework/Resources/generateMap.py \"DSYM_ARCHIVE_PATH\" \"YOUR_NEW_RELIC_APPLICATION_TOKEN\" Copy Via command line To manually upload individual dSYM files from the command line: Zip up your dSYM file or files using the following command. Replace ~ /ZIPPED_DSYM_PATH with your new dSYM archive path and file name (for example, Users/my-name/desktop). Also replace ~ /dSYM_PATH with your existing dSYM file path. /usr/bin/zip --recurse-paths --quiet \"~/ZIPPED_DSYM_PATH\" \"~/dSYM_PATH\" Copy Upload the dSYM zip file using the following command: For US accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.newrelic.com/symbol Copy For EU accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.eu01.nr-data.net/symbol Copy Troubleshooting Auto-upload failure If a dSYM auto-upload failed, the Report Navigator may have a fully formed cURL command. You can use this cURL command to reattempt an upload. Depending on the error, you may also need to follow some of the dSYM manual upload steps. Here is an example of a successful dSYM upload in the Report Navigator: Example: A successful dSYM upload in the Report Navigator. Missing dSYMs If dSYM files are missing, you may need to check Xcode build settings to ensure the file is being generated. Frameworks which are built locally have separate build settings and may need to be updated as well. Build settings: Debug Information Format : Dwarf with dSYM File Deployment Postprocessing: Yes Strip Linked Product: Yes Strip Debug Symbols During Copy : Yes Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.51004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Upload dSYM files through the <em>mobile</em> <em>monitoring</em> <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": ". In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you&#x27;ll see three indicators in the <em>mobile</em> <em>monitoring</em> <em>UI</em>: Banner notification: A banner warning appears on the <em>Crash</em> report page. The warning reads: We were unable to locate your dsym. Copy"
      },
      "id": "60441960e7b9d24f705799ca"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-09-27T03:00:13Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.46378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-09-27T02:59:21Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.45244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/handled-exceptions-analyze-trends-prevent-crashes": [
    {
      "sections": [
        "Upload dSYM files",
        "Automatic script",
        "Identify missing dSYMs",
        "Upload dSYM files through the mobile monitoring UI",
        "Manually upload dSYM files",
        "Via Python script (agent versions 6.0.0 or higher)",
        "Via command line",
        "Troubleshooting",
        "Auto-upload failure",
        "Missing dSYMs"
      ],
      "title": "Upload dSYM files",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Configuration"
      ],
      "external_id": "3655f49cf0e1ae693de0f8ea45bf4e5e6437e399",
      "image": "https://docs.newrelic.com/static/5c859575f391fbb1eaa18243a8c97000/8c557/Screen-Shot-2014-09-23-at-11.30.35-AM_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/configuration/upload-dsyms-bitcode-apps/",
      "published_at": "2021-09-27T15:06:37Z",
      "updated_at": "2021-09-27T15:06:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your app's dSYM files are stored in Xcode's dSYM archive path folder. This is the folder where the iOS agent gets the dSYM files that are used to symbolicate your crash reports. New Relic provides a post-build script as part of the iOS agent's install process and the tvOS agent's install process. This script automatically uploads your app's dSYM files. Automatic script The script automatically uploads dSYM files only for release builds. Non-release builds must upload their files either manually or through the mobile monitoring UI. Bitcode-enabled apps have their dSYM files generated by Apple. You must download the dSYM files for Bitcode-enabled apps from Apple and upload them to New Relic. If you see unreadable machine code in the Crashes page, your dSYM files may not be uploaded correctly. In some cases, you may need to manually upload dSYM files. The automatic script uses Python 2. As of October 2019 with macOS 10.15 (Catalina), Python won't be installed by default. If you're using the automatic script (recommended), you may need to manually install Python 2. If you're using Homebrew, see Python on Homebrew. Identify missing dSYMs When a Bitcode-enabled app is uploaded to Apple for App Store review or ad-hoc distribution, dSYMs need to be manually downloaded from Apple and uploaded to New Relic to allow the mobile crash reports to be properly symbolicated. These dSYMs can be downloaded through the archives organizer in Xcode within several minutes of uploading the app. In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you'll see three indicators in the mobile monitoring UI: Banner notification: A banner warning appears on the Crash report page. The warning reads: We were unable to locate your dsym. Copy Upload prompt: From the Crash type summary page you will be automatically prompted to upload a dSYM file if it is missing. Machine code: The crash stack trace on the Crash report page displays machine code and not a human-readable error message. Upload dSYM files through the mobile monitoring UI You can easily upload your dSYM files directly from the New Relic One UI. The maximum file size is 600 MB. To upload your dSYM files: Go to one.newrelic.com and click Mobile. Then select your app from the list. View Crash analysis. Select a specific crash from the Crash types list. Click Upload dSYM. You can either drag and drop your dSYMs directly, or select the file form your computer. Manually upload dSYM files In some circumstances, New Relic's automatic upload of dSYM files may fail. If a dSYM upload is attempted and fails, it creates a build error with a detailed message. For example, if there's a network failure and the dSYM upload isn't completed, Xcode will report an error. For additional information about how New Relic handles dSYM uploads, see New Relic's Online Technical Community. If the automatic upload fails, you can manually upload your dSYM file. If you have multiple dSYM files, they can be within a single zip with a maximum file size of 600 MB. The YOUR_NEW_RELIC_APPLICATION_TOKEN value in the commands below is the same key used for +[NewRelic startWithApplicationToken:] (in Objective-C) or NewRelic.start(withApplicationToken:) (in Swift). To manually upload your dSYM files: Via Python script (agent versions 6.0.0 or higher) In iOS agent versions 6.0.0 or higher, the agent includes a Python script that automatically processes and uploads symbols. You can call this script from the command line: NewRelicAgent.framework/Resources/generateMap.py \"DSYM_ARCHIVE_PATH\" \"YOUR_NEW_RELIC_APPLICATION_TOKEN\" Copy Via command line To manually upload individual dSYM files from the command line: Zip up your dSYM file or files using the following command. Replace ~ /ZIPPED_DSYM_PATH with your new dSYM archive path and file name (for example, Users/my-name/desktop). Also replace ~ /dSYM_PATH with your existing dSYM file path. /usr/bin/zip --recurse-paths --quiet \"~/ZIPPED_DSYM_PATH\" \"~/dSYM_PATH\" Copy Upload the dSYM zip file using the following command: For US accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.newrelic.com/symbol Copy For EU accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.eu01.nr-data.net/symbol Copy Troubleshooting Auto-upload failure If a dSYM auto-upload failed, the Report Navigator may have a fully formed cURL command. You can use this cURL command to reattempt an upload. Depending on the error, you may also need to follow some of the dSYM manual upload steps. Here is an example of a successful dSYM upload in the Report Navigator: Example: A successful dSYM upload in the Report Navigator. Missing dSYMs If dSYM files are missing, you may need to check Xcode build settings to ensure the file is being generated. Frameworks which are built locally have separate build settings and may need to be updated as well. Build settings: Debug Information Format : Dwarf with dSYM File Deployment Postprocessing: Yes Strip Linked Product: Yes Strip Debug Symbols During Copy : Yes Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.50992,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Upload dSYM files through the <em>mobile</em> <em>monitoring</em> <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": ". In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you&#x27;ll see three indicators in the <em>mobile</em> <em>monitoring</em> <em>UI</em>: Banner notification: A banner warning appears on the <em>Crash</em> report page. The warning reads: We were unable to locate your dsym. Copy"
      },
      "id": "60441960e7b9d24f705799ca"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-09-27T03:00:13Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.46378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-09-27T02:59:21Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.45244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/handled-exceptions-occurrences": [
    {
      "sections": [
        "Upload dSYM files",
        "Automatic script",
        "Identify missing dSYMs",
        "Upload dSYM files through the mobile monitoring UI",
        "Manually upload dSYM files",
        "Via Python script (agent versions 6.0.0 or higher)",
        "Via command line",
        "Troubleshooting",
        "Auto-upload failure",
        "Missing dSYMs"
      ],
      "title": "Upload dSYM files",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Configuration"
      ],
      "external_id": "3655f49cf0e1ae693de0f8ea45bf4e5e6437e399",
      "image": "https://docs.newrelic.com/static/5c859575f391fbb1eaa18243a8c97000/8c557/Screen-Shot-2014-09-23-at-11.30.35-AM_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/configuration/upload-dsyms-bitcode-apps/",
      "published_at": "2021-09-27T15:06:37Z",
      "updated_at": "2021-09-27T15:06:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your app's dSYM files are stored in Xcode's dSYM archive path folder. This is the folder where the iOS agent gets the dSYM files that are used to symbolicate your crash reports. New Relic provides a post-build script as part of the iOS agent's install process and the tvOS agent's install process. This script automatically uploads your app's dSYM files. Automatic script The script automatically uploads dSYM files only for release builds. Non-release builds must upload their files either manually or through the mobile monitoring UI. Bitcode-enabled apps have their dSYM files generated by Apple. You must download the dSYM files for Bitcode-enabled apps from Apple and upload them to New Relic. If you see unreadable machine code in the Crashes page, your dSYM files may not be uploaded correctly. In some cases, you may need to manually upload dSYM files. The automatic script uses Python 2. As of October 2019 with macOS 10.15 (Catalina), Python won't be installed by default. If you're using the automatic script (recommended), you may need to manually install Python 2. If you're using Homebrew, see Python on Homebrew. Identify missing dSYMs When a Bitcode-enabled app is uploaded to Apple for App Store review or ad-hoc distribution, dSYMs need to be manually downloaded from Apple and uploaded to New Relic to allow the mobile crash reports to be properly symbolicated. These dSYMs can be downloaded through the archives organizer in Xcode within several minutes of uploading the app. In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you'll see three indicators in the mobile monitoring UI: Banner notification: A banner warning appears on the Crash report page. The warning reads: We were unable to locate your dsym. Copy Upload prompt: From the Crash type summary page you will be automatically prompted to upload a dSYM file if it is missing. Machine code: The crash stack trace on the Crash report page displays machine code and not a human-readable error message. Upload dSYM files through the mobile monitoring UI You can easily upload your dSYM files directly from the New Relic One UI. The maximum file size is 600 MB. To upload your dSYM files: Go to one.newrelic.com and click Mobile. Then select your app from the list. View Crash analysis. Select a specific crash from the Crash types list. Click Upload dSYM. You can either drag and drop your dSYMs directly, or select the file form your computer. Manually upload dSYM files In some circumstances, New Relic's automatic upload of dSYM files may fail. If a dSYM upload is attempted and fails, it creates a build error with a detailed message. For example, if there's a network failure and the dSYM upload isn't completed, Xcode will report an error. For additional information about how New Relic handles dSYM uploads, see New Relic's Online Technical Community. If the automatic upload fails, you can manually upload your dSYM file. If you have multiple dSYM files, they can be within a single zip with a maximum file size of 600 MB. The YOUR_NEW_RELIC_APPLICATION_TOKEN value in the commands below is the same key used for +[NewRelic startWithApplicationToken:] (in Objective-C) or NewRelic.start(withApplicationToken:) (in Swift). To manually upload your dSYM files: Via Python script (agent versions 6.0.0 or higher) In iOS agent versions 6.0.0 or higher, the agent includes a Python script that automatically processes and uploads symbols. You can call this script from the command line: NewRelicAgent.framework/Resources/generateMap.py \"DSYM_ARCHIVE_PATH\" \"YOUR_NEW_RELIC_APPLICATION_TOKEN\" Copy Via command line To manually upload individual dSYM files from the command line: Zip up your dSYM file or files using the following command. Replace ~ /ZIPPED_DSYM_PATH with your new dSYM archive path and file name (for example, Users/my-name/desktop). Also replace ~ /dSYM_PATH with your existing dSYM file path. /usr/bin/zip --recurse-paths --quiet \"~/ZIPPED_DSYM_PATH\" \"~/dSYM_PATH\" Copy Upload the dSYM zip file using the following command: For US accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.newrelic.com/symbol Copy For EU accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.eu01.nr-data.net/symbol Copy Troubleshooting Auto-upload failure If a dSYM auto-upload failed, the Report Navigator may have a fully formed cURL command. You can use this cURL command to reattempt an upload. Depending on the error, you may also need to follow some of the dSYM manual upload steps. Here is an example of a successful dSYM upload in the Report Navigator: Example: A successful dSYM upload in the Report Navigator. Missing dSYMs If dSYM files are missing, you may need to check Xcode build settings to ensure the file is being generated. Frameworks which are built locally have separate build settings and may need to be updated as well. Build settings: Debug Information Format : Dwarf with dSYM File Deployment Postprocessing: Yes Strip Linked Product: Yes Strip Debug Symbols During Copy : Yes Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.50992,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Upload dSYM files through the <em>mobile</em> <em>monitoring</em> <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": ". In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you&#x27;ll see three indicators in the <em>mobile</em> <em>monitoring</em> <em>UI</em>: Banner notification: A banner warning appears on the <em>Crash</em> report page. The warning reads: We were unable to locate your dsym. Copy"
      },
      "id": "60441960e7b9d24f705799ca"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-09-27T03:00:13Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.46378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-09-27T02:59:21Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.45244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions": [
    {
      "sections": [
        "Upload dSYM files",
        "Automatic script",
        "Identify missing dSYMs",
        "Upload dSYM files through the mobile monitoring UI",
        "Manually upload dSYM files",
        "Via Python script (agent versions 6.0.0 or higher)",
        "Via command line",
        "Troubleshooting",
        "Auto-upload failure",
        "Missing dSYMs"
      ],
      "title": "Upload dSYM files",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Configuration"
      ],
      "external_id": "3655f49cf0e1ae693de0f8ea45bf4e5e6437e399",
      "image": "https://docs.newrelic.com/static/5c859575f391fbb1eaa18243a8c97000/8c557/Screen-Shot-2014-09-23-at-11.30.35-AM_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/configuration/upload-dsyms-bitcode-apps/",
      "published_at": "2021-09-27T15:06:37Z",
      "updated_at": "2021-09-27T15:06:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your app's dSYM files are stored in Xcode's dSYM archive path folder. This is the folder where the iOS agent gets the dSYM files that are used to symbolicate your crash reports. New Relic provides a post-build script as part of the iOS agent's install process and the tvOS agent's install process. This script automatically uploads your app's dSYM files. Automatic script The script automatically uploads dSYM files only for release builds. Non-release builds must upload their files either manually or through the mobile monitoring UI. Bitcode-enabled apps have their dSYM files generated by Apple. You must download the dSYM files for Bitcode-enabled apps from Apple and upload them to New Relic. If you see unreadable machine code in the Crashes page, your dSYM files may not be uploaded correctly. In some cases, you may need to manually upload dSYM files. The automatic script uses Python 2. As of October 2019 with macOS 10.15 (Catalina), Python won't be installed by default. If you're using the automatic script (recommended), you may need to manually install Python 2. If you're using Homebrew, see Python on Homebrew. Identify missing dSYMs When a Bitcode-enabled app is uploaded to Apple for App Store review or ad-hoc distribution, dSYMs need to be manually downloaded from Apple and uploaded to New Relic to allow the mobile crash reports to be properly symbolicated. These dSYMs can be downloaded through the archives organizer in Xcode within several minutes of uploading the app. In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you'll see three indicators in the mobile monitoring UI: Banner notification: A banner warning appears on the Crash report page. The warning reads: We were unable to locate your dsym. Copy Upload prompt: From the Crash type summary page you will be automatically prompted to upload a dSYM file if it is missing. Machine code: The crash stack trace on the Crash report page displays machine code and not a human-readable error message. Upload dSYM files through the mobile monitoring UI You can easily upload your dSYM files directly from the New Relic One UI. The maximum file size is 600 MB. To upload your dSYM files: Go to one.newrelic.com and click Mobile. Then select your app from the list. View Crash analysis. Select a specific crash from the Crash types list. Click Upload dSYM. You can either drag and drop your dSYMs directly, or select the file form your computer. Manually upload dSYM files In some circumstances, New Relic's automatic upload of dSYM files may fail. If a dSYM upload is attempted and fails, it creates a build error with a detailed message. For example, if there's a network failure and the dSYM upload isn't completed, Xcode will report an error. For additional information about how New Relic handles dSYM uploads, see New Relic's Online Technical Community. If the automatic upload fails, you can manually upload your dSYM file. If you have multiple dSYM files, they can be within a single zip with a maximum file size of 600 MB. The YOUR_NEW_RELIC_APPLICATION_TOKEN value in the commands below is the same key used for +[NewRelic startWithApplicationToken:] (in Objective-C) or NewRelic.start(withApplicationToken:) (in Swift). To manually upload your dSYM files: Via Python script (agent versions 6.0.0 or higher) In iOS agent versions 6.0.0 or higher, the agent includes a Python script that automatically processes and uploads symbols. You can call this script from the command line: NewRelicAgent.framework/Resources/generateMap.py \"DSYM_ARCHIVE_PATH\" \"YOUR_NEW_RELIC_APPLICATION_TOKEN\" Copy Via command line To manually upload individual dSYM files from the command line: Zip up your dSYM file or files using the following command. Replace ~ /ZIPPED_DSYM_PATH with your new dSYM archive path and file name (for example, Users/my-name/desktop). Also replace ~ /dSYM_PATH with your existing dSYM file path. /usr/bin/zip --recurse-paths --quiet \"~/ZIPPED_DSYM_PATH\" \"~/dSYM_PATH\" Copy Upload the dSYM zip file using the following command: For US accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.newrelic.com/symbol Copy For EU accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.eu01.nr-data.net/symbol Copy Troubleshooting Auto-upload failure If a dSYM auto-upload failed, the Report Navigator may have a fully formed cURL command. You can use this cURL command to reattempt an upload. Depending on the error, you may also need to follow some of the dSYM manual upload steps. Here is an example of a successful dSYM upload in the Report Navigator: Example: A successful dSYM upload in the Report Navigator. Missing dSYMs If dSYM files are missing, you may need to check Xcode build settings to ensure the file is being generated. Frameworks which are built locally have separate build settings and may need to be updated as well. Build settings: Debug Information Format : Dwarf with dSYM File Deployment Postprocessing: Yes Strip Linked Product: Yes Strip Debug Symbols During Copy : Yes Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.5098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Upload dSYM files through the <em>mobile</em> <em>monitoring</em> <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": ". In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you&#x27;ll see three indicators in the <em>mobile</em> <em>monitoring</em> <em>UI</em>: Banner notification: A banner warning appears on the <em>Crash</em> report page. The warning reads: We were unable to locate your dsym. Copy"
      },
      "id": "60441960e7b9d24f705799ca"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-09-27T03:00:13Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.46376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Handled exceptions: Analyze trends, prevent crashes",
        "Handled exceptions workflow",
        "Exception percentage charts",
        "Exception percentage charts example",
        "Groups and filters",
        "Groups and filters example",
        "Top five exception locations",
        "Top five exception locations example",
        "Query builder links",
        "Exception locations table",
        "Exception locations table example"
      ],
      "title": "Handled exceptions: Analyze trends, prevent crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "d325744648613b771d7dd39de3f1448fe8a54ab9",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/handled-exceptions-analyze-trends-prevent-crashes/",
      "published_at": "2021-09-27T02:58:23Z",
      "updated_at": "2021-07-21T21:33:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Handled exceptions help you identify significant factors contributing to poor mobile application experience, and use filterable data to find a resolution more quickly. You can also use the handled exceptions API to customize the data you send, and use NRQL to query and share the data. Handled exceptions workflow To get the most out of the Handled exceptions UI, use this basic workflow: Go to one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions. Use any of New Relic's standard page functions to drill down into detailed information; for example, zoom into any area of a chart. Look for obvious or general trends in the Users affected and Sessions affected percentage charts. Adjust the types of exceptions shown by using groups and filters. Optional: Query or share the chart data. Look for similar patterns where exceptions appear in stack traces with the Top 5 exception locations table. To view stack trace thread details for each occurrence of the exception, select a record from the Top 5 exceptions location table. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Exception percentage charts Start with the Users affected and Sessions affected percentage charts to see at a glance whether there are any unexpected spikes, dips, or patterns with exceptions in general. (If the Users affected chart is empty, there were no user sessions during the selected time period.) For example: Are there any spikes near a recent version release? Is there a time period when the percentage of users has been affected significantly by the exception? Are there uneventful periods? To examine data in greater detail: Below any chart, select Expand chart. Exception percentage charts example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: The percentage charts help you quickly see any unexpected spikes, dips, or patterns with exceptions in general. Groups and filters Use the groups and filters to examine attributes for crashes, devices, locations, or other custom attributes in more detail. You can select a group, then filter to specific data. For example: Group the list by exception location (default), cause, app build or version, devices, connections, or other custom attributes. This lets you discover patterns in your exceptions to determine the root cause. Use the time picker to adjust the currently selected time period. Filter by a specific Version or by one or more attribute Filter, such as appVersion, exceptionLocationMethod, lastInteraction, or any of the longer list of standard and custom attributes. The currently selected filters appear at the top of the UI page. You can close them, add other filters, or select other groups and filters. Groups and filters example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: Group the data by attributes that matter to the most to you, then select one or more filters to help pinpoint specific causes behind the exceptions. Top five exception locations Use the Top 5 exception locations table to find or sort patterns in the type of exception you selected from the groups and filters. This includes: Recurring locations in the stack trace Mobile app version Number of occurrences Number of users affected during the selected time period For example, you can group by Exception Message, filter to timeout message, then select individual timeout locations from the table to review the stack trace thread and details about each occurrence. To filter or group by other attributes, use the table's search window, or select any of the available filters. For example, filter by type of occurrence, device, a specific location, or any custom attributes. To look for other historical patterns, change the selected time period. Top five exception locations example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: This example shows the Expand chart button and links to the query builder, where you can query, create dashboards, and share the handled exceptions data. Query builder links Handled exceptions charts use default attributes for mobile events (including MobileHandledException), along with any custom attributes you have added to this event type. When you mouse over the charts, direct links appear below them. These links to the query builder allow you to analyze your mobile app data even deeper. View query link: View the NRQL query used to calculate the chart data. View in query builder link: View the chart, and share it with others. Exception locations table The Exception locations table supplements the charts. It lists where the top five handled exceptions appear in their stack trace thread, and links them to relevant details. Each row helps you find answers to questions such as: How many of this exception occurred within the selected time period? Does a specific app version have a higher (or lower) number of users affected? Which exception has the fewest number of occurrences? You can change the sort order or filter options to focus on just the types of exceptions that matter the most to you and your teams. To view additional thread details for each occurrence of the exception, select a record from the Top 5 exceptions location table. Exception locations table example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: To continue to the handled exception's Occurrences page, select any row on the table.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.42563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Handled exceptions: Analyze trends, prevent <em>crashes</em>",
        "sections": "Handled exceptions: Analyze trends, prevent <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " exceptions workflow To get the most out of the Handled exceptions <em>UI</em>, use this basic workflow: Go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select an app) &gt; Exceptions &gt; Handled exceptions. Use any of New Relic&#x27;s standard page functions to drill down into detailed information; for example, zoom into any area"
      },
      "id": "604505ae28ccbc783e2c6085"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/investigate-mobile-app-crash-report": [
    {
      "sections": [
        "Upload dSYM files",
        "Automatic script",
        "Identify missing dSYMs",
        "Upload dSYM files through the mobile monitoring UI",
        "Manually upload dSYM files",
        "Via Python script (agent versions 6.0.0 or higher)",
        "Via command line",
        "Troubleshooting",
        "Auto-upload failure",
        "Missing dSYMs"
      ],
      "title": "Upload dSYM files",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Configuration"
      ],
      "external_id": "3655f49cf0e1ae693de0f8ea45bf4e5e6437e399",
      "image": "https://docs.newrelic.com/static/5c859575f391fbb1eaa18243a8c97000/8c557/Screen-Shot-2014-09-23-at-11.30.35-AM_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/configuration/upload-dsyms-bitcode-apps/",
      "published_at": "2021-09-27T15:06:37Z",
      "updated_at": "2021-09-27T15:06:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your app's dSYM files are stored in Xcode's dSYM archive path folder. This is the folder where the iOS agent gets the dSYM files that are used to symbolicate your crash reports. New Relic provides a post-build script as part of the iOS agent's install process and the tvOS agent's install process. This script automatically uploads your app's dSYM files. Automatic script The script automatically uploads dSYM files only for release builds. Non-release builds must upload their files either manually or through the mobile monitoring UI. Bitcode-enabled apps have their dSYM files generated by Apple. You must download the dSYM files for Bitcode-enabled apps from Apple and upload them to New Relic. If you see unreadable machine code in the Crashes page, your dSYM files may not be uploaded correctly. In some cases, you may need to manually upload dSYM files. The automatic script uses Python 2. As of October 2019 with macOS 10.15 (Catalina), Python won't be installed by default. If you're using the automatic script (recommended), you may need to manually install Python 2. If you're using Homebrew, see Python on Homebrew. Identify missing dSYMs When a Bitcode-enabled app is uploaded to Apple for App Store review or ad-hoc distribution, dSYMs need to be manually downloaded from Apple and uploaded to New Relic to allow the mobile crash reports to be properly symbolicated. These dSYMs can be downloaded through the archives organizer in Xcode within several minutes of uploading the app. In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you'll see three indicators in the mobile monitoring UI: Banner notification: A banner warning appears on the Crash report page. The warning reads: We were unable to locate your dsym. Copy Upload prompt: From the Crash type summary page you will be automatically prompted to upload a dSYM file if it is missing. Machine code: The crash stack trace on the Crash report page displays machine code and not a human-readable error message. Upload dSYM files through the mobile monitoring UI You can easily upload your dSYM files directly from the New Relic One UI. The maximum file size is 600 MB. To upload your dSYM files: Go to one.newrelic.com and click Mobile. Then select your app from the list. View Crash analysis. Select a specific crash from the Crash types list. Click Upload dSYM. You can either drag and drop your dSYMs directly, or select the file form your computer. Manually upload dSYM files In some circumstances, New Relic's automatic upload of dSYM files may fail. If a dSYM upload is attempted and fails, it creates a build error with a detailed message. For example, if there's a network failure and the dSYM upload isn't completed, Xcode will report an error. For additional information about how New Relic handles dSYM uploads, see New Relic's Online Technical Community. If the automatic upload fails, you can manually upload your dSYM file. If you have multiple dSYM files, they can be within a single zip with a maximum file size of 600 MB. The YOUR_NEW_RELIC_APPLICATION_TOKEN value in the commands below is the same key used for +[NewRelic startWithApplicationToken:] (in Objective-C) or NewRelic.start(withApplicationToken:) (in Swift). To manually upload your dSYM files: Via Python script (agent versions 6.0.0 or higher) In iOS agent versions 6.0.0 or higher, the agent includes a Python script that automatically processes and uploads symbols. You can call this script from the command line: NewRelicAgent.framework/Resources/generateMap.py \"DSYM_ARCHIVE_PATH\" \"YOUR_NEW_RELIC_APPLICATION_TOKEN\" Copy Via command line To manually upload individual dSYM files from the command line: Zip up your dSYM file or files using the following command. Replace ~ /ZIPPED_DSYM_PATH with your new dSYM archive path and file name (for example, Users/my-name/desktop). Also replace ~ /dSYM_PATH with your existing dSYM file path. /usr/bin/zip --recurse-paths --quiet \"~/ZIPPED_DSYM_PATH\" \"~/dSYM_PATH\" Copy Upload the dSYM zip file using the following command: For US accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.newrelic.com/symbol Copy For EU accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.eu01.nr-data.net/symbol Copy Troubleshooting Auto-upload failure If a dSYM auto-upload failed, the Report Navigator may have a fully formed cURL command. You can use this cURL command to reattempt an upload. Depending on the error, you may also need to follow some of the dSYM manual upload steps. Here is an example of a successful dSYM upload in the Report Navigator: Example: A successful dSYM upload in the Report Navigator. Missing dSYMs If dSYM files are missing, you may need to check Xcode build settings to ensure the file is being generated. Frameworks which are built locally have separate build settings and may need to be updated as well. Build settings: Debug Information Format : Dwarf with dSYM File Deployment Postprocessing: Yes Strip Linked Product: Yes Strip Debug Symbols During Copy : Yes Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.5098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Upload dSYM files through the <em>mobile</em> <em>monitoring</em> <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": ". In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you&#x27;ll see three indicators in the <em>mobile</em> <em>monitoring</em> <em>UI</em>: Banner notification: A banner warning appears on the <em>Crash</em> report page. The warning reads: We were unable to locate your dsym. Copy"
      },
      "id": "60441960e7b9d24f705799ca"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-09-27T03:00:13Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.46376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-09-27T02:59:21Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.45244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail": [
    {
      "sections": [
        "Upload dSYM files",
        "Automatic script",
        "Identify missing dSYMs",
        "Upload dSYM files through the mobile monitoring UI",
        "Manually upload dSYM files",
        "Via Python script (agent versions 6.0.0 or higher)",
        "Via command line",
        "Troubleshooting",
        "Auto-upload failure",
        "Missing dSYMs"
      ],
      "title": "Upload dSYM files",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Configuration"
      ],
      "external_id": "3655f49cf0e1ae693de0f8ea45bf4e5e6437e399",
      "image": "https://docs.newrelic.com/static/5c859575f391fbb1eaa18243a8c97000/8c557/Screen-Shot-2014-09-23-at-11.30.35-AM_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/configuration/upload-dsyms-bitcode-apps/",
      "published_at": "2021-09-27T15:06:37Z",
      "updated_at": "2021-09-27T15:06:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your app's dSYM files are stored in Xcode's dSYM archive path folder. This is the folder where the iOS agent gets the dSYM files that are used to symbolicate your crash reports. New Relic provides a post-build script as part of the iOS agent's install process and the tvOS agent's install process. This script automatically uploads your app's dSYM files. Automatic script The script automatically uploads dSYM files only for release builds. Non-release builds must upload their files either manually or through the mobile monitoring UI. Bitcode-enabled apps have their dSYM files generated by Apple. You must download the dSYM files for Bitcode-enabled apps from Apple and upload them to New Relic. If you see unreadable machine code in the Crashes page, your dSYM files may not be uploaded correctly. In some cases, you may need to manually upload dSYM files. The automatic script uses Python 2. As of October 2019 with macOS 10.15 (Catalina), Python won't be installed by default. If you're using the automatic script (recommended), you may need to manually install Python 2. If you're using Homebrew, see Python on Homebrew. Identify missing dSYMs When a Bitcode-enabled app is uploaded to Apple for App Store review or ad-hoc distribution, dSYMs need to be manually downloaded from Apple and uploaded to New Relic to allow the mobile crash reports to be properly symbolicated. These dSYMs can be downloaded through the archives organizer in Xcode within several minutes of uploading the app. In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you'll see three indicators in the mobile monitoring UI: Banner notification: A banner warning appears on the Crash report page. The warning reads: We were unable to locate your dsym. Copy Upload prompt: From the Crash type summary page you will be automatically prompted to upload a dSYM file if it is missing. Machine code: The crash stack trace on the Crash report page displays machine code and not a human-readable error message. Upload dSYM files through the mobile monitoring UI You can easily upload your dSYM files directly from the New Relic One UI. The maximum file size is 600 MB. To upload your dSYM files: Go to one.newrelic.com and click Mobile. Then select your app from the list. View Crash analysis. Select a specific crash from the Crash types list. Click Upload dSYM. You can either drag and drop your dSYMs directly, or select the file form your computer. Manually upload dSYM files In some circumstances, New Relic's automatic upload of dSYM files may fail. If a dSYM upload is attempted and fails, it creates a build error with a detailed message. For example, if there's a network failure and the dSYM upload isn't completed, Xcode will report an error. For additional information about how New Relic handles dSYM uploads, see New Relic's Online Technical Community. If the automatic upload fails, you can manually upload your dSYM file. If you have multiple dSYM files, they can be within a single zip with a maximum file size of 600 MB. The YOUR_NEW_RELIC_APPLICATION_TOKEN value in the commands below is the same key used for +[NewRelic startWithApplicationToken:] (in Objective-C) or NewRelic.start(withApplicationToken:) (in Swift). To manually upload your dSYM files: Via Python script (agent versions 6.0.0 or higher) In iOS agent versions 6.0.0 or higher, the agent includes a Python script that automatically processes and uploads symbols. You can call this script from the command line: NewRelicAgent.framework/Resources/generateMap.py \"DSYM_ARCHIVE_PATH\" \"YOUR_NEW_RELIC_APPLICATION_TOKEN\" Copy Via command line To manually upload individual dSYM files from the command line: Zip up your dSYM file or files using the following command. Replace ~ /ZIPPED_DSYM_PATH with your new dSYM archive path and file name (for example, Users/my-name/desktop). Also replace ~ /dSYM_PATH with your existing dSYM file path. /usr/bin/zip --recurse-paths --quiet \"~/ZIPPED_DSYM_PATH\" \"~/dSYM_PATH\" Copy Upload the dSYM zip file using the following command: For US accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.newrelic.com/symbol Copy For EU accounts: curl -F dsym=@\"~/DSYM_ZIP_PATH\" -H \"X-APP-LICENSE-KEY: YOUR_NEW_RELIC_APPLICATION_TOKEN\" https://mobile-symbol-upload.eu01.nr-data.net/symbol Copy Troubleshooting Auto-upload failure If a dSYM auto-upload failed, the Report Navigator may have a fully formed cURL command. You can use this cURL command to reattempt an upload. Depending on the error, you may also need to follow some of the dSYM manual upload steps. Here is an example of a successful dSYM upload in the Report Navigator: Example: A successful dSYM upload in the Report Navigator. Missing dSYMs If dSYM files are missing, you may need to check Xcode build settings to ensure the file is being generated. Frameworks which are built locally have separate build settings and may need to be updated as well. Build settings: Debug Information Format : Dwarf with dSYM File Deployment Postprocessing: Yes Strip Linked Product: Yes Strip Debug Symbols During Copy : Yes Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.50967,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Upload dSYM files through the <em>mobile</em> <em>monitoring</em> <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": ". In this situation follow the procedures to find the archive and download dSYMs. If an app is missing a dSYM file, you&#x27;ll see three indicators in the <em>mobile</em> <em>monitoring</em> <em>UI</em>: Banner notification: A banner warning appears on the <em>Crash</em> report page. The warning reads: We were unable to locate your dsym. Copy"
      },
      "id": "60441960e7b9d24f705799ca"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-09-27T02:59:21Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.45244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    },
    {
      "sections": [
        "Handled exceptions: Analyze trends, prevent crashes",
        "Handled exceptions workflow",
        "Exception percentage charts",
        "Exception percentage charts example",
        "Groups and filters",
        "Groups and filters example",
        "Top five exception locations",
        "Top five exception locations example",
        "Query builder links",
        "Exception locations table",
        "Exception locations table example"
      ],
      "title": "Handled exceptions: Analyze trends, prevent crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "d325744648613b771d7dd39de3f1448fe8a54ab9",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/handled-exceptions-analyze-trends-prevent-crashes/",
      "published_at": "2021-09-27T02:58:23Z",
      "updated_at": "2021-07-21T21:33:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Handled exceptions help you identify significant factors contributing to poor mobile application experience, and use filterable data to find a resolution more quickly. You can also use the handled exceptions API to customize the data you send, and use NRQL to query and share the data. Handled exceptions workflow To get the most out of the Handled exceptions UI, use this basic workflow: Go to one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions. Use any of New Relic's standard page functions to drill down into detailed information; for example, zoom into any area of a chart. Look for obvious or general trends in the Users affected and Sessions affected percentage charts. Adjust the types of exceptions shown by using groups and filters. Optional: Query or share the chart data. Look for similar patterns where exceptions appear in stack traces with the Top 5 exception locations table. To view stack trace thread details for each occurrence of the exception, select a record from the Top 5 exceptions location table. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Exception percentage charts Start with the Users affected and Sessions affected percentage charts to see at a glance whether there are any unexpected spikes, dips, or patterns with exceptions in general. (If the Users affected chart is empty, there were no user sessions during the selected time period.) For example: Are there any spikes near a recent version release? Is there a time period when the percentage of users has been affected significantly by the exception? Are there uneventful periods? To examine data in greater detail: Below any chart, select Expand chart. Exception percentage charts example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: The percentage charts help you quickly see any unexpected spikes, dips, or patterns with exceptions in general. Groups and filters Use the groups and filters to examine attributes for crashes, devices, locations, or other custom attributes in more detail. You can select a group, then filter to specific data. For example: Group the list by exception location (default), cause, app build or version, devices, connections, or other custom attributes. This lets you discover patterns in your exceptions to determine the root cause. Use the time picker to adjust the currently selected time period. Filter by a specific Version or by one or more attribute Filter, such as appVersion, exceptionLocationMethod, lastInteraction, or any of the longer list of standard and custom attributes. The currently selected filters appear at the top of the UI page. You can close them, add other filters, or select other groups and filters. Groups and filters example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: Group the data by attributes that matter to the most to you, then select one or more filters to help pinpoint specific causes behind the exceptions. Top five exception locations Use the Top 5 exception locations table to find or sort patterns in the type of exception you selected from the groups and filters. This includes: Recurring locations in the stack trace Mobile app version Number of occurrences Number of users affected during the selected time period For example, you can group by Exception Message, filter to timeout message, then select individual timeout locations from the table to review the stack trace thread and details about each occurrence. To filter or group by other attributes, use the table's search window, or select any of the available filters. For example, filter by type of occurrence, device, a specific location, or any custom attributes. To look for other historical patterns, change the selected time period. Top five exception locations example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: This example shows the Expand chart button and links to the query builder, where you can query, create dashboards, and share the handled exceptions data. Query builder links Handled exceptions charts use default attributes for mobile events (including MobileHandledException), along with any custom attributes you have added to this event type. When you mouse over the charts, direct links appear below them. These links to the query builder allow you to analyze your mobile app data even deeper. View query link: View the NRQL query used to calculate the chart data. View in query builder link: View the chart, and share it with others. Exception locations table The Exception locations table supplements the charts. It lists where the top five handled exceptions appear in their stack trace thread, and links them to relevant details. Each row helps you find answers to questions such as: How many of this exception occurred within the selected time period? Does a specific app version have a higher (or lower) number of users affected? Which exception has the fewest number of occurrences? You can change the sort order or filter options to focus on just the types of exceptions that matter the most to you and your teams. To view additional thread details for each occurrence of the exception, select a record from the Top 5 exceptions location table. Exception locations table example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: To continue to the handled exception's Occurrences page, select any row on the table.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.42563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Handled exceptions: Analyze trends, prevent <em>crashes</em>",
        "sections": "Handled exceptions: Analyze trends, prevent <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " exceptions workflow To get the most out of the Handled exceptions <em>UI</em>, use this basic workflow: Go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select an app) &gt; Exceptions &gt; Handled exceptions. Use any of New Relic&#x27;s standard page functions to drill down into detailed information; for example, zoom into any area"
      },
      "id": "604505ae28ccbc783e2c6085"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/alerts-page-mobile-apps": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-09-27T03:01:15Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.96527,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-09-27T03:02:22Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.03967,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-09-27T03:04:49Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.99557,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/devices-page": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-09-27T03:01:15Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.96527,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-09-27T03:02:22Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.03967,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-09-27T03:04:49Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.99556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/interactions-page": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-09-27T03:01:15Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.96527,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-09-27T03:02:22Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.03967,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-09-27T03:04:49Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.99556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index": [
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-09-27T03:02:22Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.03967,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-09-27T03:04:49Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.99556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    },
    {
      "sections": [
        "Mobile apps Overview page",
        "Key app metrics",
        "View the Overview page",
        "View drill-down details"
      ],
      "title": "Mobile apps Overview page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "cd97681b7f6391d971176efba71c85e0fdc76680",
      "image": "https://docs.newrelic.com/static/815e271adddca68b8f3e3810b09f8045/c1b63/new-mobile-apps-overview.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-overview-page/",
      "published_at": "2021-09-27T03:02:22Z",
      "updated_at": "2021-07-09T11:45:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Overview page provides an operational snapshot of your mobile app. All charts, tables, and statistics show data for the currently selected time window and application version. Key app metrics The Overview page captures five key app metrics: Metric Description Application crash rate Plots the number of crashed sessions over time as a percentage of all sessions, broken out by app version. The average crashed session percent, total number of crashes, and count of unique users affected by those crashes during the time window is shown in the upper right. App launches Charts the number of app session launches monitored over the time window. New Relic defines a mobile session as beginning when an app appears on screen and ending when the app is sent to the background. HTTP errors / network failures Charts the number of network requests that result in a http status code error (400 or higher) as a percentage of all completed requests, and the number of failed network calls (for example, a connection failure) as a percentage of completed requests. HTTP response time Charts the average response time of all completed http requests from each of the top five hosts your app communicates with. Top five is calculated based on count of completed requests to each host. Frequent interactions Presents key performance metrics for each of the five most commonly executed Interactions in your app. View the Overview page To view the Overview page for your mobile apps: Go to one.newrelic.com > Mobile > (select an app). To view other pages for your mobile app, select the links from the Overview page or from the Mobile menus. one.newrelic.com > Mobile > (select an app): The Overview page provides charts and tables that you can drill down into, to gain insights about your mobile application's performance. View drill-down details Use any of New Relic's standard user interface functions and page functions to drill down into detailed information. The Overview page includes several additional options. If you want to... Do this Limit information to a specific version of your app Select your choice from the Versions menu below the New Relic menu bar (if applicable). View the Overview page for another mobile app Use the dropdown menu from the currently selected mobile app's title OR: Go to one.newrelic.com > Mobile > Select and App. View additional details about interactions Select the Frequent interactions table's title OR select a named Interaction in the table to drill into that interaction directly. View additional details about mobile app crashes Select the Crash rate chart's title to go to the Crash list page. View additional details about mobile versions Select the App launches chart's title to go to the Versions page. View additional details about HTTP response time Select a point anywhere in the HTTP response time chart to go to the HTTP requests page. View additional details about HTTP errors or network failures Select the HTTP errors/network failure chart's title, OR click anywhere in the table to go to the Errors page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.99544,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "sections": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " &gt; <em>Mobile</em> &gt; (select an <em>app</em>). To view other <em>pages</em> for your <em>mobile</em> <em>app</em>, select the links from the Overview <em>page</em> or from the <em>Mobile</em> menus. one.newrelic.com &gt; <em>Mobile</em> &gt; (select an <em>app</em>): The Overview <em>page</em> provides charts and tables that you can drill down into, to gain insights about your <em>mobile</em> application"
      },
      "id": "60450e1728ccbc840c2c60d8"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-overview-page": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-09-27T03:01:15Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.96526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-09-27T03:02:22Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.03967,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-09-27T03:04:49Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.99556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-monitoring-email-notifications": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-09-27T03:01:15Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.96526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-09-27T03:02:22Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.03967,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-09-27T03:04:49Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.99556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-09-27T03:01:15Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.96524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-09-27T03:02:22Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.03966,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "Mobile apps Overview page",
        "Key app metrics",
        "View the Overview page",
        "View drill-down details"
      ],
      "title": "Mobile apps Overview page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "cd97681b7f6391d971176efba71c85e0fdc76680",
      "image": "https://docs.newrelic.com/static/815e271adddca68b8f3e3810b09f8045/c1b63/new-mobile-apps-overview.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-overview-page/",
      "published_at": "2021-09-27T03:02:22Z",
      "updated_at": "2021-07-09T11:45:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Overview page provides an operational snapshot of your mobile app. All charts, tables, and statistics show data for the currently selected time window and application version. Key app metrics The Overview page captures five key app metrics: Metric Description Application crash rate Plots the number of crashed sessions over time as a percentage of all sessions, broken out by app version. The average crashed session percent, total number of crashes, and count of unique users affected by those crashes during the time window is shown in the upper right. App launches Charts the number of app session launches monitored over the time window. New Relic defines a mobile session as beginning when an app appears on screen and ending when the app is sent to the background. HTTP errors / network failures Charts the number of network requests that result in a http status code error (400 or higher) as a percentage of all completed requests, and the number of failed network calls (for example, a connection failure) as a percentage of completed requests. HTTP response time Charts the average response time of all completed http requests from each of the top five hosts your app communicates with. Top five is calculated based on count of completed requests to each host. Frequent interactions Presents key performance metrics for each of the five most commonly executed Interactions in your app. View the Overview page To view the Overview page for your mobile apps: Go to one.newrelic.com > Mobile > (select an app). To view other pages for your mobile app, select the links from the Overview page or from the Mobile menus. one.newrelic.com > Mobile > (select an app): The Overview page provides charts and tables that you can drill down into, to gain insights about your mobile application's performance. View drill-down details Use any of New Relic's standard user interface functions and page functions to drill down into detailed information. The Overview page includes several additional options. If you want to... Do this Limit information to a specific version of your app Select your choice from the Versions menu below the New Relic menu bar (if applicable). View the Overview page for another mobile app Use the dropdown menu from the currently selected mobile app's title OR: Go to one.newrelic.com > Mobile > Select and App. View additional details about interactions Select the Frequent interactions table's title OR select a named Interaction in the table to drill into that interaction directly. View additional details about mobile app crashes Select the Crash rate chart's title to go to the Crash list page. View additional details about mobile versions Select the App launches chart's title to go to the Versions page. View additional details about HTTP response time Select a point anywhere in the HTTP response time chart to go to the HTTP requests page. View additional details about HTTP errors or network failures Select the HTTP errors/network failure chart's title, OR click anywhere in the table to go to the Errors page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.99544,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "sections": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " &gt; <em>Mobile</em> &gt; (select an <em>app</em>). To view other <em>pages</em> for your <em>mobile</em> <em>app</em>, select the links from the Overview <em>page</em> or from the <em>Mobile</em> menus. one.newrelic.com &gt; <em>Mobile</em> &gt; (select an <em>app</em>): The Overview <em>page</em> provides charts and tables that you can drill down into, to gain insights about your <em>mobile</em> application"
      },
      "id": "60450e1728ccbc840c2c60d8"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-09-27T03:01:15Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.96524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-09-27T03:04:49Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.99556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    },
    {
      "sections": [
        "Mobile apps Overview page",
        "Key app metrics",
        "View the Overview page",
        "View drill-down details"
      ],
      "title": "Mobile apps Overview page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "cd97681b7f6391d971176efba71c85e0fdc76680",
      "image": "https://docs.newrelic.com/static/815e271adddca68b8f3e3810b09f8045/c1b63/new-mobile-apps-overview.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-overview-page/",
      "published_at": "2021-09-27T03:02:22Z",
      "updated_at": "2021-07-09T11:45:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Overview page provides an operational snapshot of your mobile app. All charts, tables, and statistics show data for the currently selected time window and application version. Key app metrics The Overview page captures five key app metrics: Metric Description Application crash rate Plots the number of crashed sessions over time as a percentage of all sessions, broken out by app version. The average crashed session percent, total number of crashes, and count of unique users affected by those crashes during the time window is shown in the upper right. App launches Charts the number of app session launches monitored over the time window. New Relic defines a mobile session as beginning when an app appears on screen and ending when the app is sent to the background. HTTP errors / network failures Charts the number of network requests that result in a http status code error (400 or higher) as a percentage of all completed requests, and the number of failed network calls (for example, a connection failure) as a percentage of completed requests. HTTP response time Charts the average response time of all completed http requests from each of the top five hosts your app communicates with. Top five is calculated based on count of completed requests to each host. Frequent interactions Presents key performance metrics for each of the five most commonly executed Interactions in your app. View the Overview page To view the Overview page for your mobile apps: Go to one.newrelic.com > Mobile > (select an app). To view other pages for your mobile app, select the links from the Overview page or from the Mobile menus. one.newrelic.com > Mobile > (select an app): The Overview page provides charts and tables that you can drill down into, to gain insights about your mobile application's performance. View drill-down details Use any of New Relic's standard user interface functions and page functions to drill down into detailed information. The Overview page includes several additional options. If you want to... Do this Limit information to a specific version of your app Select your choice from the Versions menu below the New Relic menu bar (if applicable). View the Overview page for another mobile app Use the dropdown menu from the currently selected mobile app's title OR: Go to one.newrelic.com > Mobile > Select and App. View additional details about interactions Select the Frequent interactions table's title OR select a named Interaction in the table to drill into that interaction directly. View additional details about mobile app crashes Select the Crash rate chart's title to go to the Crash list page. View additional details about mobile versions Select the App launches chart's title to go to the Versions page. View additional details about HTTP response time Select a point anywhere in the HTTP response time chart to go to the HTTP requests page. View additional details about HTTP errors or network failures Select the HTTP errors/network failure chart's title, OR click anywhere in the table to go to the Errors page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.99544,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "sections": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " &gt; <em>Mobile</em> &gt; (select an <em>app</em>). To view other <em>pages</em> for your <em>mobile</em> <em>app</em>, select the links from the Overview <em>page</em> or from the <em>Mobile</em> menus. one.newrelic.com &gt; <em>Mobile</em> &gt; (select an <em>app</em>): The Overview <em>page</em> provides charts and tables that you can drill down into, to gain insights about your <em>mobile</em> application"
      },
      "id": "60450e1728ccbc840c2c60d8"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/analyze-network-requests-using-mobilerequest-event-data": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-26T22:36:15Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.60715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "Important",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "https://docs.newrelic.com/static/44339db3414bda429d69b74258ab64e8/8c557/screen-http-requests-details_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-09-26T22:35:25Z",
      "updated_at": "2021-07-09T12:28:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): Here is an example of a selected HTTP request for an app monitored with mobile. To view details for the transaction, select App server drill-down. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View the related app's transaction Important This feature is not available when the related app has distributed tracing enabled. To view the related app's transaction: Select App server drill-down, then view the Transactions page for the app associated with this HTTP request. To return to the HTTP requests page, select your browser's Back function. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.11356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "Geography page for mobile apps",
        "Tip",
        "Viewing the Geography page",
        "Viewing drill-down details"
      ],
      "title": "Geography page for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "ec64765f7b48034c3c6e666cd8f553b28be7ca06",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/geography-page-mobile-apps/",
      "published_at": "2021-09-26T22:34:28Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Geography page shows your mobile users' experience as a world view, including: Color-coded response times Network requests (calls per minute) Data transfer size Active devices Network failure rates You can also drill down to detailed information about each country. Tip The Geography feature is not the same as the Map feature. The Map page shows an architectural view of the relationship between a mobile app and its related services. Viewing the Geography page To view or sort the mobile response time by country: Go to one.newrelic.com > Mobile > (select an app) > Network > Geography. To change the information that appears (including response time, requests per minute, total transfer size, active devices, or network failure rate), select your choice from the Sort by menu. To adjust the amount of information that appears, select Hide < 1% throughput. To view summary information about a location, mouse over any area in color on the map, or mouse over the country's name on the list. Use any of our standard user interface functions and page functions to drill down into detailed information. Viewing drill-down details To view detailed information about a specific location (including average response time, calls per minute, active devices, and network failure by type), select its location on the Geography page's map, or select its name on the list.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.11346,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Geography <em>page</em> for <em>mobile</em> apps",
        "sections": "Geography <em>page</em> for <em>mobile</em> apps",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The Geography <em>page</em> shows your <em>mobile</em> users&#x27; experience as a world view, including: Color-coded response times <em>Network</em> requests (calls per minute) Data transfer size Active devices <em>Network</em> failure rates You can also drill down to detailed information about each country. Tip The Geography feature"
      },
      "id": "6044165a196a67660d960f44"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/carriers-page": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-26T22:36:15Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.60715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "Important",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "https://docs.newrelic.com/static/44339db3414bda429d69b74258ab64e8/8c557/screen-http-requests-details_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-09-26T22:35:25Z",
      "updated_at": "2021-07-09T12:28:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): Here is an example of a selected HTTP request for an app monitored with mobile. To view details for the transaction, select App server drill-down. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View the related app's transaction Important This feature is not available when the related app has distributed tracing enabled. To view the related app's transaction: Select App server drill-down, then view the Transactions page for the app associated with this HTTP request. To return to the HTTP requests page, select your browser's Back function. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.11356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "Geography page for mobile apps",
        "Tip",
        "Viewing the Geography page",
        "Viewing drill-down details"
      ],
      "title": "Geography page for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "ec64765f7b48034c3c6e666cd8f553b28be7ca06",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/geography-page-mobile-apps/",
      "published_at": "2021-09-26T22:34:28Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Geography page shows your mobile users' experience as a world view, including: Color-coded response times Network requests (calls per minute) Data transfer size Active devices Network failure rates You can also drill down to detailed information about each country. Tip The Geography feature is not the same as the Map feature. The Map page shows an architectural view of the relationship between a mobile app and its related services. Viewing the Geography page To view or sort the mobile response time by country: Go to one.newrelic.com > Mobile > (select an app) > Network > Geography. To change the information that appears (including response time, requests per minute, total transfer size, active devices, or network failure rate), select your choice from the Sort by menu. To adjust the amount of information that appears, select Hide < 1% throughput. To view summary information about a location, mouse over any area in color on the map, or mouse over the country's name on the list. Use any of our standard user interface functions and page functions to drill down into detailed information. Viewing drill-down details To view detailed information about a specific location (including average response time, calls per minute, active devices, and network failure by type), select its location on the Geography page's map, or select its name on the list.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.11346,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Geography <em>page</em> for <em>mobile</em> apps",
        "sections": "Geography <em>page</em> for <em>mobile</em> apps",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The Geography <em>page</em> shows your <em>mobile</em> users&#x27; experience as a world view, including: Color-coded response times <em>Network</em> requests (calls per minute) Data transfer size Active devices <em>Network</em> failure rates You can also drill down to detailed information about each country. Tip The Geography feature"
      },
      "id": "6044165a196a67660d960f44"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/connection-types-page": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-26T22:36:15Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.60712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "Important",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "https://docs.newrelic.com/static/44339db3414bda429d69b74258ab64e8/8c557/screen-http-requests-details_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-09-26T22:35:25Z",
      "updated_at": "2021-07-09T12:28:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): Here is an example of a selected HTTP request for an app monitored with mobile. To view details for the transaction, select App server drill-down. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View the related app's transaction Important This feature is not available when the related app has distributed tracing enabled. To view the related app's transaction: Select App server drill-down, then view the Transactions page for the app associated with this HTTP request. To return to the HTTP requests page, select your browser's Back function. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.11356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "Geography page for mobile apps",
        "Tip",
        "Viewing the Geography page",
        "Viewing drill-down details"
      ],
      "title": "Geography page for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "ec64765f7b48034c3c6e666cd8f553b28be7ca06",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/geography-page-mobile-apps/",
      "published_at": "2021-09-26T22:34:28Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Geography page shows your mobile users' experience as a world view, including: Color-coded response times Network requests (calls per minute) Data transfer size Active devices Network failure rates You can also drill down to detailed information about each country. Tip The Geography feature is not the same as the Map feature. The Map page shows an architectural view of the relationship between a mobile app and its related services. Viewing the Geography page To view or sort the mobile response time by country: Go to one.newrelic.com > Mobile > (select an app) > Network > Geography. To change the information that appears (including response time, requests per minute, total transfer size, active devices, or network failure rate), select your choice from the Sort by menu. To adjust the amount of information that appears, select Hide < 1% throughput. To view summary information about a location, mouse over any area in color on the map, or mouse over the country's name on the list. Use any of our standard user interface functions and page functions to drill down into detailed information. Viewing drill-down details To view detailed information about a specific location (including average response time, calls per minute, active devices, and network failure by type), select its location on the Geography page's map, or select its name on the list.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.11345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Geography <em>page</em> for <em>mobile</em> apps",
        "sections": "Geography <em>page</em> for <em>mobile</em> apps",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The Geography <em>page</em> shows your <em>mobile</em> users&#x27; experience as a world view, including: Color-coded response times <em>Network</em> requests (calls per minute) Data transfer size Active devices <em>Network</em> failure rates You can also drill down to detailed information about each country. Tip The Geography feature"
      },
      "id": "6044165a196a67660d960f44"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/geography-page-mobile-apps": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-26T22:36:15Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.60712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "Important",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "https://docs.newrelic.com/static/44339db3414bda429d69b74258ab64e8/8c557/screen-http-requests-details_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-09-26T22:35:25Z",
      "updated_at": "2021-07-09T12:28:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): Here is an example of a selected HTTP request for an app monitored with mobile. To view details for the transaction, select App server drill-down. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View the related app's transaction Important This feature is not available when the related app has distributed tracing enabled. To view the related app's transaction: Select App server drill-down, then view the Transactions page for the app associated with this HTTP request. To return to the HTTP requests page, select your browser's Back function. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.11356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "HTTP errors: Network failure analysis",
        "Find and use the HTTP errors page",
        "Group, sort, and filter errors and failures",
        "HTTP error profiles",
        "View more details about a specific error",
        "View and share error data with query builder",
        "View legacy HTTP errors UI page",
        "View the Errors page",
        "Error trace details",
        "View error data in query builder",
        "Unknown errors or URL errors"
      ],
      "title": "HTTP errors: Network failure analysis",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "04631e122b061663c6fd261b605202654aadcf96",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-errors-network-failure-analysis/",
      "published_at": "2021-09-26T22:36:15Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring's HTTP errors page helps you to better understand HTTP errors and network failures associated with your mobile app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager See a list of errors and failures so you can coordinate mobile app teams with backend teams and share the data they need to fix issues. QA engineer Make sure that a new version of your app does not cause a spike in errors compared to a previous version. DevOps engineer See a list of domains and URLs associated with HTTP errors and network failures, so you can focus on the ones that are causing errors and filter out status codes that are too noisy for your alerts. Mobile developer Find out if there are frontend or backend problems affecting your mobile app (even without an error alert going off) so that you can address them in a new version. Support engineer View the errors and session attributes (geography, connection type, device, app version) associated with an error so that you can help customers with their issues. Find and use the HTTP errors page There are two ways to get to the HTTP errors page: Go to one.newrelic.com > Mobile > (select an app) > Network > Network errors. From a mobile app's Overview page in mobile monitoring, select the HTTP errors/network failures chart title link. From the HTTP errors page, investigate HTTP request and network failures: Use any standard page functions to look for trends in Errors and failures charts. Target specific types of errors and failures by grouping, sorting, and filtering the data. Find anomalies in your request errors with HTTP error profiles. Select an error or failure to view details for it. You can also define NRQL alerts that are focused on error types for your critical services or query your app data. Group, sort, and filter errors and failures If you want to do this... Do this... Change how the page groups and sorts errors and network failures Make selections from the Group by and Sort by dropdowns. By default, the Network errors page is grouped by request domain and sorted by errors and failures. Filter for specific errors and network failures Select an error or failure from the Errors and failures list and/or select multiple filters from the Filter dropdown. See which filters you applied or remove filters The filters you select display next to the filter dropdown. To clear filters, select the X next to the filter you want to clear. Change the time window Select a new time period from the Time picker dropdown. View information for one specific app version Select the version that you want to see charts and lists for in the Versions dropdown. HTTP error profiles Error profiles provide visual details about significant differences in the frequency of different values for HTTP error events. For each attribute, the error profile includes: A pie chart showing how the error's attribute is distributed for values that deviate the most A table comparing the error attribute's distribution to that of other errors This helps you take more of the guesswork out of resolving your mobile application's HTTP errors. You can more easily determine if you safely ignore the error, or if you should attempt to resolve the error with a new deployment, code change, customer communication or other actions. View more details about a specific error To view details about an error or failure, select the Request URL link to be directed to the Error summary page. From the Error summary page, you can view the version information, request attributes, and Response body, as well as get a breakdown of error types for the request URL. View and share error data with query builder To explore the data behind any of the charts or lists on the HTTP errors/requests page: Select for any chart. Select View query and then View in Insights. This will open the query builder. From the query builder, you can add the error data to a dashboard and share it via a permalink. To dig deeper into the error data, query your data for the following events and attributes: MobileRequestError events and attributes MobileRequest events and attributes View legacy HTTP errors UI page Accounts that do not have an Enterprise-level subscription see a different HTTP Errors UI page: The Errors page includes details about HTTP errors (403, 404, 422, 500, 502, etc.) and network failures for your hosts; for example: Secure connection failed Timed out Cannot find host Not connected to Internet Cannot connect to host View the Errors page To view HTTP errors or network failures for your mobile app: Go to one.newrelic.com > Mobile > (select an app) > Network > Errors. To change the view to errors or failures, select the Sort by option. To hide low-usage hosts, select the Hide < 1% throughput option. To limit information to a specific version of your app, or to change the time period, select your choice from the Versions menu or the time picker below the menu bar. To view details for a specific host, HTTP status error, or network failure, select its name. Use any of our standard user interface functions to drill down into detailed information. Error trace details Mobile monitoring will capture the response details from HTTP requests that return a 400 or 500 level status code. In addition, error messages generated from Android apps will include a stack trace. To view details about an error trace on the Errors page, select its request URL link. From here you can: View the response body. Share the error details with others by email. File a ticket about it through a ticketing system integrated with New Relic. Delete or hide the error. The errors chart also appears on the selected mobile app's Overview page. If the chart shows errors, you can select its HTTP errors/network failures title or select anywhere on the Overview page's chart to go directly to this Errors page. View error data in query builder To dig deeper into your request data, use the query builder to query and chart the MobileRequest events and attributes. Unknown errors or URL errors The mobile agents maintain a list of exception types. In some cases, custom exceptions thrown by applications fall outside of this list. When this happens, Unknown may appear in the mobile Errors page. If you find Unknown in your list of errors and need assistance in researching which exception types are being missed, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.11345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP errors: <em>Network</em> failure analysis",
        "sections": "View legacy HTTP errors <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em>&#x27;s HTTP errors <em>page</em> helps you to better understand HTTP errors and <em>network</em> failures associated with your <em>mobile</em> app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors <em>page</em> to... Manager"
      },
      "id": "603e8eb428ccbcd174eba791"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-errors-network-failure-analysis": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-26T22:36:15Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.60706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "Important",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "https://docs.newrelic.com/static/44339db3414bda429d69b74258ab64e8/8c557/screen-http-requests-details_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-09-26T22:35:25Z",
      "updated_at": "2021-07-09T12:28:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): Here is an example of a selected HTTP request for an app monitored with mobile. To view details for the transaction, select App server drill-down. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View the related app's transaction Important This feature is not available when the related app has distributed tracing enabled. To view the related app's transaction: Select App server drill-down, then view the Transactions page for the app associated with this HTTP request. To return to the HTTP requests page, select your browser's Back function. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.11356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "Geography page for mobile apps",
        "Tip",
        "Viewing the Geography page",
        "Viewing drill-down details"
      ],
      "title": "Geography page for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "ec64765f7b48034c3c6e666cd8f553b28be7ca06",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/geography-page-mobile-apps/",
      "published_at": "2021-09-26T22:34:28Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Geography page shows your mobile users' experience as a world view, including: Color-coded response times Network requests (calls per minute) Data transfer size Active devices Network failure rates You can also drill down to detailed information about each country. Tip The Geography feature is not the same as the Map feature. The Map page shows an architectural view of the relationship between a mobile app and its related services. Viewing the Geography page To view or sort the mobile response time by country: Go to one.newrelic.com > Mobile > (select an app) > Network > Geography. To change the information that appears (including response time, requests per minute, total transfer size, active devices, or network failure rate), select your choice from the Sort by menu. To adjust the amount of information that appears, select Hide < 1% throughput. To view summary information about a location, mouse over any area in color on the map, or mouse over the country's name on the list. Use any of our standard user interface functions and page functions to drill down into detailed information. Viewing drill-down details To view detailed information about a specific location (including average response time, calls per minute, active devices, and network failure by type), select its location on the Geography page's map, or select its name on the list.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.11345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Geography <em>page</em> for <em>mobile</em> apps",
        "sections": "Geography <em>page</em> for <em>mobile</em> apps",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The Geography <em>page</em> shows your <em>mobile</em> users&#x27; experience as a world view, including: Color-coded response times <em>Network</em> requests (calls per minute) Data transfer size Active devices <em>Network</em> failure rates You can also drill down to detailed information about each country. Tip The Geography feature"
      },
      "id": "6044165a196a67660d960f44"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-09-26T22:36:15Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.60706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Geography page for mobile apps",
        "Tip",
        "Viewing the Geography page",
        "Viewing drill-down details"
      ],
      "title": "Geography page for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "ec64765f7b48034c3c6e666cd8f553b28be7ca06",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/geography-page-mobile-apps/",
      "published_at": "2021-09-26T22:34:28Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Geography page shows your mobile users' experience as a world view, including: Color-coded response times Network requests (calls per minute) Data transfer size Active devices Network failure rates You can also drill down to detailed information about each country. Tip The Geography feature is not the same as the Map feature. The Map page shows an architectural view of the relationship between a mobile app and its related services. Viewing the Geography page To view or sort the mobile response time by country: Go to one.newrelic.com > Mobile > (select an app) > Network > Geography. To change the information that appears (including response time, requests per minute, total transfer size, active devices, or network failure rate), select your choice from the Sort by menu. To adjust the amount of information that appears, select Hide < 1% throughput. To view summary information about a location, mouse over any area in color on the map, or mouse over the country's name on the list. Use any of our standard user interface functions and page functions to drill down into detailed information. Viewing drill-down details To view detailed information about a specific location (including average response time, calls per minute, active devices, and network failure by type), select its location on the Geography page's map, or select its name on the list.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.11345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Geography <em>page</em> for <em>mobile</em> apps",
        "sections": "Geography <em>page</em> for <em>mobile</em> apps",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The Geography <em>page</em> shows your <em>mobile</em> users&#x27; experience as a world view, including: Color-coded response times <em>Network</em> requests (calls per minute) Data transfer size Active devices <em>Network</em> failure rates You can also drill down to detailed information about each country. Tip The Geography feature"
      },
      "id": "6044165a196a67660d960f44"
    },
    {
      "sections": [
        "HTTP errors: Network failure analysis",
        "Find and use the HTTP errors page",
        "Group, sort, and filter errors and failures",
        "HTTP error profiles",
        "View more details about a specific error",
        "View and share error data with query builder",
        "View legacy HTTP errors UI page",
        "View the Errors page",
        "Error trace details",
        "View error data in query builder",
        "Unknown errors or URL errors"
      ],
      "title": "HTTP errors: Network failure analysis",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "04631e122b061663c6fd261b605202654aadcf96",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-errors-network-failure-analysis/",
      "published_at": "2021-09-26T22:36:15Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring's HTTP errors page helps you to better understand HTTP errors and network failures associated with your mobile app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager See a list of errors and failures so you can coordinate mobile app teams with backend teams and share the data they need to fix issues. QA engineer Make sure that a new version of your app does not cause a spike in errors compared to a previous version. DevOps engineer See a list of domains and URLs associated with HTTP errors and network failures, so you can focus on the ones that are causing errors and filter out status codes that are too noisy for your alerts. Mobile developer Find out if there are frontend or backend problems affecting your mobile app (even without an error alert going off) so that you can address them in a new version. Support engineer View the errors and session attributes (geography, connection type, device, app version) associated with an error so that you can help customers with their issues. Find and use the HTTP errors page There are two ways to get to the HTTP errors page: Go to one.newrelic.com > Mobile > (select an app) > Network > Network errors. From a mobile app's Overview page in mobile monitoring, select the HTTP errors/network failures chart title link. From the HTTP errors page, investigate HTTP request and network failures: Use any standard page functions to look for trends in Errors and failures charts. Target specific types of errors and failures by grouping, sorting, and filtering the data. Find anomalies in your request errors with HTTP error profiles. Select an error or failure to view details for it. You can also define NRQL alerts that are focused on error types for your critical services or query your app data. Group, sort, and filter errors and failures If you want to do this... Do this... Change how the page groups and sorts errors and network failures Make selections from the Group by and Sort by dropdowns. By default, the Network errors page is grouped by request domain and sorted by errors and failures. Filter for specific errors and network failures Select an error or failure from the Errors and failures list and/or select multiple filters from the Filter dropdown. See which filters you applied or remove filters The filters you select display next to the filter dropdown. To clear filters, select the X next to the filter you want to clear. Change the time window Select a new time period from the Time picker dropdown. View information for one specific app version Select the version that you want to see charts and lists for in the Versions dropdown. HTTP error profiles Error profiles provide visual details about significant differences in the frequency of different values for HTTP error events. For each attribute, the error profile includes: A pie chart showing how the error's attribute is distributed for values that deviate the most A table comparing the error attribute's distribution to that of other errors This helps you take more of the guesswork out of resolving your mobile application's HTTP errors. You can more easily determine if you safely ignore the error, or if you should attempt to resolve the error with a new deployment, code change, customer communication or other actions. View more details about a specific error To view details about an error or failure, select the Request URL link to be directed to the Error summary page. From the Error summary page, you can view the version information, request attributes, and Response body, as well as get a breakdown of error types for the request URL. View and share error data with query builder To explore the data behind any of the charts or lists on the HTTP errors/requests page: Select for any chart. Select View query and then View in Insights. This will open the query builder. From the query builder, you can add the error data to a dashboard and share it via a permalink. To dig deeper into the error data, query your data for the following events and attributes: MobileRequestError events and attributes MobileRequest events and attributes View legacy HTTP errors UI page Accounts that do not have an Enterprise-level subscription see a different HTTP Errors UI page: The Errors page includes details about HTTP errors (403, 404, 422, 500, 502, etc.) and network failures for your hosts; for example: Secure connection failed Timed out Cannot find host Not connected to Internet Cannot connect to host View the Errors page To view HTTP errors or network failures for your mobile app: Go to one.newrelic.com > Mobile > (select an app) > Network > Errors. To change the view to errors or failures, select the Sort by option. To hide low-usage hosts, select the Hide < 1% throughput option. To limit information to a specific version of your app, or to change the time period, select your choice from the Versions menu or the time picker below the menu bar. To view details for a specific host, HTTP status error, or network failure, select its name. Use any of our standard user interface functions to drill down into detailed information. Error trace details Mobile monitoring will capture the response details from HTTP requests that return a 400 or 500 level status code. In addition, error messages generated from Android apps will include a stack trace. To view details about an error trace on the Errors page, select its request URL link. From here you can: View the response body. Share the error details with others by email. File a ticket about it through a ticketing system integrated with New Relic. Delete or hide the error. The errors chart also appears on the selected mobile app's Overview page. If the chart shows errors, you can select its HTTP errors/network failures title or select anywhere on the Overview page's chart to go directly to this Errors page. View error data in query builder To dig deeper into your request data, use the query builder to query and chart the MobileRequest events and attributes. Unknown errors or URL errors The mobile agents maintain a list of exception types. In some cases, custom exceptions thrown by applications fall outside of this list. When this happens, Unknown may appear in the mobile Errors page. If you find Unknown in your list of errors and need assistance in researching which exception types are being missed, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.11345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP errors: <em>Network</em> failure analysis",
        "sections": "View legacy HTTP errors <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em>&#x27;s HTTP errors <em>page</em> helps you to better understand HTTP errors and <em>network</em> failures associated with your <em>mobile</em> app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors <em>page</em> to... Manager"
      },
      "id": "603e8eb428ccbcd174eba791"
    }
  ]
}