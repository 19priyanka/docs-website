{
  "/docs/new-relic-one/use-new-relic-one/ui-data/service-maps/introduction-service-maps": [
    {
      "sections": [
        "Legacy APM service maps",
        "Requirements",
        "Create maps",
        "Important",
        "Save and rename maps",
        "Save",
        "Rename",
        "Add or remove nodes on maps",
        "Applications and mobile apps",
        "Browser, databases, external services, connected apps",
        "Custom nodes",
        "Move around the map",
        "Select, arrange, group nodes",
        "Select nodes",
        "Arrange nodes",
        "Caution",
        "Group and ungroup nodes",
        "Add maps and charts to dashboards",
        "Delete maps",
        "Identify issues with external services",
        "Visualize and monitor complex architectures",
        "Nodes",
        "Node arrangement and grouping",
        "Incoming and outgoing connections",
        "View performance summary",
        "Map list and app/service list panels",
        "Health status and performance metrics",
        "View all connected apps and services",
        "Traffic light mode",
        "Midnight mode"
      ],
      "title": "Legacy APM service maps",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Understand system dependencies",
        "Service maps"
      ],
      "external_id": "01918fc622e45cdba5aabfc94c9d55803544c06d",
      "image": "https://docs.newrelic.com/static/535d1f8a57752280221e9a9f9a40c9fc/8bac5/traffic-lights_service-maps_APM.jpg",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/service-maps/service-maps-apm/",
      "published_at": "2022-01-12T16:51:05Z",
      "updated_at": "2021-10-31T14:48:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here is information about using the legacy APM service maps feature to create, customize, and use service maps. For help using the current service maps feature, see How to use service maps. Requirements The legacy service map features in APM depend on your New Relic agent version: Feature Requirements App visibility For your app to appear in service maps, one of the following must be true: Your app must have the minimum agent version required for distributed tracing and have distributed tracing enabled. Note: Mobile monitoring doesn't support distributed tracing yet and will not show relationships to apps that have distributed tracing enabled. Your app must have the minimum APM agent version required for cross app tracing and have cross app tracing enabled. Host and instance visibility To view specific hosts, instances, and types of database information, your agent must meet the same minimum agent versions as the APM database and instance feature and use any of the compatible database drivers. Database-only visibility APM's service maps feature includes the ability to opt out of the deeper, host and instance level view. However, to view databases in service maps without the instance-level details, you must still meet the same minimum agent versions as the Database and slow queries features. Create maps The APM service maps feature helps you create your first map by providing default map or architecture suggestions that automatically build a default map (if you have more than ten reporting apps). To view these suggested maps, go to one.newrelic.com > More > Service Maps > Suggested maps. To create a new map: Do one of the following: Start from scratch: Go to one.newrelic.com > More > Service maps > Map list > Create new map . Copy an existing map: Go to one.newrelic.com > More > Service maps > (select a map) > Save as new. Name your map. Rearrange, group, or add nodes on the map as needed. Important Previously, you could have private service maps. Now, all users can view, edit, and delete all existing or new service maps in the account. Save and rename maps Here are some tips about saving and renaming maps: Save To save changes to a map, select Save. To create a copy of the current map, select Save as new. Rename To rename a map: Go to one.newrelic.com > More > Service maps > (select a map). Select the pencil icon next to the map name. Change the name, then select Save. Add or remove nodes on maps After you create or save a map, build out your map by adding nodes to it. Nodes are added to the map differently based on the node type. To remove any node from the map, mouse over the node, then select the remove X icon. Applications and mobile apps Nodes for applications or mobile apps need to be added to the map in order to add any other nodes. Nodes are added and connected into the map as you select them. The check mark icon means that node is already on the map. To add apps to the map: Go to one.newrelic.com > More > Service maps > (select a map) > App/Service. Select any applications from the App/Service list. Rearrange or group together as needed. Browser, databases, external services, connected apps In the New Relic UI, your out-of-process services are referred to as web external or background external data. To add browser apps, databases, external services, or other connected apps to the map: Select an incoming or outgoing connection widget. From the list of connections, mouse over an app or service, then select the plus icon. Rearrange as needed. Custom nodes To add a custom node to the map: Go to one.newrelic.com > More > Service maps > (select a map) > App/Service. From the App/Service list, select Create custom node. Name the node. Add connections: Select the left (for incoming) or right (for outgoing) arrow icons. Then select the plus icon on your target node. Select Save. Rearrange as needed. To add or remove custom node connections: Mouse over the custom node and select the pencil icon. Select the left (for incoming) or right (for outgoing) arrow icons. To add a connection, select the plus icon. To remove a connection, select the minus icon. Select Save. Move around the map Move around the map by panning or zooming in and out. If you want to... Do this... Pan the map In pan mode, click and drag. In drag-select mode, hold the Alt key, then click and drag. Zoom in and out In either mode, zoom in and out by scrolling the mouse wheel. View your entire map in traffic light mode Zoom out until node details fade out and are replaced by health status colors. Toggle the traffic light view on and off Select Views, then select Traffic light mode. View all the nodes and their dependencies Select Discover your environment. Drill down into more detail from a node Use standard UI functions. Select, arrange, group nodes Click on a node to select it and view its performance summary. You can also select multiple nodes at once, to group and ungroup them: Select nodes To select one node, click on the node. To select multiple nodes: Click the drag-select icon to switch to drag-select mode. Click and drag the mouse to draw a square around the nodes you want to select. OR Hold the Shift key and click on each node you want to select. Arrange nodes Caution Auto-arrange cannot be undone. Consider saving a copy of your map first. To arrange nodes on the map, select one or more node, then drag to a snap point on the map. To automatically organize all your nodes and connections, select Auto-arrange map. Group and ungroup nodes If you want to... Do this... Group nodes together on the map Select two or more nodes, then select Create group. Name your new group Mouse over the group, then select the pencil icon. Rename an existing group Select the pencil icon. Remove nodes from a group Select the group, then select the minus icon for each item you want to remove. Add maps and charts to dashboards one.newrelic.com > Dashboards: adding a service map to a dashboard provides context for the data being reported and where it's coming from. You can add legacy service maps to a dashboard. For example, if you have a dashboard showcasing performance metrics for several entities, adding a service map to the dashboard shows how all the entities are related and provides additional context about your system. To add a service map to a dashboard: Go to one.newrelic.com and select the Explorer. Select an entity from the index. Click on Service map. Click Add to dashboard. Search for the dashboard you want to add the map to. Delete maps To delete a map: Go to one.newrelic.com > More > Service maps > (select a map). Select the map name's pencil icon. Select Delete map. Identify issues with external services If your app connects to an external service that New Relic does not monitor (for example, a third-party API), New Relic watches the service for a week in order to baseline its response time. If New Relic can collect a statistically significant number of data points (more than 100), New Relic compares the current response time to this baseline and uses this to set the health status indicator: Green: Response time from the service is less than 1.75 times the baseline. Yellow: Response time from the service is longer than 1.75 times the baseline. Red: Response time from the service is longer than 2.5 times the baseline. Gray: Alerts concluded it does not have enough data to determine the health status. Purple: Alerts cannot yet conclude if it has enough data to determine the health status. Visualize and monitor complex architectures Use service maps to visualize and monitor complex architectures. For a tutorial introducing the latest features, select the service map's question icon. Nodes Nodes are the basic building blocks for your map. You can add a variety of node types including: Node type Description New Relic APM-monitored app Add your app to the map to view their connections to databases, browser apps, out-of-process services, and other instrumented apps. (In the New Relic UI, your out-of-process services are also referred to as web external or background external data.) Browser apps Automatically detected for each app and added via the incoming connections widget. Only displays browser apps linked to an APM app (standalone browser apps are not supported). New Relic mobile monitoring apps Automatically detected and added via the app/service list panel. External services Service maps automatically detects external services (visible in the connections widget), to track your app's external dependencies and monitor the health of those connections. Custom nodes Add custom nodes via the app/service list panel to include apps and services not automatically instrumented by New Relic (for example, load balancers, implementation planning, and so on). Group nodes A group node contains multiple other nodes. For apps, group nodes include a summarized health status indicator for all nodes in the group. Node arrangement and grouping Click and drag a node to move it around the map, for a customizable view of your architecture. App nodes can also be grouped together into a single node to better organize related apps and services. Grouped nodes include summarized health status indicator for all nodes in the group. To remove items from a group, mouse over the group and select the pencil pencil icon, then select the minus minus-circle icon to remove the item from the group. Incoming and outgoing connections Service maps automatically detects incoming and outgoing connections based on HTTP calls between entities. Mouse over a node to highlight the node's connections. Widgets at the end of each node display a count of that node's connections, and you can click on those widgets to add related entities to the map: View performance summary Click on an app to view its performance over the last 30 minutes. The chart defaults to Response time, but you can view other metrics by selecting any of the available Apdex, Throughput, or Error rate links. While charts use the last 30 minutes of performance data, the service map as a whole is based on the last five minutes. View the app in APM or browser and view its labels by selecting the overflow ellipsis-v icon. Click the app name again to hide the summary charts, and select the overflow ellipsis-h icon again to hide other details. Map list and app/service list panels Select the Map list panel to: Search for and view your maps, and access other users' shared maps. Create a new map. Select the App/Service List panel to: Add new apps and mobile apps to your map. Create custom nodes and add them to the map. Health status and performance metrics You can see health status indicators for most nodes. Except for out-of-process services (external services or background services), entities use the health status indicators used by New Relic Alerts. For out-of-process (external) services, the health status indicator measures the health of the connection to the external service. View all connected apps and services The Discover your environment feature allows you to view all of your apps, services, and dependencies together with a single click. This feature detects all connected applications and services (including externals and databases) to give you a comprehensive view of your overall software architecture environment. To view all connected apps and services: In APM, select Service maps. From your Map list, select Discover your environment to display all of your nodes. Hover over any node to view its dependencies and how it connects to other parts of your service map. Click on individual nodes to zoom in and view their details. The Discover your environment feature may not be available if you are using an older New Relic agent version. See Troubleshooting cross application tracing for version information. This feature may also not be available for highly complex service maps with many elements. Go to one.newrelic.com > More > Service maps > Map list > Discover your environment: Use this option to view all of your nodes and their dependencies in one place. Traffic light mode Traffic light mode lets you view the health status of your entire architecture at a glance. This feature helps you quickly find service and app problems, even within a complex environment with many nodes. To toggle this mode, select the Views tab, then select Traffic light mode. When traffic lights mode is On, zooming out far enough on a service map eventually causes the nodes to switch from displaying textual information, to only health status colors. Click on individual nodes to zoom in and view more details. Traffic light mode is on by default. When traffic lights mode is Off, service map nodes retain their textual information and do not switch to health status colors, No matter how far you zoom out. one.newrelic.com > More > Service maps > Views > Traffic light mode: When traffic light mode is enabled, zooming out of your service map displays nodes in health status colors. Midnight mode Midnight mode inverts the screen's colors, going from a white background to a dark background. Midnight mode reduces eye strain, especially in low light environments. To toggle this mode, select the Views tab, then select Midnight mode.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.73251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Legacy APM <em>service</em> <em>maps</em>",
        "sections": "Legacy APM <em>service</em> <em>maps</em>",
        "tags": "<em>Understand</em> <em>system</em> <em>dependencies</em>",
        "body": "Here is information about using the legacy APM <em>service</em> <em>maps</em> feature to create, customize, and use <em>service</em> <em>maps</em>. For help using the current <em>service</em> <em>maps</em> feature, see How to use <em>service</em> <em>maps</em>. Requirements The legacy <em>service</em> <em>map</em> features in APM <em>depend</em> on your New Relic agent version: Feature"
      },
      "id": "60446a3a28ccbc04a2313970"
    },
    {
      "sections": [
        "How to use service maps",
        "Requirements",
        "Minimum versions when distributed tracing is enabled",
        "Minimum versions when distributed tracing is NOT enabled",
        "Add or remove connections to an entity",
        "Color coded for alerts",
        "Understand dependencies using API",
        "Externals and databases in maps",
        "Missing nodes"
      ],
      "title": "How to use service maps",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Understand system dependencies",
        "Service maps"
      ],
      "external_id": "34d576d70a4393eea903e46c6dc9297303f821eb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/service-maps/how-use-service-maps/",
      "published_at": "2022-01-12T16:50:20Z",
      "updated_at": "2021-10-24T01:51:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here is information about how to use the current service maps feature. For help using the earlier service maps feature, see Legacy APM service maps. Service maps helps you visualize dependencies quickly and easily across your environment. They help you see how all your entities work together across your system. You can use service maps to troubleshoot problems, see how your environment works together, and ensure that issues don’t have downstream repercussions. Service maps also supports cross-account access so help you see relationships between entities for all your accounts. Requirements Service maps work with distributed tracing to connect relationships between entities. Service maps are still functional if you have not enabled distributed tracing, but we recommend having distributed tracing enabled for all agents. This ensures a more consistent experience while using service maps. For best results, update existing agents to the latest version. The required minimum agent versions for maps are: Minimum versions when distributed tracing is enabled The required minimum agent versions for maps using distributed tracing are: C SDK 1.1.0 or higher Go agent 2.1.0 or higher Java agent 4.3.0 or higher .NET agent 8.6.45.0 or higher Node.js agent 4.7.0 or higher PHP agent 8.4 or higher Python agent 4.2.0.100 or higher Ruby agent 5.3.0.346 or higher Minimum versions when distributed tracing is NOT enabled The minimum version requirements for maps not using distributed tracing are: C SDK: not available Go 1.11 or higher Java 3.9.0 or higher .NET 4.2 or higher Node.js 2.0.0 or higher PHP 4.19.0 or higher Python 2.38.0.31 or higher Ruby 4.3.0 or higher Add or remove connections to an entity To view service maps, from one.newrelic.com click Explorer. Once you select an entity to view, you can select service maps from the sidebar. The map shows your upstream and downstream services: entities toward the left are upstream, entities toward the right are downstream. To add or remove connections to an entity: Hover over the entity in the map that you want to alter. Click add or remove more connections. In the connection list, keep boxes checked for the entities that you want to appear in the map. Unchecked entities will be removed from the map. Color coded for alerts Each entity in a map displays a color dependent on its performance. Green: there are currently no violations for this entities performance. Yellow: there is an open warning violation for this entity. Red: there is an open critical violation for this entity. Gray: no alert conditions have been set for the entity White: agent not reporting. This means that the agent installed on the entity is not reporting any data. This is expected behavior for databases or externals. Understand dependencies using API You can discover the same relationship connections available in service maps with NerdGraph. For more information and examples, see the NerdGraph GraphiQL relationships API tutorial. Externals and databases in maps In the New Relic UI, your out-of-process services are referred to as web external or background external data. Externals and databases have slightly different features in service maps than other entity types: Unlike other entities that appear in service maps, externals are aggregates. Clicking on an external service in the map shows you the list of all the external services that are rolled up into the one external entity. This is to reduce map clutter, as some entities can have dozens of externals being reported. Databases are agentless. Because of this, alerts cannot be set for the database, as only see the service call is reported to New Relic. Missing nodes If you are unable to view certain entities in New Relic One service maps, see Troubleshooting: Missing or obfuscated data in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.26843,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How to use <em>service</em> <em>maps</em>",
        "sections": "How to use <em>service</em> <em>maps</em>",
        "tags": "<em>Understand</em> <em>system</em> <em>dependencies</em>",
        "body": " data. This is expected behavior for databases or externals. <em>Understand</em> <em>dependencies</em> using API You can discover the same relationship connections available in <em>service</em> <em>maps</em> with NerdGraph. For more information and examples, see the NerdGraph GraphiQL relationships API tutorial. Externals"
      },
      "id": "603ec23264441fb02c4e8893"
    },
    {
      "sections": [
        "Troubleshooting: Missing entities in service maps",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "Troubleshooting: Missing entities in service maps",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Understand system dependencies",
        "Service maps"
      ],
      "external_id": "44f9c026ad8e1c9d6ba02bd1ec2f2deecbc26832",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/service-maps/troubleshooting-missing-entities-service-maps/",
      "published_at": "2022-01-12T16:51:05Z",
      "updated_at": "2021-10-24T01:50:44Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When using service maps, you can't view the full set of entities or the relationships between entities that you expect to see. Solution Make sure that the entities are being monitored with an agent. If you have a mix of agents with some having distributed tracing turned on and some having it turned off, you will not see the relations between those agents. The solution for this scenario is to run all agents either with distributed tracing turned on (preferred) or turn it off for all agents. If this does not remedy the issue, the service you're trying to view may require manual instrumentation. When you view applications and services that we automatically instrument in service maps, you'll usually see complete and detailed data for those nodes in the distributed tracing UI. However, you may notice that some of these services or applications are missing from service maps. Tip Some browser apps are exceptions to this, and may be missing because: Relationships for copy and paste browser agents are not detected. Only the relationships for injected browser agents is shown (the app the agent is injected into). Call relationships (for example, AJAX calling to other apps) are not displayed. If services or apps are missing, you may want to implement custom instrumentation of applications or specific transactions to see more detail in traces. Some examples of when you may need to do this: Transactions not automatically instrumented. To ensure your application is automatically instrumented, read the compatibility and requirements documentation for the agent you're using. If an application isn't automatically instrumented, or if you'd like to add instrumentation of specific activity, see Custom instrumentation. All Go applications. The Go agent, unlike other agents, requires manual instrumentation of your code. For instructions, see Instrument a Go application. A service doesn't use HTTP. If a service doesn't communicate via HTTP, the agent won't send distributed tracing headers. This may be the case for some non-web applications or message queues. To remedy this, use the distributed tracing APIs to instrument either the calling or called application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.26831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting: Missing entities in <em>service</em> <em>maps</em>",
        "sections": "Troubleshooting: Missing entities in <em>service</em> <em>maps</em>",
        "tags": "<em>Understand</em> <em>system</em> <em>dependencies</em>",
        "body": "Problem When using <em>service</em> <em>maps</em>, you can&#x27;t view the full set of entities or the relationships between entities that you expect to see. Solution Make sure that the entities are being monitored with an agent. If you have a mix of agents with some having distributed tracing turned on and some having"
      },
      "id": "603eb369196a67b4aaa83d8d"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/ui-data/service-maps/service-maps-apm": [
    {
      "sections": [
        "How to use service maps",
        "Requirements",
        "Minimum versions when distributed tracing is enabled",
        "Minimum versions when distributed tracing is NOT enabled",
        "Add or remove connections to an entity",
        "Color coded for alerts",
        "Understand dependencies using API",
        "Externals and databases in maps",
        "Missing nodes"
      ],
      "title": "How to use service maps",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Understand system dependencies",
        "Service maps"
      ],
      "external_id": "34d576d70a4393eea903e46c6dc9297303f821eb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/service-maps/how-use-service-maps/",
      "published_at": "2022-01-12T16:50:20Z",
      "updated_at": "2021-10-24T01:51:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here is information about how to use the current service maps feature. For help using the earlier service maps feature, see Legacy APM service maps. Service maps helps you visualize dependencies quickly and easily across your environment. They help you see how all your entities work together across your system. You can use service maps to troubleshoot problems, see how your environment works together, and ensure that issues don’t have downstream repercussions. Service maps also supports cross-account access so help you see relationships between entities for all your accounts. Requirements Service maps work with distributed tracing to connect relationships between entities. Service maps are still functional if you have not enabled distributed tracing, but we recommend having distributed tracing enabled for all agents. This ensures a more consistent experience while using service maps. For best results, update existing agents to the latest version. The required minimum agent versions for maps are: Minimum versions when distributed tracing is enabled The required minimum agent versions for maps using distributed tracing are: C SDK 1.1.0 or higher Go agent 2.1.0 or higher Java agent 4.3.0 or higher .NET agent 8.6.45.0 or higher Node.js agent 4.7.0 or higher PHP agent 8.4 or higher Python agent 4.2.0.100 or higher Ruby agent 5.3.0.346 or higher Minimum versions when distributed tracing is NOT enabled The minimum version requirements for maps not using distributed tracing are: C SDK: not available Go 1.11 or higher Java 3.9.0 or higher .NET 4.2 or higher Node.js 2.0.0 or higher PHP 4.19.0 or higher Python 2.38.0.31 or higher Ruby 4.3.0 or higher Add or remove connections to an entity To view service maps, from one.newrelic.com click Explorer. Once you select an entity to view, you can select service maps from the sidebar. The map shows your upstream and downstream services: entities toward the left are upstream, entities toward the right are downstream. To add or remove connections to an entity: Hover over the entity in the map that you want to alter. Click add or remove more connections. In the connection list, keep boxes checked for the entities that you want to appear in the map. Unchecked entities will be removed from the map. Color coded for alerts Each entity in a map displays a color dependent on its performance. Green: there are currently no violations for this entities performance. Yellow: there is an open warning violation for this entity. Red: there is an open critical violation for this entity. Gray: no alert conditions have been set for the entity White: agent not reporting. This means that the agent installed on the entity is not reporting any data. This is expected behavior for databases or externals. Understand dependencies using API You can discover the same relationship connections available in service maps with NerdGraph. For more information and examples, see the NerdGraph GraphiQL relationships API tutorial. Externals and databases in maps In the New Relic UI, your out-of-process services are referred to as web external or background external data. Externals and databases have slightly different features in service maps than other entity types: Unlike other entities that appear in service maps, externals are aggregates. Clicking on an external service in the map shows you the list of all the external services that are rolled up into the one external entity. This is to reduce map clutter, as some entities can have dozens of externals being reported. Databases are agentless. Because of this, alerts cannot be set for the database, as only see the service call is reported to New Relic. Missing nodes If you are unable to view certain entities in New Relic One service maps, see Troubleshooting: Missing or obfuscated data in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.26843,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How to use <em>service</em> <em>maps</em>",
        "sections": "How to use <em>service</em> <em>maps</em>",
        "tags": "<em>Understand</em> <em>system</em> <em>dependencies</em>",
        "body": " data. This is expected behavior for databases or externals. <em>Understand</em> <em>dependencies</em> using API You can discover the same relationship connections available in <em>service</em> <em>maps</em> with NerdGraph. For more information and examples, see the NerdGraph GraphiQL relationships API tutorial. Externals"
      },
      "id": "603ec23264441fb02c4e8893"
    },
    {
      "sections": [
        "Introduction to service maps",
        "Tip",
        "Access service maps",
        "Identify operational issues"
      ],
      "title": "Introduction to service maps",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Understand system dependencies",
        "Service maps"
      ],
      "external_id": "aca003c282581d2ec459e9584199739e40b0d04e",
      "image": "https://docs.newrelic.com/static/89460254fa31376b446585fb72b476a1/c1b63/NR1_service_maps.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/service-maps/introduction-service-maps/",
      "published_at": "2022-01-12T16:50:20Z",
      "updated_at": "2021-10-24T01:51:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Service maps are visual, customizable representations of your architecture. Maps automatically show your app's connections and dependencies, including applications, databases, hosts, servers, and out-of-process services. Tip In the New Relic UI, your out-of-process services are referred to as web external or background external data. Health indicators and performance metrics show you the current operational status for every part of your architecture. Service maps help you: Understand how apps and services in your architecture connect and communicate. Quickly see the current health and operational state of your entire environment. Troubleshoot operational issues and understand the impact of problems down to the host and instance level. Collaborate and drive shared understanding of an architecture. Access service maps Two options are available in New Relic One: the current service maps and the legacy APM service maps. To access the different service maps: Type To view maps Purpose Current service maps Go to one.newrelic.com > Explorer > (select an entity) > Monitor > Service map Service maps give you increased access to all the entities across your accounts, and help you understand how your entire environment is connected. Legacy APM service maps Go to one.newrelic.com > More > Service maps Legacy APM service maps let you create, customize, and share maps related to an individual app. Identify operational issues Service maps are color-coded to provide a quick look at the current status of your environment. Select nodes on a map to view additional performance metrics, and a full list and health check of each node's connections. The map automatically connects nodes into the map, so you can see which apps on the map connect to others. This helps you troubleshoot and assess the impact of a performance problem between a calling application and a specific database. With service maps, you can view your service and its status in the context of its up and downstream dependencies. Use maps in New Relic One to identify the root cause when troubleshooting an incident. Check out How to use service maps for details about these topics: View all your entities without any setup: most entities are automatically connected to their dependencies in service maps. View entities all across your organization's accounts. Add a map to a dashboard. one.newrelic.com > Explorer > (select an entity) > Monitor > Service map: Service maps show your dependencies and how they're performing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.26843,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>service</em> <em>maps</em>",
        "sections": "Introduction to <em>service</em> <em>maps</em>",
        "tags": "<em>Understand</em> <em>system</em> <em>dependencies</em>",
        "body": " and the legacy APM <em>service</em> <em>maps</em>. To access the different <em>service</em> <em>maps</em>: Type To view <em>maps</em> Purpose Current <em>service</em> <em>maps</em> Go to one.newrelic.com &gt; Explorer &gt; (select an entity) &gt; Monitor &gt; <em>Service</em> <em>map</em> <em>Service</em> <em>maps</em> give you increased access to all the entities across your accounts, and help you <em>understand</em>"
      },
      "id": "60450348e7b9d26e905799d4"
    },
    {
      "sections": [
        "Troubleshooting: Missing entities in service maps",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "Troubleshooting: Missing entities in service maps",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Understand system dependencies",
        "Service maps"
      ],
      "external_id": "44f9c026ad8e1c9d6ba02bd1ec2f2deecbc26832",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/service-maps/troubleshooting-missing-entities-service-maps/",
      "published_at": "2022-01-12T16:51:05Z",
      "updated_at": "2021-10-24T01:50:44Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When using service maps, you can't view the full set of entities or the relationships between entities that you expect to see. Solution Make sure that the entities are being monitored with an agent. If you have a mix of agents with some having distributed tracing turned on and some having it turned off, you will not see the relations between those agents. The solution for this scenario is to run all agents either with distributed tracing turned on (preferred) or turn it off for all agents. If this does not remedy the issue, the service you're trying to view may require manual instrumentation. When you view applications and services that we automatically instrument in service maps, you'll usually see complete and detailed data for those nodes in the distributed tracing UI. However, you may notice that some of these services or applications are missing from service maps. Tip Some browser apps are exceptions to this, and may be missing because: Relationships for copy and paste browser agents are not detected. Only the relationships for injected browser agents is shown (the app the agent is injected into). Call relationships (for example, AJAX calling to other apps) are not displayed. If services or apps are missing, you may want to implement custom instrumentation of applications or specific transactions to see more detail in traces. Some examples of when you may need to do this: Transactions not automatically instrumented. To ensure your application is automatically instrumented, read the compatibility and requirements documentation for the agent you're using. If an application isn't automatically instrumented, or if you'd like to add instrumentation of specific activity, see Custom instrumentation. All Go applications. The Go agent, unlike other agents, requires manual instrumentation of your code. For instructions, see Instrument a Go application. A service doesn't use HTTP. If a service doesn't communicate via HTTP, the agent won't send distributed tracing headers. This may be the case for some non-web applications or message queues. To remedy this, use the distributed tracing APIs to instrument either the calling or called application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.26831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting: Missing entities in <em>service</em> <em>maps</em>",
        "sections": "Troubleshooting: Missing entities in <em>service</em> <em>maps</em>",
        "tags": "<em>Understand</em> <em>system</em> <em>dependencies</em>",
        "body": "Problem When using <em>service</em> <em>maps</em>, you can&#x27;t view the full set of entities or the relationships between entities that you expect to see. Solution Make sure that the entities are being monitored with an agent. If you have a mix of agents with some having distributed tracing turned on and some having"
      },
      "id": "603eb369196a67b4aaa83d8d"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/ui-data/service-maps/troubleshooting-missing-entities-service-maps": [
    {
      "sections": [
        "Legacy APM service maps",
        "Requirements",
        "Create maps",
        "Important",
        "Save and rename maps",
        "Save",
        "Rename",
        "Add or remove nodes on maps",
        "Applications and mobile apps",
        "Browser, databases, external services, connected apps",
        "Custom nodes",
        "Move around the map",
        "Select, arrange, group nodes",
        "Select nodes",
        "Arrange nodes",
        "Caution",
        "Group and ungroup nodes",
        "Add maps and charts to dashboards",
        "Delete maps",
        "Identify issues with external services",
        "Visualize and monitor complex architectures",
        "Nodes",
        "Node arrangement and grouping",
        "Incoming and outgoing connections",
        "View performance summary",
        "Map list and app/service list panels",
        "Health status and performance metrics",
        "View all connected apps and services",
        "Traffic light mode",
        "Midnight mode"
      ],
      "title": "Legacy APM service maps",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Understand system dependencies",
        "Service maps"
      ],
      "external_id": "01918fc622e45cdba5aabfc94c9d55803544c06d",
      "image": "https://docs.newrelic.com/static/535d1f8a57752280221e9a9f9a40c9fc/8bac5/traffic-lights_service-maps_APM.jpg",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/service-maps/service-maps-apm/",
      "published_at": "2022-01-12T16:51:05Z",
      "updated_at": "2021-10-31T14:48:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here is information about using the legacy APM service maps feature to create, customize, and use service maps. For help using the current service maps feature, see How to use service maps. Requirements The legacy service map features in APM depend on your New Relic agent version: Feature Requirements App visibility For your app to appear in service maps, one of the following must be true: Your app must have the minimum agent version required for distributed tracing and have distributed tracing enabled. Note: Mobile monitoring doesn't support distributed tracing yet and will not show relationships to apps that have distributed tracing enabled. Your app must have the minimum APM agent version required for cross app tracing and have cross app tracing enabled. Host and instance visibility To view specific hosts, instances, and types of database information, your agent must meet the same minimum agent versions as the APM database and instance feature and use any of the compatible database drivers. Database-only visibility APM's service maps feature includes the ability to opt out of the deeper, host and instance level view. However, to view databases in service maps without the instance-level details, you must still meet the same minimum agent versions as the Database and slow queries features. Create maps The APM service maps feature helps you create your first map by providing default map or architecture suggestions that automatically build a default map (if you have more than ten reporting apps). To view these suggested maps, go to one.newrelic.com > More > Service Maps > Suggested maps. To create a new map: Do one of the following: Start from scratch: Go to one.newrelic.com > More > Service maps > Map list > Create new map . Copy an existing map: Go to one.newrelic.com > More > Service maps > (select a map) > Save as new. Name your map. Rearrange, group, or add nodes on the map as needed. Important Previously, you could have private service maps. Now, all users can view, edit, and delete all existing or new service maps in the account. Save and rename maps Here are some tips about saving and renaming maps: Save To save changes to a map, select Save. To create a copy of the current map, select Save as new. Rename To rename a map: Go to one.newrelic.com > More > Service maps > (select a map). Select the pencil icon next to the map name. Change the name, then select Save. Add or remove nodes on maps After you create or save a map, build out your map by adding nodes to it. Nodes are added to the map differently based on the node type. To remove any node from the map, mouse over the node, then select the remove X icon. Applications and mobile apps Nodes for applications or mobile apps need to be added to the map in order to add any other nodes. Nodes are added and connected into the map as you select them. The check mark icon means that node is already on the map. To add apps to the map: Go to one.newrelic.com > More > Service maps > (select a map) > App/Service. Select any applications from the App/Service list. Rearrange or group together as needed. Browser, databases, external services, connected apps In the New Relic UI, your out-of-process services are referred to as web external or background external data. To add browser apps, databases, external services, or other connected apps to the map: Select an incoming or outgoing connection widget. From the list of connections, mouse over an app or service, then select the plus icon. Rearrange as needed. Custom nodes To add a custom node to the map: Go to one.newrelic.com > More > Service maps > (select a map) > App/Service. From the App/Service list, select Create custom node. Name the node. Add connections: Select the left (for incoming) or right (for outgoing) arrow icons. Then select the plus icon on your target node. Select Save. Rearrange as needed. To add or remove custom node connections: Mouse over the custom node and select the pencil icon. Select the left (for incoming) or right (for outgoing) arrow icons. To add a connection, select the plus icon. To remove a connection, select the minus icon. Select Save. Move around the map Move around the map by panning or zooming in and out. If you want to... Do this... Pan the map In pan mode, click and drag. In drag-select mode, hold the Alt key, then click and drag. Zoom in and out In either mode, zoom in and out by scrolling the mouse wheel. View your entire map in traffic light mode Zoom out until node details fade out and are replaced by health status colors. Toggle the traffic light view on and off Select Views, then select Traffic light mode. View all the nodes and their dependencies Select Discover your environment. Drill down into more detail from a node Use standard UI functions. Select, arrange, group nodes Click on a node to select it and view its performance summary. You can also select multiple nodes at once, to group and ungroup them: Select nodes To select one node, click on the node. To select multiple nodes: Click the drag-select icon to switch to drag-select mode. Click and drag the mouse to draw a square around the nodes you want to select. OR Hold the Shift key and click on each node you want to select. Arrange nodes Caution Auto-arrange cannot be undone. Consider saving a copy of your map first. To arrange nodes on the map, select one or more node, then drag to a snap point on the map. To automatically organize all your nodes and connections, select Auto-arrange map. Group and ungroup nodes If you want to... Do this... Group nodes together on the map Select two or more nodes, then select Create group. Name your new group Mouse over the group, then select the pencil icon. Rename an existing group Select the pencil icon. Remove nodes from a group Select the group, then select the minus icon for each item you want to remove. Add maps and charts to dashboards one.newrelic.com > Dashboards: adding a service map to a dashboard provides context for the data being reported and where it's coming from. You can add legacy service maps to a dashboard. For example, if you have a dashboard showcasing performance metrics for several entities, adding a service map to the dashboard shows how all the entities are related and provides additional context about your system. To add a service map to a dashboard: Go to one.newrelic.com and select the Explorer. Select an entity from the index. Click on Service map. Click Add to dashboard. Search for the dashboard you want to add the map to. Delete maps To delete a map: Go to one.newrelic.com > More > Service maps > (select a map). Select the map name's pencil icon. Select Delete map. Identify issues with external services If your app connects to an external service that New Relic does not monitor (for example, a third-party API), New Relic watches the service for a week in order to baseline its response time. If New Relic can collect a statistically significant number of data points (more than 100), New Relic compares the current response time to this baseline and uses this to set the health status indicator: Green: Response time from the service is less than 1.75 times the baseline. Yellow: Response time from the service is longer than 1.75 times the baseline. Red: Response time from the service is longer than 2.5 times the baseline. Gray: Alerts concluded it does not have enough data to determine the health status. Purple: Alerts cannot yet conclude if it has enough data to determine the health status. Visualize and monitor complex architectures Use service maps to visualize and monitor complex architectures. For a tutorial introducing the latest features, select the service map's question icon. Nodes Nodes are the basic building blocks for your map. You can add a variety of node types including: Node type Description New Relic APM-monitored app Add your app to the map to view their connections to databases, browser apps, out-of-process services, and other instrumented apps. (In the New Relic UI, your out-of-process services are also referred to as web external or background external data.) Browser apps Automatically detected for each app and added via the incoming connections widget. Only displays browser apps linked to an APM app (standalone browser apps are not supported). New Relic mobile monitoring apps Automatically detected and added via the app/service list panel. External services Service maps automatically detects external services (visible in the connections widget), to track your app's external dependencies and monitor the health of those connections. Custom nodes Add custom nodes via the app/service list panel to include apps and services not automatically instrumented by New Relic (for example, load balancers, implementation planning, and so on). Group nodes A group node contains multiple other nodes. For apps, group nodes include a summarized health status indicator for all nodes in the group. Node arrangement and grouping Click and drag a node to move it around the map, for a customizable view of your architecture. App nodes can also be grouped together into a single node to better organize related apps and services. Grouped nodes include summarized health status indicator for all nodes in the group. To remove items from a group, mouse over the group and select the pencil pencil icon, then select the minus minus-circle icon to remove the item from the group. Incoming and outgoing connections Service maps automatically detects incoming and outgoing connections based on HTTP calls between entities. Mouse over a node to highlight the node's connections. Widgets at the end of each node display a count of that node's connections, and you can click on those widgets to add related entities to the map: View performance summary Click on an app to view its performance over the last 30 minutes. The chart defaults to Response time, but you can view other metrics by selecting any of the available Apdex, Throughput, or Error rate links. While charts use the last 30 minutes of performance data, the service map as a whole is based on the last five minutes. View the app in APM or browser and view its labels by selecting the overflow ellipsis-v icon. Click the app name again to hide the summary charts, and select the overflow ellipsis-h icon again to hide other details. Map list and app/service list panels Select the Map list panel to: Search for and view your maps, and access other users' shared maps. Create a new map. Select the App/Service List panel to: Add new apps and mobile apps to your map. Create custom nodes and add them to the map. Health status and performance metrics You can see health status indicators for most nodes. Except for out-of-process services (external services or background services), entities use the health status indicators used by New Relic Alerts. For out-of-process (external) services, the health status indicator measures the health of the connection to the external service. View all connected apps and services The Discover your environment feature allows you to view all of your apps, services, and dependencies together with a single click. This feature detects all connected applications and services (including externals and databases) to give you a comprehensive view of your overall software architecture environment. To view all connected apps and services: In APM, select Service maps. From your Map list, select Discover your environment to display all of your nodes. Hover over any node to view its dependencies and how it connects to other parts of your service map. Click on individual nodes to zoom in and view their details. The Discover your environment feature may not be available if you are using an older New Relic agent version. See Troubleshooting cross application tracing for version information. This feature may also not be available for highly complex service maps with many elements. Go to one.newrelic.com > More > Service maps > Map list > Discover your environment: Use this option to view all of your nodes and their dependencies in one place. Traffic light mode Traffic light mode lets you view the health status of your entire architecture at a glance. This feature helps you quickly find service and app problems, even within a complex environment with many nodes. To toggle this mode, select the Views tab, then select Traffic light mode. When traffic lights mode is On, zooming out far enough on a service map eventually causes the nodes to switch from displaying textual information, to only health status colors. Click on individual nodes to zoom in and view more details. Traffic light mode is on by default. When traffic lights mode is Off, service map nodes retain their textual information and do not switch to health status colors, No matter how far you zoom out. one.newrelic.com > More > Service maps > Views > Traffic light mode: When traffic light mode is enabled, zooming out of your service map displays nodes in health status colors. Midnight mode Midnight mode inverts the screen's colors, going from a white background to a dark background. Midnight mode reduces eye strain, especially in low light environments. To toggle this mode, select the Views tab, then select Midnight mode.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.73251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Legacy APM <em>service</em> <em>maps</em>",
        "sections": "Legacy APM <em>service</em> <em>maps</em>",
        "tags": "<em>Understand</em> <em>system</em> <em>dependencies</em>",
        "body": "Here is information about using the legacy APM <em>service</em> <em>maps</em> feature to create, customize, and use <em>service</em> <em>maps</em>. For help using the current <em>service</em> <em>maps</em> feature, see How to use <em>service</em> <em>maps</em>. Requirements The legacy <em>service</em> <em>map</em> features in APM <em>depend</em> on your New Relic agent version: Feature"
      },
      "id": "60446a3a28ccbc04a2313970"
    },
    {
      "sections": [
        "How to use service maps",
        "Requirements",
        "Minimum versions when distributed tracing is enabled",
        "Minimum versions when distributed tracing is NOT enabled",
        "Add or remove connections to an entity",
        "Color coded for alerts",
        "Understand dependencies using API",
        "Externals and databases in maps",
        "Missing nodes"
      ],
      "title": "How to use service maps",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Understand system dependencies",
        "Service maps"
      ],
      "external_id": "34d576d70a4393eea903e46c6dc9297303f821eb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/service-maps/how-use-service-maps/",
      "published_at": "2022-01-12T16:50:20Z",
      "updated_at": "2021-10-24T01:51:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here is information about how to use the current service maps feature. For help using the earlier service maps feature, see Legacy APM service maps. Service maps helps you visualize dependencies quickly and easily across your environment. They help you see how all your entities work together across your system. You can use service maps to troubleshoot problems, see how your environment works together, and ensure that issues don’t have downstream repercussions. Service maps also supports cross-account access so help you see relationships between entities for all your accounts. Requirements Service maps work with distributed tracing to connect relationships between entities. Service maps are still functional if you have not enabled distributed tracing, but we recommend having distributed tracing enabled for all agents. This ensures a more consistent experience while using service maps. For best results, update existing agents to the latest version. The required minimum agent versions for maps are: Minimum versions when distributed tracing is enabled The required minimum agent versions for maps using distributed tracing are: C SDK 1.1.0 or higher Go agent 2.1.0 or higher Java agent 4.3.0 or higher .NET agent 8.6.45.0 or higher Node.js agent 4.7.0 or higher PHP agent 8.4 or higher Python agent 4.2.0.100 or higher Ruby agent 5.3.0.346 or higher Minimum versions when distributed tracing is NOT enabled The minimum version requirements for maps not using distributed tracing are: C SDK: not available Go 1.11 or higher Java 3.9.0 or higher .NET 4.2 or higher Node.js 2.0.0 or higher PHP 4.19.0 or higher Python 2.38.0.31 or higher Ruby 4.3.0 or higher Add or remove connections to an entity To view service maps, from one.newrelic.com click Explorer. Once you select an entity to view, you can select service maps from the sidebar. The map shows your upstream and downstream services: entities toward the left are upstream, entities toward the right are downstream. To add or remove connections to an entity: Hover over the entity in the map that you want to alter. Click add or remove more connections. In the connection list, keep boxes checked for the entities that you want to appear in the map. Unchecked entities will be removed from the map. Color coded for alerts Each entity in a map displays a color dependent on its performance. Green: there are currently no violations for this entities performance. Yellow: there is an open warning violation for this entity. Red: there is an open critical violation for this entity. Gray: no alert conditions have been set for the entity White: agent not reporting. This means that the agent installed on the entity is not reporting any data. This is expected behavior for databases or externals. Understand dependencies using API You can discover the same relationship connections available in service maps with NerdGraph. For more information and examples, see the NerdGraph GraphiQL relationships API tutorial. Externals and databases in maps In the New Relic UI, your out-of-process services are referred to as web external or background external data. Externals and databases have slightly different features in service maps than other entity types: Unlike other entities that appear in service maps, externals are aggregates. Clicking on an external service in the map shows you the list of all the external services that are rolled up into the one external entity. This is to reduce map clutter, as some entities can have dozens of externals being reported. Databases are agentless. Because of this, alerts cannot be set for the database, as only see the service call is reported to New Relic. Missing nodes If you are unable to view certain entities in New Relic One service maps, see Troubleshooting: Missing or obfuscated data in New Relic One.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.26843,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How to use <em>service</em> <em>maps</em>",
        "sections": "How to use <em>service</em> <em>maps</em>",
        "tags": "<em>Understand</em> <em>system</em> <em>dependencies</em>",
        "body": " data. This is expected behavior for databases or externals. <em>Understand</em> <em>dependencies</em> using API You can discover the same relationship connections available in <em>service</em> <em>maps</em> with NerdGraph. For more information and examples, see the NerdGraph GraphiQL relationships API tutorial. Externals"
      },
      "id": "603ec23264441fb02c4e8893"
    },
    {
      "sections": [
        "Introduction to service maps",
        "Tip",
        "Access service maps",
        "Identify operational issues"
      ],
      "title": "Introduction to service maps",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Understand system dependencies",
        "Service maps"
      ],
      "external_id": "aca003c282581d2ec459e9584199739e40b0d04e",
      "image": "https://docs.newrelic.com/static/89460254fa31376b446585fb72b476a1/c1b63/NR1_service_maps.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/service-maps/introduction-service-maps/",
      "published_at": "2022-01-12T16:50:20Z",
      "updated_at": "2021-10-24T01:51:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Service maps are visual, customizable representations of your architecture. Maps automatically show your app's connections and dependencies, including applications, databases, hosts, servers, and out-of-process services. Tip In the New Relic UI, your out-of-process services are referred to as web external or background external data. Health indicators and performance metrics show you the current operational status for every part of your architecture. Service maps help you: Understand how apps and services in your architecture connect and communicate. Quickly see the current health and operational state of your entire environment. Troubleshoot operational issues and understand the impact of problems down to the host and instance level. Collaborate and drive shared understanding of an architecture. Access service maps Two options are available in New Relic One: the current service maps and the legacy APM service maps. To access the different service maps: Type To view maps Purpose Current service maps Go to one.newrelic.com > Explorer > (select an entity) > Monitor > Service map Service maps give you increased access to all the entities across your accounts, and help you understand how your entire environment is connected. Legacy APM service maps Go to one.newrelic.com > More > Service maps Legacy APM service maps let you create, customize, and share maps related to an individual app. Identify operational issues Service maps are color-coded to provide a quick look at the current status of your environment. Select nodes on a map to view additional performance metrics, and a full list and health check of each node's connections. The map automatically connects nodes into the map, so you can see which apps on the map connect to others. This helps you troubleshoot and assess the impact of a performance problem between a calling application and a specific database. With service maps, you can view your service and its status in the context of its up and downstream dependencies. Use maps in New Relic One to identify the root cause when troubleshooting an incident. Check out How to use service maps for details about these topics: View all your entities without any setup: most entities are automatically connected to their dependencies in service maps. View entities all across your organization's accounts. Add a map to a dashboard. one.newrelic.com > Explorer > (select an entity) > Monitor > Service map: Service maps show your dependencies and how they're performing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.26843,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>service</em> <em>maps</em>",
        "sections": "Introduction to <em>service</em> <em>maps</em>",
        "tags": "<em>Understand</em> <em>system</em> <em>dependencies</em>",
        "body": " and the legacy APM <em>service</em> <em>maps</em>. To access the different <em>service</em> <em>maps</em>: Type To view <em>maps</em> Purpose Current <em>service</em> <em>maps</em> Go to one.newrelic.com &gt; Explorer &gt; (select an entity) &gt; Monitor &gt; <em>Service</em> <em>map</em> <em>Service</em> <em>maps</em> give you increased access to all the entities across your accounts, and help you <em>understand</em>"
      },
      "id": "60450348e7b9d26e905799d4"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/workloads/use-workloads": [
    {
      "sections": [
        "Use tags to help organize and find your data",
        "Tip",
        "Tag format and limits",
        "Best practices and tips",
        "Tips on keeping tags simple:",
        "Tips on using tags consistently:",
        "Tips on cross-team implementation:",
        "Tag examples",
        "Team-related tags",
        "Environment-related tags",
        "Criticality-related tags",
        "How tags are added",
        "Add tags via UI or API",
        "APM agent tags",
        "Infrastructure data tags",
        "Automate tags with our CLI",
        "Use tags to filter the UI",
        "Custom queries, charts, and alerts",
        "Query and alert on APM tags",
        "Throughput across shards",
        "Transactions per team",
        "Alert on error rate for teams",
        "Query and alert on attributes"
      ],
      "title": "Use tags to help organize and find your data",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e2e2d53776b9109965df9de2a20660e9f60bd479",
      "image": "https://docs.newrelic.com/static/529f55ef72f3e366e6cb4a7be67229b6/c1b63/new-relic-tags-workloads_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data/",
      "published_at": "2022-01-12T02:03:57Z",
      "updated_at": "2021-12-25T14:30:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the software industry, a tag typically refers to a piece of metadata added to a data set for the purpose of improving data organization and findability. At New Relic, our tags are key:value pairs (like team: operations) added to various sets of data, like monitored apps and hosts, agents, dashboards, and workloads. We make some important attributes available as tags (for example, app metadata like app name and language, and host metadata like host name and AWS region). You can also add your own custom tags. You can use tags in the UI to filter down to relevant data. Here is an example: Here you can see an accountId tag being used to filter workloads to a specific account. Tags help you to: Organize data coming from a large number of sources and/or to a large number of New Relic accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example use cases). Better organize and search dashboards and workloads. Query and chart APM data. Tags are useful for organizing data at a high level. If you want to add more fine-grained detail, like capturing user names or other high-cardinality values, custom attributes or custom events are a better solution. Tip Tags were previously called labels in the New Relic UI. You may sometimes see labelin our code; for example, some of our APM agent config files use a label config option for tags. Tag format and limits Format requirements and limits for tags: The UI has limits on the total number of tags it can display per entity: Limit of 100 for tags reported by default or added via agent/integration configuration. Limit of 100 for custom tags added via UI or API. The following are maximum character length for tags: Key: 128 characters Value: 256 characters Allowed characters: Characters must be UTF-8. When using NerdGraph to add tags, a dash (-) in a tag key is interpreted as a minus symbol. If your tag key has a dash, use back ticks around it (like `key-name`). Best practices and tips Before adding tags, we recommend first seeing how our default tags work for you. When you're ready to add your own tags, review the following best practices tips to get the most out of them. Tips on keeping tags simple: Start by adding only tags you know you’ll definitely use. Unused tags create noise and may add confusion. Try to use short tags. Shorter tags are easier to parse, and also the UI may sometimes truncate longer tags. (See character limits.) When possible, use keys and values that are human-readable (for example, region: EMEA is better than Param8323 : 1229072). Avoid including several values like regions: EMEA | US | LATAM in a single tag. We recommend using three different tags for that, like region: emea, region: us, and region: latam. If you want to match multiple tags, you can do that using the advanced options in the filter UI. Tips on using tags consistently: Try to be consistent with tag language across your teams and entities. Be consistent with naming. For example, avoid using both region: emea and reg: emea. Be consistent with format. For example, avoid using both camelCase and kebab-case. Although tag searching is not case-sensitive in the UI and API, try to be consistent with capitalization. For example, avoid using both env: staging and env: Staging. Tips on cross-team implementation: Tags help improve observability and cost allocation. For this reason, responsibility for tag implementation is often assigned to an observability team, SREs, a group of architects, or a cross-team task force. We recommend the people responsible for implementing tags meet and create an internal policy to describe how the tags are defined and which conventions are to be used. Then: Keep this reference manual up to date. Automate the definition of tags when you deploy New Relic agents, at the cloud provider, or through New Relic automation tools, such as the API or Terraform. Create recurring reports that identify entities that are non-compliant with your tagging standards. Tag examples Here are some examples of common ways to use tags to organize data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department, or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db Role examples: roles: architecture roles: devops roles: pm Region examples: region: emea region: america region: asia Environment-related tags You can create entities for the environment they belong to. Examples: env: production env: qa env: development env: staging Criticality-related tags You can create tags related to criticality levels, which lets you easier track the most critical issues. Examples: layer: level1 layer: level2 layer: level3 How tags are added Some important attributes, by default, are available for use as tags. For example, the account name, the account ID, and some basic host/server metadata are available as default tags. You can't remove these available-by-default tags. Here are some details about how tags are added for some specific data sources: Add tags via UI or API When you add tags via the UI or API, this occurs at the entity level. This means that, for example, if you have multiple APM agents monitoring a single entity and apply a tag via the UI, that tag is available for all data coming from that entity. To add or delete tags via the UI: Select a monitored entity, like a monitored app or host. Near the entity’s name at the top of the page, select the See metadata and manage tags menu. In the menu that pops up, add or delete a tag. For APM agents, restart your service. To manage tags via API: see our NerdGraph tagging docs. For a guide to using our CLI to automate tagging, see our developer site. APM agent tags You can add tags via the UI and API or you can add tags using APM agent configuration, both methods require you to restart your service. There are differences in how these apply tags: Via agent config: These tags are applied at the agent-level, not the entity/application level. This would be a good option if you have multiple agents monitoring different aspects of the same app (for example, a blue-green deployment model). Via the UI or API: These tags are applied at the entity/application level. Here are links to the agent configuration options: C SDK: not available Java Go .NET Node.js PHP Python Ruby For information on querying APM tags, see Query APM tags. And check out this short video on querying APM tags (3:20 minutes). Infrastructure data tags There are several ways tags are added to infrastructure entities and services: Use the UI or API to add tags at the entity level. Infrastructure agent: some attributes are available by default as tags. You can also add custom attributes, which are also available as tags in the UI. On-host integrations: some attributes are available by default as tags. You can also add tags by using integration-specific labels config options (for an example, see the labels config for the Apache integration). Cloud service integrations: by default we report tags and labels that are defined in the cloud service. To add tags, you'd add them on the cloud-service-side. Automate tags with our CLI For a guide to automating tags using our CLI tool, see our developer site. Use tags to filter the UI Use the filter field at the top of the New Relic Explorer to filter down to the entities you care about. You can use multiple filter conditions. To filter down to certain entities using tags: From one.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown of available attributes and tags. You can filter by multiple elements and use advanced search options. To find an entity’s metadata and tags from the UI, here are two options: From a list of entities in the UI, at the far right, select an entity's icon. OR Select an entity. Near the top of the page, select the icon. To use the API to view tags, see our NerdGraph docs. Learn about how to use tags with dashboards and how to use tags with workloads. Custom queries, charts, and alerts Different features handle tags differently. Here are some details about how you can use NRQL to query tag data, or create NRQL condition alerts. Query and alert on APM tags You can query APM tags using NRQL. Minimum agent versions: C: not available Go: 2.3.0 Java: 4.9.0 .NET: 8.17 Node: v4.13.0 PHP: not available Python: v4.10.0.112 Ruby: 6.1.0.352 Here are some query examples: Throughput across shards Given a service that is distributed across nine shards, each shard assigned as an environment, we can plot the transaction throughput on all shards using a wildcard query like: SELECT rate(count(apm.service.transaction.duration), 1 minute) FROM Metric WHERE appName LIKE 'MyApp (%' AND transactionType = 'Other' FACET tags.Environment TIMESERIES Copy Transactions per team To see the number of transactions per service for a specific team, we might use a query like: FROM Transaction SELECT count(*) WHERE tags.Team = 'team-a' FACET tags.Project TIMESERIES Copy Alert on error rate for teams You can use a query for your services’ error rate for setting an alert without having to create a rule for each service. Here is the error rate for all services on a team called team-b. And this alert will automatically monitor any new app names added with the team tag. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Team = 'team-b' FACET appName Copy Related to this, you might create a general rule for a specific service deployed across several environments, so that we have an alarm for a single service monitoring each environment individually: From Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Project = 'MyProject' FACET tags.Environment Copy Query and alert on attributes As explained in the tag sources information, some important attributes are used as tags. You can query all attributes and create custom charts using NRQL, and create NRQL alert conditions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.03494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> tags to help organize and find your data",
        "sections": "<em>Use</em> tags to help organize and find your data",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": ": Here you can see an accountId tag being used to filter <em>workloads</em> to a specific account. Tags help you to: Organize data coming from a large number of sources and&#x2F;or to a large number of <em>New</em> <em>Relic</em> accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example"
      },
      "id": "603ebd1228ccbc6278eba754"
    },
    {
      "sections": [
        "Workloads: Isolate and resolve incidents faster",
        "What is a workload in New Relic?",
        "Tip",
        "Why it matters",
        "Requirements",
        "Impact of accounts on the workload permissions and content",
        "Workload account",
        "Scope accounts"
      ],
      "title": "Workloads: Isolate and resolve incidents faster",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "858e74779a209ac0eb948405c311e59a71eb8d9b",
      "image": "https://docs.newrelic.com/static/bb2929677005af573675e7eceead70de/c1b63/1_workload_health_tab.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster/",
      "published_at": "2022-01-12T05:50:03Z",
      "updated_at": "2021-07-30T01:57:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our workloads feature gives you the ability to group and monitor entities based on a team or a set of responsibilities, providing aggregated health and activity data from frontend to backend services across your entire stack. Workloads help you understand the status of complex systems, detect issues, understand the cause and impact of an incident, and resolve those issues quickly. Want to try it? Create a New Relic account for free! No credit card required. What is a workload in New Relic? New Relic monitors a wide range of entities and data, from client-side applications and backend APIs, to the underlying infrastructure. To make sense of this large data set, we give you the ability to create and monitor workloads. Workloads give you the ability to group and monitor entities based on a team or a set of responsibilities, and provide an aggregated view of the health and activity of the entities in the workload. Thus, you can understand better how your business logic is working, from frontend to backend services, across your entire stack. Here are some workload examples: A serverless application that includes an API gateway, a few serverless functions, and a managed database and storage. A browser application and the backend APIs that support it. A collection of Java microservices and the infrastructure they run on. Here's a workload: one.newrelic.com > Explorer > Workloads > (selected workload): The workloads UI provides a curated view of how the entities in your workload are performing. The charts you see will depend on the types of entities you've included to the workload. Tip Learn how to use workloads. Why it matters Workloads give you visibility into the end-to-end availability and consumption of resources across an entire service, and provide you a way to define what’s relevant to you. You can use workloads to group together entities that are important to a specific team or project, so you can better browse and isolate the most relevant data for that service. Because our UI gives you cross-account access, you can add entities to your workload from any of the accounts you have access to. A workload can include: Any New Relic-monitored entity, including services, browser apps, mobile apps, databases, and hosts. Dashboards. Other workloads: this is useful for complex teams who need to divide and overlap workloads. Requirements Requirements for creating and managing workloads: All users for an account can view that account's workloads. To create, edit, and delete workloads, you must have a user role with that permission. Impact of accounts on the workload permissions and content Workloads can group and display entities from multiple accounts to provide complete observability of complex systems. When creating a workload, you must set: The workload account Scope accounts Learn how to find a New Relic account ID. Workload account The workload account is where any workload-specific data is stored. For example, a workload might generate NrAuditEvent data, and you would find that data by querying the workload account. The workload account determines the user permissions that govern which users can see and manage the workload, through the account roles. Once created, the workload account can’t be changed. Scope accounts Scope accounts are the accounts from which a workload fetches entity data. In other words, the scope accounts provide the content for a workload. Users who don’t have access to all of a workload's scope accounts may not be able to see complete workload data. Scope accounts can be updated at any point in time by any user with workload management capabilities on the workload account. By default, all accounts that the workload creator has access to at the moment of the workload creation are set as scope accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.23497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Workloads</em>: Isolate and resolve incidents faster",
        "sections": "What is a <em>workload</em> in <em>New</em> <em>Relic</em>?",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " of the accounts you have access to. A <em>workload</em> can include: Any <em>New</em> <em>Relic</em>-monitored entity, including services, browser apps, mobile apps, databases, and hosts. Dashboards. Other <em>workloads</em>: this is useful for complex teams who need to divide and overlap <em>workloads</em>. Requirements Requirements for creating"
      },
      "id": "6043cb93196a67f988960f76"
    },
    {
      "sections": [
        "Workload status views and notifications",
        "Why it matters",
        "Get started with workload status",
        "Obtain your workload status",
        "Save views with sets of workloads",
        "Get notified when the workload status changes"
      ],
      "title": "Workload status views and notifications",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "1633f322d9f0c907a9636e0c71aee7a0a38ba85b",
      "image": "https://docs.newrelic.com/static/5ea6d75d1efb047eda59eee3f12e08a9/c1b63/workloads_views.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/workload-status-views-notifications/",
      "published_at": "2022-01-12T05:49:24Z",
      "updated_at": "2021-05-10T14:02:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The workload status, which is derived from the alerting status of the entities in your workload, informs you about how your workload is behaving. Why it matters Workload status: Is a quick indicator of how your system is doing, and tells you if you need to take action on any of your workloads in just a glance. Adapts to your needs and to how important each entity is. Allows you to share the status of your workloads. Other teams that depend on your services or infrastructure can learn the status of the workload without them needing to understand your system’s architecture details, or look at custom dashboards. Get started with workload status New Relic One provides a status value for all entities, which is based on the results of New Relic alerts. You can check the color-coded alert status for each entity on the New Relic Explorer, or consume the alert status value through the API. For example, you may see a red alert status indicating that a critical violation is in progress. With Workloads you can group entities that are part of a complex system and obtain a single, global value that summarizes the status of all the entities in your workload. Thus, you can quickly detect when the workload stops being operational, or anticipate any potential incident or loss of quality of service. Obtain your workload status A workload can have one of the following status values: Operational: The workload is working fine. Degraded: The workload is showing some degradation in performance or errors, but it’s still providing an acceptable level of service, and you don’t need to take any urgent action. Critical or Disrupted: The workload is not providing an acceptable level of service, and you need to take urgent action. Unknown: You haven’t configured how to calculate workload status, or there aren’t any alert conditions set up that can determine the status of the workload entities. To learn how to define or edit the workload status, refer to Workload status configuration. Save views with sets of workloads If you usually need to see the status of a certain group of workloads, you can save views that contain only those workloads. The tile view mode helps you quickly find your workloads and see their status at a glance. To create a view, follow these steps: Go to one.newrelic.com and click on More > Workload views. Click on Add view. Give the view a meaningful name (such as the name of a team or business unit), and select an account to associate the view with. Select the workloads you want to include in the view, by their name or tags. Save the new view. Status views are most useful for teams that are accountable for more than one workload, support roles, and business unit managers. Get notified when the workload status changes You may need to follow the status of a workload, either because it represents the services your team is accountable for, or because your own services depend on that workload, which is managed by another team. The status of all workloads is calculated regularly and the result is stored in NRDB through a WorkloadStatus event. This allows you to set up an alert condition to notify you whenever the Workload goes into a Disrupted or Degraded status. To set up the alert condition follow these steps: Go to one.newrelic.com and select Alerts & AI. Select the policy where you want to add the new alert condition, or create a new policy with the appropriate notification channel. Then click on Create a condition. Where prompted to Select a product, click NRQL. Add the following NRQL query: SELECT latest(statusValueCode) FROM WorkloadStatus WHERE workloadGuid = '<GUID>' FACET workloadGuid as 'entity.guid', entity.name Copy You can obtain the workload GUID by clicking on the See metadata and manage tags on the workload UI. Write the WHERE clause so the alert condition applies to just one workload (as in the example) or more than one. Or remove the WHERE clause if you want the alert condition to apply to all the workloads on the account. By adding the FACET you can use these fields on the alert description, as explained below. Set one of the following static thresholds: (Recommended) Critical when the query returns a value equal to 3 for at least 1 minute, if you want to be notified when the workload status is disrupted. Critical when the query returns a value equal to 2 for at least 1 minute, if you want to be notified when the workload status is degraded. Remember that a warning threshold doesn't generate an incident or send a notification. As a result, you need to create two alert conditions with a critical threshold (as explained above) if you want to be notified of any status change. Complete the alert condition: Set a violation time limit, to automatically force-close a long-lasting violation after the selected amount of time you select. Choose to fill data gaps with last known value. Optionally, you can also add a custom violation description that includes the workload name and permanent link to the UI in the alert notification: Workload: {{tag.entity.name}} Direct link: https://one.newrelic.com/redirect/entity/{{tag.entity.guid}} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.9345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Workload</em> status views and notifications",
        "sections": "Save views with sets of <em>workloads</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " at custom dashboards. Get started with <em>workload</em> status <em>New</em> <em>Relic</em> <em>One</em> provides a status value for all entities, which is based on the results of <em>New</em> <em>Relic</em> alerts. You can check the color-coded alert status for each entity on the <em>New</em> <em>Relic</em> Explorer, or consume the alert status value through the API"
      },
      "id": "603e967564441ff8cd4e8855"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/workloads/workload-status-configuration": [
    {
      "sections": [
        "Use workloads",
        "Health",
        "Activity",
        "Owner",
        "Header",
        "Create a workload",
        "Use tags to define the workload content",
        "How the dynamic query logic works",
        "Add dashboards to workloads",
        "Use the API"
      ],
      "title": "Use workloads",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "c39090bde9b797940e7f5ba0c9610ba39879677b",
      "image": "https://docs.newrelic.com/static/14c811e218cfc8793bb4d2bd4b2aad0b/c1b63/new-relic-workloads-add-dashboards.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/use-workloads/",
      "published_at": "2022-01-12T05:30:45Z",
      "updated_at": "2021-12-30T18:57:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view workloads, go to one.newrelic.com and find them on the Explorer. There are three main tabs (Health, Activity, and Owner) plus the header. Health The Health tab in a workload provides relevant status data that helps you operate the workload: It shows the global status of the workload, as well as the individual status of all the entities that make up the workload at each point in time. It looks like this: It comprises the following: The navigator view shows the entities that make up the workload, and provides controls to group and sort them. If you’ve used queries to dynamically select entities, the workload entities will change over time. The workload status informs about how your workload is performing, based on the individual alerting status of the entities in your workload. With health over time you’ll see whether and how the workload status has changed in the past three hours. If one or more entities are alerting, you’ll get a count of criticals and warnings and a summary of the open conditions, which will make it easier to identify and troubleshoot the most important issues. Activity The Activity tab shows performance data related to the entities in the workload, along with the events that could explain any changes in those time series. It looks like this: Here are the most important sections: Linked dashboards. You can add links to dashboards from your workload, and create pre-filtered, workload-relevant links to dashboards. Golden metrics. These are charts with the most relevant metrics for each entity type, such as number of requests, response time, and error rate for an application. Explore the charts to detect correlations among different entities (for example, two applications) and different stack layers (for example, applications and hosts). The golden metrics that you see for each entity type on a workload can be customized either at the account or the workload level through the NerdGraph API. Events timeline. This includes the start and end time of incidents and anomalies that refer to the workload entities. It also shows other event types that can explain a change in the status or performance of the workload, such as deployments and configuration changes. You can control which golden metrics are used to visualize your workload entities by using the golden metrics API. To learn more, watch this short video (approx. 4 minutes). Owner The Owner tab gives you information about the team responsible for the workload. It looks like this: It contains: The team responsible for the workload. You can include more than one team. The workload description. Share the mission of the workload, and the business logic it represents: Is it a web application? An API? A backend process? Fill in any details that are relevant to your team, or to other teams in your organization. Contact information. From the drop-down menu, choose how your team prefers to be contacted. Links to the most relevant resources to operate the workload. Here you can add links to runbooks, code repositories, productivity tools, or anything else related to the workload that you need at hand. Header The header contains the filter bar and the edition controls: Filter bar. Use the advanced filtering options when you need to focus only on certain entities within the workload. Edit workload. Define the entities that are part of the workload, and the accounts they’ll be fetched from. Setup status. Configure how the global workload status will be determined, based on the workload entities health. Summary page. See all the tags that have been added to the workload, as well as metadata such as the workload's identifier (GUID) and account. You can create workloads that update dynamically by leveraging tags. To learn how, watch this short video (approx. 3 minutes). Create a workload A workload should contain the entities you and your team want to see. Your choice of entities depends on your organization structure and goals. one.newrelic.com > Explorer > Workloads > Create a workload: When you create a workload, you choose the associated accounts and monitored entities. You can use New Relic One or the NerdGraph API to create a workload. Follow these steps to create a workload using the UI: Go to one.newrelic.com and click on the Explorer, and then click + Create a workload. Give the workload a name that will be meaningful for you and your team later. From the Select an account dropdown, select the workload account you'd like to use. Click Choose the scope accounts to check all of the accounts related to this workload. Find and choose the entities that make up the workload. When you have the results you're looking for, you can add specific entities or add the query to dynamically update the entities in the workload. You can search by entity type, tags, or attributes (like entity name, account ID, and AWS region). Click + Add this query to create a list of dynamically updated entities for your workload. We recommend this if you want your workload to update its entities as your system changes. Click + Add next to an entity to add it to your workload. This is a good choice if you know that the entities will stay useful even as your system changes. You can add a combination of queries and specific entities to the workload, which combine according to the query logic. Click Create a workload to save the workload. Once you've created the workload, you can edit it at any time If your workload contains one or more dashboards, you can set filters on those dashboard links. Below are more details about some aspects of how to define workloads: Use tags to define the workload content You can query and select workload entities using both tags and attributes. Therefore, to optimize your use of workloads, it helps to have a good entity-tagging strategy. We recommend reading the tagging documentation. How the dynamic query logic works You can add several individual entities and queries to define a workload. Queries can include multiple search terms. These are combined with an AND operator. Separate queries within a workload are combined with an OR operator. You can wrap strings between percent signs (%) to match exact substrings within a query. If you use substrings in entity names to categorize those entities (for example, <team>-<env>-<appName>), consider using tags complementarily, which are more powerful for filtering and grouping (for example, team:awesome, env:production). We recommend not to use percent signs (%) in dynamic queries that might return over 500 entities. This way, you get a more consistent experience in the user interface. Add dashboards to workloads If you have custom dashboards and you already know which data is relevant to your team for observing and operating their workloads, you can link those dashboards from your workload. You can also set filters on dashboards to scope them to a workload-specific context. When a user selects that dashboard from the workload, it opens with the filter already applied. one.newrelic.com > Apps > Workloads: You can add dashboards to a workload. To add dashboards to a workload: When creating or editing a workload, type Dashboard in the workload search bar to filter to dashboard entities. Add other search terms to filter to specific dashboards. Click Add. one.newrelic.com > Apps > Workloads: You can set filters on the dashboards you've linked to a workload. To filter a workload’s dashboard: From a workload’s Overview page, select a dashboard. Add search terms to filter the dashboard to a view that’s relevant for that workload. Select Save filter for this workload. Use the API You can query, create, and update workloads with our NerdGraph API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 277.44864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>workloads</em>",
        "sections": "<em>Use</em> <em>workloads</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " of entities depends on your organization structure and goals. <em>one</em>.newrelic.com &gt; Explorer &gt; <em>Workloads</em> &gt; Create a <em>workload</em>: When you create a <em>workload</em>, you choose the associated accounts and monitored entities. You can <em>use</em> <em>New</em> <em>Relic</em> <em>One</em> or the NerdGraph API to create a <em>workload</em>. Follow these steps"
      },
      "id": "603e81e8196a67c972a83db1"
    },
    {
      "sections": [
        "Use tags to help organize and find your data",
        "Tip",
        "Tag format and limits",
        "Best practices and tips",
        "Tips on keeping tags simple:",
        "Tips on using tags consistently:",
        "Tips on cross-team implementation:",
        "Tag examples",
        "Team-related tags",
        "Environment-related tags",
        "Criticality-related tags",
        "How tags are added",
        "Add tags via UI or API",
        "APM agent tags",
        "Infrastructure data tags",
        "Automate tags with our CLI",
        "Use tags to filter the UI",
        "Custom queries, charts, and alerts",
        "Query and alert on APM tags",
        "Throughput across shards",
        "Transactions per team",
        "Alert on error rate for teams",
        "Query and alert on attributes"
      ],
      "title": "Use tags to help organize and find your data",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e2e2d53776b9109965df9de2a20660e9f60bd479",
      "image": "https://docs.newrelic.com/static/529f55ef72f3e366e6cb4a7be67229b6/c1b63/new-relic-tags-workloads_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data/",
      "published_at": "2022-01-12T02:03:57Z",
      "updated_at": "2021-12-25T14:30:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the software industry, a tag typically refers to a piece of metadata added to a data set for the purpose of improving data organization and findability. At New Relic, our tags are key:value pairs (like team: operations) added to various sets of data, like monitored apps and hosts, agents, dashboards, and workloads. We make some important attributes available as tags (for example, app metadata like app name and language, and host metadata like host name and AWS region). You can also add your own custom tags. You can use tags in the UI to filter down to relevant data. Here is an example: Here you can see an accountId tag being used to filter workloads to a specific account. Tags help you to: Organize data coming from a large number of sources and/or to a large number of New Relic accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example use cases). Better organize and search dashboards and workloads. Query and chart APM data. Tags are useful for organizing data at a high level. If you want to add more fine-grained detail, like capturing user names or other high-cardinality values, custom attributes or custom events are a better solution. Tip Tags were previously called labels in the New Relic UI. You may sometimes see labelin our code; for example, some of our APM agent config files use a label config option for tags. Tag format and limits Format requirements and limits for tags: The UI has limits on the total number of tags it can display per entity: Limit of 100 for tags reported by default or added via agent/integration configuration. Limit of 100 for custom tags added via UI or API. The following are maximum character length for tags: Key: 128 characters Value: 256 characters Allowed characters: Characters must be UTF-8. When using NerdGraph to add tags, a dash (-) in a tag key is interpreted as a minus symbol. If your tag key has a dash, use back ticks around it (like `key-name`). Best practices and tips Before adding tags, we recommend first seeing how our default tags work for you. When you're ready to add your own tags, review the following best practices tips to get the most out of them. Tips on keeping tags simple: Start by adding only tags you know you’ll definitely use. Unused tags create noise and may add confusion. Try to use short tags. Shorter tags are easier to parse, and also the UI may sometimes truncate longer tags. (See character limits.) When possible, use keys and values that are human-readable (for example, region: EMEA is better than Param8323 : 1229072). Avoid including several values like regions: EMEA | US | LATAM in a single tag. We recommend using three different tags for that, like region: emea, region: us, and region: latam. If you want to match multiple tags, you can do that using the advanced options in the filter UI. Tips on using tags consistently: Try to be consistent with tag language across your teams and entities. Be consistent with naming. For example, avoid using both region: emea and reg: emea. Be consistent with format. For example, avoid using both camelCase and kebab-case. Although tag searching is not case-sensitive in the UI and API, try to be consistent with capitalization. For example, avoid using both env: staging and env: Staging. Tips on cross-team implementation: Tags help improve observability and cost allocation. For this reason, responsibility for tag implementation is often assigned to an observability team, SREs, a group of architects, or a cross-team task force. We recommend the people responsible for implementing tags meet and create an internal policy to describe how the tags are defined and which conventions are to be used. Then: Keep this reference manual up to date. Automate the definition of tags when you deploy New Relic agents, at the cloud provider, or through New Relic automation tools, such as the API or Terraform. Create recurring reports that identify entities that are non-compliant with your tagging standards. Tag examples Here are some examples of common ways to use tags to organize data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department, or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db Role examples: roles: architecture roles: devops roles: pm Region examples: region: emea region: america region: asia Environment-related tags You can create entities for the environment they belong to. Examples: env: production env: qa env: development env: staging Criticality-related tags You can create tags related to criticality levels, which lets you easier track the most critical issues. Examples: layer: level1 layer: level2 layer: level3 How tags are added Some important attributes, by default, are available for use as tags. For example, the account name, the account ID, and some basic host/server metadata are available as default tags. You can't remove these available-by-default tags. Here are some details about how tags are added for some specific data sources: Add tags via UI or API When you add tags via the UI or API, this occurs at the entity level. This means that, for example, if you have multiple APM agents monitoring a single entity and apply a tag via the UI, that tag is available for all data coming from that entity. To add or delete tags via the UI: Select a monitored entity, like a monitored app or host. Near the entity’s name at the top of the page, select the See metadata and manage tags menu. In the menu that pops up, add or delete a tag. For APM agents, restart your service. To manage tags via API: see our NerdGraph tagging docs. For a guide to using our CLI to automate tagging, see our developer site. APM agent tags You can add tags via the UI and API or you can add tags using APM agent configuration, both methods require you to restart your service. There are differences in how these apply tags: Via agent config: These tags are applied at the agent-level, not the entity/application level. This would be a good option if you have multiple agents monitoring different aspects of the same app (for example, a blue-green deployment model). Via the UI or API: These tags are applied at the entity/application level. Here are links to the agent configuration options: C SDK: not available Java Go .NET Node.js PHP Python Ruby For information on querying APM tags, see Query APM tags. And check out this short video on querying APM tags (3:20 minutes). Infrastructure data tags There are several ways tags are added to infrastructure entities and services: Use the UI or API to add tags at the entity level. Infrastructure agent: some attributes are available by default as tags. You can also add custom attributes, which are also available as tags in the UI. On-host integrations: some attributes are available by default as tags. You can also add tags by using integration-specific labels config options (for an example, see the labels config for the Apache integration). Cloud service integrations: by default we report tags and labels that are defined in the cloud service. To add tags, you'd add them on the cloud-service-side. Automate tags with our CLI For a guide to automating tags using our CLI tool, see our developer site. Use tags to filter the UI Use the filter field at the top of the New Relic Explorer to filter down to the entities you care about. You can use multiple filter conditions. To filter down to certain entities using tags: From one.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown of available attributes and tags. You can filter by multiple elements and use advanced search options. To find an entity’s metadata and tags from the UI, here are two options: From a list of entities in the UI, at the far right, select an entity's icon. OR Select an entity. Near the top of the page, select the icon. To use the API to view tags, see our NerdGraph docs. Learn about how to use tags with dashboards and how to use tags with workloads. Custom queries, charts, and alerts Different features handle tags differently. Here are some details about how you can use NRQL to query tag data, or create NRQL condition alerts. Query and alert on APM tags You can query APM tags using NRQL. Minimum agent versions: C: not available Go: 2.3.0 Java: 4.9.0 .NET: 8.17 Node: v4.13.0 PHP: not available Python: v4.10.0.112 Ruby: 6.1.0.352 Here are some query examples: Throughput across shards Given a service that is distributed across nine shards, each shard assigned as an environment, we can plot the transaction throughput on all shards using a wildcard query like: SELECT rate(count(apm.service.transaction.duration), 1 minute) FROM Metric WHERE appName LIKE 'MyApp (%' AND transactionType = 'Other' FACET tags.Environment TIMESERIES Copy Transactions per team To see the number of transactions per service for a specific team, we might use a query like: FROM Transaction SELECT count(*) WHERE tags.Team = 'team-a' FACET tags.Project TIMESERIES Copy Alert on error rate for teams You can use a query for your services’ error rate for setting an alert without having to create a rule for each service. Here is the error rate for all services on a team called team-b. And this alert will automatically monitor any new app names added with the team tag. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Team = 'team-b' FACET appName Copy Related to this, you might create a general rule for a specific service deployed across several environments, so that we have an alarm for a single service monitoring each environment individually: From Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Project = 'MyProject' FACET tags.Environment Copy Query and alert on attributes As explained in the tag sources information, some important attributes are used as tags. You can query all attributes and create custom charts using NRQL, and create NRQL alert conditions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.03494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> tags to help organize and find your data",
        "sections": "<em>Use</em> tags to help organize and find your data",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": ": Here you can see an accountId tag being used to filter <em>workloads</em> to a specific account. Tags help you to: Organize data coming from a large number of sources and&#x2F;or to a large number of <em>New</em> <em>Relic</em> accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example"
      },
      "id": "603ebd1228ccbc6278eba754"
    },
    {
      "sections": [
        "Workloads: Isolate and resolve incidents faster",
        "What is a workload in New Relic?",
        "Tip",
        "Why it matters",
        "Requirements",
        "Impact of accounts on the workload permissions and content",
        "Workload account",
        "Scope accounts"
      ],
      "title": "Workloads: Isolate and resolve incidents faster",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "858e74779a209ac0eb948405c311e59a71eb8d9b",
      "image": "https://docs.newrelic.com/static/bb2929677005af573675e7eceead70de/c1b63/1_workload_health_tab.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster/",
      "published_at": "2022-01-12T05:50:03Z",
      "updated_at": "2021-07-30T01:57:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our workloads feature gives you the ability to group and monitor entities based on a team or a set of responsibilities, providing aggregated health and activity data from frontend to backend services across your entire stack. Workloads help you understand the status of complex systems, detect issues, understand the cause and impact of an incident, and resolve those issues quickly. Want to try it? Create a New Relic account for free! No credit card required. What is a workload in New Relic? New Relic monitors a wide range of entities and data, from client-side applications and backend APIs, to the underlying infrastructure. To make sense of this large data set, we give you the ability to create and monitor workloads. Workloads give you the ability to group and monitor entities based on a team or a set of responsibilities, and provide an aggregated view of the health and activity of the entities in the workload. Thus, you can understand better how your business logic is working, from frontend to backend services, across your entire stack. Here are some workload examples: A serverless application that includes an API gateway, a few serverless functions, and a managed database and storage. A browser application and the backend APIs that support it. A collection of Java microservices and the infrastructure they run on. Here's a workload: one.newrelic.com > Explorer > Workloads > (selected workload): The workloads UI provides a curated view of how the entities in your workload are performing. The charts you see will depend on the types of entities you've included to the workload. Tip Learn how to use workloads. Why it matters Workloads give you visibility into the end-to-end availability and consumption of resources across an entire service, and provide you a way to define what’s relevant to you. You can use workloads to group together entities that are important to a specific team or project, so you can better browse and isolate the most relevant data for that service. Because our UI gives you cross-account access, you can add entities to your workload from any of the accounts you have access to. A workload can include: Any New Relic-monitored entity, including services, browser apps, mobile apps, databases, and hosts. Dashboards. Other workloads: this is useful for complex teams who need to divide and overlap workloads. Requirements Requirements for creating and managing workloads: All users for an account can view that account's workloads. To create, edit, and delete workloads, you must have a user role with that permission. Impact of accounts on the workload permissions and content Workloads can group and display entities from multiple accounts to provide complete observability of complex systems. When creating a workload, you must set: The workload account Scope accounts Learn how to find a New Relic account ID. Workload account The workload account is where any workload-specific data is stored. For example, a workload might generate NrAuditEvent data, and you would find that data by querying the workload account. The workload account determines the user permissions that govern which users can see and manage the workload, through the account roles. Once created, the workload account can’t be changed. Scope accounts Scope accounts are the accounts from which a workload fetches entity data. In other words, the scope accounts provide the content for a workload. Users who don’t have access to all of a workload's scope accounts may not be able to see complete workload data. Scope accounts can be updated at any point in time by any user with workload management capabilities on the workload account. By default, all accounts that the workload creator has access to at the moment of the workload creation are set as scope accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.23497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Workloads</em>: Isolate and resolve incidents faster",
        "sections": "What is a <em>workload</em> in <em>New</em> <em>Relic</em>?",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " of the accounts you have access to. A <em>workload</em> can include: Any <em>New</em> <em>Relic</em>-monitored entity, including services, browser apps, mobile apps, databases, and hosts. Dashboards. Other <em>workloads</em>: this is useful for complex teams who need to divide and overlap <em>workloads</em>. Requirements Requirements for creating"
      },
      "id": "6043cb93196a67f988960f76"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/workloads/workload-status-views-notifications": [
    {
      "sections": [
        "Use workloads",
        "Health",
        "Activity",
        "Owner",
        "Header",
        "Create a workload",
        "Use tags to define the workload content",
        "How the dynamic query logic works",
        "Add dashboards to workloads",
        "Use the API"
      ],
      "title": "Use workloads",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "c39090bde9b797940e7f5ba0c9610ba39879677b",
      "image": "https://docs.newrelic.com/static/14c811e218cfc8793bb4d2bd4b2aad0b/c1b63/new-relic-workloads-add-dashboards.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/use-workloads/",
      "published_at": "2022-01-12T05:30:45Z",
      "updated_at": "2021-12-30T18:57:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view workloads, go to one.newrelic.com and find them on the Explorer. There are three main tabs (Health, Activity, and Owner) plus the header. Health The Health tab in a workload provides relevant status data that helps you operate the workload: It shows the global status of the workload, as well as the individual status of all the entities that make up the workload at each point in time. It looks like this: It comprises the following: The navigator view shows the entities that make up the workload, and provides controls to group and sort them. If you’ve used queries to dynamically select entities, the workload entities will change over time. The workload status informs about how your workload is performing, based on the individual alerting status of the entities in your workload. With health over time you’ll see whether and how the workload status has changed in the past three hours. If one or more entities are alerting, you’ll get a count of criticals and warnings and a summary of the open conditions, which will make it easier to identify and troubleshoot the most important issues. Activity The Activity tab shows performance data related to the entities in the workload, along with the events that could explain any changes in those time series. It looks like this: Here are the most important sections: Linked dashboards. You can add links to dashboards from your workload, and create pre-filtered, workload-relevant links to dashboards. Golden metrics. These are charts with the most relevant metrics for each entity type, such as number of requests, response time, and error rate for an application. Explore the charts to detect correlations among different entities (for example, two applications) and different stack layers (for example, applications and hosts). The golden metrics that you see for each entity type on a workload can be customized either at the account or the workload level through the NerdGraph API. Events timeline. This includes the start and end time of incidents and anomalies that refer to the workload entities. It also shows other event types that can explain a change in the status or performance of the workload, such as deployments and configuration changes. You can control which golden metrics are used to visualize your workload entities by using the golden metrics API. To learn more, watch this short video (approx. 4 minutes). Owner The Owner tab gives you information about the team responsible for the workload. It looks like this: It contains: The team responsible for the workload. You can include more than one team. The workload description. Share the mission of the workload, and the business logic it represents: Is it a web application? An API? A backend process? Fill in any details that are relevant to your team, or to other teams in your organization. Contact information. From the drop-down menu, choose how your team prefers to be contacted. Links to the most relevant resources to operate the workload. Here you can add links to runbooks, code repositories, productivity tools, or anything else related to the workload that you need at hand. Header The header contains the filter bar and the edition controls: Filter bar. Use the advanced filtering options when you need to focus only on certain entities within the workload. Edit workload. Define the entities that are part of the workload, and the accounts they’ll be fetched from. Setup status. Configure how the global workload status will be determined, based on the workload entities health. Summary page. See all the tags that have been added to the workload, as well as metadata such as the workload's identifier (GUID) and account. You can create workloads that update dynamically by leveraging tags. To learn how, watch this short video (approx. 3 minutes). Create a workload A workload should contain the entities you and your team want to see. Your choice of entities depends on your organization structure and goals. one.newrelic.com > Explorer > Workloads > Create a workload: When you create a workload, you choose the associated accounts and monitored entities. You can use New Relic One or the NerdGraph API to create a workload. Follow these steps to create a workload using the UI: Go to one.newrelic.com and click on the Explorer, and then click + Create a workload. Give the workload a name that will be meaningful for you and your team later. From the Select an account dropdown, select the workload account you'd like to use. Click Choose the scope accounts to check all of the accounts related to this workload. Find and choose the entities that make up the workload. When you have the results you're looking for, you can add specific entities or add the query to dynamically update the entities in the workload. You can search by entity type, tags, or attributes (like entity name, account ID, and AWS region). Click + Add this query to create a list of dynamically updated entities for your workload. We recommend this if you want your workload to update its entities as your system changes. Click + Add next to an entity to add it to your workload. This is a good choice if you know that the entities will stay useful even as your system changes. You can add a combination of queries and specific entities to the workload, which combine according to the query logic. Click Create a workload to save the workload. Once you've created the workload, you can edit it at any time If your workload contains one or more dashboards, you can set filters on those dashboard links. Below are more details about some aspects of how to define workloads: Use tags to define the workload content You can query and select workload entities using both tags and attributes. Therefore, to optimize your use of workloads, it helps to have a good entity-tagging strategy. We recommend reading the tagging documentation. How the dynamic query logic works You can add several individual entities and queries to define a workload. Queries can include multiple search terms. These are combined with an AND operator. Separate queries within a workload are combined with an OR operator. You can wrap strings between percent signs (%) to match exact substrings within a query. If you use substrings in entity names to categorize those entities (for example, <team>-<env>-<appName>), consider using tags complementarily, which are more powerful for filtering and grouping (for example, team:awesome, env:production). We recommend not to use percent signs (%) in dynamic queries that might return over 500 entities. This way, you get a more consistent experience in the user interface. Add dashboards to workloads If you have custom dashboards and you already know which data is relevant to your team for observing and operating their workloads, you can link those dashboards from your workload. You can also set filters on dashboards to scope them to a workload-specific context. When a user selects that dashboard from the workload, it opens with the filter already applied. one.newrelic.com > Apps > Workloads: You can add dashboards to a workload. To add dashboards to a workload: When creating or editing a workload, type Dashboard in the workload search bar to filter to dashboard entities. Add other search terms to filter to specific dashboards. Click Add. one.newrelic.com > Apps > Workloads: You can set filters on the dashboards you've linked to a workload. To filter a workload’s dashboard: From a workload’s Overview page, select a dashboard. Add search terms to filter the dashboard to a view that’s relevant for that workload. Select Save filter for this workload. Use the API You can query, create, and update workloads with our NerdGraph API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 277.44864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>workloads</em>",
        "sections": "<em>Use</em> <em>workloads</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " of entities depends on your organization structure and goals. <em>one</em>.newrelic.com &gt; Explorer &gt; <em>Workloads</em> &gt; Create a <em>workload</em>: When you create a <em>workload</em>, you choose the associated accounts and monitored entities. You can <em>use</em> <em>New</em> <em>Relic</em> <em>One</em> or the NerdGraph API to create a <em>workload</em>. Follow these steps"
      },
      "id": "603e81e8196a67c972a83db1"
    },
    {
      "sections": [
        "Use tags to help organize and find your data",
        "Tip",
        "Tag format and limits",
        "Best practices and tips",
        "Tips on keeping tags simple:",
        "Tips on using tags consistently:",
        "Tips on cross-team implementation:",
        "Tag examples",
        "Team-related tags",
        "Environment-related tags",
        "Criticality-related tags",
        "How tags are added",
        "Add tags via UI or API",
        "APM agent tags",
        "Infrastructure data tags",
        "Automate tags with our CLI",
        "Use tags to filter the UI",
        "Custom queries, charts, and alerts",
        "Query and alert on APM tags",
        "Throughput across shards",
        "Transactions per team",
        "Alert on error rate for teams",
        "Query and alert on attributes"
      ],
      "title": "Use tags to help organize and find your data",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e2e2d53776b9109965df9de2a20660e9f60bd479",
      "image": "https://docs.newrelic.com/static/529f55ef72f3e366e6cb4a7be67229b6/c1b63/new-relic-tags-workloads_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data/",
      "published_at": "2022-01-12T02:03:57Z",
      "updated_at": "2021-12-25T14:30:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the software industry, a tag typically refers to a piece of metadata added to a data set for the purpose of improving data organization and findability. At New Relic, our tags are key:value pairs (like team: operations) added to various sets of data, like monitored apps and hosts, agents, dashboards, and workloads. We make some important attributes available as tags (for example, app metadata like app name and language, and host metadata like host name and AWS region). You can also add your own custom tags. You can use tags in the UI to filter down to relevant data. Here is an example: Here you can see an accountId tag being used to filter workloads to a specific account. Tags help you to: Organize data coming from a large number of sources and/or to a large number of New Relic accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example use cases). Better organize and search dashboards and workloads. Query and chart APM data. Tags are useful for organizing data at a high level. If you want to add more fine-grained detail, like capturing user names or other high-cardinality values, custom attributes or custom events are a better solution. Tip Tags were previously called labels in the New Relic UI. You may sometimes see labelin our code; for example, some of our APM agent config files use a label config option for tags. Tag format and limits Format requirements and limits for tags: The UI has limits on the total number of tags it can display per entity: Limit of 100 for tags reported by default or added via agent/integration configuration. Limit of 100 for custom tags added via UI or API. The following are maximum character length for tags: Key: 128 characters Value: 256 characters Allowed characters: Characters must be UTF-8. When using NerdGraph to add tags, a dash (-) in a tag key is interpreted as a minus symbol. If your tag key has a dash, use back ticks around it (like `key-name`). Best practices and tips Before adding tags, we recommend first seeing how our default tags work for you. When you're ready to add your own tags, review the following best practices tips to get the most out of them. Tips on keeping tags simple: Start by adding only tags you know you’ll definitely use. Unused tags create noise and may add confusion. Try to use short tags. Shorter tags are easier to parse, and also the UI may sometimes truncate longer tags. (See character limits.) When possible, use keys and values that are human-readable (for example, region: EMEA is better than Param8323 : 1229072). Avoid including several values like regions: EMEA | US | LATAM in a single tag. We recommend using three different tags for that, like region: emea, region: us, and region: latam. If you want to match multiple tags, you can do that using the advanced options in the filter UI. Tips on using tags consistently: Try to be consistent with tag language across your teams and entities. Be consistent with naming. For example, avoid using both region: emea and reg: emea. Be consistent with format. For example, avoid using both camelCase and kebab-case. Although tag searching is not case-sensitive in the UI and API, try to be consistent with capitalization. For example, avoid using both env: staging and env: Staging. Tips on cross-team implementation: Tags help improve observability and cost allocation. For this reason, responsibility for tag implementation is often assigned to an observability team, SREs, a group of architects, or a cross-team task force. We recommend the people responsible for implementing tags meet and create an internal policy to describe how the tags are defined and which conventions are to be used. Then: Keep this reference manual up to date. Automate the definition of tags when you deploy New Relic agents, at the cloud provider, or through New Relic automation tools, such as the API or Terraform. Create recurring reports that identify entities that are non-compliant with your tagging standards. Tag examples Here are some examples of common ways to use tags to organize data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department, or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db Role examples: roles: architecture roles: devops roles: pm Region examples: region: emea region: america region: asia Environment-related tags You can create entities for the environment they belong to. Examples: env: production env: qa env: development env: staging Criticality-related tags You can create tags related to criticality levels, which lets you easier track the most critical issues. Examples: layer: level1 layer: level2 layer: level3 How tags are added Some important attributes, by default, are available for use as tags. For example, the account name, the account ID, and some basic host/server metadata are available as default tags. You can't remove these available-by-default tags. Here are some details about how tags are added for some specific data sources: Add tags via UI or API When you add tags via the UI or API, this occurs at the entity level. This means that, for example, if you have multiple APM agents monitoring a single entity and apply a tag via the UI, that tag is available for all data coming from that entity. To add or delete tags via the UI: Select a monitored entity, like a monitored app or host. Near the entity’s name at the top of the page, select the See metadata and manage tags menu. In the menu that pops up, add or delete a tag. For APM agents, restart your service. To manage tags via API: see our NerdGraph tagging docs. For a guide to using our CLI to automate tagging, see our developer site. APM agent tags You can add tags via the UI and API or you can add tags using APM agent configuration, both methods require you to restart your service. There are differences in how these apply tags: Via agent config: These tags are applied at the agent-level, not the entity/application level. This would be a good option if you have multiple agents monitoring different aspects of the same app (for example, a blue-green deployment model). Via the UI or API: These tags are applied at the entity/application level. Here are links to the agent configuration options: C SDK: not available Java Go .NET Node.js PHP Python Ruby For information on querying APM tags, see Query APM tags. And check out this short video on querying APM tags (3:20 minutes). Infrastructure data tags There are several ways tags are added to infrastructure entities and services: Use the UI or API to add tags at the entity level. Infrastructure agent: some attributes are available by default as tags. You can also add custom attributes, which are also available as tags in the UI. On-host integrations: some attributes are available by default as tags. You can also add tags by using integration-specific labels config options (for an example, see the labels config for the Apache integration). Cloud service integrations: by default we report tags and labels that are defined in the cloud service. To add tags, you'd add them on the cloud-service-side. Automate tags with our CLI For a guide to automating tags using our CLI tool, see our developer site. Use tags to filter the UI Use the filter field at the top of the New Relic Explorer to filter down to the entities you care about. You can use multiple filter conditions. To filter down to certain entities using tags: From one.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown of available attributes and tags. You can filter by multiple elements and use advanced search options. To find an entity’s metadata and tags from the UI, here are two options: From a list of entities in the UI, at the far right, select an entity's icon. OR Select an entity. Near the top of the page, select the icon. To use the API to view tags, see our NerdGraph docs. Learn about how to use tags with dashboards and how to use tags with workloads. Custom queries, charts, and alerts Different features handle tags differently. Here are some details about how you can use NRQL to query tag data, or create NRQL condition alerts. Query and alert on APM tags You can query APM tags using NRQL. Minimum agent versions: C: not available Go: 2.3.0 Java: 4.9.0 .NET: 8.17 Node: v4.13.0 PHP: not available Python: v4.10.0.112 Ruby: 6.1.0.352 Here are some query examples: Throughput across shards Given a service that is distributed across nine shards, each shard assigned as an environment, we can plot the transaction throughput on all shards using a wildcard query like: SELECT rate(count(apm.service.transaction.duration), 1 minute) FROM Metric WHERE appName LIKE 'MyApp (%' AND transactionType = 'Other' FACET tags.Environment TIMESERIES Copy Transactions per team To see the number of transactions per service for a specific team, we might use a query like: FROM Transaction SELECT count(*) WHERE tags.Team = 'team-a' FACET tags.Project TIMESERIES Copy Alert on error rate for teams You can use a query for your services’ error rate for setting an alert without having to create a rule for each service. Here is the error rate for all services on a team called team-b. And this alert will automatically monitor any new app names added with the team tag. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Team = 'team-b' FACET appName Copy Related to this, you might create a general rule for a specific service deployed across several environments, so that we have an alarm for a single service monitoring each environment individually: From Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Project = 'MyProject' FACET tags.Environment Copy Query and alert on attributes As explained in the tag sources information, some important attributes are used as tags. You can query all attributes and create custom charts using NRQL, and create NRQL alert conditions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.03494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> tags to help organize and find your data",
        "sections": "<em>Use</em> tags to help organize and find your data",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": ": Here you can see an accountId tag being used to filter <em>workloads</em> to a specific account. Tags help you to: Organize data coming from a large number of sources and&#x2F;or to a large number of <em>New</em> <em>Relic</em> accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example"
      },
      "id": "603ebd1228ccbc6278eba754"
    },
    {
      "sections": [
        "Workloads: Isolate and resolve incidents faster",
        "What is a workload in New Relic?",
        "Tip",
        "Why it matters",
        "Requirements",
        "Impact of accounts on the workload permissions and content",
        "Workload account",
        "Scope accounts"
      ],
      "title": "Workloads: Isolate and resolve incidents faster",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "858e74779a209ac0eb948405c311e59a71eb8d9b",
      "image": "https://docs.newrelic.com/static/bb2929677005af573675e7eceead70de/c1b63/1_workload_health_tab.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster/",
      "published_at": "2022-01-12T05:50:03Z",
      "updated_at": "2021-07-30T01:57:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our workloads feature gives you the ability to group and monitor entities based on a team or a set of responsibilities, providing aggregated health and activity data from frontend to backend services across your entire stack. Workloads help you understand the status of complex systems, detect issues, understand the cause and impact of an incident, and resolve those issues quickly. Want to try it? Create a New Relic account for free! No credit card required. What is a workload in New Relic? New Relic monitors a wide range of entities and data, from client-side applications and backend APIs, to the underlying infrastructure. To make sense of this large data set, we give you the ability to create and monitor workloads. Workloads give you the ability to group and monitor entities based on a team or a set of responsibilities, and provide an aggregated view of the health and activity of the entities in the workload. Thus, you can understand better how your business logic is working, from frontend to backend services, across your entire stack. Here are some workload examples: A serverless application that includes an API gateway, a few serverless functions, and a managed database and storage. A browser application and the backend APIs that support it. A collection of Java microservices and the infrastructure they run on. Here's a workload: one.newrelic.com > Explorer > Workloads > (selected workload): The workloads UI provides a curated view of how the entities in your workload are performing. The charts you see will depend on the types of entities you've included to the workload. Tip Learn how to use workloads. Why it matters Workloads give you visibility into the end-to-end availability and consumption of resources across an entire service, and provide you a way to define what’s relevant to you. You can use workloads to group together entities that are important to a specific team or project, so you can better browse and isolate the most relevant data for that service. Because our UI gives you cross-account access, you can add entities to your workload from any of the accounts you have access to. A workload can include: Any New Relic-monitored entity, including services, browser apps, mobile apps, databases, and hosts. Dashboards. Other workloads: this is useful for complex teams who need to divide and overlap workloads. Requirements Requirements for creating and managing workloads: All users for an account can view that account's workloads. To create, edit, and delete workloads, you must have a user role with that permission. Impact of accounts on the workload permissions and content Workloads can group and display entities from multiple accounts to provide complete observability of complex systems. When creating a workload, you must set: The workload account Scope accounts Learn how to find a New Relic account ID. Workload account The workload account is where any workload-specific data is stored. For example, a workload might generate NrAuditEvent data, and you would find that data by querying the workload account. The workload account determines the user permissions that govern which users can see and manage the workload, through the account roles. Once created, the workload account can’t be changed. Scope accounts Scope accounts are the accounts from which a workload fetches entity data. In other words, the scope accounts provide the content for a workload. Users who don’t have access to all of a workload's scope accounts may not be able to see complete workload data. Scope accounts can be updated at any point in time by any user with workload management capabilities on the workload account. By default, all accounts that the workload creator has access to at the moment of the workload creation are set as scope accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.23497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Workloads</em>: Isolate and resolve incidents faster",
        "sections": "What is a <em>workload</em> in <em>New</em> <em>Relic</em>?",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " of the accounts you have access to. A <em>workload</em> can include: Any <em>New</em> <em>Relic</em>-monitored entity, including services, browser apps, mobile apps, databases, and hosts. Dashboards. Other <em>workloads</em>: this is useful for complex teams who need to divide and overlap <em>workloads</em>. Requirements Requirements for creating"
      },
      "id": "6043cb93196a67f988960f76"
    }
  ],
  "/docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster": [
    {
      "sections": [
        "Use workloads",
        "Health",
        "Activity",
        "Owner",
        "Header",
        "Create a workload",
        "Use tags to define the workload content",
        "How the dynamic query logic works",
        "Add dashboards to workloads",
        "Use the API"
      ],
      "title": "Use workloads",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "c39090bde9b797940e7f5ba0c9610ba39879677b",
      "image": "https://docs.newrelic.com/static/14c811e218cfc8793bb4d2bd4b2aad0b/c1b63/new-relic-workloads-add-dashboards.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/use-workloads/",
      "published_at": "2022-01-12T05:30:45Z",
      "updated_at": "2021-12-30T18:57:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To view workloads, go to one.newrelic.com and find them on the Explorer. There are three main tabs (Health, Activity, and Owner) plus the header. Health The Health tab in a workload provides relevant status data that helps you operate the workload: It shows the global status of the workload, as well as the individual status of all the entities that make up the workload at each point in time. It looks like this: It comprises the following: The navigator view shows the entities that make up the workload, and provides controls to group and sort them. If you’ve used queries to dynamically select entities, the workload entities will change over time. The workload status informs about how your workload is performing, based on the individual alerting status of the entities in your workload. With health over time you’ll see whether and how the workload status has changed in the past three hours. If one or more entities are alerting, you’ll get a count of criticals and warnings and a summary of the open conditions, which will make it easier to identify and troubleshoot the most important issues. Activity The Activity tab shows performance data related to the entities in the workload, along with the events that could explain any changes in those time series. It looks like this: Here are the most important sections: Linked dashboards. You can add links to dashboards from your workload, and create pre-filtered, workload-relevant links to dashboards. Golden metrics. These are charts with the most relevant metrics for each entity type, such as number of requests, response time, and error rate for an application. Explore the charts to detect correlations among different entities (for example, two applications) and different stack layers (for example, applications and hosts). The golden metrics that you see for each entity type on a workload can be customized either at the account or the workload level through the NerdGraph API. Events timeline. This includes the start and end time of incidents and anomalies that refer to the workload entities. It also shows other event types that can explain a change in the status or performance of the workload, such as deployments and configuration changes. You can control which golden metrics are used to visualize your workload entities by using the golden metrics API. To learn more, watch this short video (approx. 4 minutes). Owner The Owner tab gives you information about the team responsible for the workload. It looks like this: It contains: The team responsible for the workload. You can include more than one team. The workload description. Share the mission of the workload, and the business logic it represents: Is it a web application? An API? A backend process? Fill in any details that are relevant to your team, or to other teams in your organization. Contact information. From the drop-down menu, choose how your team prefers to be contacted. Links to the most relevant resources to operate the workload. Here you can add links to runbooks, code repositories, productivity tools, or anything else related to the workload that you need at hand. Header The header contains the filter bar and the edition controls: Filter bar. Use the advanced filtering options when you need to focus only on certain entities within the workload. Edit workload. Define the entities that are part of the workload, and the accounts they’ll be fetched from. Setup status. Configure how the global workload status will be determined, based on the workload entities health. Summary page. See all the tags that have been added to the workload, as well as metadata such as the workload's identifier (GUID) and account. You can create workloads that update dynamically by leveraging tags. To learn how, watch this short video (approx. 3 minutes). Create a workload A workload should contain the entities you and your team want to see. Your choice of entities depends on your organization structure and goals. one.newrelic.com > Explorer > Workloads > Create a workload: When you create a workload, you choose the associated accounts and monitored entities. You can use New Relic One or the NerdGraph API to create a workload. Follow these steps to create a workload using the UI: Go to one.newrelic.com and click on the Explorer, and then click + Create a workload. Give the workload a name that will be meaningful for you and your team later. From the Select an account dropdown, select the workload account you'd like to use. Click Choose the scope accounts to check all of the accounts related to this workload. Find and choose the entities that make up the workload. When you have the results you're looking for, you can add specific entities or add the query to dynamically update the entities in the workload. You can search by entity type, tags, or attributes (like entity name, account ID, and AWS region). Click + Add this query to create a list of dynamically updated entities for your workload. We recommend this if you want your workload to update its entities as your system changes. Click + Add next to an entity to add it to your workload. This is a good choice if you know that the entities will stay useful even as your system changes. You can add a combination of queries and specific entities to the workload, which combine according to the query logic. Click Create a workload to save the workload. Once you've created the workload, you can edit it at any time If your workload contains one or more dashboards, you can set filters on those dashboard links. Below are more details about some aspects of how to define workloads: Use tags to define the workload content You can query and select workload entities using both tags and attributes. Therefore, to optimize your use of workloads, it helps to have a good entity-tagging strategy. We recommend reading the tagging documentation. How the dynamic query logic works You can add several individual entities and queries to define a workload. Queries can include multiple search terms. These are combined with an AND operator. Separate queries within a workload are combined with an OR operator. You can wrap strings between percent signs (%) to match exact substrings within a query. If you use substrings in entity names to categorize those entities (for example, <team>-<env>-<appName>), consider using tags complementarily, which are more powerful for filtering and grouping (for example, team:awesome, env:production). We recommend not to use percent signs (%) in dynamic queries that might return over 500 entities. This way, you get a more consistent experience in the user interface. Add dashboards to workloads If you have custom dashboards and you already know which data is relevant to your team for observing and operating their workloads, you can link those dashboards from your workload. You can also set filters on dashboards to scope them to a workload-specific context. When a user selects that dashboard from the workload, it opens with the filter already applied. one.newrelic.com > Apps > Workloads: You can add dashboards to a workload. To add dashboards to a workload: When creating or editing a workload, type Dashboard in the workload search bar to filter to dashboard entities. Add other search terms to filter to specific dashboards. Click Add. one.newrelic.com > Apps > Workloads: You can set filters on the dashboards you've linked to a workload. To filter a workload’s dashboard: From a workload’s Overview page, select a dashboard. Add search terms to filter the dashboard to a view that’s relevant for that workload. Select Save filter for this workload. Use the API You can query, create, and update workloads with our NerdGraph API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 277.44858,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>workloads</em>",
        "sections": "<em>Use</em> <em>workloads</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " of entities depends on your organization structure and goals. <em>one</em>.newrelic.com &gt; Explorer &gt; <em>Workloads</em> &gt; Create a <em>workload</em>: When you create a <em>workload</em>, you choose the associated accounts and monitored entities. You can <em>use</em> <em>New</em> <em>Relic</em> <em>One</em> or the NerdGraph API to create a <em>workload</em>. Follow these steps"
      },
      "id": "603e81e8196a67c972a83db1"
    },
    {
      "sections": [
        "Use tags to help organize and find your data",
        "Tip",
        "Tag format and limits",
        "Best practices and tips",
        "Tips on keeping tags simple:",
        "Tips on using tags consistently:",
        "Tips on cross-team implementation:",
        "Tag examples",
        "Team-related tags",
        "Environment-related tags",
        "Criticality-related tags",
        "How tags are added",
        "Add tags via UI or API",
        "APM agent tags",
        "Infrastructure data tags",
        "Automate tags with our CLI",
        "Use tags to filter the UI",
        "Custom queries, charts, and alerts",
        "Query and alert on APM tags",
        "Throughput across shards",
        "Transactions per team",
        "Alert on error rate for teams",
        "Query and alert on attributes"
      ],
      "title": "Use tags to help organize and find your data",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "e2e2d53776b9109965df9de2a20660e9f60bd479",
      "image": "https://docs.newrelic.com/static/529f55ef72f3e366e6cb4a7be67229b6/c1b63/new-relic-tags-workloads_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/use-tags-help-organize-find-your-data/",
      "published_at": "2022-01-12T02:03:57Z",
      "updated_at": "2021-12-25T14:30:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the software industry, a tag typically refers to a piece of metadata added to a data set for the purpose of improving data organization and findability. At New Relic, our tags are key:value pairs (like team: operations) added to various sets of data, like monitored apps and hosts, agents, dashboards, and workloads. We make some important attributes available as tags (for example, app metadata like app name and language, and host metadata like host name and AWS region). You can also add your own custom tags. You can use tags in the UI to filter down to relevant data. Here is an example: Here you can see an accountId tag being used to filter workloads to a specific account. Tags help you to: Organize data coming from a large number of sources and/or to a large number of New Relic accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example use cases). Better organize and search dashboards and workloads. Query and chart APM data. Tags are useful for organizing data at a high level. If you want to add more fine-grained detail, like capturing user names or other high-cardinality values, custom attributes or custom events are a better solution. Tip Tags were previously called labels in the New Relic UI. You may sometimes see labelin our code; for example, some of our APM agent config files use a label config option for tags. Tag format and limits Format requirements and limits for tags: The UI has limits on the total number of tags it can display per entity: Limit of 100 for tags reported by default or added via agent/integration configuration. Limit of 100 for custom tags added via UI or API. The following are maximum character length for tags: Key: 128 characters Value: 256 characters Allowed characters: Characters must be UTF-8. When using NerdGraph to add tags, a dash (-) in a tag key is interpreted as a minus symbol. If your tag key has a dash, use back ticks around it (like `key-name`). Best practices and tips Before adding tags, we recommend first seeing how our default tags work for you. When you're ready to add your own tags, review the following best practices tips to get the most out of them. Tips on keeping tags simple: Start by adding only tags you know you’ll definitely use. Unused tags create noise and may add confusion. Try to use short tags. Shorter tags are easier to parse, and also the UI may sometimes truncate longer tags. (See character limits.) When possible, use keys and values that are human-readable (for example, region: EMEA is better than Param8323 : 1229072). Avoid including several values like regions: EMEA | US | LATAM in a single tag. We recommend using three different tags for that, like region: emea, region: us, and region: latam. If you want to match multiple tags, you can do that using the advanced options in the filter UI. Tips on using tags consistently: Try to be consistent with tag language across your teams and entities. Be consistent with naming. For example, avoid using both region: emea and reg: emea. Be consistent with format. For example, avoid using both camelCase and kebab-case. Although tag searching is not case-sensitive in the UI and API, try to be consistent with capitalization. For example, avoid using both env: staging and env: Staging. Tips on cross-team implementation: Tags help improve observability and cost allocation. For this reason, responsibility for tag implementation is often assigned to an observability team, SREs, a group of architects, or a cross-team task force. We recommend the people responsible for implementing tags meet and create an internal policy to describe how the tags are defined and which conventions are to be used. Then: Keep this reference manual up to date. Automate the definition of tags when you deploy New Relic agents, at the cloud provider, or through New Relic automation tools, such as the API or Terraform. Create recurring reports that identify entities that are non-compliant with your tagging standards. Tag examples Here are some examples of common ways to use tags to organize data: Team-related tags Creating tags for team names can be helpful to understand which team, group, department, or region was responsible for a change that led to a performance issue. Team examples: team: backend team: frontend team: db Role examples: roles: architecture roles: devops roles: pm Region examples: region: emea region: america region: asia Environment-related tags You can create entities for the environment they belong to. Examples: env: production env: qa env: development env: staging Criticality-related tags You can create tags related to criticality levels, which lets you easier track the most critical issues. Examples: layer: level1 layer: level2 layer: level3 How tags are added Some important attributes, by default, are available for use as tags. For example, the account name, the account ID, and some basic host/server metadata are available as default tags. You can't remove these available-by-default tags. Here are some details about how tags are added for some specific data sources: Add tags via UI or API When you add tags via the UI or API, this occurs at the entity level. This means that, for example, if you have multiple APM agents monitoring a single entity and apply a tag via the UI, that tag is available for all data coming from that entity. To add or delete tags via the UI: Select a monitored entity, like a monitored app or host. Near the entity’s name at the top of the page, select the See metadata and manage tags menu. In the menu that pops up, add or delete a tag. For APM agents, restart your service. To manage tags via API: see our NerdGraph tagging docs. For a guide to using our CLI to automate tagging, see our developer site. APM agent tags You can add tags via the UI and API or you can add tags using APM agent configuration, both methods require you to restart your service. There are differences in how these apply tags: Via agent config: These tags are applied at the agent-level, not the entity/application level. This would be a good option if you have multiple agents monitoring different aspects of the same app (for example, a blue-green deployment model). Via the UI or API: These tags are applied at the entity/application level. Here are links to the agent configuration options: C SDK: not available Java Go .NET Node.js PHP Python Ruby For information on querying APM tags, see Query APM tags. And check out this short video on querying APM tags (3:20 minutes). Infrastructure data tags There are several ways tags are added to infrastructure entities and services: Use the UI or API to add tags at the entity level. Infrastructure agent: some attributes are available by default as tags. You can also add custom attributes, which are also available as tags in the UI. On-host integrations: some attributes are available by default as tags. You can also add tags by using integration-specific labels config options (for an example, see the labels config for the Apache integration). Cloud service integrations: by default we report tags and labels that are defined in the cloud service. To add tags, you'd add them on the cloud-service-side. Automate tags with our CLI For a guide to automating tags using our CLI tool, see our developer site. Use tags to filter the UI Use the filter field at the top of the New Relic Explorer to filter down to the entities you care about. You can use multiple filter conditions. To filter down to certain entities using tags: From one.newrelic.com, click Explorer. Click the Filter by... field to see a dropdown of available attributes and tags. You can filter by multiple elements and use advanced search options. To find an entity’s metadata and tags from the UI, here are two options: From a list of entities in the UI, at the far right, select an entity's icon. OR Select an entity. Near the top of the page, select the icon. To use the API to view tags, see our NerdGraph docs. Learn about how to use tags with dashboards and how to use tags with workloads. Custom queries, charts, and alerts Different features handle tags differently. Here are some details about how you can use NRQL to query tag data, or create NRQL condition alerts. Query and alert on APM tags You can query APM tags using NRQL. Minimum agent versions: C: not available Go: 2.3.0 Java: 4.9.0 .NET: 8.17 Node: v4.13.0 PHP: not available Python: v4.10.0.112 Ruby: 6.1.0.352 Here are some query examples: Throughput across shards Given a service that is distributed across nine shards, each shard assigned as an environment, we can plot the transaction throughput on all shards using a wildcard query like: SELECT rate(count(apm.service.transaction.duration), 1 minute) FROM Metric WHERE appName LIKE 'MyApp (%' AND transactionType = 'Other' FACET tags.Environment TIMESERIES Copy Transactions per team To see the number of transactions per service for a specific team, we might use a query like: FROM Transaction SELECT count(*) WHERE tags.Team = 'team-a' FACET tags.Project TIMESERIES Copy Alert on error rate for teams You can use a query for your services’ error rate for setting an alert without having to create a rule for each service. Here is the error rate for all services on a team called team-b. And this alert will automatically monitor any new app names added with the team tag. FROM Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Team = 'team-b' FACET appName Copy Related to this, you might create a general rule for a specific service deployed across several environments, so that we have an alarm for a single service monitoring each environment individually: From Metric SELECT count(apm.service.error.count) / count(apm.service.transaction.duration) WHERE tags.Project = 'MyProject' FACET tags.Environment Copy Query and alert on attributes As explained in the tag sources information, some important attributes are used as tags. You can query all attributes and create custom charts using NRQL, and create NRQL alert conditions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.03491,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> tags to help organize and find your data",
        "sections": "<em>Use</em> tags to help organize and find your data",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": ": Here you can see an accountId tag being used to filter <em>workloads</em> to a specific account. Tags help you to: Organize data coming from a large number of sources and&#x2F;or to a large number of <em>New</em> <em>Relic</em> accounts. Identify teams, roles, environments, or regions to know who’s responsible for what (see example"
      },
      "id": "603ebd1228ccbc6278eba754"
    },
    {
      "sections": [
        "Workload status views and notifications",
        "Why it matters",
        "Get started with workload status",
        "Obtain your workload status",
        "Save views with sets of workloads",
        "Get notified when the workload status changes"
      ],
      "title": "Workload status views and notifications",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Workloads"
      ],
      "external_id": "1633f322d9f0c907a9636e0c71aee7a0a38ba85b",
      "image": "https://docs.newrelic.com/static/5ea6d75d1efb047eda59eee3f12e08a9/c1b63/workloads_views.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/workloads/workload-status-views-notifications/",
      "published_at": "2022-01-12T05:49:24Z",
      "updated_at": "2021-05-10T14:02:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The workload status, which is derived from the alerting status of the entities in your workload, informs you about how your workload is behaving. Why it matters Workload status: Is a quick indicator of how your system is doing, and tells you if you need to take action on any of your workloads in just a glance. Adapts to your needs and to how important each entity is. Allows you to share the status of your workloads. Other teams that depend on your services or infrastructure can learn the status of the workload without them needing to understand your system’s architecture details, or look at custom dashboards. Get started with workload status New Relic One provides a status value for all entities, which is based on the results of New Relic alerts. You can check the color-coded alert status for each entity on the New Relic Explorer, or consume the alert status value through the API. For example, you may see a red alert status indicating that a critical violation is in progress. With Workloads you can group entities that are part of a complex system and obtain a single, global value that summarizes the status of all the entities in your workload. Thus, you can quickly detect when the workload stops being operational, or anticipate any potential incident or loss of quality of service. Obtain your workload status A workload can have one of the following status values: Operational: The workload is working fine. Degraded: The workload is showing some degradation in performance or errors, but it’s still providing an acceptable level of service, and you don’t need to take any urgent action. Critical or Disrupted: The workload is not providing an acceptable level of service, and you need to take urgent action. Unknown: You haven’t configured how to calculate workload status, or there aren’t any alert conditions set up that can determine the status of the workload entities. To learn how to define or edit the workload status, refer to Workload status configuration. Save views with sets of workloads If you usually need to see the status of a certain group of workloads, you can save views that contain only those workloads. The tile view mode helps you quickly find your workloads and see their status at a glance. To create a view, follow these steps: Go to one.newrelic.com and click on More > Workload views. Click on Add view. Give the view a meaningful name (such as the name of a team or business unit), and select an account to associate the view with. Select the workloads you want to include in the view, by their name or tags. Save the new view. Status views are most useful for teams that are accountable for more than one workload, support roles, and business unit managers. Get notified when the workload status changes You may need to follow the status of a workload, either because it represents the services your team is accountable for, or because your own services depend on that workload, which is managed by another team. The status of all workloads is calculated regularly and the result is stored in NRDB through a WorkloadStatus event. This allows you to set up an alert condition to notify you whenever the Workload goes into a Disrupted or Degraded status. To set up the alert condition follow these steps: Go to one.newrelic.com and select Alerts & AI. Select the policy where you want to add the new alert condition, or create a new policy with the appropriate notification channel. Then click on Create a condition. Where prompted to Select a product, click NRQL. Add the following NRQL query: SELECT latest(statusValueCode) FROM WorkloadStatus WHERE workloadGuid = '<GUID>' FACET workloadGuid as 'entity.guid', entity.name Copy You can obtain the workload GUID by clicking on the See metadata and manage tags on the workload UI. Write the WHERE clause so the alert condition applies to just one workload (as in the example) or more than one. Or remove the WHERE clause if you want the alert condition to apply to all the workloads on the account. By adding the FACET you can use these fields on the alert description, as explained below. Set one of the following static thresholds: (Recommended) Critical when the query returns a value equal to 3 for at least 1 minute, if you want to be notified when the workload status is disrupted. Critical when the query returns a value equal to 2 for at least 1 minute, if you want to be notified when the workload status is degraded. Remember that a warning threshold doesn't generate an incident or send a notification. As a result, you need to create two alert conditions with a critical threshold (as explained above) if you want to be notified of any status change. Complete the alert condition: Set a violation time limit, to automatically force-close a long-lasting violation after the selected amount of time you select. Choose to fill data gaps with last known value. Optionally, you can also add a custom violation description that includes the workload name and permanent link to the UI in the alert notification: Workload: {{tag.entity.name}} Direct link: https://one.newrelic.com/redirect/entity/{{tag.entity.guid}} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.9345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Workload</em> status views and notifications",
        "sections": "Save views with sets of <em>workloads</em>",
        "tags": "<em>Use</em> <em>New</em> <em>Relic</em> <em>One</em>",
        "body": " at custom dashboards. Get started with <em>workload</em> status <em>New</em> <em>Relic</em> <em>One</em> provides a status value for all entities, which is based on the results of <em>New</em> <em>Relic</em> alerts. You can check the color-coded alert status for each entity on the <em>New</em> <em>Relic</em> Explorer, or consume the alert status value through the API"
      },
      "id": "603e967564441ff8cd4e8855"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/appendix/version-history": [
    {
      "sections": [
        "Walkthrough and signoff"
      ],
      "title": "Walkthrough and signoff",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "dd4bafe85fefaa2a81c625f948ff4ca5ca1d9313",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/walkthrough-signoff/",
      "published_at": "2022-01-12T03:39:09Z",
      "updated_at": "2021-10-31T16:21:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a final step before going live, an integration walkthrough will be performed (typically via a conference call). The goals of this call and typical topic areas are to: Confirm the functionality of the integration. Understand and document the customer signup and usage UI workflow for the integration. Establish that mutual contractual commitments have been met. Evaluate ease of deployment. Create a plan for fine-tuning where required. Where deployment of New Relic requires working accounts or deployed applications, provision should be made in advance of the call for these elements to be in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.96101,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " for the <em>integration</em>. Establish that mutual contractual commitments have been met. Evaluate ease of deployment. Create a plan for fine-tuning where required. Where deployment of <em>New</em> <em>Relic</em> requires working accounts or deployed applications, provision should be made in advance of the call for these elements to be in place."
      },
      "id": "6044e9c2196a67a23c960f82"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.68744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This document is for <em>New</em> <em>Relic</em> partners. After you complete your <em>partnership</em> <em>integration</em>, you will be introduced to your technical contacts at <em>New</em> <em>Relic</em>. Use these channels for non-urgent escalations. Tip If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, see <em>New</em> <em>Relic</em>&#x27;s resources for finding help or filing"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Intro to Partnership API",
        "Requirements",
        "Customer partnership restrictions",
        "Password requirements",
        "Things you can do",
        "Get started"
      ],
      "title": "Intro to Partnership API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "074cf4e7c590dfa2332284a7b7f394e2f7ba45ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api/",
      "published_at": "2022-01-12T03:40:16Z",
      "updated_at": "2021-11-13T15:06:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Partnership API allows New Relic partners, and New Relic accounts set up as customer partnerships, to manage accounts, users, and subscription-related settings. Requirements The Partnership API can be used by two types of New Relic accounts: partners (managed service providers, resellers) and customer partnerships (larger customers who have been given access to our partnership account structure). These docs are for version 2 of the Partner API. Earlier versions have been deprecated. If you have problems with an older integration, upgrade to version 2. Access to the partnership account structure and the Partnership API requires prior setup and approval by New Relic. Partnership API calls require authentication with both your partnership owner account's REST API key and your Partner ID. Accounts that are genuine New Relic partners (managed service providers, resellers) have no restrictions on using the API. Accounts set up as customer partnerships have restrictions that follow. Customer partnership restrictions If your New Relic organization is set up as a customer partnership, there are some restrictions in place if your organization is on our newer pricing model or our newer user model. Details: Pricing plan. If you’re on New Relic One pricing, you can't use API calls that govern our original pricing model. The API impacts are: You can't use the subscription object You can't use the NerdGraph Provisioning API. User model. If your New Relic account has been converted to be entirely on the New Relic One user model, you can no longer use API calls that create or govern users on our original user model. The API impacts are: You can't use the user object. Instead, you'd manage users with these user management docs. For the account object: you can't add users via the users field. Instead, you'd manage users with these user management docs. To determine your pricing model or user model, see Overview of pricing and user model changes. Password requirements Passwords passed for account creation have these requirements: 8 to 50 characters in length Only contain letters, numbers, or special characters Cannot contain spaces Must contain at least 1 letter Must contain at least 1 number or special character Things you can do Here is an overview of the API's functionality. Account: The account object is what you use to create and update accounts. You can do the following with it: Create new Show Update Cancel Show usage Set primary admin (some accounts) Set subscription (some accounts) There is also a child account object for creating child accounts. Users: Some organizations that meet the requirements can use the user object to: Add user access to account Remove user access from account Subscription: Organizations that meet the requirements and are on our original product pricing model can use the subscription object to configure various subscription-related traits. Get started To start using the Partnership API, see the Partner API reference docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.4915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>Partnership</em> API",
        "sections": "Intro to <em>Partnership</em> API",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "Our <em>Partnership</em> API allows <em>New</em> <em>Relic</em> partners, and <em>New</em> <em>Relic</em> accounts set up as customer <em>partnerships</em>, to manage accounts, users, and subscription-related settings. Requirements The <em>Partnership</em> API can be used by two types of <em>New</em> <em>Relic</em> accounts: partners (managed service providers, resellers"
      },
      "id": "603ed42328ccbcd4b3eba7ca"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/getting-started/co-branding-new-relic-partners": [
    {
      "sections": [
        "Walkthrough and signoff"
      ],
      "title": "Walkthrough and signoff",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "dd4bafe85fefaa2a81c625f948ff4ca5ca1d9313",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/walkthrough-signoff/",
      "published_at": "2022-01-12T03:39:09Z",
      "updated_at": "2021-10-31T16:21:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a final step before going live, an integration walkthrough will be performed (typically via a conference call). The goals of this call and typical topic areas are to: Confirm the functionality of the integration. Understand and document the customer signup and usage UI workflow for the integration. Establish that mutual contractual commitments have been met. Evaluate ease of deployment. Create a plan for fine-tuning where required. Where deployment of New Relic requires working accounts or deployed applications, provision should be made in advance of the call for these elements to be in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.28036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " for the <em>integration</em>. Establish that mutual contractual commitments have been met. Evaluate ease of deployment. Create a plan for fine-tuning where required. Where deployment of <em>New</em> <em>Relic</em> requires working accounts or deployed applications, provision should be made in advance of the call for these elements to be in place."
      },
      "id": "6044e9c2196a67a23c960f82"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.45856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This document is for <em>New</em> <em>Relic</em> partners. After you complete your <em>partnership</em> <em>integration</em>, you will be introduced to your technical contacts at <em>New</em> <em>Relic</em>. Use these channels for non-urgent escalations. Tip If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, see <em>New</em> <em>Relic</em>&#x27;s resources for finding help or filing"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Partnership admin console",
        "Console components",
        "Partnership configuration settings",
        "Customer activity monitoring",
        "State-of-the-Partnership report",
        "Partner customer monitoring",
        "View an arbitrary customer",
        "Viewing detailed customer data"
      ],
      "title": "Partnership admin console",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "670e4d2e1db957100b23a7b8b0af6bf50cc8c996",
      "image": "https://docs.newrelic.com/static/43369c88523ebf526ae58fa5719d4efe/0abdd/crop-partnership-owner-account-settings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-07-02T15:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Partnership Admin Console is the interface for managing your customers' accounts and integration with New Relic. To access the console, sign into the partnership owner account, and go to: https://partner-admin-console.newrelic.com/accounts/ACCOUNT_ID/admin_console/ Copy You can also access the console from the New Relic UI: Go to one.newrelic.com > (account dropdown) > Account settings. From the left menu bar, select Partnerships. one.newrelic.com > (account dropdown) > Account settings > Partnerships: Partnership owners can access the Partnership Admin Console from their account settings in the New Relic UI. Console components The Partnership Admin Console has two main components: Partnership configuration settings Customer activity monitoring If multiple partnerships are associated with the New Relic parent account, the menu also includes an option to switch partnership accounts. Partnership configuration settings In developing your integration with New Relic, you must specify a number of settings. For your convenience these settings are grouped together in the partnership console, including URLs for header/footer and various redirects, SSO configuration, and keys and the ability to manipulate them. Customer activity monitoring New Relic provides you with two tools for managing your customers: State-of-the-Partnership reports and live monitoring of all deployed New Relic agents in your partnership. Both of these tools provide insight into your customers who are using New Relic. They can be used to identify up-sale opportunities or to assist your support group in proactive support. State-of-the-Partnership report The State-of-the-Partnership report provides a summary of your customers with New Relic accounts and their activities. The report is broken down by language of the agents deployed, the agent version and the language version for each account. This report is run weekly for each partner. It is available on request from your New Relic Business Development contact. This report is an excellent way to see which of your customers with New Relic accounts are in fact using the service. Partner customer monitoring The Partner customer monitoring facility provides application performance data on the New Relic enabled applications that are running on your service. This facility allows you to easily identify customers experiencing performance problems. Where the performance problems are caused by under capacity, these customers are excellent sales opportunities. Alternatively your support or services organization will find this information useful in pre-emptively identifying customer issues or as good prospects for consulting services. View an arbitrary customer To view activity of a customer that does not appear in any of the filtered views: Go to one.newrelic.com > (account dropdown) > Switch accounts > Other accounts. New Relic will list all of the reporting accounts in the partnership. You can filter or search the list. Viewing detailed customer data Under normal circumstances a partner will be able to see only the summary level data in a customer's New Relic account. Through the Partnership Admin Console, partners will be permitted to drill down to the more detailed presentation. If you want to drill down from the Partnership Admin Console, add your user (typically support@partner.com or something similar) to the account. Typically this will be done at account creation. Avoid provisioning this user as the account Owner.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.53123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> admin console",
        "sections": "<em>Partnership</em> admin console",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "The <em>Partnership</em> Admin Console is the interface for managing your customers&#x27; accounts and <em>integration</em> with <em>New</em> <em>Relic</em>. To access the console, sign into the <em>partnership</em> owner account, and go to: https:&#x2F;&#x2F;<em>partner</em>-admin-console.newrelic.com&#x2F;accounts&#x2F;ACCOUNT_ID&#x2F;admin_console&#x2F; Copy You can also access"
      },
      "id": "603ed3e3196a6735baa83dad"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/getting-started/partner-integration-requirements": [
    {
      "sections": [
        "Walkthrough and signoff"
      ],
      "title": "Walkthrough and signoff",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "dd4bafe85fefaa2a81c625f948ff4ca5ca1d9313",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/walkthrough-signoff/",
      "published_at": "2022-01-12T03:39:09Z",
      "updated_at": "2021-10-31T16:21:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a final step before going live, an integration walkthrough will be performed (typically via a conference call). The goals of this call and typical topic areas are to: Confirm the functionality of the integration. Understand and document the customer signup and usage UI workflow for the integration. Establish that mutual contractual commitments have been met. Evaluate ease of deployment. Create a plan for fine-tuning where required. Where deployment of New Relic requires working accounts or deployed applications, provision should be made in advance of the call for these elements to be in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.28036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " for the <em>integration</em>. Establish that mutual contractual commitments have been met. Evaluate ease of deployment. Create a plan for fine-tuning where required. Where deployment of <em>New</em> <em>Relic</em> requires working accounts or deployed applications, provision should be made in advance of the call for these elements to be in place."
      },
      "id": "6044e9c2196a67a23c960f82"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.45856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This document is for <em>New</em> <em>Relic</em> partners. After you complete your <em>partnership</em> <em>integration</em>, you will be introduced to your technical contacts at <em>New</em> <em>Relic</em>. Use these channels for non-urgent escalations. Tip If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, see <em>New</em> <em>Relic</em>&#x27;s resources for finding help or filing"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Partnership admin console",
        "Console components",
        "Partnership configuration settings",
        "Customer activity monitoring",
        "State-of-the-Partnership report",
        "Partner customer monitoring",
        "View an arbitrary customer",
        "Viewing detailed customer data"
      ],
      "title": "Partnership admin console",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "670e4d2e1db957100b23a7b8b0af6bf50cc8c996",
      "image": "https://docs.newrelic.com/static/43369c88523ebf526ae58fa5719d4efe/0abdd/crop-partnership-owner-account-settings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-07-02T15:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Partnership Admin Console is the interface for managing your customers' accounts and integration with New Relic. To access the console, sign into the partnership owner account, and go to: https://partner-admin-console.newrelic.com/accounts/ACCOUNT_ID/admin_console/ Copy You can also access the console from the New Relic UI: Go to one.newrelic.com > (account dropdown) > Account settings. From the left menu bar, select Partnerships. one.newrelic.com > (account dropdown) > Account settings > Partnerships: Partnership owners can access the Partnership Admin Console from their account settings in the New Relic UI. Console components The Partnership Admin Console has two main components: Partnership configuration settings Customer activity monitoring If multiple partnerships are associated with the New Relic parent account, the menu also includes an option to switch partnership accounts. Partnership configuration settings In developing your integration with New Relic, you must specify a number of settings. For your convenience these settings are grouped together in the partnership console, including URLs for header/footer and various redirects, SSO configuration, and keys and the ability to manipulate them. Customer activity monitoring New Relic provides you with two tools for managing your customers: State-of-the-Partnership reports and live monitoring of all deployed New Relic agents in your partnership. Both of these tools provide insight into your customers who are using New Relic. They can be used to identify up-sale opportunities or to assist your support group in proactive support. State-of-the-Partnership report The State-of-the-Partnership report provides a summary of your customers with New Relic accounts and their activities. The report is broken down by language of the agents deployed, the agent version and the language version for each account. This report is run weekly for each partner. It is available on request from your New Relic Business Development contact. This report is an excellent way to see which of your customers with New Relic accounts are in fact using the service. Partner customer monitoring The Partner customer monitoring facility provides application performance data on the New Relic enabled applications that are running on your service. This facility allows you to easily identify customers experiencing performance problems. Where the performance problems are caused by under capacity, these customers are excellent sales opportunities. Alternatively your support or services organization will find this information useful in pre-emptively identifying customer issues or as good prospects for consulting services. View an arbitrary customer To view activity of a customer that does not appear in any of the filtered views: Go to one.newrelic.com > (account dropdown) > Switch accounts > Other accounts. New Relic will list all of the reporting accounts in the partnership. You can filter or search the list. Viewing detailed customer data Under normal circumstances a partner will be able to see only the summary level data in a customer's New Relic account. Through the Partnership Admin Console, partners will be permitted to drill down to the more detailed presentation. If you want to drill down from the Partnership Admin Console, add your user (typically support@partner.com or something similar) to the account. Typically this will be done at account creation. Avoid provisioning this user as the account Owner.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.53123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> admin console",
        "sections": "<em>Partnership</em> admin console",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "The <em>Partnership</em> Admin Console is the interface for managing your customers&#x27; accounts and <em>integration</em> with <em>New</em> <em>Relic</em>. To access the console, sign into the <em>partnership</em> owner account, and go to: https:&#x2F;&#x2F;<em>partner</em>-admin-console.newrelic.com&#x2F;accounts&#x2F;ACCOUNT_ID&#x2F;admin_console&#x2F; Copy You can also access"
      },
      "id": "603ed3e3196a6735baa83dad"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/getting-started/partners-contact-new-relic": [
    {
      "sections": [
        "Walkthrough and signoff"
      ],
      "title": "Walkthrough and signoff",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "dd4bafe85fefaa2a81c625f948ff4ca5ca1d9313",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/walkthrough-signoff/",
      "published_at": "2022-01-12T03:39:09Z",
      "updated_at": "2021-10-31T16:21:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a final step before going live, an integration walkthrough will be performed (typically via a conference call). The goals of this call and typical topic areas are to: Confirm the functionality of the integration. Understand and document the customer signup and usage UI workflow for the integration. Establish that mutual contractual commitments have been met. Evaluate ease of deployment. Create a plan for fine-tuning where required. Where deployment of New Relic requires working accounts or deployed applications, provision should be made in advance of the call for these elements to be in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.28036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " for the <em>integration</em>. Establish that mutual contractual commitments have been met. Evaluate ease of deployment. Create a plan for fine-tuning where required. Where deployment of <em>New</em> <em>Relic</em> requires working accounts or deployed applications, provision should be made in advance of the call for these elements to be in place."
      },
      "id": "6044e9c2196a67a23c960f82"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.45856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This document is for <em>New</em> <em>Relic</em> partners. After you complete your <em>partnership</em> <em>integration</em>, you will be introduced to your technical contacts at <em>New</em> <em>Relic</em>. Use these channels for non-urgent escalations. Tip If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, see <em>New</em> <em>Relic</em>&#x27;s resources for finding help or filing"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Partnership admin console",
        "Console components",
        "Partnership configuration settings",
        "Customer activity monitoring",
        "State-of-the-Partnership report",
        "Partner customer monitoring",
        "View an arbitrary customer",
        "Viewing detailed customer data"
      ],
      "title": "Partnership admin console",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "670e4d2e1db957100b23a7b8b0af6bf50cc8c996",
      "image": "https://docs.newrelic.com/static/43369c88523ebf526ae58fa5719d4efe/0abdd/crop-partnership-owner-account-settings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-07-02T15:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Partnership Admin Console is the interface for managing your customers' accounts and integration with New Relic. To access the console, sign into the partnership owner account, and go to: https://partner-admin-console.newrelic.com/accounts/ACCOUNT_ID/admin_console/ Copy You can also access the console from the New Relic UI: Go to one.newrelic.com > (account dropdown) > Account settings. From the left menu bar, select Partnerships. one.newrelic.com > (account dropdown) > Account settings > Partnerships: Partnership owners can access the Partnership Admin Console from their account settings in the New Relic UI. Console components The Partnership Admin Console has two main components: Partnership configuration settings Customer activity monitoring If multiple partnerships are associated with the New Relic parent account, the menu also includes an option to switch partnership accounts. Partnership configuration settings In developing your integration with New Relic, you must specify a number of settings. For your convenience these settings are grouped together in the partnership console, including URLs for header/footer and various redirects, SSO configuration, and keys and the ability to manipulate them. Customer activity monitoring New Relic provides you with two tools for managing your customers: State-of-the-Partnership reports and live monitoring of all deployed New Relic agents in your partnership. Both of these tools provide insight into your customers who are using New Relic. They can be used to identify up-sale opportunities or to assist your support group in proactive support. State-of-the-Partnership report The State-of-the-Partnership report provides a summary of your customers with New Relic accounts and their activities. The report is broken down by language of the agents deployed, the agent version and the language version for each account. This report is run weekly for each partner. It is available on request from your New Relic Business Development contact. This report is an excellent way to see which of your customers with New Relic accounts are in fact using the service. Partner customer monitoring The Partner customer monitoring facility provides application performance data on the New Relic enabled applications that are running on your service. This facility allows you to easily identify customers experiencing performance problems. Where the performance problems are caused by under capacity, these customers are excellent sales opportunities. Alternatively your support or services organization will find this information useful in pre-emptively identifying customer issues or as good prospects for consulting services. View an arbitrary customer To view activity of a customer that does not appear in any of the filtered views: Go to one.newrelic.com > (account dropdown) > Switch accounts > Other accounts. New Relic will list all of the reporting accounts in the partnership. You can filter or search the list. Viewing detailed customer data Under normal circumstances a partner will be able to see only the summary level data in a customer's New Relic account. Through the Partnership Admin Console, partners will be permitted to drill down to the more detailed presentation. If you want to drill down from the Partnership Admin Console, add your user (typically support@partner.com or something similar) to the account. Typically this will be done at account creation. Avoid provisioning this user as the account Owner.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.53123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> admin console",
        "sections": "<em>Partnership</em> admin console",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "The <em>Partnership</em> Admin Console is the interface for managing your customers&#x27; accounts and <em>integration</em> with <em>New</em> <em>Relic</em>. To access the console, sign into the <em>partnership</em> owner account, and go to: https:&#x2F;&#x2F;<em>partner</em>-admin-console.newrelic.com&#x2F;accounts&#x2F;ACCOUNT_ID&#x2F;admin_console&#x2F; Copy You can also access"
      },
      "id": "603ed3e3196a6735baa83dad"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console": [
    {
      "sections": [
        "Walkthrough and signoff"
      ],
      "title": "Walkthrough and signoff",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "dd4bafe85fefaa2a81c625f948ff4ca5ca1d9313",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/walkthrough-signoff/",
      "published_at": "2022-01-12T03:39:09Z",
      "updated_at": "2021-10-31T16:21:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a final step before going live, an integration walkthrough will be performed (typically via a conference call). The goals of this call and typical topic areas are to: Confirm the functionality of the integration. Understand and document the customer signup and usage UI workflow for the integration. Establish that mutual contractual commitments have been met. Evaluate ease of deployment. Create a plan for fine-tuning where required. Where deployment of New Relic requires working accounts or deployed applications, provision should be made in advance of the call for these elements to be in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.28036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " for the <em>integration</em>. Establish that mutual contractual commitments have been met. Evaluate ease of deployment. Create a plan for fine-tuning where required. Where deployment of <em>New</em> <em>Relic</em> requires working accounts or deployed applications, provision should be made in advance of the call for these elements to be in place."
      },
      "id": "6044e9c2196a67a23c960f82"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.45856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This document is for <em>New</em> <em>Relic</em> partners. After you complete your <em>partnership</em> <em>integration</em>, you will be introduced to your technical contacts at <em>New</em> <em>Relic</em>. Use these channels for non-urgent escalations. Tip If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, see <em>New</em> <em>Relic</em>&#x27;s resources for finding help or filing"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Partners: Contact New Relic",
        "Integration assistance",
        "Technical assistance (regular priority)",
        "Emergency technical assistance",
        "Customer support"
      ],
      "title": "Partners: Contact New Relic",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "0ccf40e755893e6c718ec900144a46f9d4f31230",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partners-contact-new-relic/",
      "published_at": "2022-01-12T05:50:52Z",
      "updated_at": "2021-03-16T10:06:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are New Relic's resources for partners. If you are not a New Relic partner, follow standard procedures to find help or file a support ticket. Integration assistance For technical assistance or coordination to create your integration, contact your New Relic account representative. In addition, if you are interested in becoming a new partner, contact your New Relic account representative. Technical assistance (regular priority) Once your integration is live, follow standard procedures to find help or file a support ticket. Emergency technical assistance The New Relic partner support queue is continually monitored during business hours (Pacific time). New Relic strives to respond to partner support requests sent by email within an hour. For emergency assistance, email support @ newrelic.com, or contact your New Relic account representative. Customer support When your integration with New Relic is implemented and ready to launch, New Relic will arrange an introduction to your technical support contacts at New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.79758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partners</em>: Contact <em>New</em> <em>Relic</em>",
        "sections": "<em>Partners</em>: Contact <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "Here are <em>New</em> <em>Relic</em>&#x27;s resources for partners. If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, follow standard procedures to find help or file a support ticket. <em>Integration</em> assistance For technical assistance or coordination to create your <em>integration</em>, contact your <em>New</em> <em>Relic</em> account representative. In addition"
      },
      "id": "603ed39f64441fbe7f4e887d"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners": [
    {
      "sections": [
        "Walkthrough and signoff"
      ],
      "title": "Walkthrough and signoff",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "dd4bafe85fefaa2a81c625f948ff4ca5ca1d9313",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/walkthrough-signoff/",
      "published_at": "2022-01-12T03:39:09Z",
      "updated_at": "2021-10-31T16:21:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a final step before going live, an integration walkthrough will be performed (typically via a conference call). The goals of this call and typical topic areas are to: Confirm the functionality of the integration. Understand and document the customer signup and usage UI workflow for the integration. Establish that mutual contractual commitments have been met. Evaluate ease of deployment. Create a plan for fine-tuning where required. Where deployment of New Relic requires working accounts or deployed applications, provision should be made in advance of the call for these elements to be in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.28036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " for the <em>integration</em>. Establish that mutual contractual commitments have been met. Evaluate ease of deployment. Create a plan for fine-tuning where required. Where deployment of <em>New</em> <em>Relic</em> requires working accounts or deployed applications, provision should be made in advance of the call for these elements to be in place."
      },
      "id": "6044e9c2196a67a23c960f82"
    },
    {
      "sections": [
        "Partnership admin console",
        "Console components",
        "Partnership configuration settings",
        "Customer activity monitoring",
        "State-of-the-Partnership report",
        "Partner customer monitoring",
        "View an arbitrary customer",
        "Viewing detailed customer data"
      ],
      "title": "Partnership admin console",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "670e4d2e1db957100b23a7b8b0af6bf50cc8c996",
      "image": "https://docs.newrelic.com/static/43369c88523ebf526ae58fa5719d4efe/0abdd/crop-partnership-owner-account-settings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-07-02T15:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Partnership Admin Console is the interface for managing your customers' accounts and integration with New Relic. To access the console, sign into the partnership owner account, and go to: https://partner-admin-console.newrelic.com/accounts/ACCOUNT_ID/admin_console/ Copy You can also access the console from the New Relic UI: Go to one.newrelic.com > (account dropdown) > Account settings. From the left menu bar, select Partnerships. one.newrelic.com > (account dropdown) > Account settings > Partnerships: Partnership owners can access the Partnership Admin Console from their account settings in the New Relic UI. Console components The Partnership Admin Console has two main components: Partnership configuration settings Customer activity monitoring If multiple partnerships are associated with the New Relic parent account, the menu also includes an option to switch partnership accounts. Partnership configuration settings In developing your integration with New Relic, you must specify a number of settings. For your convenience these settings are grouped together in the partnership console, including URLs for header/footer and various redirects, SSO configuration, and keys and the ability to manipulate them. Customer activity monitoring New Relic provides you with two tools for managing your customers: State-of-the-Partnership reports and live monitoring of all deployed New Relic agents in your partnership. Both of these tools provide insight into your customers who are using New Relic. They can be used to identify up-sale opportunities or to assist your support group in proactive support. State-of-the-Partnership report The State-of-the-Partnership report provides a summary of your customers with New Relic accounts and their activities. The report is broken down by language of the agents deployed, the agent version and the language version for each account. This report is run weekly for each partner. It is available on request from your New Relic Business Development contact. This report is an excellent way to see which of your customers with New Relic accounts are in fact using the service. Partner customer monitoring The Partner customer monitoring facility provides application performance data on the New Relic enabled applications that are running on your service. This facility allows you to easily identify customers experiencing performance problems. Where the performance problems are caused by under capacity, these customers are excellent sales opportunities. Alternatively your support or services organization will find this information useful in pre-emptively identifying customer issues or as good prospects for consulting services. View an arbitrary customer To view activity of a customer that does not appear in any of the filtered views: Go to one.newrelic.com > (account dropdown) > Switch accounts > Other accounts. New Relic will list all of the reporting accounts in the partnership. You can filter or search the list. Viewing detailed customer data Under normal circumstances a partner will be able to see only the summary level data in a customer's New Relic account. Through the Partnership Admin Console, partners will be permitted to drill down to the more detailed presentation. If you want to drill down from the Partnership Admin Console, add your user (typically support@partner.com or something similar) to the account. Typically this will be done at account creation. Avoid provisioning this user as the account Owner.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.53123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> admin console",
        "sections": "<em>Partnership</em> admin console",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "The <em>Partnership</em> Admin Console is the interface for managing your customers&#x27; accounts and <em>integration</em> with <em>New</em> <em>Relic</em>. To access the console, sign into the <em>partnership</em> owner account, and go to: https:&#x2F;&#x2F;<em>partner</em>-admin-console.newrelic.com&#x2F;accounts&#x2F;ACCOUNT_ID&#x2F;admin_console&#x2F; Copy You can also access"
      },
      "id": "603ed3e3196a6735baa83dad"
    },
    {
      "sections": [
        "Partners: Contact New Relic",
        "Integration assistance",
        "Technical assistance (regular priority)",
        "Emergency technical assistance",
        "Customer support"
      ],
      "title": "Partners: Contact New Relic",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "0ccf40e755893e6c718ec900144a46f9d4f31230",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partners-contact-new-relic/",
      "published_at": "2022-01-12T05:50:52Z",
      "updated_at": "2021-03-16T10:06:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are New Relic's resources for partners. If you are not a New Relic partner, follow standard procedures to find help or file a support ticket. Integration assistance For technical assistance or coordination to create your integration, contact your New Relic account representative. In addition, if you are interested in becoming a new partner, contact your New Relic account representative. Technical assistance (regular priority) Once your integration is live, follow standard procedures to find help or file a support ticket. Emergency technical assistance The New Relic partner support queue is continually monitored during business hours (Pacific time). New Relic strives to respond to partner support requests sent by email within an hour. For emergency assistance, email support @ newrelic.com, or contact your New Relic account representative. Customer support When your integration with New Relic is implemented and ready to launch, New Relic will arrange an introduction to your technical support contacts at New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.79758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partners</em>: Contact <em>New</em> <em>Relic</em>",
        "sections": "<em>Partners</em>: Contact <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "Here are <em>New</em> <em>Relic</em>&#x27;s resources for partners. If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, follow standard procedures to find help or file a support ticket. <em>Integration</em> assistance For technical assistance or coordination to create your <em>integration</em>, contact your <em>New</em> <em>Relic</em> account representative. In addition"
      },
      "id": "603ed39f64441fbe7f4e887d"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/getting-started/walkthrough-signoff": [
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.45856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This document is for <em>New</em> <em>Relic</em> partners. After you complete your <em>partnership</em> <em>integration</em>, you will be introduced to your technical contacts at <em>New</em> <em>Relic</em>. Use these channels for non-urgent escalations. Tip If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, see <em>New</em> <em>Relic</em>&#x27;s resources for finding help or filing"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Partnership admin console",
        "Console components",
        "Partnership configuration settings",
        "Customer activity monitoring",
        "State-of-the-Partnership report",
        "Partner customer monitoring",
        "View an arbitrary customer",
        "Viewing detailed customer data"
      ],
      "title": "Partnership admin console",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "670e4d2e1db957100b23a7b8b0af6bf50cc8c996",
      "image": "https://docs.newrelic.com/static/43369c88523ebf526ae58fa5719d4efe/0abdd/crop-partnership-owner-account-settings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-07-02T15:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Partnership Admin Console is the interface for managing your customers' accounts and integration with New Relic. To access the console, sign into the partnership owner account, and go to: https://partner-admin-console.newrelic.com/accounts/ACCOUNT_ID/admin_console/ Copy You can also access the console from the New Relic UI: Go to one.newrelic.com > (account dropdown) > Account settings. From the left menu bar, select Partnerships. one.newrelic.com > (account dropdown) > Account settings > Partnerships: Partnership owners can access the Partnership Admin Console from their account settings in the New Relic UI. Console components The Partnership Admin Console has two main components: Partnership configuration settings Customer activity monitoring If multiple partnerships are associated with the New Relic parent account, the menu also includes an option to switch partnership accounts. Partnership configuration settings In developing your integration with New Relic, you must specify a number of settings. For your convenience these settings are grouped together in the partnership console, including URLs for header/footer and various redirects, SSO configuration, and keys and the ability to manipulate them. Customer activity monitoring New Relic provides you with two tools for managing your customers: State-of-the-Partnership reports and live monitoring of all deployed New Relic agents in your partnership. Both of these tools provide insight into your customers who are using New Relic. They can be used to identify up-sale opportunities or to assist your support group in proactive support. State-of-the-Partnership report The State-of-the-Partnership report provides a summary of your customers with New Relic accounts and their activities. The report is broken down by language of the agents deployed, the agent version and the language version for each account. This report is run weekly for each partner. It is available on request from your New Relic Business Development contact. This report is an excellent way to see which of your customers with New Relic accounts are in fact using the service. Partner customer monitoring The Partner customer monitoring facility provides application performance data on the New Relic enabled applications that are running on your service. This facility allows you to easily identify customers experiencing performance problems. Where the performance problems are caused by under capacity, these customers are excellent sales opportunities. Alternatively your support or services organization will find this information useful in pre-emptively identifying customer issues or as good prospects for consulting services. View an arbitrary customer To view activity of a customer that does not appear in any of the filtered views: Go to one.newrelic.com > (account dropdown) > Switch accounts > Other accounts. New Relic will list all of the reporting accounts in the partnership. You can filter or search the list. Viewing detailed customer data Under normal circumstances a partner will be able to see only the summary level data in a customer's New Relic account. Through the Partnership Admin Console, partners will be permitted to drill down to the more detailed presentation. If you want to drill down from the Partnership Admin Console, add your user (typically support@partner.com or something similar) to the account. Typically this will be done at account creation. Avoid provisioning this user as the account Owner.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.53123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> admin console",
        "sections": "<em>Partnership</em> admin console",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "The <em>Partnership</em> Admin Console is the interface for managing your customers&#x27; accounts and <em>integration</em> with <em>New</em> <em>Relic</em>. To access the console, sign into the <em>partnership</em> owner account, and go to: https:&#x2F;&#x2F;<em>partner</em>-admin-console.newrelic.com&#x2F;accounts&#x2F;ACCOUNT_ID&#x2F;admin_console&#x2F; Copy You can also access"
      },
      "id": "603ed3e3196a6735baa83dad"
    },
    {
      "sections": [
        "Partners: Contact New Relic",
        "Integration assistance",
        "Technical assistance (regular priority)",
        "Emergency technical assistance",
        "Customer support"
      ],
      "title": "Partners: Contact New Relic",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "0ccf40e755893e6c718ec900144a46f9d4f31230",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partners-contact-new-relic/",
      "published_at": "2022-01-12T05:50:52Z",
      "updated_at": "2021-03-16T10:06:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are New Relic's resources for partners. If you are not a New Relic partner, follow standard procedures to find help or file a support ticket. Integration assistance For technical assistance or coordination to create your integration, contact your New Relic account representative. In addition, if you are interested in becoming a new partner, contact your New Relic account representative. Technical assistance (regular priority) Once your integration is live, follow standard procedures to find help or file a support ticket. Emergency technical assistance The New Relic partner support queue is continually monitored during business hours (Pacific time). New Relic strives to respond to partner support requests sent by email within an hour. For emergency assistance, email support @ newrelic.com, or contact your New Relic account representative. Customer support When your integration with New Relic is implemented and ready to launch, New Relic will arrange an introduction to your technical support contacts at New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.79758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partners</em>: Contact <em>New</em> <em>Relic</em>",
        "sections": "<em>Partners</em>: Contact <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "Here are <em>New</em> <em>Relic</em>&#x27;s resources for partners. If you are not a <em>New</em> <em>Relic</em> <em>partner</em>, follow standard procedures to find help or file a support ticket. <em>Integration</em> assistance For technical assistance or coordination to create your <em>integration</em>, contact your <em>New</em> <em>Relic</em> account representative. In addition"
      },
      "id": "603ed39f64441fbe7f4e887d"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/other-partnership-settings": [
    {
      "sections": [
        "Partnership accounts: Single sign on and access control",
        "Implement Single Sign On",
        "Use shared secret method",
        "SSO API",
        "Description",
        "Method",
        "URI",
        "Parameters",
        "**cURL examples**"
      ],
      "title": "Partnership accounts: Single sign on and access control",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "New Relic products features"
      ],
      "external_id": "7054f72ececf6692e3abdcc1573276559be841ca",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/single-sign-access-control/",
      "published_at": "2022-01-12T05:52:20Z",
      "updated_at": "2021-10-31T16:22:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic supports Single Sign On (SSO) as a convenience for partner customers. Partners implementing SSO also have the option to restrict access by requiring customers to access New Relic via the partner's management site or product login. Single Sign On is a convenience for your customers, eliminating the requirement of entering sign on credentials multiple times, and it creates a more unified experience for the user. In situations where this distinction is desired, SSO is recommended. Where it is desirable to maintain a distinction between the services or where technical considerations preclude implementing SSO, a fully functioning integration is still achievable. Implement Single Sign On Two methods for SSO are supported by New Relic. New Relic upgraded its single sign on system during 2011. If you implemented single sign on with New Relic prior to September 2011, you will have used the old system. That method of implementing SSO has been deprecated. All new integrations must use the new system. Existing implementations using the old system will continue to work indefinitely. However, we encourage all partners using the old system to upgrade to the new model. Use shared secret method The upgraded shared secret version of New Relic's SSO implementation offers several improvements over the old handshake version. Most important, the system is more secure. Security is enhanced by the use of passing a SHA1 digest of a shared secret, a timestamp, and request specific data in the authentication SSO request. The shared secret can be any string. Whatever shared secret is chosen, enter it in the appropriate field in the New Relic Partner console. To edit the SSO settings: Log in to the partnership owner account. From the account dropdown in the New Relic UI, select Account settings > Partnerships > Edit settings. For SSO type, select signature. For SSO data, type the shared secret. Select Save. In addition to enhanced security, the new SSO method supports a session cookie. Nav data may be stored in the session cookie to support enhanced functionality of headers and footers. The name of the cookie is specified through the Partner console. If unspecified the cookie name defaults to nav_data. To successfully use this SSO method, the SSO URI must be invoked from the user's browser. On success the browser will be automatically logged into New Relic and the redirect URL to that account returned. The SSO URI however should not be generated on the browser, as this would expose the shared secret and allow the login to be spoofed. The URI should be generated on a host and passed to the user's browser. SSO API Description SSO authentication request Method POST or GET URI https://rpm.newrelic.com/accounts/sso_access Copy Parameters Name Required Description id Yes ID of the New Relic account. email No Email address of user logging in (optional). If given, the user must already have been added to the account. By default, the account Owner role is used. Account Owners have full privileges on accounts. If some lesser degree of account privileges or a different user is desired, the email must be provided. timestamp Yes Timestamp used to generate token, in seconds since the epoch. Only timestamps within five minutes (300 seconds) of the New Relic system clock are accepted. nav-data OR nav_data No Partner navigation data. This data will be set in the session cookie using the name as specified in the partnership configuration, or nav_data by default. token Yes Signed token. The signature token is generated by applying a SHA1 hex digest on a seed string, which is composed as Account_id:secret:timestamp or Account_id:secret:timestamp:email. Each component is separated by a colon (:). Example without email: \"12345:MySecret:0987654321\" Using Ruby syntax: \"#{account_id}:#{secret}:#{timestamp}\" Example with email: \"12345:MySecret:0987654321:user@host.com\" Using Ruby syntax: \"#{account_id}:#{secret}:#{timestamp}:#{email}\" remote_url No Relative path of a New Relic page to which the users will be directed. ** cURL examples * * curl -X POST -d \"id=63790\" -d \"timestamp=1319659982\" -d \"token=a4d30d6f1f1a5b6c2872ab\" https://rpm.newrelic.com/accounts/sso_access Copy curl -X POST -d \"id=63790\" -d \"timestamp=1319659982\" -d \"token=a4d30d6f1f1a5b6c2872ab\" -d \"remote_url=/account/63790/servers\" https://rpm.newrelic.com/accounts/sso_access Copy On success returns: <html><body>You are being redirected.</body></html> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.84355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> accounts: Single sign on and access control",
        "sections": "<em>Partnership</em> accounts: Single sign on and access control",
        "tags": "<em>New</em> <em>Relic</em> <em>products</em> <em>features</em>",
        "body": "<em>New</em> <em>Relic</em> supports Single Sign On (SSO) as a convenience for <em>partner</em> customers. Partners implementing SSO also have the option to restrict access by requiring customers to access <em>New</em> <em>Relic</em> via the <em>partner</em>&#x27;s management site or <em>product</em> login. Single Sign On is a convenience for your customers"
      },
      "id": "6044175564441fd3fa378f1f"
    },
    {
      "sections": [
        "Partner products, pricing, and billing",
        "Important",
        "Commitment levels",
        "Customized partnership pricing",
        "Partnership billing options",
        "Cancellations",
        "Promotions",
        "Legacy products and commitment levels"
      ],
      "title": "Partner products, pricing, and billing",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "New Relic products features"
      ],
      "external_id": "05d2d31e3eb7c18d7d0b13eac2d3fead6fd58bbf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/partner-products-pricing-billing/",
      "published_at": "2022-01-12T09:15:27Z",
      "updated_at": "2021-10-31T16:22:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This information is for New Relic partners. If you are not a New Relic partner, refer to the information about pricing and billing for New Relic accounts. Partners: For account setup procedures, see New Relic's Partner API documentation. For specific product pricing details (such as New Relic APM), visit New Relic's website, or contact your Alliance & Channels representative at New Relic. Commitment levels When customers choose a product, they also choose a monthly or annual commitment level. Existing partnerships have the option of limiting available product offerings for their customers. Reseller partners may be able to modify these subscription terms based on the contractual terms in the partner agreement with New Relic. Customized partnership pricing Partnership accounts may offer customized pricing. Customized pricing models, rates, minimums, discounts, and options vary by partnership--the actual pricing model used is subject to the contractual terms of the partner's agreement with New Relic. Contact your Alliance & Channels representative at New Relic to learn more. Partnership billing options New Relic supports the following billing options for partnerships. All subscriptions commence and expire at midnight GMT. For host-based subscriptions, fees are charged in advance for the month. Upgrade requests are honored immediately without any billing for partial use during the month. Downgrades take effect at the next payment date. To view New Relic account billing details and history from the user interface: From one.newrelic.com, select (account dropdown) > Account settings > Account > Billing. Billing option Description Credit card When partners choose credit card billing, your customers are directly charged using the credit card information provided during their New Relic subscription signup. This does not include any license fees paid directly by the partner for their customers' accounts. Invoice When partners choose invoice billing, your customers are billed directly by New Relic via invoice for their subscriptions. This option is normally provided on special request to customers with large monthly costs for which credit card billing would be impractical. Reseller For resellers, partners are billed directly for all customer accounts based on the calendar month. Partners may be responsible for accounting for customer usage, pricing, and subscriptions. Resellers have the option to implement an integration between our respective accounting systems. New Relic will invoice the partner monthly, using the Billing integration API for each of the paying accounts under the partnership. Cancellations Once a New Relic account cancellation takes effect, you must uninstall and/or delete all agents or other data-reporting integrations. For uninstallation details, see the documentation for the relevant agents and integrations. Customers may continue to access their data on New Relic until it is purged in accordance with the data retention policy corresponding to the product level. For existing accounts with paid, fixed host subscriptions, cancellations take effect at the next payment date. New Relic will continue to accept data for cancelled accounts until this date. Cancellations for accounts with free or paid based subscriptions take effect immediately. Promotions New Relic allows promotions for accounts offered through partnerships. Promotions associated with a specific partnership may only be redeemed on accounts associated with the partnership. Each promotion has a unique code. This promotion code may be applied only once per account. New Relic may impose further limits on the number of promotions that a customer may apply to an account. Promotion Description Free trials New Relic may include a free trial period for features normally available only through a paid subscription level. This option is provided for a specified number of days. The customer's subscription automatically reverts to its prior level at the conclusion of the trial. Payments for paid subscriptions are not interrupted by the redemption of a free trial promotion on the account. Single use Single use trials expire after they are used once. Discount (deprecated) A one-time percentage discount is applied to a paid subscription. This discount is applied in addition to any volume discounts and customized partner prices. The discount remains in effect until the subscription is modified or cancelled. Legacy products and commitment levels If you have questions about older New Relic products that have been converted to new pricing models, contact your Alliance & Channels representative at New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.84355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>products</em>, pricing, and billing",
        "sections": "<em>Partner</em> <em>products</em>, pricing, and billing",
        "tags": "<em>New</em> <em>Relic</em> <em>products</em> <em>features</em>",
        "body": " by <em>partnership</em>--the actual pricing model used is subject to the contractual terms of the <em>partner</em>&#x27;s agreement with <em>New</em> <em>Relic</em>. Contact your Alliance &amp; Channels representative at <em>New</em> <em>Relic</em> to learn more. <em>Partnership</em> billing options <em>New</em> <em>Relic</em> supports the following billing options for <em>partnerships</em>. All"
      },
      "id": "603ece55e7b9d254192a080c"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.74533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " <em>New</em> <em>Relic</em> <em>products</em> and <em>features</em> by category. Tip The docs site includes a <em>Partnerships</em> category with information for <em>New</em> <em>Relic</em> partners and some <em>partnership</em> customers. Here are the five most commonly consulted articles on the <em>New</em> <em>Relic</em> docs site. Providing easily found and direct links"
      },
      "id": "60450ecf28ccbc45632c6095"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/partner-products-pricing-billing": [
    {
      "sections": [
        "Partnership accounts: Single sign on and access control",
        "Implement Single Sign On",
        "Use shared secret method",
        "SSO API",
        "Description",
        "Method",
        "URI",
        "Parameters",
        "**cURL examples**"
      ],
      "title": "Partnership accounts: Single sign on and access control",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "New Relic products features"
      ],
      "external_id": "7054f72ececf6692e3abdcc1573276559be841ca",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/single-sign-access-control/",
      "published_at": "2022-01-12T05:52:20Z",
      "updated_at": "2021-10-31T16:22:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic supports Single Sign On (SSO) as a convenience for partner customers. Partners implementing SSO also have the option to restrict access by requiring customers to access New Relic via the partner's management site or product login. Single Sign On is a convenience for your customers, eliminating the requirement of entering sign on credentials multiple times, and it creates a more unified experience for the user. In situations where this distinction is desired, SSO is recommended. Where it is desirable to maintain a distinction between the services or where technical considerations preclude implementing SSO, a fully functioning integration is still achievable. Implement Single Sign On Two methods for SSO are supported by New Relic. New Relic upgraded its single sign on system during 2011. If you implemented single sign on with New Relic prior to September 2011, you will have used the old system. That method of implementing SSO has been deprecated. All new integrations must use the new system. Existing implementations using the old system will continue to work indefinitely. However, we encourage all partners using the old system to upgrade to the new model. Use shared secret method The upgraded shared secret version of New Relic's SSO implementation offers several improvements over the old handshake version. Most important, the system is more secure. Security is enhanced by the use of passing a SHA1 digest of a shared secret, a timestamp, and request specific data in the authentication SSO request. The shared secret can be any string. Whatever shared secret is chosen, enter it in the appropriate field in the New Relic Partner console. To edit the SSO settings: Log in to the partnership owner account. From the account dropdown in the New Relic UI, select Account settings > Partnerships > Edit settings. For SSO type, select signature. For SSO data, type the shared secret. Select Save. In addition to enhanced security, the new SSO method supports a session cookie. Nav data may be stored in the session cookie to support enhanced functionality of headers and footers. The name of the cookie is specified through the Partner console. If unspecified the cookie name defaults to nav_data. To successfully use this SSO method, the SSO URI must be invoked from the user's browser. On success the browser will be automatically logged into New Relic and the redirect URL to that account returned. The SSO URI however should not be generated on the browser, as this would expose the shared secret and allow the login to be spoofed. The URI should be generated on a host and passed to the user's browser. SSO API Description SSO authentication request Method POST or GET URI https://rpm.newrelic.com/accounts/sso_access Copy Parameters Name Required Description id Yes ID of the New Relic account. email No Email address of user logging in (optional). If given, the user must already have been added to the account. By default, the account Owner role is used. Account Owners have full privileges on accounts. If some lesser degree of account privileges or a different user is desired, the email must be provided. timestamp Yes Timestamp used to generate token, in seconds since the epoch. Only timestamps within five minutes (300 seconds) of the New Relic system clock are accepted. nav-data OR nav_data No Partner navigation data. This data will be set in the session cookie using the name as specified in the partnership configuration, or nav_data by default. token Yes Signed token. The signature token is generated by applying a SHA1 hex digest on a seed string, which is composed as Account_id:secret:timestamp or Account_id:secret:timestamp:email. Each component is separated by a colon (:). Example without email: \"12345:MySecret:0987654321\" Using Ruby syntax: \"#{account_id}:#{secret}:#{timestamp}\" Example with email: \"12345:MySecret:0987654321:user@host.com\" Using Ruby syntax: \"#{account_id}:#{secret}:#{timestamp}:#{email}\" remote_url No Relative path of a New Relic page to which the users will be directed. ** cURL examples * * curl -X POST -d \"id=63790\" -d \"timestamp=1319659982\" -d \"token=a4d30d6f1f1a5b6c2872ab\" https://rpm.newrelic.com/accounts/sso_access Copy curl -X POST -d \"id=63790\" -d \"timestamp=1319659982\" -d \"token=a4d30d6f1f1a5b6c2872ab\" -d \"remote_url=/account/63790/servers\" https://rpm.newrelic.com/accounts/sso_access Copy On success returns: <html><body>You are being redirected.</body></html> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.84355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> accounts: Single sign on and access control",
        "sections": "<em>Partnership</em> accounts: Single sign on and access control",
        "tags": "<em>New</em> <em>Relic</em> <em>products</em> <em>features</em>",
        "body": "<em>New</em> <em>Relic</em> supports Single Sign On (SSO) as a convenience for <em>partner</em> customers. Partners implementing SSO also have the option to restrict access by requiring customers to access <em>New</em> <em>Relic</em> via the <em>partner</em>&#x27;s management site or <em>product</em> login. Single Sign On is a convenience for your customers"
      },
      "id": "6044175564441fd3fa378f1f"
    },
    {
      "sections": [
        "Other partnership settings",
        "Types of settings"
      ],
      "title": "Other partnership settings",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "New Relic products features"
      ],
      "external_id": "df23328a14acab54c7f100c723f6feee68927c6b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/other-partnership-settings/",
      "published_at": "2022-01-12T03:39:40Z",
      "updated_at": "2021-10-31T16:22:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are a number of miscellaneous settings that are available to partners for customization of their partnership integration. Most of these settings enable or disable the presentation of New Relic features. These settings must be set by New Relic and are not configurable through the Partnership Console. Types of settings Contact your partnership technical contact to have any of these settings modified. Download links: Show agent link Show configuration file link Welcome messages: Signup message: A customized welcome message Hide or show banner welcome message Hide or show invoice message Email control: Send deploy reminders Send trial emails Billing email: This is for partnerships where the billing method is \"Reseller\" and invoices should be directed to the attention of a specific party. Feature access: Server monitoring User administration)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.84355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Other <em>partnership</em> settings",
        "sections": "Other <em>partnership</em> settings",
        "tags": "<em>New</em> <em>Relic</em> <em>products</em> <em>features</em>",
        "body": "There are a number of miscellaneous settings that are available to partners for customization of their <em>partnership</em> <em>integration</em>. Most of these settings enable or disable the presentation of <em>New</em> <em>Relic</em> <em>features</em>. These settings must be set by <em>New</em> <em>Relic</em> and are not configurable through the <em>Partnership</em>"
      },
      "id": "603ed42364441fb51f4e88a9"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.74533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " <em>New</em> <em>Relic</em> <em>products</em> and <em>features</em> by category. Tip The docs site includes a <em>Partnerships</em> category with information for <em>New</em> <em>Relic</em> partners and some <em>partnership</em> customers. Here are the five most commonly consulted articles on the <em>New</em> <em>Relic</em> docs site. Providing easily found and direct links"
      },
      "id": "60450ecf28ccbc45632c6095"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/single-sign-access-control": [
    {
      "sections": [
        "Partner products, pricing, and billing",
        "Important",
        "Commitment levels",
        "Customized partnership pricing",
        "Partnership billing options",
        "Cancellations",
        "Promotions",
        "Legacy products and commitment levels"
      ],
      "title": "Partner products, pricing, and billing",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "New Relic products features"
      ],
      "external_id": "05d2d31e3eb7c18d7d0b13eac2d3fead6fd58bbf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/partner-products-pricing-billing/",
      "published_at": "2022-01-12T09:15:27Z",
      "updated_at": "2021-10-31T16:22:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This information is for New Relic partners. If you are not a New Relic partner, refer to the information about pricing and billing for New Relic accounts. Partners: For account setup procedures, see New Relic's Partner API documentation. For specific product pricing details (such as New Relic APM), visit New Relic's website, or contact your Alliance & Channels representative at New Relic. Commitment levels When customers choose a product, they also choose a monthly or annual commitment level. Existing partnerships have the option of limiting available product offerings for their customers. Reseller partners may be able to modify these subscription terms based on the contractual terms in the partner agreement with New Relic. Customized partnership pricing Partnership accounts may offer customized pricing. Customized pricing models, rates, minimums, discounts, and options vary by partnership--the actual pricing model used is subject to the contractual terms of the partner's agreement with New Relic. Contact your Alliance & Channels representative at New Relic to learn more. Partnership billing options New Relic supports the following billing options for partnerships. All subscriptions commence and expire at midnight GMT. For host-based subscriptions, fees are charged in advance for the month. Upgrade requests are honored immediately without any billing for partial use during the month. Downgrades take effect at the next payment date. To view New Relic account billing details and history from the user interface: From one.newrelic.com, select (account dropdown) > Account settings > Account > Billing. Billing option Description Credit card When partners choose credit card billing, your customers are directly charged using the credit card information provided during their New Relic subscription signup. This does not include any license fees paid directly by the partner for their customers' accounts. Invoice When partners choose invoice billing, your customers are billed directly by New Relic via invoice for their subscriptions. This option is normally provided on special request to customers with large monthly costs for which credit card billing would be impractical. Reseller For resellers, partners are billed directly for all customer accounts based on the calendar month. Partners may be responsible for accounting for customer usage, pricing, and subscriptions. Resellers have the option to implement an integration between our respective accounting systems. New Relic will invoice the partner monthly, using the Billing integration API for each of the paying accounts under the partnership. Cancellations Once a New Relic account cancellation takes effect, you must uninstall and/or delete all agents or other data-reporting integrations. For uninstallation details, see the documentation for the relevant agents and integrations. Customers may continue to access their data on New Relic until it is purged in accordance with the data retention policy corresponding to the product level. For existing accounts with paid, fixed host subscriptions, cancellations take effect at the next payment date. New Relic will continue to accept data for cancelled accounts until this date. Cancellations for accounts with free or paid based subscriptions take effect immediately. Promotions New Relic allows promotions for accounts offered through partnerships. Promotions associated with a specific partnership may only be redeemed on accounts associated with the partnership. Each promotion has a unique code. This promotion code may be applied only once per account. New Relic may impose further limits on the number of promotions that a customer may apply to an account. Promotion Description Free trials New Relic may include a free trial period for features normally available only through a paid subscription level. This option is provided for a specified number of days. The customer's subscription automatically reverts to its prior level at the conclusion of the trial. Payments for paid subscriptions are not interrupted by the redemption of a free trial promotion on the account. Single use Single use trials expire after they are used once. Discount (deprecated) A one-time percentage discount is applied to a paid subscription. This discount is applied in addition to any volume discounts and customized partner prices. The discount remains in effect until the subscription is modified or cancelled. Legacy products and commitment levels If you have questions about older New Relic products that have been converted to new pricing models, contact your Alliance & Channels representative at New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.84355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>products</em>, pricing, and billing",
        "sections": "<em>Partner</em> <em>products</em>, pricing, and billing",
        "tags": "<em>New</em> <em>Relic</em> <em>products</em> <em>features</em>",
        "body": " by <em>partnership</em>--the actual pricing model used is subject to the contractual terms of the <em>partner</em>&#x27;s agreement with <em>New</em> <em>Relic</em>. Contact your Alliance &amp; Channels representative at <em>New</em> <em>Relic</em> to learn more. <em>Partnership</em> billing options <em>New</em> <em>Relic</em> supports the following billing options for <em>partnerships</em>. All"
      },
      "id": "603ece55e7b9d254192a080c"
    },
    {
      "sections": [
        "Other partnership settings",
        "Types of settings"
      ],
      "title": "Other partnership settings",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "New Relic products features"
      ],
      "external_id": "df23328a14acab54c7f100c723f6feee68927c6b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/new-relic-products-features/other-partnership-settings/",
      "published_at": "2022-01-12T03:39:40Z",
      "updated_at": "2021-10-31T16:22:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are a number of miscellaneous settings that are available to partners for customization of their partnership integration. Most of these settings enable or disable the presentation of New Relic features. These settings must be set by New Relic and are not configurable through the Partnership Console. Types of settings Contact your partnership technical contact to have any of these settings modified. Download links: Show agent link Show configuration file link Welcome messages: Signup message: A customized welcome message Hide or show banner welcome message Hide or show invoice message Email control: Send deploy reminders Send trial emails Billing email: This is for partnerships where the billing method is \"Reseller\" and invoices should be directed to the attention of a specific party. Feature access: Server monitoring User administration)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.84355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Other <em>partnership</em> settings",
        "sections": "Other <em>partnership</em> settings",
        "tags": "<em>New</em> <em>Relic</em> <em>products</em> <em>features</em>",
        "body": "There are a number of miscellaneous settings that are available to partners for customization of their <em>partnership</em> <em>integration</em>. Most of these settings enable or disable the presentation of <em>New</em> <em>Relic</em> <em>features</em>. These settings must be set by <em>New</em> <em>Relic</em> and are not configurable through the <em>Partnership</em>"
      },
      "id": "603ed42364441fb51f4e88a9"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.74533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "sections": "Support resources for <em>New</em> <em>Relic</em> <em>partners</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " <em>New</em> <em>Relic</em> <em>products</em> and <em>features</em> by category. Tip The docs site includes a <em>Partnerships</em> category with information for <em>New</em> <em>Relic</em> partners and some <em>partnership</em> customers. Here are the five most commonly consulted articles on the <em>New</em> <em>Relic</em> docs site. Providing easily found and direct links"
      },
      "id": "60450ecf28ccbc45632c6095"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-account-access-administrators": [
    {
      "sections": [
        "Intro to Partnership API",
        "Requirements",
        "Customer partnership restrictions",
        "Password requirements",
        "Things you can do",
        "Get started"
      ],
      "title": "Intro to Partnership API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "074cf4e7c590dfa2332284a7b7f394e2f7ba45ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api/",
      "published_at": "2022-01-12T03:40:16Z",
      "updated_at": "2021-11-13T15:06:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Partnership API allows New Relic partners, and New Relic accounts set up as customer partnerships, to manage accounts, users, and subscription-related settings. Requirements The Partnership API can be used by two types of New Relic accounts: partners (managed service providers, resellers) and customer partnerships (larger customers who have been given access to our partnership account structure). These docs are for version 2 of the Partner API. Earlier versions have been deprecated. If you have problems with an older integration, upgrade to version 2. Access to the partnership account structure and the Partnership API requires prior setup and approval by New Relic. Partnership API calls require authentication with both your partnership owner account's REST API key and your Partner ID. Accounts that are genuine New Relic partners (managed service providers, resellers) have no restrictions on using the API. Accounts set up as customer partnerships have restrictions that follow. Customer partnership restrictions If your New Relic organization is set up as a customer partnership, there are some restrictions in place if your organization is on our newer pricing model or our newer user model. Details: Pricing plan. If you’re on New Relic One pricing, you can't use API calls that govern our original pricing model. The API impacts are: You can't use the subscription object You can't use the NerdGraph Provisioning API. User model. If your New Relic account has been converted to be entirely on the New Relic One user model, you can no longer use API calls that create or govern users on our original user model. The API impacts are: You can't use the user object. Instead, you'd manage users with these user management docs. For the account object: you can't add users via the users field. Instead, you'd manage users with these user management docs. To determine your pricing model or user model, see Overview of pricing and user model changes. Password requirements Passwords passed for account creation have these requirements: 8 to 50 characters in length Only contain letters, numbers, or special characters Cannot contain spaces Must contain at least 1 letter Must contain at least 1 number or special character Things you can do Here is an overview of the API's functionality. Account: The account object is what you use to create and update accounts. You can do the following with it: Create new Show Update Cancel Show usage Set primary admin (some accounts) Set subscription (some accounts) There is also a child account object for creating child accounts. Users: Some organizations that meet the requirements can use the user object to: Add user access to account Remove user access from account Subscription: Organizations that meet the requirements and are on our original product pricing model can use the subscription object to configure various subscription-related traits. Get started To start using the Partnership API, see the Partner API reference docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.15797,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>Partnership</em> API",
        "sections": "Intro to <em>Partnership</em> API",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": ") and customer <em>partnerships</em> (larger customers who have been given access to our <em>partnership</em> <em>account</em> structure). These docs are for version 2 of the <em>Partner</em> API. Earlier versions have been deprecated. If you have problems with an older <em>integration</em>, upgrade to version 2. Access to the <em>partnership</em> <em>account</em>"
      },
      "id": "603ed42328ccbcd4b3eba7ca"
    },
    {
      "sections": [
        "Restricted access partnerships",
        "Limitations",
        "Account settings",
        "License key",
        "Direct login",
        "Restricted access URLs",
        "Enabling restricted access"
      ],
      "title": "Restricted access partnerships",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "76413b7966350501a506e3e24df99269e2131848",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/restricted-access-partnerships/",
      "published_at": "2022-01-12T05:52:25Z",
      "updated_at": "2021-10-31T16:24:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Partners who implement Single Sign On have the option to enable restricted account access by requiring their customers to access New Relic via their own management application. New Relic recommends that partners who want to manage their customers' accounts directly enable this option. This option is also recommended for partners with reseller agreements. Limitations Partners who implement restricted access are responsible for providing customers with a means for upgrading, administrating, adding and removing users, etc., through the partner's product or interface. Customers who purchase New Relic subscriptions directly from New Relic are not subject to these restrictions. When a partnership enables restricted access, its accounts are subject to the following limitations: Account settings License key Direct login Account settings Customers are not allowed to access any pages in New Relic's Account settings. This prevents customers from modifying the account, changing the subscription level, viewing billing information, and adding or removing users from within New Relic. License key Customers will not be able to access their license key or download their customized newrelic.yml file on the New Relic site. If customers have applications deployed elsewhere, this helps to prevent them from reporting to their partnership accounts in New Relic. Direct login Customers may not directly log in to New Relic to access their associated partner's accounts. Account access is provided solely using SSO and controlled via the partner's website. Restricted access URLs If you elect to enable restricted partnership access, specify the following URLs in the Partnership Console: URL Description Redirect URL Enter your login page for this field. If your customers try to directly log in to the New Relic site, they will be redirected to your login page. Change subscription URL When your customers select the New Relic Subscription option, they will be redirected to the URL that you specify here. Feature unavailable URL When your customers select premium New Relic features, they will be redirected to the URL that you specify here. Logout URL When your customers log out of a New Relic session, they are redirected to this page rather than the New Relic logout page. This option works with restricted access partnerships only. Enabling restricted access Restricted access settings are controlled by New Relic. To arrange changes to your partnership's restricted access settings, contact New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.49252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Restricted access <em>partnerships</em>",
        "sections": "Restricted access <em>partnerships</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " on the <em>New</em> <em>Relic</em> site. If customers have applications deployed elsewhere, this helps to prevent them from reporting to their <em>partnership</em> accounts in <em>New</em> <em>Relic</em>. Direct login Customers may not directly log in to <em>New</em> <em>Relic</em> to access their associated <em>partner</em>&#x27;s accounts. <em>Account</em> access is provided"
      },
      "id": "60441786e7b9d285595799b2"
    },
    {
      "sections": [
        "Partnership accounts, users, and subscriptions",
        "Partnerships with New Relic",
        "Account hierarchy",
        "Tip",
        "Partnership owner accounts (POA)",
        "Child accounts with partnerships",
        "Account users",
        "Partnership pricing"
      ],
      "title": "Partnership accounts, users, and subscriptions",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ae2f39a8ff0395815b3e31a9d8ad9361beca2c4e",
      "image": "https://docs.newrelic.com/static/7280d9af3c35c6eac85c43c7034ae789/db3a5/partnership-hierarchy.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partnership-accounts-users-subscriptions/",
      "published_at": "2022-01-12T05:52:19Z",
      "updated_at": "2021-07-02T15:20:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic organizations set up as partnership accounts have access to an enhanced hierarchical way of organizing their account structure. Partnerships with New Relic There are two types of New Relic organizations that are able to use our partnership account structure and the Partnership API: An actual partnership: A partnership refers to managed service providers or resellers, who offer New Relic products to their customers. Heroku is one example of such a New Relic partner. A customer partnership: some of our larger organizations also make use of our partnership account structure. We call these customers \"customer partnerships.\" Use of our partnership account structure requires prior approval and set up by New Relic representatives. For customer partnerships, New Relic contacts organizations that would benefit from such a structure. Partnerships are identified by a numeric PARTNER_ID. In some cases, a New Relic customer may have more than one partnership; for example, when one section of New Relic users must be managed differently from another. Partnerships are administered by a partnership owner account. The account that owns a partnership functions differently from a regular account. If multiple partnerships have been set up, each has a unique PARTNER_ID. Account hierarchy New Relic partnership organizations consist of the partnership owning account, partnerships, parent accounts, and child accounts. A partnership can have multiple parent and child accounts. To understand how child accounts and parent accounts scale with EU region accounts, see EU region account hierarchy. Tip If you don't have a partnership organization, you can only have one parent account. For more information, see Manage apps or users with child accounts. All parent and child accounts roll up to your partnership account. Partnership owner accounts (POA) The partnership owner account (POA) is the entity that is used to administer a partnership. It controls which users manage accounts under partnerships, have access to the partner API, and manage other aspects of the partnership. Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership and monitor apps from that account. Users on the partnership owner account can access accounts under their partnerships and enjoy User level privileges. Admins on the POA can access accounts under their partnerships and enjoy Admin level privileges, including permission to manage users. The Owner of the partnership owner account will still only have Admin level access on accounts under the partnership. That means that the owner cannot enable SAML SSO, change the account owner, cancel the account via the UI, etc. The partnership owner account enjoys special privileges, and it lets you exercise the capabilities defined in your partnership agreement with New Relic. For example, you may use your partnership owner account with the New Relic Partnership API to set up and manage users on your accounts or to view your customers' performance data in the New Relic UI. Tip Many of the Partnership API calls return an account status as part of the XML. Child accounts with partnerships Child accounts behave differently than other New Relic accounts provisioned through your partnership: Child accounts Comments Account creation Child accounts can be created through the Partnership API or New Relic user interface. In order to group accounts through the New Relic user interface, your partnership must have Admin privileges, and the account must have the appropriate subscription level. If you have any questions about partnership privileges or subscription levels, contact your New Relic account representative. Child accounts do not have a New Relic subscription of their own. They inherit the parent account's subscription. Billing Billing is applied at the parent account level. Exception: Reseller partnerships receive consolidated billing for all accounts under the partnership. Permissions Admin-level users on a parent account have the ability to create, modify, and delete children accounts for the parent account. Users that have been granted access permissions on a parent account automatically inherit the same level of access for all children accounts. This is also true for add-on roles. Exception: Child account users won't receive alert emails or weekly report emails unless they are explicitly granted permission on these child accounts. Account users You can use the Partnership user API to add and maintain your customer users. An account must always have at least one person (the Owner) associated with it. For security purposes, you cannot change an account Owner with the Partnership user API. Instead, you must change the account Owner from the Users page in the New Relic UI. In addition, a specific user may be associated with multiple accounts. For example, many New Relic users have accounts through a partnership, and they also have accounts they created directly with New Relic. Partnership pricing Accounts within a partnership organization may have different levels of access to New Relic products. Tip Many of the Partnership API calls return a subscription status as part of the XML. For accounts set up through a partnership: An account can have multiple New Relic products associated with it. However, only one subscription per product may be active at any time. For example, a user may have both an Essentials subscription and a higher service level Pro Trial subscription. When the Pro Trial subscription expires, the service level returns to the Essentials subscription. Promotions may appear as a subscription change. Several factors affect starting and stopping subscriptions, including how New Relic handles pricing and billing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.84935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>accounts</em>, users, and subscriptions",
        "sections": "<em>Partnerships</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " these customers &quot;customer <em>partnerships</em>.&quot; Use of our <em>partnership</em> <em>account</em> structure requires prior approval and set up by <em>New</em> <em>Relic</em> representatives. For customer <em>partnerships</em>, <em>New</em> <em>Relic</em> contacts organizations that would benefit from such a structure. <em>Partnerships</em> are identified by a numeric <em>PARTNER</em>"
      },
      "id": "603ece55e7b9d273782a0804"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api": [
    {
      "sections": [
        "Restricted access partnerships",
        "Limitations",
        "Account settings",
        "License key",
        "Direct login",
        "Restricted access URLs",
        "Enabling restricted access"
      ],
      "title": "Restricted access partnerships",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "76413b7966350501a506e3e24df99269e2131848",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/restricted-access-partnerships/",
      "published_at": "2022-01-12T05:52:25Z",
      "updated_at": "2021-10-31T16:24:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Partners who implement Single Sign On have the option to enable restricted account access by requiring their customers to access New Relic via their own management application. New Relic recommends that partners who want to manage their customers' accounts directly enable this option. This option is also recommended for partners with reseller agreements. Limitations Partners who implement restricted access are responsible for providing customers with a means for upgrading, administrating, adding and removing users, etc., through the partner's product or interface. Customers who purchase New Relic subscriptions directly from New Relic are not subject to these restrictions. When a partnership enables restricted access, its accounts are subject to the following limitations: Account settings License key Direct login Account settings Customers are not allowed to access any pages in New Relic's Account settings. This prevents customers from modifying the account, changing the subscription level, viewing billing information, and adding or removing users from within New Relic. License key Customers will not be able to access their license key or download their customized newrelic.yml file on the New Relic site. If customers have applications deployed elsewhere, this helps to prevent them from reporting to their partnership accounts in New Relic. Direct login Customers may not directly log in to New Relic to access their associated partner's accounts. Account access is provided solely using SSO and controlled via the partner's website. Restricted access URLs If you elect to enable restricted partnership access, specify the following URLs in the Partnership Console: URL Description Redirect URL Enter your login page for this field. If your customers try to directly log in to the New Relic site, they will be redirected to your login page. Change subscription URL When your customers select the New Relic Subscription option, they will be redirected to the URL that you specify here. Feature unavailable URL When your customers select premium New Relic features, they will be redirected to the URL that you specify here. Logout URL When your customers log out of a New Relic session, they are redirected to this page rather than the New Relic logout page. This option works with restricted access partnerships only. Enabling restricted access Restricted access settings are controlled by New Relic. To arrange changes to your partnership's restricted access settings, contact New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.49252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Restricted access <em>partnerships</em>",
        "sections": "Restricted access <em>partnerships</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " on the <em>New</em> <em>Relic</em> site. If customers have applications deployed elsewhere, this helps to prevent them from reporting to their <em>partnership</em> accounts in <em>New</em> <em>Relic</em>. Direct login Customers may not directly log in to <em>New</em> <em>Relic</em> to access their associated <em>partner</em>&#x27;s accounts. <em>Account</em> access is provided"
      },
      "id": "60441786e7b9d285595799b2"
    },
    {
      "sections": [
        "Partnership accounts, users, and subscriptions",
        "Partnerships with New Relic",
        "Account hierarchy",
        "Tip",
        "Partnership owner accounts (POA)",
        "Child accounts with partnerships",
        "Account users",
        "Partnership pricing"
      ],
      "title": "Partnership accounts, users, and subscriptions",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ae2f39a8ff0395815b3e31a9d8ad9361beca2c4e",
      "image": "https://docs.newrelic.com/static/7280d9af3c35c6eac85c43c7034ae789/db3a5/partnership-hierarchy.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partnership-accounts-users-subscriptions/",
      "published_at": "2022-01-12T05:52:19Z",
      "updated_at": "2021-07-02T15:20:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic organizations set up as partnership accounts have access to an enhanced hierarchical way of organizing their account structure. Partnerships with New Relic There are two types of New Relic organizations that are able to use our partnership account structure and the Partnership API: An actual partnership: A partnership refers to managed service providers or resellers, who offer New Relic products to their customers. Heroku is one example of such a New Relic partner. A customer partnership: some of our larger organizations also make use of our partnership account structure. We call these customers \"customer partnerships.\" Use of our partnership account structure requires prior approval and set up by New Relic representatives. For customer partnerships, New Relic contacts organizations that would benefit from such a structure. Partnerships are identified by a numeric PARTNER_ID. In some cases, a New Relic customer may have more than one partnership; for example, when one section of New Relic users must be managed differently from another. Partnerships are administered by a partnership owner account. The account that owns a partnership functions differently from a regular account. If multiple partnerships have been set up, each has a unique PARTNER_ID. Account hierarchy New Relic partnership organizations consist of the partnership owning account, partnerships, parent accounts, and child accounts. A partnership can have multiple parent and child accounts. To understand how child accounts and parent accounts scale with EU region accounts, see EU region account hierarchy. Tip If you don't have a partnership organization, you can only have one parent account. For more information, see Manage apps or users with child accounts. All parent and child accounts roll up to your partnership account. Partnership owner accounts (POA) The partnership owner account (POA) is the entity that is used to administer a partnership. It controls which users manage accounts under partnerships, have access to the partner API, and manage other aspects of the partnership. Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership and monitor apps from that account. Users on the partnership owner account can access accounts under their partnerships and enjoy User level privileges. Admins on the POA can access accounts under their partnerships and enjoy Admin level privileges, including permission to manage users. The Owner of the partnership owner account will still only have Admin level access on accounts under the partnership. That means that the owner cannot enable SAML SSO, change the account owner, cancel the account via the UI, etc. The partnership owner account enjoys special privileges, and it lets you exercise the capabilities defined in your partnership agreement with New Relic. For example, you may use your partnership owner account with the New Relic Partnership API to set up and manage users on your accounts or to view your customers' performance data in the New Relic UI. Tip Many of the Partnership API calls return an account status as part of the XML. Child accounts with partnerships Child accounts behave differently than other New Relic accounts provisioned through your partnership: Child accounts Comments Account creation Child accounts can be created through the Partnership API or New Relic user interface. In order to group accounts through the New Relic user interface, your partnership must have Admin privileges, and the account must have the appropriate subscription level. If you have any questions about partnership privileges or subscription levels, contact your New Relic account representative. Child accounts do not have a New Relic subscription of their own. They inherit the parent account's subscription. Billing Billing is applied at the parent account level. Exception: Reseller partnerships receive consolidated billing for all accounts under the partnership. Permissions Admin-level users on a parent account have the ability to create, modify, and delete children accounts for the parent account. Users that have been granted access permissions on a parent account automatically inherit the same level of access for all children accounts. This is also true for add-on roles. Exception: Child account users won't receive alert emails or weekly report emails unless they are explicitly granted permission on these child accounts. Account users You can use the Partnership user API to add and maintain your customer users. An account must always have at least one person (the Owner) associated with it. For security purposes, you cannot change an account Owner with the Partnership user API. Instead, you must change the account Owner from the Users page in the New Relic UI. In addition, a specific user may be associated with multiple accounts. For example, many New Relic users have accounts through a partnership, and they also have accounts they created directly with New Relic. Partnership pricing Accounts within a partnership organization may have different levels of access to New Relic products. Tip Many of the Partnership API calls return a subscription status as part of the XML. For accounts set up through a partnership: An account can have multiple New Relic products associated with it. However, only one subscription per product may be active at any time. For example, a user may have both an Essentials subscription and a higher service level Pro Trial subscription. When the Pro Trial subscription expires, the service level returns to the Essentials subscription. Promotions may appear as a subscription change. Several factors affect starting and stopping subscriptions, including how New Relic handles pricing and billing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.84935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>accounts</em>, users, and subscriptions",
        "sections": "<em>Partnerships</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " these customers &quot;customer <em>partnerships</em>.&quot; Use of our <em>partnership</em> <em>account</em> structure requires prior approval and set up by <em>New</em> <em>Relic</em> representatives. For customer <em>partnerships</em>, <em>New</em> <em>Relic</em> contacts organizations that would benefit from such a structure. <em>Partnerships</em> are identified by a numeric <em>PARTNER</em>"
      },
      "id": "603ece55e7b9d273782a0804"
    },
    {
      "sections": [
        "Partner account access for administrators",
        "Guest level access",
        "Administrative level access"
      ],
      "title": "Partner account access for administrators",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "619eaa0ec75341c74c05afc0b888d2cc46d08767",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-account-access-administrators/",
      "published_at": "2022-01-12T03:40:16Z",
      "updated_at": "2021-03-16T10:08:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers the option for partner administrators to access their customers' accounts, subject to the contractual terms of the partnership agreement. These settings are controlled by a New Relic admin. For permissions for non-partner accounts, see Users and roles. Guest level access Guest level access allows administrators to view application data on their customers' accounts. This is particularly useful for troubleshooting customer issues related to performance. Administrative level access Administrative level access, in addition to viewing application data, allows partner administrators to modify the account and subscription terms, and add or remove users from an account. This access level is required for partners who will remotely administer customer accounts using the API or who enable Restricted access on their accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.44244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>account</em> access for administrators",
        "sections": "<em>Partner</em> <em>account</em> access for administrators",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em> offers the option for <em>partner</em> administrators to access their customers&#x27; accounts, subject to the contractual terms of the <em>partnership</em> agreement. These settings are controlled by a <em>New</em> <em>Relic</em> admin. For permissions for non-<em>partner</em> accounts, see Users and roles. Guest level access Guest"
      },
      "id": "603ec86ee7b9d2756c2a07c7"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partnership-accounts-users-subscriptions": [
    {
      "sections": [
        "Intro to Partnership API",
        "Requirements",
        "Customer partnership restrictions",
        "Password requirements",
        "Things you can do",
        "Get started"
      ],
      "title": "Intro to Partnership API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "074cf4e7c590dfa2332284a7b7f394e2f7ba45ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api/",
      "published_at": "2022-01-12T03:40:16Z",
      "updated_at": "2021-11-13T15:06:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Partnership API allows New Relic partners, and New Relic accounts set up as customer partnerships, to manage accounts, users, and subscription-related settings. Requirements The Partnership API can be used by two types of New Relic accounts: partners (managed service providers, resellers) and customer partnerships (larger customers who have been given access to our partnership account structure). These docs are for version 2 of the Partner API. Earlier versions have been deprecated. If you have problems with an older integration, upgrade to version 2. Access to the partnership account structure and the Partnership API requires prior setup and approval by New Relic. Partnership API calls require authentication with both your partnership owner account's REST API key and your Partner ID. Accounts that are genuine New Relic partners (managed service providers, resellers) have no restrictions on using the API. Accounts set up as customer partnerships have restrictions that follow. Customer partnership restrictions If your New Relic organization is set up as a customer partnership, there are some restrictions in place if your organization is on our newer pricing model or our newer user model. Details: Pricing plan. If you’re on New Relic One pricing, you can't use API calls that govern our original pricing model. The API impacts are: You can't use the subscription object You can't use the NerdGraph Provisioning API. User model. If your New Relic account has been converted to be entirely on the New Relic One user model, you can no longer use API calls that create or govern users on our original user model. The API impacts are: You can't use the user object. Instead, you'd manage users with these user management docs. For the account object: you can't add users via the users field. Instead, you'd manage users with these user management docs. To determine your pricing model or user model, see Overview of pricing and user model changes. Password requirements Passwords passed for account creation have these requirements: 8 to 50 characters in length Only contain letters, numbers, or special characters Cannot contain spaces Must contain at least 1 letter Must contain at least 1 number or special character Things you can do Here is an overview of the API's functionality. Account: The account object is what you use to create and update accounts. You can do the following with it: Create new Show Update Cancel Show usage Set primary admin (some accounts) Set subscription (some accounts) There is also a child account object for creating child accounts. Users: Some organizations that meet the requirements can use the user object to: Add user access to account Remove user access from account Subscription: Organizations that meet the requirements and are on our original product pricing model can use the subscription object to configure various subscription-related traits. Get started To start using the Partnership API, see the Partner API reference docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.15797,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>Partnership</em> API",
        "sections": "Intro to <em>Partnership</em> API",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": ") and customer <em>partnerships</em> (larger customers who have been given access to our <em>partnership</em> <em>account</em> structure). These docs are for version 2 of the <em>Partner</em> API. Earlier versions have been deprecated. If you have problems with an older <em>integration</em>, upgrade to version 2. Access to the <em>partnership</em> <em>account</em>"
      },
      "id": "603ed42328ccbcd4b3eba7ca"
    },
    {
      "sections": [
        "Restricted access partnerships",
        "Limitations",
        "Account settings",
        "License key",
        "Direct login",
        "Restricted access URLs",
        "Enabling restricted access"
      ],
      "title": "Restricted access partnerships",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "76413b7966350501a506e3e24df99269e2131848",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/restricted-access-partnerships/",
      "published_at": "2022-01-12T05:52:25Z",
      "updated_at": "2021-10-31T16:24:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Partners who implement Single Sign On have the option to enable restricted account access by requiring their customers to access New Relic via their own management application. New Relic recommends that partners who want to manage their customers' accounts directly enable this option. This option is also recommended for partners with reseller agreements. Limitations Partners who implement restricted access are responsible for providing customers with a means for upgrading, administrating, adding and removing users, etc., through the partner's product or interface. Customers who purchase New Relic subscriptions directly from New Relic are not subject to these restrictions. When a partnership enables restricted access, its accounts are subject to the following limitations: Account settings License key Direct login Account settings Customers are not allowed to access any pages in New Relic's Account settings. This prevents customers from modifying the account, changing the subscription level, viewing billing information, and adding or removing users from within New Relic. License key Customers will not be able to access their license key or download their customized newrelic.yml file on the New Relic site. If customers have applications deployed elsewhere, this helps to prevent them from reporting to their partnership accounts in New Relic. Direct login Customers may not directly log in to New Relic to access their associated partner's accounts. Account access is provided solely using SSO and controlled via the partner's website. Restricted access URLs If you elect to enable restricted partnership access, specify the following URLs in the Partnership Console: URL Description Redirect URL Enter your login page for this field. If your customers try to directly log in to the New Relic site, they will be redirected to your login page. Change subscription URL When your customers select the New Relic Subscription option, they will be redirected to the URL that you specify here. Feature unavailable URL When your customers select premium New Relic features, they will be redirected to the URL that you specify here. Logout URL When your customers log out of a New Relic session, they are redirected to this page rather than the New Relic logout page. This option works with restricted access partnerships only. Enabling restricted access Restricted access settings are controlled by New Relic. To arrange changes to your partnership's restricted access settings, contact New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.49251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Restricted access <em>partnerships</em>",
        "sections": "Restricted access <em>partnerships</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " on the <em>New</em> <em>Relic</em> site. If customers have applications deployed elsewhere, this helps to prevent them from reporting to their <em>partnership</em> accounts in <em>New</em> <em>Relic</em>. Direct login Customers may not directly log in to <em>New</em> <em>Relic</em> to access their associated <em>partner</em>&#x27;s accounts. <em>Account</em> access is provided"
      },
      "id": "60441786e7b9d285595799b2"
    },
    {
      "sections": [
        "Partner account access for administrators",
        "Guest level access",
        "Administrative level access"
      ],
      "title": "Partner account access for administrators",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "619eaa0ec75341c74c05afc0b888d2cc46d08767",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-account-access-administrators/",
      "published_at": "2022-01-12T03:40:16Z",
      "updated_at": "2021-03-16T10:08:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers the option for partner administrators to access their customers' accounts, subject to the contractual terms of the partnership agreement. These settings are controlled by a New Relic admin. For permissions for non-partner accounts, see Users and roles. Guest level access Guest level access allows administrators to view application data on their customers' accounts. This is particularly useful for troubleshooting customer issues related to performance. Administrative level access Administrative level access, in addition to viewing application data, allows partner administrators to modify the account and subscription terms, and add or remove users from an account. This access level is required for partners who will remotely administer customer accounts using the API or who enable Restricted access on their accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.44244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>account</em> access for administrators",
        "sections": "<em>Partner</em> <em>account</em> access for administrators",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em> offers the option for <em>partner</em> administrators to access their customers&#x27; accounts, subject to the contractual terms of the <em>partnership</em> agreement. These settings are controlled by a <em>New</em> <em>Relic</em> admin. For permissions for non-<em>partner</em> accounts, see Users and roles. Guest level access Guest"
      },
      "id": "603ec86ee7b9d2756c2a07c7"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/restricted-access-partnerships": [
    {
      "sections": [
        "Intro to Partnership API",
        "Requirements",
        "Customer partnership restrictions",
        "Password requirements",
        "Things you can do",
        "Get started"
      ],
      "title": "Intro to Partnership API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "074cf4e7c590dfa2332284a7b7f394e2f7ba45ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api/",
      "published_at": "2022-01-12T03:40:16Z",
      "updated_at": "2021-11-13T15:06:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Partnership API allows New Relic partners, and New Relic accounts set up as customer partnerships, to manage accounts, users, and subscription-related settings. Requirements The Partnership API can be used by two types of New Relic accounts: partners (managed service providers, resellers) and customer partnerships (larger customers who have been given access to our partnership account structure). These docs are for version 2 of the Partner API. Earlier versions have been deprecated. If you have problems with an older integration, upgrade to version 2. Access to the partnership account structure and the Partnership API requires prior setup and approval by New Relic. Partnership API calls require authentication with both your partnership owner account's REST API key and your Partner ID. Accounts that are genuine New Relic partners (managed service providers, resellers) have no restrictions on using the API. Accounts set up as customer partnerships have restrictions that follow. Customer partnership restrictions If your New Relic organization is set up as a customer partnership, there are some restrictions in place if your organization is on our newer pricing model or our newer user model. Details: Pricing plan. If you’re on New Relic One pricing, you can't use API calls that govern our original pricing model. The API impacts are: You can't use the subscription object You can't use the NerdGraph Provisioning API. User model. If your New Relic account has been converted to be entirely on the New Relic One user model, you can no longer use API calls that create or govern users on our original user model. The API impacts are: You can't use the user object. Instead, you'd manage users with these user management docs. For the account object: you can't add users via the users field. Instead, you'd manage users with these user management docs. To determine your pricing model or user model, see Overview of pricing and user model changes. Password requirements Passwords passed for account creation have these requirements: 8 to 50 characters in length Only contain letters, numbers, or special characters Cannot contain spaces Must contain at least 1 letter Must contain at least 1 number or special character Things you can do Here is an overview of the API's functionality. Account: The account object is what you use to create and update accounts. You can do the following with it: Create new Show Update Cancel Show usage Set primary admin (some accounts) Set subscription (some accounts) There is also a child account object for creating child accounts. Users: Some organizations that meet the requirements can use the user object to: Add user access to account Remove user access from account Subscription: Organizations that meet the requirements and are on our original product pricing model can use the subscription object to configure various subscription-related traits. Get started To start using the Partnership API, see the Partner API reference docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.15797,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>Partnership</em> API",
        "sections": "Intro to <em>Partnership</em> API",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": ") and customer <em>partnerships</em> (larger customers who have been given access to our <em>partnership</em> <em>account</em> structure). These docs are for version 2 of the <em>Partner</em> API. Earlier versions have been deprecated. If you have problems with an older <em>integration</em>, upgrade to version 2. Access to the <em>partnership</em> <em>account</em>"
      },
      "id": "603ed42328ccbcd4b3eba7ca"
    },
    {
      "sections": [
        "Partnership accounts, users, and subscriptions",
        "Partnerships with New Relic",
        "Account hierarchy",
        "Tip",
        "Partnership owner accounts (POA)",
        "Child accounts with partnerships",
        "Account users",
        "Partnership pricing"
      ],
      "title": "Partnership accounts, users, and subscriptions",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ae2f39a8ff0395815b3e31a9d8ad9361beca2c4e",
      "image": "https://docs.newrelic.com/static/7280d9af3c35c6eac85c43c7034ae789/db3a5/partnership-hierarchy.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partnership-accounts-users-subscriptions/",
      "published_at": "2022-01-12T05:52:19Z",
      "updated_at": "2021-07-02T15:20:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic organizations set up as partnership accounts have access to an enhanced hierarchical way of organizing their account structure. Partnerships with New Relic There are two types of New Relic organizations that are able to use our partnership account structure and the Partnership API: An actual partnership: A partnership refers to managed service providers or resellers, who offer New Relic products to their customers. Heroku is one example of such a New Relic partner. A customer partnership: some of our larger organizations also make use of our partnership account structure. We call these customers \"customer partnerships.\" Use of our partnership account structure requires prior approval and set up by New Relic representatives. For customer partnerships, New Relic contacts organizations that would benefit from such a structure. Partnerships are identified by a numeric PARTNER_ID. In some cases, a New Relic customer may have more than one partnership; for example, when one section of New Relic users must be managed differently from another. Partnerships are administered by a partnership owner account. The account that owns a partnership functions differently from a regular account. If multiple partnerships have been set up, each has a unique PARTNER_ID. Account hierarchy New Relic partnership organizations consist of the partnership owning account, partnerships, parent accounts, and child accounts. A partnership can have multiple parent and child accounts. To understand how child accounts and parent accounts scale with EU region accounts, see EU region account hierarchy. Tip If you don't have a partnership organization, you can only have one parent account. For more information, see Manage apps or users with child accounts. All parent and child accounts roll up to your partnership account. Partnership owner accounts (POA) The partnership owner account (POA) is the entity that is used to administer a partnership. It controls which users manage accounts under partnerships, have access to the partner API, and manage other aspects of the partnership. Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership and monitor apps from that account. Users on the partnership owner account can access accounts under their partnerships and enjoy User level privileges. Admins on the POA can access accounts under their partnerships and enjoy Admin level privileges, including permission to manage users. The Owner of the partnership owner account will still only have Admin level access on accounts under the partnership. That means that the owner cannot enable SAML SSO, change the account owner, cancel the account via the UI, etc. The partnership owner account enjoys special privileges, and it lets you exercise the capabilities defined in your partnership agreement with New Relic. For example, you may use your partnership owner account with the New Relic Partnership API to set up and manage users on your accounts or to view your customers' performance data in the New Relic UI. Tip Many of the Partnership API calls return an account status as part of the XML. Child accounts with partnerships Child accounts behave differently than other New Relic accounts provisioned through your partnership: Child accounts Comments Account creation Child accounts can be created through the Partnership API or New Relic user interface. In order to group accounts through the New Relic user interface, your partnership must have Admin privileges, and the account must have the appropriate subscription level. If you have any questions about partnership privileges or subscription levels, contact your New Relic account representative. Child accounts do not have a New Relic subscription of their own. They inherit the parent account's subscription. Billing Billing is applied at the parent account level. Exception: Reseller partnerships receive consolidated billing for all accounts under the partnership. Permissions Admin-level users on a parent account have the ability to create, modify, and delete children accounts for the parent account. Users that have been granted access permissions on a parent account automatically inherit the same level of access for all children accounts. This is also true for add-on roles. Exception: Child account users won't receive alert emails or weekly report emails unless they are explicitly granted permission on these child accounts. Account users You can use the Partnership user API to add and maintain your customer users. An account must always have at least one person (the Owner) associated with it. For security purposes, you cannot change an account Owner with the Partnership user API. Instead, you must change the account Owner from the Users page in the New Relic UI. In addition, a specific user may be associated with multiple accounts. For example, many New Relic users have accounts through a partnership, and they also have accounts they created directly with New Relic. Partnership pricing Accounts within a partnership organization may have different levels of access to New Relic products. Tip Many of the Partnership API calls return a subscription status as part of the XML. For accounts set up through a partnership: An account can have multiple New Relic products associated with it. However, only one subscription per product may be active at any time. For example, a user may have both an Essentials subscription and a higher service level Pro Trial subscription. When the Pro Trial subscription expires, the service level returns to the Essentials subscription. Promotions may appear as a subscription change. Several factors affect starting and stopping subscriptions, including how New Relic handles pricing and billing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.84935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>accounts</em>, users, and subscriptions",
        "sections": "<em>Partnerships</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " these customers &quot;customer <em>partnerships</em>.&quot; Use of our <em>partnership</em> <em>account</em> structure requires prior approval and set up by <em>New</em> <em>Relic</em> representatives. For customer <em>partnerships</em>, <em>New</em> <em>Relic</em> contacts organizations that would benefit from such a structure. <em>Partnerships</em> are identified by a numeric <em>PARTNER</em>"
      },
      "id": "603ece55e7b9d273782a0804"
    },
    {
      "sections": [
        "Partner account access for administrators",
        "Guest level access",
        "Administrative level access"
      ],
      "title": "Partner account access for administrators",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "619eaa0ec75341c74c05afc0b888d2cc46d08767",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-account-access-administrators/",
      "published_at": "2022-01-12T03:40:16Z",
      "updated_at": "2021-03-16T10:08:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers the option for partner administrators to access their customers' accounts, subject to the contractual terms of the partnership agreement. These settings are controlled by a New Relic admin. For permissions for non-partner accounts, see Users and roles. Guest level access Guest level access allows administrators to view application data on their customers' accounts. This is particularly useful for troubleshooting customer issues related to performance. Administrative level access Administrative level access, in addition to viewing application data, allows partner administrators to modify the account and subscription terms, and add or remove users from an account. This access level is required for partners who will remotely administer customer accounts using the API or who enable Restricted access on their accounts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.44244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partner</em> <em>account</em> access for administrators",
        "sections": "<em>Partner</em> <em>account</em> access for administrators",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em> offers the option for <em>partner</em> administrators to access their customers&#x27; accounts, subject to the contractual terms of the <em>partnership</em> agreement. These settings are controlled by a <em>New</em> <em>Relic</em> admin. For permissions for non-<em>partner</em> accounts, see Users and roles. Guest level access Guest"
      },
      "id": "603ec86ee7b9d2756c2a07c7"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/staging-production": [
    {
      "sections": [
        "Intro to Partnership API",
        "Requirements",
        "Customer partnership restrictions",
        "Password requirements",
        "Things you can do",
        "Get started"
      ],
      "title": "Intro to Partnership API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "074cf4e7c590dfa2332284a7b7f394e2f7ba45ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api/",
      "published_at": "2022-01-12T03:40:16Z",
      "updated_at": "2021-11-13T15:06:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Partnership API allows New Relic partners, and New Relic accounts set up as customer partnerships, to manage accounts, users, and subscription-related settings. Requirements The Partnership API can be used by two types of New Relic accounts: partners (managed service providers, resellers) and customer partnerships (larger customers who have been given access to our partnership account structure). These docs are for version 2 of the Partner API. Earlier versions have been deprecated. If you have problems with an older integration, upgrade to version 2. Access to the partnership account structure and the Partnership API requires prior setup and approval by New Relic. Partnership API calls require authentication with both your partnership owner account's REST API key and your Partner ID. Accounts that are genuine New Relic partners (managed service providers, resellers) have no restrictions on using the API. Accounts set up as customer partnerships have restrictions that follow. Customer partnership restrictions If your New Relic organization is set up as a customer partnership, there are some restrictions in place if your organization is on our newer pricing model or our newer user model. Details: Pricing plan. If you’re on New Relic One pricing, you can't use API calls that govern our original pricing model. The API impacts are: You can't use the subscription object You can't use the NerdGraph Provisioning API. User model. If your New Relic account has been converted to be entirely on the New Relic One user model, you can no longer use API calls that create or govern users on our original user model. The API impacts are: You can't use the user object. Instead, you'd manage users with these user management docs. For the account object: you can't add users via the users field. Instead, you'd manage users with these user management docs. To determine your pricing model or user model, see Overview of pricing and user model changes. Password requirements Passwords passed for account creation have these requirements: 8 to 50 characters in length Only contain letters, numbers, or special characters Cannot contain spaces Must contain at least 1 letter Must contain at least 1 number or special character Things you can do Here is an overview of the API's functionality. Account: The account object is what you use to create and update accounts. You can do the following with it: Create new Show Update Cancel Show usage Set primary admin (some accounts) Set subscription (some accounts) There is also a child account object for creating child accounts. Users: Some organizations that meet the requirements can use the user object to: Add user access to account Remove user access from account Subscription: Organizations that meet the requirements and are on our original product pricing model can use the subscription object to configure various subscription-related traits. Get started To start using the Partnership API, see the Partner API reference docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.15796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>Partnership</em> API",
        "sections": "Intro to <em>Partnership</em> API",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": ") and customer <em>partnerships</em> (larger customers who have been given access to our <em>partnership</em> <em>account</em> structure). These docs are for version 2 of the <em>Partner</em> API. Earlier versions have been deprecated. If you have problems with an older <em>integration</em>, upgrade to version 2. Access to the <em>partnership</em> <em>account</em>"
      },
      "id": "603ed42328ccbcd4b3eba7ca"
    },
    {
      "sections": [
        "Restricted access partnerships",
        "Limitations",
        "Account settings",
        "License key",
        "Direct login",
        "Restricted access URLs",
        "Enabling restricted access"
      ],
      "title": "Restricted access partnerships",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "76413b7966350501a506e3e24df99269e2131848",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/restricted-access-partnerships/",
      "published_at": "2022-01-12T05:52:25Z",
      "updated_at": "2021-10-31T16:24:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Partners who implement Single Sign On have the option to enable restricted account access by requiring their customers to access New Relic via their own management application. New Relic recommends that partners who want to manage their customers' accounts directly enable this option. This option is also recommended for partners with reseller agreements. Limitations Partners who implement restricted access are responsible for providing customers with a means for upgrading, administrating, adding and removing users, etc., through the partner's product or interface. Customers who purchase New Relic subscriptions directly from New Relic are not subject to these restrictions. When a partnership enables restricted access, its accounts are subject to the following limitations: Account settings License key Direct login Account settings Customers are not allowed to access any pages in New Relic's Account settings. This prevents customers from modifying the account, changing the subscription level, viewing billing information, and adding or removing users from within New Relic. License key Customers will not be able to access their license key or download their customized newrelic.yml file on the New Relic site. If customers have applications deployed elsewhere, this helps to prevent them from reporting to their partnership accounts in New Relic. Direct login Customers may not directly log in to New Relic to access their associated partner's accounts. Account access is provided solely using SSO and controlled via the partner's website. Restricted access URLs If you elect to enable restricted partnership access, specify the following URLs in the Partnership Console: URL Description Redirect URL Enter your login page for this field. If your customers try to directly log in to the New Relic site, they will be redirected to your login page. Change subscription URL When your customers select the New Relic Subscription option, they will be redirected to the URL that you specify here. Feature unavailable URL When your customers select premium New Relic features, they will be redirected to the URL that you specify here. Logout URL When your customers log out of a New Relic session, they are redirected to this page rather than the New Relic logout page. This option works with restricted access partnerships only. Enabling restricted access Restricted access settings are controlled by New Relic. To arrange changes to your partnership's restricted access settings, contact New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.49251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Restricted access <em>partnerships</em>",
        "sections": "Restricted access <em>partnerships</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " on the <em>New</em> <em>Relic</em> site. If customers have applications deployed elsewhere, this helps to prevent them from reporting to their <em>partnership</em> accounts in <em>New</em> <em>Relic</em>. Direct login Customers may not directly log in to <em>New</em> <em>Relic</em> to access their associated <em>partner</em>&#x27;s accounts. <em>Account</em> access is provided"
      },
      "id": "60441786e7b9d285595799b2"
    },
    {
      "sections": [
        "Partnership accounts, users, and subscriptions",
        "Partnerships with New Relic",
        "Account hierarchy",
        "Tip",
        "Partnership owner accounts (POA)",
        "Child accounts with partnerships",
        "Account users",
        "Partnership pricing"
      ],
      "title": "Partnership accounts, users, and subscriptions",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ae2f39a8ff0395815b3e31a9d8ad9361beca2c4e",
      "image": "https://docs.newrelic.com/static/7280d9af3c35c6eac85c43c7034ae789/db3a5/partnership-hierarchy.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partnership-accounts-users-subscriptions/",
      "published_at": "2022-01-12T05:52:19Z",
      "updated_at": "2021-07-02T15:20:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic organizations set up as partnership accounts have access to an enhanced hierarchical way of organizing their account structure. Partnerships with New Relic There are two types of New Relic organizations that are able to use our partnership account structure and the Partnership API: An actual partnership: A partnership refers to managed service providers or resellers, who offer New Relic products to their customers. Heroku is one example of such a New Relic partner. A customer partnership: some of our larger organizations also make use of our partnership account structure. We call these customers \"customer partnerships.\" Use of our partnership account structure requires prior approval and set up by New Relic representatives. For customer partnerships, New Relic contacts organizations that would benefit from such a structure. Partnerships are identified by a numeric PARTNER_ID. In some cases, a New Relic customer may have more than one partnership; for example, when one section of New Relic users must be managed differently from another. Partnerships are administered by a partnership owner account. The account that owns a partnership functions differently from a regular account. If multiple partnerships have been set up, each has a unique PARTNER_ID. Account hierarchy New Relic partnership organizations consist of the partnership owning account, partnerships, parent accounts, and child accounts. A partnership can have multiple parent and child accounts. To understand how child accounts and parent accounts scale with EU region accounts, see EU region account hierarchy. Tip If you don't have a partnership organization, you can only have one parent account. For more information, see Manage apps or users with child accounts. All parent and child accounts roll up to your partnership account. Partnership owner accounts (POA) The partnership owner account (POA) is the entity that is used to administer a partnership. It controls which users manage accounts under partnerships, have access to the partner API, and manage other aspects of the partnership. Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership and monitor apps from that account. Users on the partnership owner account can access accounts under their partnerships and enjoy User level privileges. Admins on the POA can access accounts under their partnerships and enjoy Admin level privileges, including permission to manage users. The Owner of the partnership owner account will still only have Admin level access on accounts under the partnership. That means that the owner cannot enable SAML SSO, change the account owner, cancel the account via the UI, etc. The partnership owner account enjoys special privileges, and it lets you exercise the capabilities defined in your partnership agreement with New Relic. For example, you may use your partnership owner account with the New Relic Partnership API to set up and manage users on your accounts or to view your customers' performance data in the New Relic UI. Tip Many of the Partnership API calls return an account status as part of the XML. Child accounts with partnerships Child accounts behave differently than other New Relic accounts provisioned through your partnership: Child accounts Comments Account creation Child accounts can be created through the Partnership API or New Relic user interface. In order to group accounts through the New Relic user interface, your partnership must have Admin privileges, and the account must have the appropriate subscription level. If you have any questions about partnership privileges or subscription levels, contact your New Relic account representative. Child accounts do not have a New Relic subscription of their own. They inherit the parent account's subscription. Billing Billing is applied at the parent account level. Exception: Reseller partnerships receive consolidated billing for all accounts under the partnership. Permissions Admin-level users on a parent account have the ability to create, modify, and delete children accounts for the parent account. Users that have been granted access permissions on a parent account automatically inherit the same level of access for all children accounts. This is also true for add-on roles. Exception: Child account users won't receive alert emails or weekly report emails unless they are explicitly granted permission on these child accounts. Account users You can use the Partnership user API to add and maintain your customer users. An account must always have at least one person (the Owner) associated with it. For security purposes, you cannot change an account Owner with the Partnership user API. Instead, you must change the account Owner from the Users page in the New Relic UI. In addition, a specific user may be associated with multiple accounts. For example, many New Relic users have accounts through a partnership, and they also have accounts they created directly with New Relic. Partnership pricing Accounts within a partnership organization may have different levels of access to New Relic products. Tip Many of the Partnership API calls return a subscription status as part of the XML. For accounts set up through a partnership: An account can have multiple New Relic products associated with it. However, only one subscription per product may be active at any time. For example, a user may have both an Essentials subscription and a higher service level Pro Trial subscription. When the Pro Trial subscription expires, the service level returns to the Essentials subscription. Promotions may appear as a subscription change. Several factors affect starting and stopping subscriptions, including how New Relic handles pricing and billing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.84935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>accounts</em>, users, and subscriptions",
        "sections": "<em>Partnerships</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " these customers &quot;customer <em>partnerships</em>.&quot; Use of our <em>partnership</em> <em>account</em> structure requires prior approval and set up by <em>New</em> <em>Relic</em> representatives. For customer <em>partnerships</em>, <em>New</em> <em>Relic</em> contacts organizations that would benefit from such a structure. <em>Partnerships</em> are identified by a numeric <em>PARTNER</em>"
      },
      "id": "603ece55e7b9d273782a0804"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/tips-tricks": [
    {
      "sections": [
        "Intro to Partnership API",
        "Requirements",
        "Customer partnership restrictions",
        "Password requirements",
        "Things you can do",
        "Get started"
      ],
      "title": "Intro to Partnership API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "074cf4e7c590dfa2332284a7b7f394e2f7ba45ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api/",
      "published_at": "2022-01-12T03:40:16Z",
      "updated_at": "2021-11-13T15:06:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Partnership API allows New Relic partners, and New Relic accounts set up as customer partnerships, to manage accounts, users, and subscription-related settings. Requirements The Partnership API can be used by two types of New Relic accounts: partners (managed service providers, resellers) and customer partnerships (larger customers who have been given access to our partnership account structure). These docs are for version 2 of the Partner API. Earlier versions have been deprecated. If you have problems with an older integration, upgrade to version 2. Access to the partnership account structure and the Partnership API requires prior setup and approval by New Relic. Partnership API calls require authentication with both your partnership owner account's REST API key and your Partner ID. Accounts that are genuine New Relic partners (managed service providers, resellers) have no restrictions on using the API. Accounts set up as customer partnerships have restrictions that follow. Customer partnership restrictions If your New Relic organization is set up as a customer partnership, there are some restrictions in place if your organization is on our newer pricing model or our newer user model. Details: Pricing plan. If you’re on New Relic One pricing, you can't use API calls that govern our original pricing model. The API impacts are: You can't use the subscription object You can't use the NerdGraph Provisioning API. User model. If your New Relic account has been converted to be entirely on the New Relic One user model, you can no longer use API calls that create or govern users on our original user model. The API impacts are: You can't use the user object. Instead, you'd manage users with these user management docs. For the account object: you can't add users via the users field. Instead, you'd manage users with these user management docs. To determine your pricing model or user model, see Overview of pricing and user model changes. Password requirements Passwords passed for account creation have these requirements: 8 to 50 characters in length Only contain letters, numbers, or special characters Cannot contain spaces Must contain at least 1 letter Must contain at least 1 number or special character Things you can do Here is an overview of the API's functionality. Account: The account object is what you use to create and update accounts. You can do the following with it: Create new Show Update Cancel Show usage Set primary admin (some accounts) Set subscription (some accounts) There is also a child account object for creating child accounts. Users: Some organizations that meet the requirements can use the user object to: Add user access to account Remove user access from account Subscription: Organizations that meet the requirements and are on our original product pricing model can use the subscription object to configure various subscription-related traits. Get started To start using the Partnership API, see the Partner API reference docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.15796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>Partnership</em> API",
        "sections": "Intro to <em>Partnership</em> API",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": ") and customer <em>partnerships</em> (larger customers who have been given access to our <em>partnership</em> <em>account</em> structure). These docs are for version 2 of the <em>Partner</em> API. Earlier versions have been deprecated. If you have problems with an older <em>integration</em>, upgrade to version 2. Access to the <em>partnership</em> <em>account</em>"
      },
      "id": "603ed42328ccbcd4b3eba7ca"
    },
    {
      "sections": [
        "Restricted access partnerships",
        "Limitations",
        "Account settings",
        "License key",
        "Direct login",
        "Restricted access URLs",
        "Enabling restricted access"
      ],
      "title": "Restricted access partnerships",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "76413b7966350501a506e3e24df99269e2131848",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/restricted-access-partnerships/",
      "published_at": "2022-01-12T05:52:25Z",
      "updated_at": "2021-10-31T16:24:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Partners who implement Single Sign On have the option to enable restricted account access by requiring their customers to access New Relic via their own management application. New Relic recommends that partners who want to manage their customers' accounts directly enable this option. This option is also recommended for partners with reseller agreements. Limitations Partners who implement restricted access are responsible for providing customers with a means for upgrading, administrating, adding and removing users, etc., through the partner's product or interface. Customers who purchase New Relic subscriptions directly from New Relic are not subject to these restrictions. When a partnership enables restricted access, its accounts are subject to the following limitations: Account settings License key Direct login Account settings Customers are not allowed to access any pages in New Relic's Account settings. This prevents customers from modifying the account, changing the subscription level, viewing billing information, and adding or removing users from within New Relic. License key Customers will not be able to access their license key or download their customized newrelic.yml file on the New Relic site. If customers have applications deployed elsewhere, this helps to prevent them from reporting to their partnership accounts in New Relic. Direct login Customers may not directly log in to New Relic to access their associated partner's accounts. Account access is provided solely using SSO and controlled via the partner's website. Restricted access URLs If you elect to enable restricted partnership access, specify the following URLs in the Partnership Console: URL Description Redirect URL Enter your login page for this field. If your customers try to directly log in to the New Relic site, they will be redirected to your login page. Change subscription URL When your customers select the New Relic Subscription option, they will be redirected to the URL that you specify here. Feature unavailable URL When your customers select premium New Relic features, they will be redirected to the URL that you specify here. Logout URL When your customers log out of a New Relic session, they are redirected to this page rather than the New Relic logout page. This option works with restricted access partnerships only. Enabling restricted access Restricted access settings are controlled by New Relic. To arrange changes to your partnership's restricted access settings, contact New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.49251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Restricted access <em>partnerships</em>",
        "sections": "Restricted access <em>partnerships</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " on the <em>New</em> <em>Relic</em> site. If customers have applications deployed elsewhere, this helps to prevent them from reporting to their <em>partnership</em> accounts in <em>New</em> <em>Relic</em>. Direct login Customers may not directly log in to <em>New</em> <em>Relic</em> to access their associated <em>partner</em>&#x27;s accounts. <em>Account</em> access is provided"
      },
      "id": "60441786e7b9d285595799b2"
    },
    {
      "sections": [
        "Partnership accounts, users, and subscriptions",
        "Partnerships with New Relic",
        "Account hierarchy",
        "Tip",
        "Partnership owner accounts (POA)",
        "Child accounts with partnerships",
        "Account users",
        "Partnership pricing"
      ],
      "title": "Partnership accounts, users, and subscriptions",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ae2f39a8ff0395815b3e31a9d8ad9361beca2c4e",
      "image": "https://docs.newrelic.com/static/7280d9af3c35c6eac85c43c7034ae789/db3a5/partnership-hierarchy.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partnership-accounts-users-subscriptions/",
      "published_at": "2022-01-12T05:52:19Z",
      "updated_at": "2021-07-02T15:20:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic organizations set up as partnership accounts have access to an enhanced hierarchical way of organizing their account structure. Partnerships with New Relic There are two types of New Relic organizations that are able to use our partnership account structure and the Partnership API: An actual partnership: A partnership refers to managed service providers or resellers, who offer New Relic products to their customers. Heroku is one example of such a New Relic partner. A customer partnership: some of our larger organizations also make use of our partnership account structure. We call these customers \"customer partnerships.\" Use of our partnership account structure requires prior approval and set up by New Relic representatives. For customer partnerships, New Relic contacts organizations that would benefit from such a structure. Partnerships are identified by a numeric PARTNER_ID. In some cases, a New Relic customer may have more than one partnership; for example, when one section of New Relic users must be managed differently from another. Partnerships are administered by a partnership owner account. The account that owns a partnership functions differently from a regular account. If multiple partnerships have been set up, each has a unique PARTNER_ID. Account hierarchy New Relic partnership organizations consist of the partnership owning account, partnerships, parent accounts, and child accounts. A partnership can have multiple parent and child accounts. To understand how child accounts and parent accounts scale with EU region accounts, see EU region account hierarchy. Tip If you don't have a partnership organization, you can only have one parent account. For more information, see Manage apps or users with child accounts. All parent and child accounts roll up to your partnership account. Partnership owner accounts (POA) The partnership owner account (POA) is the entity that is used to administer a partnership. It controls which users manage accounts under partnerships, have access to the partner API, and manage other aspects of the partnership. Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership and monitor apps from that account. Users on the partnership owner account can access accounts under their partnerships and enjoy User level privileges. Admins on the POA can access accounts under their partnerships and enjoy Admin level privileges, including permission to manage users. The Owner of the partnership owner account will still only have Admin level access on accounts under the partnership. That means that the owner cannot enable SAML SSO, change the account owner, cancel the account via the UI, etc. The partnership owner account enjoys special privileges, and it lets you exercise the capabilities defined in your partnership agreement with New Relic. For example, you may use your partnership owner account with the New Relic Partnership API to set up and manage users on your accounts or to view your customers' performance data in the New Relic UI. Tip Many of the Partnership API calls return an account status as part of the XML. Child accounts with partnerships Child accounts behave differently than other New Relic accounts provisioned through your partnership: Child accounts Comments Account creation Child accounts can be created through the Partnership API or New Relic user interface. In order to group accounts through the New Relic user interface, your partnership must have Admin privileges, and the account must have the appropriate subscription level. If you have any questions about partnership privileges or subscription levels, contact your New Relic account representative. Child accounts do not have a New Relic subscription of their own. They inherit the parent account's subscription. Billing Billing is applied at the parent account level. Exception: Reseller partnerships receive consolidated billing for all accounts under the partnership. Permissions Admin-level users on a parent account have the ability to create, modify, and delete children accounts for the parent account. Users that have been granted access permissions on a parent account automatically inherit the same level of access for all children accounts. This is also true for add-on roles. Exception: Child account users won't receive alert emails or weekly report emails unless they are explicitly granted permission on these child accounts. Account users You can use the Partnership user API to add and maintain your customer users. An account must always have at least one person (the Owner) associated with it. For security purposes, you cannot change an account Owner with the Partnership user API. Instead, you must change the account Owner from the Users page in the New Relic UI. In addition, a specific user may be associated with multiple accounts. For example, many New Relic users have accounts through a partnership, and they also have accounts they created directly with New Relic. Partnership pricing Accounts within a partnership organization may have different levels of access to New Relic products. Tip Many of the Partnership API calls return a subscription status as part of the XML. For accounts set up through a partnership: An account can have multiple New Relic products associated with it. However, only one subscription per product may be active at any time. For example, a user may have both an Essentials subscription and a higher service level Pro Trial subscription. When the Pro Trial subscription expires, the service level returns to the Essentials subscription. Promotions may appear as a subscription change. Several factors affect starting and stopping subscriptions, including how New Relic handles pricing and billing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.84935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>accounts</em>, users, and subscriptions",
        "sections": "<em>Partnerships</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " these customers &quot;customer <em>partnerships</em>.&quot; Use of our <em>partnership</em> <em>account</em> structure requires prior approval and set up by <em>New</em> <em>Relic</em> representatives. For customer <em>partnerships</em>, <em>New</em> <em>Relic</em> contacts organizations that would benefit from such a structure. <em>Partnerships</em> are identified by a numeric <em>PARTNER</em>"
      },
      "id": "603ece55e7b9d273782a0804"
    }
  ],
  "/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/welcome-messages-partnerships": [
    {
      "sections": [
        "Intro to Partnership API",
        "Requirements",
        "Customer partnership restrictions",
        "Password requirements",
        "Things you can do",
        "Get started"
      ],
      "title": "Intro to Partnership API",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "074cf4e7c590dfa2332284a7b7f394e2f7ba45ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partner-api/",
      "published_at": "2022-01-12T03:40:16Z",
      "updated_at": "2021-11-13T15:06:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Partnership API allows New Relic partners, and New Relic accounts set up as customer partnerships, to manage accounts, users, and subscription-related settings. Requirements The Partnership API can be used by two types of New Relic accounts: partners (managed service providers, resellers) and customer partnerships (larger customers who have been given access to our partnership account structure). These docs are for version 2 of the Partner API. Earlier versions have been deprecated. If you have problems with an older integration, upgrade to version 2. Access to the partnership account structure and the Partnership API requires prior setup and approval by New Relic. Partnership API calls require authentication with both your partnership owner account's REST API key and your Partner ID. Accounts that are genuine New Relic partners (managed service providers, resellers) have no restrictions on using the API. Accounts set up as customer partnerships have restrictions that follow. Customer partnership restrictions If your New Relic organization is set up as a customer partnership, there are some restrictions in place if your organization is on our newer pricing model or our newer user model. Details: Pricing plan. If you’re on New Relic One pricing, you can't use API calls that govern our original pricing model. The API impacts are: You can't use the subscription object You can't use the NerdGraph Provisioning API. User model. If your New Relic account has been converted to be entirely on the New Relic One user model, you can no longer use API calls that create or govern users on our original user model. The API impacts are: You can't use the user object. Instead, you'd manage users with these user management docs. For the account object: you can't add users via the users field. Instead, you'd manage users with these user management docs. To determine your pricing model or user model, see Overview of pricing and user model changes. Password requirements Passwords passed for account creation have these requirements: 8 to 50 characters in length Only contain letters, numbers, or special characters Cannot contain spaces Must contain at least 1 letter Must contain at least 1 number or special character Things you can do Here is an overview of the API's functionality. Account: The account object is what you use to create and update accounts. You can do the following with it: Create new Show Update Cancel Show usage Set primary admin (some accounts) Set subscription (some accounts) There is also a child account object for creating child accounts. Users: Some organizations that meet the requirements can use the user object to: Add user access to account Remove user access from account Subscription: Organizations that meet the requirements and are on our original product pricing model can use the subscription object to configure various subscription-related traits. Get started To start using the Partnership API, see the Partner API reference docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.15796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to <em>Partnership</em> API",
        "sections": "Intro to <em>Partnership</em> API",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": ") and customer <em>partnerships</em> (larger customers who have been given access to our <em>partnership</em> <em>account</em> structure). These docs are for version 2 of the <em>Partner</em> API. Earlier versions have been deprecated. If you have problems with an older <em>integration</em>, upgrade to version 2. Access to the <em>partnership</em> <em>account</em>"
      },
      "id": "603ed42328ccbcd4b3eba7ca"
    },
    {
      "sections": [
        "Restricted access partnerships",
        "Limitations",
        "Account settings",
        "License key",
        "Direct login",
        "Restricted access URLs",
        "Enabling restricted access"
      ],
      "title": "Restricted access partnerships",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "76413b7966350501a506e3e24df99269e2131848",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/restricted-access-partnerships/",
      "published_at": "2022-01-12T05:52:25Z",
      "updated_at": "2021-10-31T16:24:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Partners who implement Single Sign On have the option to enable restricted account access by requiring their customers to access New Relic via their own management application. New Relic recommends that partners who want to manage their customers' accounts directly enable this option. This option is also recommended for partners with reseller agreements. Limitations Partners who implement restricted access are responsible for providing customers with a means for upgrading, administrating, adding and removing users, etc., through the partner's product or interface. Customers who purchase New Relic subscriptions directly from New Relic are not subject to these restrictions. When a partnership enables restricted access, its accounts are subject to the following limitations: Account settings License key Direct login Account settings Customers are not allowed to access any pages in New Relic's Account settings. This prevents customers from modifying the account, changing the subscription level, viewing billing information, and adding or removing users from within New Relic. License key Customers will not be able to access their license key or download their customized newrelic.yml file on the New Relic site. If customers have applications deployed elsewhere, this helps to prevent them from reporting to their partnership accounts in New Relic. Direct login Customers may not directly log in to New Relic to access their associated partner's accounts. Account access is provided solely using SSO and controlled via the partner's website. Restricted access URLs If you elect to enable restricted partnership access, specify the following URLs in the Partnership Console: URL Description Redirect URL Enter your login page for this field. If your customers try to directly log in to the New Relic site, they will be redirected to your login page. Change subscription URL When your customers select the New Relic Subscription option, they will be redirected to the URL that you specify here. Feature unavailable URL When your customers select premium New Relic features, they will be redirected to the URL that you specify here. Logout URL When your customers log out of a New Relic session, they are redirected to this page rather than the New Relic logout page. This option works with restricted access partnerships only. Enabling restricted access Restricted access settings are controlled by New Relic. To arrange changes to your partnership's restricted access settings, contact New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.49251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Restricted access <em>partnerships</em>",
        "sections": "Restricted access <em>partnerships</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " on the <em>New</em> <em>Relic</em> site. If customers have applications deployed elsewhere, this helps to prevent them from reporting to their <em>partnership</em> accounts in <em>New</em> <em>Relic</em>. Direct login Customers may not directly log in to <em>New</em> <em>Relic</em> to access their associated <em>partner</em>&#x27;s accounts. <em>Account</em> access is provided"
      },
      "id": "60441786e7b9d285595799b2"
    },
    {
      "sections": [
        "Partnership accounts, users, and subscriptions",
        "Partnerships with New Relic",
        "Account hierarchy",
        "Tip",
        "Partnership owner accounts (POA)",
        "Child accounts with partnerships",
        "Account users",
        "Partnership pricing"
      ],
      "title": "Partnership accounts, users, and subscriptions",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Partner account maintenance"
      ],
      "external_id": "ae2f39a8ff0395815b3e31a9d8ad9361beca2c4e",
      "image": "https://docs.newrelic.com/static/7280d9af3c35c6eac85c43c7034ae789/db3a5/partnership-hierarchy.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/partner-account-maintenance/partnership-accounts-users-subscriptions/",
      "published_at": "2022-01-12T05:52:19Z",
      "updated_at": "2021-07-02T15:20:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic organizations set up as partnership accounts have access to an enhanced hierarchical way of organizing their account structure. Partnerships with New Relic There are two types of New Relic organizations that are able to use our partnership account structure and the Partnership API: An actual partnership: A partnership refers to managed service providers or resellers, who offer New Relic products to their customers. Heroku is one example of such a New Relic partner. A customer partnership: some of our larger organizations also make use of our partnership account structure. We call these customers \"customer partnerships.\" Use of our partnership account structure requires prior approval and set up by New Relic representatives. For customer partnerships, New Relic contacts organizations that would benefit from such a structure. Partnerships are identified by a numeric PARTNER_ID. In some cases, a New Relic customer may have more than one partnership; for example, when one section of New Relic users must be managed differently from another. Partnerships are administered by a partnership owner account. The account that owns a partnership functions differently from a regular account. If multiple partnerships have been set up, each has a unique PARTNER_ID. Account hierarchy New Relic partnership organizations consist of the partnership owning account, partnerships, parent accounts, and child accounts. A partnership can have multiple parent and child accounts. To understand how child accounts and parent accounts scale with EU region accounts, see EU region account hierarchy. Tip If you don't have a partnership organization, you can only have one parent account. For more information, see Manage apps or users with child accounts. All parent and child accounts roll up to your partnership account. Partnership owner accounts (POA) The partnership owner account (POA) is the entity that is used to administer a partnership. It controls which users manage accounts under partnerships, have access to the partner API, and manage other aspects of the partnership. Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership and monitor apps from that account. Users on the partnership owner account can access accounts under their partnerships and enjoy User level privileges. Admins on the POA can access accounts under their partnerships and enjoy Admin level privileges, including permission to manage users. The Owner of the partnership owner account will still only have Admin level access on accounts under the partnership. That means that the owner cannot enable SAML SSO, change the account owner, cancel the account via the UI, etc. The partnership owner account enjoys special privileges, and it lets you exercise the capabilities defined in your partnership agreement with New Relic. For example, you may use your partnership owner account with the New Relic Partnership API to set up and manage users on your accounts or to view your customers' performance data in the New Relic UI. Tip Many of the Partnership API calls return an account status as part of the XML. Child accounts with partnerships Child accounts behave differently than other New Relic accounts provisioned through your partnership: Child accounts Comments Account creation Child accounts can be created through the Partnership API or New Relic user interface. In order to group accounts through the New Relic user interface, your partnership must have Admin privileges, and the account must have the appropriate subscription level. If you have any questions about partnership privileges or subscription levels, contact your New Relic account representative. Child accounts do not have a New Relic subscription of their own. They inherit the parent account's subscription. Billing Billing is applied at the parent account level. Exception: Reseller partnerships receive consolidated billing for all accounts under the partnership. Permissions Admin-level users on a parent account have the ability to create, modify, and delete children accounts for the parent account. Users that have been granted access permissions on a parent account automatically inherit the same level of access for all children accounts. This is also true for add-on roles. Exception: Child account users won't receive alert emails or weekly report emails unless they are explicitly granted permission on these child accounts. Account users You can use the Partnership user API to add and maintain your customer users. An account must always have at least one person (the Owner) associated with it. For security purposes, you cannot change an account Owner with the Partnership user API. Instead, you must change the account Owner from the Users page in the New Relic UI. In addition, a specific user may be associated with multiple accounts. For example, many New Relic users have accounts through a partnership, and they also have accounts they created directly with New Relic. Partnership pricing Accounts within a partnership organization may have different levels of access to New Relic products. Tip Many of the Partnership API calls return a subscription status as part of the XML. For accounts set up through a partnership: An account can have multiple New Relic products associated with it. However, only one subscription per product may be active at any time. For example, a user may have both an Essentials subscription and a higher service level Pro Trial subscription. When the Pro Trial subscription expires, the service level returns to the Essentials subscription. Promotions may appear as a subscription change. Several factors affect starting and stopping subscriptions, including how New Relic handles pricing and billing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.84935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>accounts</em>, users, and subscriptions",
        "sections": "<em>Partnerships</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " these customers &quot;customer <em>partnerships</em>.&quot; Use of our <em>partnership</em> <em>account</em> structure requires prior approval and set up by <em>New</em> <em>Relic</em> representatives. For customer <em>partnerships</em>, <em>New</em> <em>Relic</em> contacts organizations that would benefit from such a structure. <em>Partnerships</em> are identified by a numeric <em>PARTNER</em>"
      },
      "id": "603ece55e7b9d273782a0804"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/getting-started/partner-marketing": [
    {
      "sections": [
        "Using the Partner Portal"
      ],
      "title": "Using the Partner Portal",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Getting started"
      ],
      "external_id": "2f149ab0c15dadf598fa1833be58caeecb6ed493",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/getting-started/using-partner-portal/",
      "published_at": "2022-01-12T03:41:23Z",
      "updated_at": "2021-10-31T16:26:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides a web portal for partners to easily access valuable resources provided to them by the New Relic Partner Program, such as partner sales enablement content, training, marketing materials, etc. If you are a partner and do not have access to this already, contact your Partner Sales Manager or email partnersales @ newrelic.com. To access the Partner Portal: From your browser, type (or bookmark) the following URL, and then log in with your user name and password. https://partners.newrelic-external.com/English/ Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.97397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "<em>New</em> <em>Relic</em> provides a web portal for partners to easily access valuable resources provided to them by the <em>New</em> <em>Relic</em> Partner Program, such as partner sales enablement content, training, marketing materials, etc. If you are a partner and do not have access to this already, contact your Partner Sales"
      },
      "id": "603ebb3528ccbc63d5eba791"
    },
    {
      "sections": [
        "Typical Partnership integration example",
        "Account creation and value storage",
        "Deploying the agent",
        "Deploying the page widget with SSO"
      ],
      "title": "Typical Partnership integration example",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "491849d6f08b80969013fb1d0c9ce154cbbc2e64",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/typical-integration-example/",
      "published_at": "2022-01-12T05:55:20Z",
      "updated_at": "2021-03-29T21:07:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This provides the step-by-step details of a typical integration using the page widget and SSO. Recommendation: Start new projects by referring to Getting started with API and the New Relic REST API v2 examples. Also, begin migrating any of your API v1 scripts to their v2 equivalent. Account creation and value storage Using the accounts/create endpoint, create an account, subscription and user. From the payload, extract and store the account values. Typically you will create a new table in your accounts database and associate the record containing this information with your user record. The values used in this scenario include data-access-key, id, and license-key. You may want to store additional values. Deploying the agent New Relic highly recommends automatically deploying the agents for your customers if your architecture and choice of languages permit. Our experience is that even the best documented and easiest user deployment of the agent results in only a 75% success rate. Auto-deploying the agent for your customers eliminates this dropout. Whether your intention is to auto-deploy or allow the user to do so, the license key from the account creation payload is required for this operation. If you are planning a manual deploy, it is helpful to make the license key easily available to your users. This is a convenience for your users. The key is available by logging into the account. Deploying the page widget with SSO Using the data access key from the newly created account and the user's email, along with the partnership shared secret and timestamp, create a digest that can be transformed into an SHA-2 hash. The elements are assembled into the widget URL. Note: As a standard security measure for data collection, New Relic requires that your application server supports SHA-2 (256-bit). SHA-1 is not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.37097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Typical <em>Partnership</em> integration example",
        "sections": "Typical <em>Partnership</em> integration example",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This provides the step-by-step details of a typical integration using the page widget and SSO. Recommendation: <em>Start</em> <em>new</em> projects by referring to <em>Getting</em> <em>started</em> with API and the <em>New</em> <em>Relic</em> REST API v2 examples. Also, begin migrating any of your API v1 scripts to their v2 equivalent. Account"
      },
      "id": "603ed3e7e7b9d2e5b52a07c8"
    },
    {
      "sections": [
        "Partnership admin console",
        "Console components",
        "Partnership configuration settings",
        "Customer activity monitoring",
        "State-of-the-Partnership report",
        "Partner customer monitoring",
        "View an arbitrary customer",
        "Viewing detailed customer data"
      ],
      "title": "Partnership admin console",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "670e4d2e1db957100b23a7b8b0af6bf50cc8c996",
      "image": "https://docs.newrelic.com/static/43369c88523ebf526ae58fa5719d4efe/0abdd/crop-partnership-owner-account-settings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-07-02T15:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Partnership Admin Console is the interface for managing your customers' accounts and integration with New Relic. To access the console, sign into the partnership owner account, and go to: https://partner-admin-console.newrelic.com/accounts/ACCOUNT_ID/admin_console/ Copy You can also access the console from the New Relic UI: Go to one.newrelic.com > (account dropdown) > Account settings. From the left menu bar, select Partnerships. one.newrelic.com > (account dropdown) > Account settings > Partnerships: Partnership owners can access the Partnership Admin Console from their account settings in the New Relic UI. Console components The Partnership Admin Console has two main components: Partnership configuration settings Customer activity monitoring If multiple partnerships are associated with the New Relic parent account, the menu also includes an option to switch partnership accounts. Partnership configuration settings In developing your integration with New Relic, you must specify a number of settings. For your convenience these settings are grouped together in the partnership console, including URLs for header/footer and various redirects, SSO configuration, and keys and the ability to manipulate them. Customer activity monitoring New Relic provides you with two tools for managing your customers: State-of-the-Partnership reports and live monitoring of all deployed New Relic agents in your partnership. Both of these tools provide insight into your customers who are using New Relic. They can be used to identify up-sale opportunities or to assist your support group in proactive support. State-of-the-Partnership report The State-of-the-Partnership report provides a summary of your customers with New Relic accounts and their activities. The report is broken down by language of the agents deployed, the agent version and the language version for each account. This report is run weekly for each partner. It is available on request from your New Relic Business Development contact. This report is an excellent way to see which of your customers with New Relic accounts are in fact using the service. Partner customer monitoring The Partner customer monitoring facility provides application performance data on the New Relic enabled applications that are running on your service. This facility allows you to easily identify customers experiencing performance problems. Where the performance problems are caused by under capacity, these customers are excellent sales opportunities. Alternatively your support or services organization will find this information useful in pre-emptively identifying customer issues or as good prospects for consulting services. View an arbitrary customer To view activity of a customer that does not appear in any of the filtered views: Go to one.newrelic.com > (account dropdown) > Switch accounts > Other accounts. New Relic will list all of the reporting accounts in the partnership. You can filter or search the list. Viewing detailed customer data Under normal circumstances a partner will be able to see only the summary level data in a customer's New Relic account. Through the Partnership Admin Console, partners will be permitted to drill down to the more detailed presentation. If you want to drill down from the Partnership Admin Console, add your user (typically support@partner.com or something similar) to the account. Typically this will be done at account creation. Avoid provisioning this user as the account Owner.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.55786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> admin console",
        "sections": "<em>Partnership</em> admin console",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " the console from the <em>New</em> <em>Relic</em> UI: Go to one.newrelic.com &gt; (account dropdown) &gt; Account settings. From the left menu bar, select <em>Partnerships</em>. one.newrelic.com &gt; (account dropdown) &gt; Account settings &gt; <em>Partnerships</em>: <em>Partnership</em> owners can access the <em>Partnership</em> Admin Console from their account settings"
      },
      "id": "603ed3e3196a6735baa83dad"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/getting-started/using-partner-portal": [
    {
      "sections": [
        "Partner marketing",
        "Marketing tools",
        "Marketing activities",
        "Guest blog posts",
        "What's in it for you?",
        "How does it work?",
        "How do you create a great blog post?"
      ],
      "title": "Partner marketing",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Getting started"
      ],
      "external_id": "3c8149518849df6b00f17244aec711aad64f3952",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/getting-started/partner-marketing/",
      "published_at": "2022-01-12T03:40:48Z",
      "updated_at": "2021-08-02T12:01:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic loves to help our partners tell the world about our joint offerings. Here is a non-exhaustive list of marketing activities that we can pull into our co-marketing plan. To proceed with any co-marketing activity or to plan your strategy, email your Business Development rep at New Relic or email partners @ newrelic.com. Marketing tools If you have new ideas that are not listed here, let us know! Marketing tools Description Email template Use New Relic's HTML and/or plain text email templates to send to your customers to introduce them to New Relic. To request templates, email your Business Development rep at New Relic, or email partners @ newrelic.com. Content boilerplate New Relic's content boilerplate has everything you need to create a New Relic page on your website. To request it, email your Business Development rep at New Relic, or email partners @ newrelic.com. Blog content Follow New Relic's guidelines to post on New Relic's blog. Twitter Use sample tweets to promote our partnership, include appropriate links, and mention @newrelic. To request re-tweets, email your Business Development rep at New Relic, or email partners @ newrelic.com. New Relic media assets Get our logo and other materials from New Relic's media assets webpage. To request additional assets, email your Business Development rep at New Relic, or email partners @ newrelic.com. Joint customer case study Identify a joint customer, and work with New Relic to write and publish a joint customer case study. For more information, contact your Business Development rep at New Relic, or email partners @ newrelic.com. Marketing activities If you have new ideas that are not listed here, let us know! Marketing activity Description Social media support Let New Relic help amplify your social media through tweets, retweets, Facebook likes, shares, etc. Event opportunities Participate in local meetups or find out about other events or co-sponsorship opportunities. Webinar Co-host a webinar; for example, see: Three Powerful Tools for Improving the Performance of Your Drupal Site Guest blog posts New Relic loves great blog content, and partners are often an essential source. You're encouraged to write a guest blog post for http://blog.newrelic.com. What's in it for you? It's a great opportunity for you to promote your company and the integration you've built. Our blog is popular reading for the New Relic community, and our customers are frequently among the fastest growing innovators. How does it work? You draft the post and supply screenshots and/or video as applicable. New Relic will edit, format, publish, and promote the post. You'll get credit as the author, and you can include a paragraph at the end mentioning your product. How do you create a great blog post? The goal is to be insightful, useful, thought provoking, smart, surprising, and entertaining—or at least some combination of those elements. Blog post guidelines Comments Writing style Recommendation: Write your blog post in the first person. New Relic's target audience includes developers, DevOps, IT ops, execs, marketers, and data scientists working with big data, but we have no problem attracting a wider readership than that. We want to intrigue them and help them do their jobs better and more passionately. Passion and connection are essential. If you do not care about the topic you are blogging about or, more importantly, you do not appear to care about it, neither will the reader. Length A typical blog post runs approximately 500 words, but it may be longer or shorter if there is a good reason. Technical blog posts may run much longer, while posts with video may not need much text at all. Content Each post should focus on a single main idea. If you have a mashup of multiple ideas, consider breaking them up into a series of multiple, related posts. Posts do not have to be based on the latest news, but they shouldn't pretend that old news is new. If you're writing about something that's not brand new, you need to acknowledge that and come up with a fresh take or new angle. Posts should be fact based, and not mere opinion without a grounding in reality. The magic is in the details. Posts should be grounded in specifics, not just general pronouncements. If you say something is bad, you need to describe why; for example, what can or did happen because of it. Similarly, if you suggest best practices, the more specific examples you provide, the better. Links Links to outside content are encouraged, but just pointing to something on the web is not enough for a post, no matter how interesting the link is. You need to bring something unique to the post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.29077,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " Follow <em>New</em> <em>Relic</em>&#x27;s guidelines to post on <em>New</em> <em>Relic</em>&#x27;s blog. Twitter Use sample tweets to promote our <em>partnership</em>, include appropriate links, and mention @newrelic. To request re-tweets, email your Business Development rep at <em>New</em> <em>Relic</em>, or email partners @ newrelic.com. <em>New</em> <em>Relic</em> media assets <em>Get</em> our"
      },
      "id": "603eb147e7b9d2f0012a07de"
    },
    {
      "sections": [
        "Typical Partnership integration example",
        "Account creation and value storage",
        "Deploying the agent",
        "Deploying the page widget with SSO"
      ],
      "title": "Typical Partnership integration example",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "491849d6f08b80969013fb1d0c9ce154cbbc2e64",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/typical-integration-example/",
      "published_at": "2022-01-12T05:55:20Z",
      "updated_at": "2021-03-29T21:07:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This provides the step-by-step details of a typical integration using the page widget and SSO. Recommendation: Start new projects by referring to Getting started with API and the New Relic REST API v2 examples. Also, begin migrating any of your API v1 scripts to their v2 equivalent. Account creation and value storage Using the accounts/create endpoint, create an account, subscription and user. From the payload, extract and store the account values. Typically you will create a new table in your accounts database and associate the record containing this information with your user record. The values used in this scenario include data-access-key, id, and license-key. You may want to store additional values. Deploying the agent New Relic highly recommends automatically deploying the agents for your customers if your architecture and choice of languages permit. Our experience is that even the best documented and easiest user deployment of the agent results in only a 75% success rate. Auto-deploying the agent for your customers eliminates this dropout. Whether your intention is to auto-deploy or allow the user to do so, the license key from the account creation payload is required for this operation. If you are planning a manual deploy, it is helpful to make the license key easily available to your users. This is a convenience for your users. The key is available by logging into the account. Deploying the page widget with SSO Using the data access key from the newly created account and the user's email, along with the partnership shared secret and timestamp, create a digest that can be transformed into an SHA-2 hash. The elements are assembled into the widget URL. Note: As a standard security measure for data collection, New Relic requires that your application server supports SHA-2 (256-bit). SHA-1 is not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.37097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Typical <em>Partnership</em> integration example",
        "sections": "Typical <em>Partnership</em> integration example",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This provides the step-by-step details of a typical integration using the page widget and SSO. Recommendation: <em>Start</em> <em>new</em> projects by referring to <em>Getting</em> <em>started</em> with API and the <em>New</em> <em>Relic</em> REST API v2 examples. Also, begin migrating any of your API v1 scripts to their v2 equivalent. Account"
      },
      "id": "603ed3e7e7b9d2e5b52a07c8"
    },
    {
      "sections": [
        "Partnership admin console",
        "Console components",
        "Partnership configuration settings",
        "Customer activity monitoring",
        "State-of-the-Partnership report",
        "Partner customer monitoring",
        "View an arbitrary customer",
        "Viewing detailed customer data"
      ],
      "title": "Partnership admin console",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "670e4d2e1db957100b23a7b8b0af6bf50cc8c996",
      "image": "https://docs.newrelic.com/static/43369c88523ebf526ae58fa5719d4efe/0abdd/crop-partnership-owner-account-settings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/partnership-admin-console/",
      "published_at": "2022-01-12T05:51:37Z",
      "updated_at": "2021-07-02T15:19:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Partnership Admin Console is the interface for managing your customers' accounts and integration with New Relic. To access the console, sign into the partnership owner account, and go to: https://partner-admin-console.newrelic.com/accounts/ACCOUNT_ID/admin_console/ Copy You can also access the console from the New Relic UI: Go to one.newrelic.com > (account dropdown) > Account settings. From the left menu bar, select Partnerships. one.newrelic.com > (account dropdown) > Account settings > Partnerships: Partnership owners can access the Partnership Admin Console from their account settings in the New Relic UI. Console components The Partnership Admin Console has two main components: Partnership configuration settings Customer activity monitoring If multiple partnerships are associated with the New Relic parent account, the menu also includes an option to switch partnership accounts. Partnership configuration settings In developing your integration with New Relic, you must specify a number of settings. For your convenience these settings are grouped together in the partnership console, including URLs for header/footer and various redirects, SSO configuration, and keys and the ability to manipulate them. Customer activity monitoring New Relic provides you with two tools for managing your customers: State-of-the-Partnership reports and live monitoring of all deployed New Relic agents in your partnership. Both of these tools provide insight into your customers who are using New Relic. They can be used to identify up-sale opportunities or to assist your support group in proactive support. State-of-the-Partnership report The State-of-the-Partnership report provides a summary of your customers with New Relic accounts and their activities. The report is broken down by language of the agents deployed, the agent version and the language version for each account. This report is run weekly for each partner. It is available on request from your New Relic Business Development contact. This report is an excellent way to see which of your customers with New Relic accounts are in fact using the service. Partner customer monitoring The Partner customer monitoring facility provides application performance data on the New Relic enabled applications that are running on your service. This facility allows you to easily identify customers experiencing performance problems. Where the performance problems are caused by under capacity, these customers are excellent sales opportunities. Alternatively your support or services organization will find this information useful in pre-emptively identifying customer issues or as good prospects for consulting services. View an arbitrary customer To view activity of a customer that does not appear in any of the filtered views: Go to one.newrelic.com > (account dropdown) > Switch accounts > Other accounts. New Relic will list all of the reporting accounts in the partnership. You can filter or search the list. Viewing detailed customer data Under normal circumstances a partner will be able to see only the summary level data in a customer's New Relic account. Through the Partnership Admin Console, partners will be permitted to drill down to the more detailed presentation. If you want to drill down from the Partnership Admin Console, add your user (typically support@partner.com or something similar) to the account. Typically this will be done at account creation. Avoid provisioning this user as the account Owner.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.55786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> admin console",
        "sections": "<em>Partnership</em> admin console",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " the console from the <em>New</em> <em>Relic</em> UI: Go to one.newrelic.com &gt; (account dropdown) &gt; Account settings. From the left menu bar, select <em>Partnerships</em>. one.newrelic.com &gt; (account dropdown) &gt; Account settings &gt; <em>Partnerships</em>: <em>Partnership</em> owners can access the <em>Partnership</em> Admin Console from their account settings"
      },
      "id": "603ed3e3196a6735baa83dad"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/partner-api-reference": [
    {
      "sections": [
        "Partnership API subscription object",
        "Requirements",
        "Subscription object attributes",
        "product_id (REQUIRED for new subscriptions)",
        "quantity (REQUIRED for new subscriptions)",
        "promo_code",
        "data_retention (required only for Insights subscriptions)",
        "Mapping for products (product_id)",
        "Important",
        "APM",
        "Mobile",
        "Insights",
        "Browser",
        "Synthetics",
        "Tip",
        "Infrastructure",
        "Subscription API calls",
        "Subscription API examples",
        "Example subscription object",
        "Example JSON response",
        "Subscription status",
        "API examples (v2)",
        "List",
        "Show",
        "Create new (replace existing subscription)"
      ],
      "title": "Partnership API subscription object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "05b65e48cf5ed981c3eb79a3b31332f452dd5b2d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-subscription-object/",
      "published_at": "2022-01-12T05:54:34Z",
      "updated_at": "2021-12-10T08:15:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you're on our original pricing model. It doesn't support accounts on our New Relic One pricing model. For more on this, read the Partnership API requirements. The Partnership API doesn't allow you to upgrade or downgrade individual product subscriptions for an account. Instead, the API requires you to replace (add) the configuration for all product subscriptions for the account. If any product configurations are not included, the New Relic Partnership API provisions the account with the best free product type available. The API automatically selects the product level based on the configuration and custom pricing for the account's partnership. Subscription object attributes Before using this, first read Requirements. Here are the subscription object's attributes: product_id (REQUIRED for new subscriptions) Type: Integer Default: (none) The product ID attribute identifies the New Relic product being defined for this subscription. It is required for Create calls. quantity (REQUIRED for new subscriptions) Type: Integer Default: (none) The quantity attribute is required for Create calls, even if a product level is unlimited. The API will ignore the quantity value entered for unlimited product subscriptions, such as New Relic APM Lite. New Relic Insights, Browser, and Synthetics require you to identify a predefined usage level (product bucket). This allows the API to apply a pricing discount based on the specific quantity you select. The quantity you identify must be an exact match for the product and subscription level. For a list of available product buckets, see: Browser PageViews Insights Events Synthetics Checks promo_code Type: String Default: (none) Any related promotional code for this subscription. Not yet supported through the Partnership API's subscription endpoint. However, you can pass the promo_code as part of the subscription with the account API's Create call. data_retention (required only for Insights subscriptions) Type: Integer Default: (none) Number of weeks the Insights event information will be retained. Mapping for products (product_id) With each account creation call, you must supply at least one New Relic product type. The API only accepts the numeric product_id for the type. Important Reminder that the subscription object only applies for accounts using our original pricing model. Also, creating subscriptions for Serverless, Logs, and Traces is not supported by the Partnership API. If your account has these subscriptions, any attempt to make changes will return an error. Please contact your account executive to modify subscriptions. Important New Startup and Small Business service plans no longer are available through the New Relic Partnership API. APM The number of allowable hosts per account and the data retention period vary by subscription level within New Relic APM's pricing structure. For example, New Relic APM allows an unlimited number of allowable hosts for Lite accounts but only a 24-hour data retention period. In addition, pricing and data retention depend on whether you select pricing models based on hosts or compute units (CU). Use the product ID's integer format to identify the subscription level and type of plan. APM subscription level Product ID Lite 1 Standard 2 Standard Annual 3 Pro (Host) 4 Pro Annual (Host) 5 Enterprise 6 Enterprise Annual 7 APM Essentials (Host) 8 APM Essentials Annual (Host) 9 If you select pricing plans based on compute units (CU), use these product ID integer formats to identify the subscription level and type of plan. APM Compute Units (CU) subscription level Product ID Pro CU 26 Pro Annual CU 27 APM Essentials CU 28 APM Essentials Annual CU 29 Mobile New Relic Mobile's pricing structure allows 100,000 monthly active users per account at the Enterprise subscription level. Data retention varies by subscription level. Use the product ID's integer format to identify the subscription level. Mobile subscription level Product ID Lite 10 Enterprise 13 Enterprise Annual 14 Insights New Relic Insights bases the pricing structure on the number of allowable events stored and the associated data retention policy (for example, data retention for Insights Free is one day). Note that the data_retention attribute is required. Insights subscription level Product ID Free 15 None 16 Pro 18 Pro Annual 19 Browser New Relic Browser's pricing structure allows an unlimited number of app users, regardless of subscription level. However, the number of allowable page views per month and the data retention period vary by subscription level. For example: Lite accounts include an unlimited number of page views per month and 24-hour data retention. Pro account pricing starts at 500,000 page views per month and three months data retention. Use the product ID's integer format to identify the subscription level. Browser subscription level Product ID Lite 20 Pro 21 Pro Annual 22 Synthetics With New Relic Synthetics' pricing structure, the default number of allowable monitoring checks and the data retention period vary by subscription level. Use the product ID's integer format to identify the subscription level. Synthetics subscription level Product ID Lite 23 Pro 24 Pro Annual 25 Tip If you previously used the deprecated Partnership availability monitoring API, you can use the Synthetics API to provision a check and the REST API for New Relic Alerts to create an alert notification for your customers. Infrastructure With New Relic's Infrastructure pricing structure, the default number of instances and the data retention period vary by subscription level. Infrastructure events do not count against your New Relic Insights quota, even though you can query them in Insights. New Relic Infrastructure offers pricing plans based on Compute Units (CU) only. Use the product ID's integer format to identify the subscription level. Infrastructure subscription level Product ID Infrastructure None 31 Infrastructure Pro (CU) 32 Infrastructure Pro Annual (CU) 33 Infrastructure Essentials (CU) 34 Infrastructure Essentials Annual (CU) 35 Subscription API calls Before using this, first read Requirements. Here are the URL patterns for subscription-related API functions. If used, send them along with the JSON object and an HTTP header containing the Partner API key. For example: GET .../api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all subscriptions of an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Show a subscription for an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/ID Copy Replace the current subscription level with a new subscription. POST /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Subscription API examples Here are examples of an API call to create an original pricing model subscription and the JSON response listing subscriptions for the account. Example subscription object { \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 2 }, { \"product_id\": 13, \"quantity\": 2 } ] } Copy Example JSON response { \"id\": 1069012, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 2, \"price\": 218.0 }, { \"product_id\": 13, \"name\": \"Mobile Enterprise\", \"units\": 2, \"price\": 1500.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 15, \"name\": \"Insights Free\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Subscription status Here are some original pricing model subscription status values that the API call may return. Subscription status Description pending The customer has signed up for a New Relic product, but payment still needs to be processed. authorized A credit card has been authorized and the vault key stored, but payment has not been captured. free This subscription is for a free New Relic product. No further processing is required. paid A payment has been captured and the next payment date has been set. payment_declined The last attempt to authorize payment failed. canceled The New Relic account has no active subscription and is not active. No payments should be authorized or captured. replaced This subscription has been superseded by another New Relic subscription. API examples (v2) Here are API example requests and responses to list, show, create, and update original pricing model subscriptions. Line breaks in responses are for readability. The actual responses appear as a continuous line. List Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"subscriptions\": [ { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/SUBSCRIPTION_ID Copy Response: { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Create new (replace existing subscription) Here is an example of how to use the Partnership API create a new subscription (replace the existing subscription level for all products) for the account. Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"subscriptions\":[{\"product_id\":\"1\", \"quantity\":1}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"id\": 1069068, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.46889,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> subscription object",
        "sections": "<em>Partnership</em> <em>API</em> subscription object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This doc explains how to use the <em>Partnership</em> <em>API</em> to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you&#x27;re on our original pricing model. It doesn&#x27;t support accounts on our <em>New</em> <em>Relic</em> One pricing model. For more on this, read"
      },
      "id": "603ebc5f28ccbcf81deba7a5"
    },
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2022-01-12T05:53:53Z",
      "updated_at": "2021-11-15T09:43:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing model: ignore this field because it applies to the original pricing model, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing model. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing models. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing model and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.95801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " that is on our <em>New</em> <em>Relic</em> One pricing and our <em>New</em> <em>Relic</em> One user model. For more on restrictions on <em>API</em> use, see requirements. curl -X POST \\ -H &#x27;x-<em>api</em>-key:<em>PARTNER</em>_ACCOUNT_KEY&#x27; \\ -H &#x27;Content-Type:application&#x2F;json&#x27; \\ -d &#x27;{&quot;account&quot;:{&quot;name&quot;:&quot;Sample account&quot;}}&#x27; \\ https:&#x2F;&#x2F;rpm.newrelic.com&#x2F;<em>api</em>&#x2F;v2&#x2F;partners"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Product buckets",
        "Requirements",
        "Overview (#overview)",
        "Quantity by product",
        "Insights Events quantity",
        "Browser PageViews quantity",
        "Synthetics Checks quantity"
      ],
      "title": "Product buckets",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "fe7632af0936f9878b04ba0c25f7cf8a7f684399",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/product-buckets/",
      "published_at": "2022-01-12T05:55:20Z",
      "updated_at": "2021-11-15T09:27:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For partnership accounts on our original product pricing, you can use the Partnership API for managing subscriptions. This doc explains some details for using the Browser, Synthetics, and Insights products. Requirements This doc applies only for partnership accounts on our original pricing model. Before using this API, please read the Partnership API requirements. Overview (#overview) When using the Partnership API for Insights, Browser, and Synthetics products, you must provide a valid quantity value. This indicates the number of Insights Events, Browser PageViews, and Synthetics Checks provisioned to that account. New Relic uses this \"bucket\" pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the New Relic Partnership API will return an error response. Quantity by product Here are the valid quantity values by New Relic product. Insights Events quantity Insights Pro Insights Pro Annual 25 25 50 50 75 75 300 300 625 625 1250 1250 2500 2500 5000 5000 10000 10000 20000 20000 40000 40000 60000 60000 80000 80000 100000 100000 120000 120000 140000 140000 Browser PageViews quantity Browser Pro Browser Pro Annual 100000 100000 250000 250000 500000 500000 1000000 1000000 1500000 1500000 2000000 2000000 2500000 2500000 3000000 3000000 4000000 4000000 5000000 5000000 6000000 6000000 7000000 7000000 7500000 7500000 8000000 8000000 9000000 9000000 10000000 10000000 12500000 12500000 15000000 15000000 20000000 20000000 25000000 25000000 30000000 30000000 35000000 35000000 40000000 40000000 50000000 50000000 75000000 75000000 100000000 100000000 125000000 125000000 150000000 150000000 175000000 175000000 200000000 200000000 250000000 250000000 300000000 300000000 350000000 350000000 400000000 400000000 450000000 450000000 500000000 500000000 600000000 600000000 700000000 700000000 800000000 800000000 900000000 900000000 1000000000 1000000000 1250000000 1250000000 1500000000 1500000000 2000000000 2000000000 2500000000 2500000000 3000000000 3000000000 4000000000 4000000000 5000000000 5000000000 10000000000 10000000000 Synthetics Checks quantity Synthetics Pro Synthetics Pro Annual 10000 10000 15000 15000 25000 25000 35000 35000 50000 50000 75000 75000 100000 100000 150000 150000 250000 250000 300000 300000 400000 400000 500000 500000 600000 600000 750000 750000 900000 900000 1000000 1000000 1150000 1150000 1300000 1300000 1500000 1500000 1750000 1750000 2000000 2000000 2500000 2500000 3000000 3000000 3500000 3500000 5000000 5000000 7000000 7000000 8500000 8500000 10000000 10000000 12500000 12500000 14000000 14000000 15000000 15000000 17500000 17500000 20000000 20000000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.95395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " provisioned to that account. <em>New</em> <em>Relic</em> uses this &quot;bucket&quot; pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the <em>New</em> <em>Relic</em> <em>Partnership</em> <em>API</em> will return an error response. Quantity by product Here"
      },
      "id": "6044181d28ccbc2ea42c608a"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object": [
    {
      "sections": [
        "Partnership API subscription object",
        "Requirements",
        "Subscription object attributes",
        "product_id (REQUIRED for new subscriptions)",
        "quantity (REQUIRED for new subscriptions)",
        "promo_code",
        "data_retention (required only for Insights subscriptions)",
        "Mapping for products (product_id)",
        "Important",
        "APM",
        "Mobile",
        "Insights",
        "Browser",
        "Synthetics",
        "Tip",
        "Infrastructure",
        "Subscription API calls",
        "Subscription API examples",
        "Example subscription object",
        "Example JSON response",
        "Subscription status",
        "API examples (v2)",
        "List",
        "Show",
        "Create new (replace existing subscription)"
      ],
      "title": "Partnership API subscription object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "05b65e48cf5ed981c3eb79a3b31332f452dd5b2d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-subscription-object/",
      "published_at": "2022-01-12T05:54:34Z",
      "updated_at": "2021-12-10T08:15:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you're on our original pricing model. It doesn't support accounts on our New Relic One pricing model. For more on this, read the Partnership API requirements. The Partnership API doesn't allow you to upgrade or downgrade individual product subscriptions for an account. Instead, the API requires you to replace (add) the configuration for all product subscriptions for the account. If any product configurations are not included, the New Relic Partnership API provisions the account with the best free product type available. The API automatically selects the product level based on the configuration and custom pricing for the account's partnership. Subscription object attributes Before using this, first read Requirements. Here are the subscription object's attributes: product_id (REQUIRED for new subscriptions) Type: Integer Default: (none) The product ID attribute identifies the New Relic product being defined for this subscription. It is required for Create calls. quantity (REQUIRED for new subscriptions) Type: Integer Default: (none) The quantity attribute is required for Create calls, even if a product level is unlimited. The API will ignore the quantity value entered for unlimited product subscriptions, such as New Relic APM Lite. New Relic Insights, Browser, and Synthetics require you to identify a predefined usage level (product bucket). This allows the API to apply a pricing discount based on the specific quantity you select. The quantity you identify must be an exact match for the product and subscription level. For a list of available product buckets, see: Browser PageViews Insights Events Synthetics Checks promo_code Type: String Default: (none) Any related promotional code for this subscription. Not yet supported through the Partnership API's subscription endpoint. However, you can pass the promo_code as part of the subscription with the account API's Create call. data_retention (required only for Insights subscriptions) Type: Integer Default: (none) Number of weeks the Insights event information will be retained. Mapping for products (product_id) With each account creation call, you must supply at least one New Relic product type. The API only accepts the numeric product_id for the type. Important Reminder that the subscription object only applies for accounts using our original pricing model. Also, creating subscriptions for Serverless, Logs, and Traces is not supported by the Partnership API. If your account has these subscriptions, any attempt to make changes will return an error. Please contact your account executive to modify subscriptions. Important New Startup and Small Business service plans no longer are available through the New Relic Partnership API. APM The number of allowable hosts per account and the data retention period vary by subscription level within New Relic APM's pricing structure. For example, New Relic APM allows an unlimited number of allowable hosts for Lite accounts but only a 24-hour data retention period. In addition, pricing and data retention depend on whether you select pricing models based on hosts or compute units (CU). Use the product ID's integer format to identify the subscription level and type of plan. APM subscription level Product ID Lite 1 Standard 2 Standard Annual 3 Pro (Host) 4 Pro Annual (Host) 5 Enterprise 6 Enterprise Annual 7 APM Essentials (Host) 8 APM Essentials Annual (Host) 9 If you select pricing plans based on compute units (CU), use these product ID integer formats to identify the subscription level and type of plan. APM Compute Units (CU) subscription level Product ID Pro CU 26 Pro Annual CU 27 APM Essentials CU 28 APM Essentials Annual CU 29 Mobile New Relic Mobile's pricing structure allows 100,000 monthly active users per account at the Enterprise subscription level. Data retention varies by subscription level. Use the product ID's integer format to identify the subscription level. Mobile subscription level Product ID Lite 10 Enterprise 13 Enterprise Annual 14 Insights New Relic Insights bases the pricing structure on the number of allowable events stored and the associated data retention policy (for example, data retention for Insights Free is one day). Note that the data_retention attribute is required. Insights subscription level Product ID Free 15 None 16 Pro 18 Pro Annual 19 Browser New Relic Browser's pricing structure allows an unlimited number of app users, regardless of subscription level. However, the number of allowable page views per month and the data retention period vary by subscription level. For example: Lite accounts include an unlimited number of page views per month and 24-hour data retention. Pro account pricing starts at 500,000 page views per month and three months data retention. Use the product ID's integer format to identify the subscription level. Browser subscription level Product ID Lite 20 Pro 21 Pro Annual 22 Synthetics With New Relic Synthetics' pricing structure, the default number of allowable monitoring checks and the data retention period vary by subscription level. Use the product ID's integer format to identify the subscription level. Synthetics subscription level Product ID Lite 23 Pro 24 Pro Annual 25 Tip If you previously used the deprecated Partnership availability monitoring API, you can use the Synthetics API to provision a check and the REST API for New Relic Alerts to create an alert notification for your customers. Infrastructure With New Relic's Infrastructure pricing structure, the default number of instances and the data retention period vary by subscription level. Infrastructure events do not count against your New Relic Insights quota, even though you can query them in Insights. New Relic Infrastructure offers pricing plans based on Compute Units (CU) only. Use the product ID's integer format to identify the subscription level. Infrastructure subscription level Product ID Infrastructure None 31 Infrastructure Pro (CU) 32 Infrastructure Pro Annual (CU) 33 Infrastructure Essentials (CU) 34 Infrastructure Essentials Annual (CU) 35 Subscription API calls Before using this, first read Requirements. Here are the URL patterns for subscription-related API functions. If used, send them along with the JSON object and an HTTP header containing the Partner API key. For example: GET .../api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all subscriptions of an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Show a subscription for an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/ID Copy Replace the current subscription level with a new subscription. POST /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Subscription API examples Here are examples of an API call to create an original pricing model subscription and the JSON response listing subscriptions for the account. Example subscription object { \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 2 }, { \"product_id\": 13, \"quantity\": 2 } ] } Copy Example JSON response { \"id\": 1069012, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 2, \"price\": 218.0 }, { \"product_id\": 13, \"name\": \"Mobile Enterprise\", \"units\": 2, \"price\": 1500.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 15, \"name\": \"Insights Free\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Subscription status Here are some original pricing model subscription status values that the API call may return. Subscription status Description pending The customer has signed up for a New Relic product, but payment still needs to be processed. authorized A credit card has been authorized and the vault key stored, but payment has not been captured. free This subscription is for a free New Relic product. No further processing is required. paid A payment has been captured and the next payment date has been set. payment_declined The last attempt to authorize payment failed. canceled The New Relic account has no active subscription and is not active. No payments should be authorized or captured. replaced This subscription has been superseded by another New Relic subscription. API examples (v2) Here are API example requests and responses to list, show, create, and update original pricing model subscriptions. Line breaks in responses are for readability. The actual responses appear as a continuous line. List Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"subscriptions\": [ { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/SUBSCRIPTION_ID Copy Response: { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Create new (replace existing subscription) Here is an example of how to use the Partnership API create a new subscription (replace the existing subscription level for all products) for the account. Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"subscriptions\":[{\"product_id\":\"1\", \"quantity\":1}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"id\": 1069068, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.46889,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> subscription object",
        "sections": "<em>Partnership</em> <em>API</em> subscription object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This doc explains how to use the <em>Partnership</em> <em>API</em> to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you&#x27;re on our original pricing model. It doesn&#x27;t support accounts on our <em>New</em> <em>Relic</em> One pricing model. For more on this, read"
      },
      "id": "603ebc5f28ccbcf81deba7a5"
    },
    {
      "sections": [
        "Product buckets",
        "Requirements",
        "Overview (#overview)",
        "Quantity by product",
        "Insights Events quantity",
        "Browser PageViews quantity",
        "Synthetics Checks quantity"
      ],
      "title": "Product buckets",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "fe7632af0936f9878b04ba0c25f7cf8a7f684399",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/product-buckets/",
      "published_at": "2022-01-12T05:55:20Z",
      "updated_at": "2021-11-15T09:27:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For partnership accounts on our original product pricing, you can use the Partnership API for managing subscriptions. This doc explains some details for using the Browser, Synthetics, and Insights products. Requirements This doc applies only for partnership accounts on our original pricing model. Before using this API, please read the Partnership API requirements. Overview (#overview) When using the Partnership API for Insights, Browser, and Synthetics products, you must provide a valid quantity value. This indicates the number of Insights Events, Browser PageViews, and Synthetics Checks provisioned to that account. New Relic uses this \"bucket\" pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the New Relic Partnership API will return an error response. Quantity by product Here are the valid quantity values by New Relic product. Insights Events quantity Insights Pro Insights Pro Annual 25 25 50 50 75 75 300 300 625 625 1250 1250 2500 2500 5000 5000 10000 10000 20000 20000 40000 40000 60000 60000 80000 80000 100000 100000 120000 120000 140000 140000 Browser PageViews quantity Browser Pro Browser Pro Annual 100000 100000 250000 250000 500000 500000 1000000 1000000 1500000 1500000 2000000 2000000 2500000 2500000 3000000 3000000 4000000 4000000 5000000 5000000 6000000 6000000 7000000 7000000 7500000 7500000 8000000 8000000 9000000 9000000 10000000 10000000 12500000 12500000 15000000 15000000 20000000 20000000 25000000 25000000 30000000 30000000 35000000 35000000 40000000 40000000 50000000 50000000 75000000 75000000 100000000 100000000 125000000 125000000 150000000 150000000 175000000 175000000 200000000 200000000 250000000 250000000 300000000 300000000 350000000 350000000 400000000 400000000 450000000 450000000 500000000 500000000 600000000 600000000 700000000 700000000 800000000 800000000 900000000 900000000 1000000000 1000000000 1250000000 1250000000 1500000000 1500000000 2000000000 2000000000 2500000000 2500000000 3000000000 3000000000 4000000000 4000000000 5000000000 5000000000 10000000000 10000000000 Synthetics Checks quantity Synthetics Pro Synthetics Pro Annual 10000 10000 15000 15000 25000 25000 35000 35000 50000 50000 75000 75000 100000 100000 150000 150000 250000 250000 300000 300000 400000 400000 500000 500000 600000 600000 750000 750000 900000 900000 1000000 1000000 1150000 1150000 1300000 1300000 1500000 1500000 1750000 1750000 2000000 2000000 2500000 2500000 3000000 3000000 3500000 3500000 5000000 5000000 7000000 7000000 8500000 8500000 10000000 10000000 12500000 12500000 14000000 14000000 15000000 15000000 17500000 17500000 20000000 20000000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.95395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " provisioned to that account. <em>New</em> <em>Relic</em> uses this &quot;bucket&quot; pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the <em>New</em> <em>Relic</em> <em>Partnership</em> <em>API</em> will return an error response. Quantity by product Here"
      },
      "id": "6044181d28ccbc2ea42c608a"
    },
    {
      "sections": [
        "Partnership API child account object",
        "Requirements",
        "Introduction to using child accounts",
        "Child account object attributes",
        "name (REQUIRED)",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "password (REQUIRED)",
        "Child account API calls",
        "JSON example",
        "Child account object JSON request",
        "JSON response",
        "Child account object API examples",
        "Create"
      ],
      "title": "Partnership API child account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "7fb13302d892a5f89c6c9371f35a60bf1ed9f6a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-sub-account-object/",
      "published_at": "2022-01-12T05:53:54Z",
      "updated_at": "2021-07-02T13:14:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage child accounts. For accounts, you'd use the child account object. Requirements You may not have access to using this object. Before using the Partnership API, first read the requirements. Introduction to using child accounts Some notes about using the child account object: To manage existing parent accounts or child accounts, use the Partnership API account object. A parent account may have more than one associated child account, but every chld account must correspond to one and only one parent account. Every child account must have at least a primary_admin user. You cannot create a child account without connecting it to an existing parent account and adding at least one user. Child account object attributes Before using the Partnership API, first read the requirements. Here are the Partnership API child account object's attributes: name (REQUIRED) Type: String Default: (none) This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you create the child account, you can define only one user: the account Owner. To add additional users, use the Partnership API user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user's current password. For some New Relic organizations, child accounts can also be created via the parent account's Account settings page in the New Relic UI. Child account API calls Here is the URL pattern to create child accounts. Notice that the Parent Account ID must be specified. If using this URL pattern, send the JSON object along with an HTTP header containing the Partner API key. For example: POST .../api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts​ x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern Create a child account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy JSON example Here is an example of a JSON request and response using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Child account object JSON request { \"account\": { \"name\": \"Sample child account\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Child account object API examples Here is an example of an API call using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Create Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"sub_account\":{\"name\":\"Sample child account\"}, \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample child account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": false, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.90009,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> child account object",
        "sections": "<em>Partnership</em> <em>API</em> child account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " additional users, use the <em>Partnership</em> <em>API</em> user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user&#x27;s current password. For some <em>New</em> <em>Relic</em>"
      },
      "id": "603eba3ae7b9d2b8e32a07b5"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-keys": [
    {
      "sections": [
        "Partnership API subscription object",
        "Requirements",
        "Subscription object attributes",
        "product_id (REQUIRED for new subscriptions)",
        "quantity (REQUIRED for new subscriptions)",
        "promo_code",
        "data_retention (required only for Insights subscriptions)",
        "Mapping for products (product_id)",
        "Important",
        "APM",
        "Mobile",
        "Insights",
        "Browser",
        "Synthetics",
        "Tip",
        "Infrastructure",
        "Subscription API calls",
        "Subscription API examples",
        "Example subscription object",
        "Example JSON response",
        "Subscription status",
        "API examples (v2)",
        "List",
        "Show",
        "Create new (replace existing subscription)"
      ],
      "title": "Partnership API subscription object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "05b65e48cf5ed981c3eb79a3b31332f452dd5b2d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-subscription-object/",
      "published_at": "2022-01-12T05:54:34Z",
      "updated_at": "2021-12-10T08:15:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you're on our original pricing model. It doesn't support accounts on our New Relic One pricing model. For more on this, read the Partnership API requirements. The Partnership API doesn't allow you to upgrade or downgrade individual product subscriptions for an account. Instead, the API requires you to replace (add) the configuration for all product subscriptions for the account. If any product configurations are not included, the New Relic Partnership API provisions the account with the best free product type available. The API automatically selects the product level based on the configuration and custom pricing for the account's partnership. Subscription object attributes Before using this, first read Requirements. Here are the subscription object's attributes: product_id (REQUIRED for new subscriptions) Type: Integer Default: (none) The product ID attribute identifies the New Relic product being defined for this subscription. It is required for Create calls. quantity (REQUIRED for new subscriptions) Type: Integer Default: (none) The quantity attribute is required for Create calls, even if a product level is unlimited. The API will ignore the quantity value entered for unlimited product subscriptions, such as New Relic APM Lite. New Relic Insights, Browser, and Synthetics require you to identify a predefined usage level (product bucket). This allows the API to apply a pricing discount based on the specific quantity you select. The quantity you identify must be an exact match for the product and subscription level. For a list of available product buckets, see: Browser PageViews Insights Events Synthetics Checks promo_code Type: String Default: (none) Any related promotional code for this subscription. Not yet supported through the Partnership API's subscription endpoint. However, you can pass the promo_code as part of the subscription with the account API's Create call. data_retention (required only for Insights subscriptions) Type: Integer Default: (none) Number of weeks the Insights event information will be retained. Mapping for products (product_id) With each account creation call, you must supply at least one New Relic product type. The API only accepts the numeric product_id for the type. Important Reminder that the subscription object only applies for accounts using our original pricing model. Also, creating subscriptions for Serverless, Logs, and Traces is not supported by the Partnership API. If your account has these subscriptions, any attempt to make changes will return an error. Please contact your account executive to modify subscriptions. Important New Startup and Small Business service plans no longer are available through the New Relic Partnership API. APM The number of allowable hosts per account and the data retention period vary by subscription level within New Relic APM's pricing structure. For example, New Relic APM allows an unlimited number of allowable hosts for Lite accounts but only a 24-hour data retention period. In addition, pricing and data retention depend on whether you select pricing models based on hosts or compute units (CU). Use the product ID's integer format to identify the subscription level and type of plan. APM subscription level Product ID Lite 1 Standard 2 Standard Annual 3 Pro (Host) 4 Pro Annual (Host) 5 Enterprise 6 Enterprise Annual 7 APM Essentials (Host) 8 APM Essentials Annual (Host) 9 If you select pricing plans based on compute units (CU), use these product ID integer formats to identify the subscription level and type of plan. APM Compute Units (CU) subscription level Product ID Pro CU 26 Pro Annual CU 27 APM Essentials CU 28 APM Essentials Annual CU 29 Mobile New Relic Mobile's pricing structure allows 100,000 monthly active users per account at the Enterprise subscription level. Data retention varies by subscription level. Use the product ID's integer format to identify the subscription level. Mobile subscription level Product ID Lite 10 Enterprise 13 Enterprise Annual 14 Insights New Relic Insights bases the pricing structure on the number of allowable events stored and the associated data retention policy (for example, data retention for Insights Free is one day). Note that the data_retention attribute is required. Insights subscription level Product ID Free 15 None 16 Pro 18 Pro Annual 19 Browser New Relic Browser's pricing structure allows an unlimited number of app users, regardless of subscription level. However, the number of allowable page views per month and the data retention period vary by subscription level. For example: Lite accounts include an unlimited number of page views per month and 24-hour data retention. Pro account pricing starts at 500,000 page views per month and three months data retention. Use the product ID's integer format to identify the subscription level. Browser subscription level Product ID Lite 20 Pro 21 Pro Annual 22 Synthetics With New Relic Synthetics' pricing structure, the default number of allowable monitoring checks and the data retention period vary by subscription level. Use the product ID's integer format to identify the subscription level. Synthetics subscription level Product ID Lite 23 Pro 24 Pro Annual 25 Tip If you previously used the deprecated Partnership availability monitoring API, you can use the Synthetics API to provision a check and the REST API for New Relic Alerts to create an alert notification for your customers. Infrastructure With New Relic's Infrastructure pricing structure, the default number of instances and the data retention period vary by subscription level. Infrastructure events do not count against your New Relic Insights quota, even though you can query them in Insights. New Relic Infrastructure offers pricing plans based on Compute Units (CU) only. Use the product ID's integer format to identify the subscription level. Infrastructure subscription level Product ID Infrastructure None 31 Infrastructure Pro (CU) 32 Infrastructure Pro Annual (CU) 33 Infrastructure Essentials (CU) 34 Infrastructure Essentials Annual (CU) 35 Subscription API calls Before using this, first read Requirements. Here are the URL patterns for subscription-related API functions. If used, send them along with the JSON object and an HTTP header containing the Partner API key. For example: GET .../api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all subscriptions of an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Show a subscription for an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/ID Copy Replace the current subscription level with a new subscription. POST /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Subscription API examples Here are examples of an API call to create an original pricing model subscription and the JSON response listing subscriptions for the account. Example subscription object { \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 2 }, { \"product_id\": 13, \"quantity\": 2 } ] } Copy Example JSON response { \"id\": 1069012, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 2, \"price\": 218.0 }, { \"product_id\": 13, \"name\": \"Mobile Enterprise\", \"units\": 2, \"price\": 1500.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 15, \"name\": \"Insights Free\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Subscription status Here are some original pricing model subscription status values that the API call may return. Subscription status Description pending The customer has signed up for a New Relic product, but payment still needs to be processed. authorized A credit card has been authorized and the vault key stored, but payment has not been captured. free This subscription is for a free New Relic product. No further processing is required. paid A payment has been captured and the next payment date has been set. payment_declined The last attempt to authorize payment failed. canceled The New Relic account has no active subscription and is not active. No payments should be authorized or captured. replaced This subscription has been superseded by another New Relic subscription. API examples (v2) Here are API example requests and responses to list, show, create, and update original pricing model subscriptions. Line breaks in responses are for readability. The actual responses appear as a continuous line. List Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"subscriptions\": [ { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/SUBSCRIPTION_ID Copy Response: { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Create new (replace existing subscription) Here is an example of how to use the Partnership API create a new subscription (replace the existing subscription level for all products) for the account. Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"subscriptions\":[{\"product_id\":\"1\", \"quantity\":1}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"id\": 1069068, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.46887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> subscription object",
        "sections": "<em>Partnership</em> <em>API</em> subscription object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This doc explains how to use the <em>Partnership</em> <em>API</em> to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you&#x27;re on our original pricing model. It doesn&#x27;t support accounts on our <em>New</em> <em>Relic</em> One pricing model. For more on this, read"
      },
      "id": "603ebc5f28ccbcf81deba7a5"
    },
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2022-01-12T05:53:53Z",
      "updated_at": "2021-11-15T09:43:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing model: ignore this field because it applies to the original pricing model, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing model. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing models. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing model and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " that is on our <em>New</em> <em>Relic</em> One pricing and our <em>New</em> <em>Relic</em> One user model. For more on restrictions on <em>API</em> use, see requirements. curl -X POST \\ -H &#x27;x-<em>api</em>-key:<em>PARTNER</em>_ACCOUNT_KEY&#x27; \\ -H &#x27;Content-Type:application&#x2F;json&#x27; \\ -d &#x27;{&quot;account&quot;:{&quot;name&quot;:&quot;Sample account&quot;}}&#x27; \\ https:&#x2F;&#x2F;rpm.newrelic.com&#x2F;<em>api</em>&#x2F;v2&#x2F;partners"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Product buckets",
        "Requirements",
        "Overview (#overview)",
        "Quantity by product",
        "Insights Events quantity",
        "Browser PageViews quantity",
        "Synthetics Checks quantity"
      ],
      "title": "Product buckets",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "fe7632af0936f9878b04ba0c25f7cf8a7f684399",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/product-buckets/",
      "published_at": "2022-01-12T05:55:20Z",
      "updated_at": "2021-11-15T09:27:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For partnership accounts on our original product pricing, you can use the Partnership API for managing subscriptions. This doc explains some details for using the Browser, Synthetics, and Insights products. Requirements This doc applies only for partnership accounts on our original pricing model. Before using this API, please read the Partnership API requirements. Overview (#overview) When using the Partnership API for Insights, Browser, and Synthetics products, you must provide a valid quantity value. This indicates the number of Insights Events, Browser PageViews, and Synthetics Checks provisioned to that account. New Relic uses this \"bucket\" pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the New Relic Partnership API will return an error response. Quantity by product Here are the valid quantity values by New Relic product. Insights Events quantity Insights Pro Insights Pro Annual 25 25 50 50 75 75 300 300 625 625 1250 1250 2500 2500 5000 5000 10000 10000 20000 20000 40000 40000 60000 60000 80000 80000 100000 100000 120000 120000 140000 140000 Browser PageViews quantity Browser Pro Browser Pro Annual 100000 100000 250000 250000 500000 500000 1000000 1000000 1500000 1500000 2000000 2000000 2500000 2500000 3000000 3000000 4000000 4000000 5000000 5000000 6000000 6000000 7000000 7000000 7500000 7500000 8000000 8000000 9000000 9000000 10000000 10000000 12500000 12500000 15000000 15000000 20000000 20000000 25000000 25000000 30000000 30000000 35000000 35000000 40000000 40000000 50000000 50000000 75000000 75000000 100000000 100000000 125000000 125000000 150000000 150000000 175000000 175000000 200000000 200000000 250000000 250000000 300000000 300000000 350000000 350000000 400000000 400000000 450000000 450000000 500000000 500000000 600000000 600000000 700000000 700000000 800000000 800000000 900000000 900000000 1000000000 1000000000 1250000000 1250000000 1500000000 1500000000 2000000000 2000000000 2500000000 2500000000 3000000000 3000000000 4000000000 4000000000 5000000000 5000000000 10000000000 10000000000 Synthetics Checks quantity Synthetics Pro Synthetics Pro Annual 10000 10000 15000 15000 25000 25000 35000 35000 50000 50000 75000 75000 100000 100000 150000 150000 250000 250000 300000 300000 400000 400000 500000 500000 600000 600000 750000 750000 900000 900000 1000000 1000000 1150000 1150000 1300000 1300000 1500000 1500000 1750000 1750000 2000000 2000000 2500000 2500000 3000000 3000000 3500000 3500000 5000000 5000000 7000000 7000000 8500000 8500000 10000000 10000000 12500000 12500000 14000000 14000000 15000000 15000000 17500000 17500000 20000000 20000000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.95393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " provisioned to that account. <em>New</em> <em>Relic</em> uses this &quot;bucket&quot; pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the <em>New</em> <em>Relic</em> <em>Partnership</em> <em>API</em> will return an error response. Quantity by product Here"
      },
      "id": "6044181d28ccbc2ea42c608a"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-sub-account-object": [
    {
      "sections": [
        "Partnership API subscription object",
        "Requirements",
        "Subscription object attributes",
        "product_id (REQUIRED for new subscriptions)",
        "quantity (REQUIRED for new subscriptions)",
        "promo_code",
        "data_retention (required only for Insights subscriptions)",
        "Mapping for products (product_id)",
        "Important",
        "APM",
        "Mobile",
        "Insights",
        "Browser",
        "Synthetics",
        "Tip",
        "Infrastructure",
        "Subscription API calls",
        "Subscription API examples",
        "Example subscription object",
        "Example JSON response",
        "Subscription status",
        "API examples (v2)",
        "List",
        "Show",
        "Create new (replace existing subscription)"
      ],
      "title": "Partnership API subscription object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "05b65e48cf5ed981c3eb79a3b31332f452dd5b2d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-subscription-object/",
      "published_at": "2022-01-12T05:54:34Z",
      "updated_at": "2021-12-10T08:15:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you're on our original pricing model. It doesn't support accounts on our New Relic One pricing model. For more on this, read the Partnership API requirements. The Partnership API doesn't allow you to upgrade or downgrade individual product subscriptions for an account. Instead, the API requires you to replace (add) the configuration for all product subscriptions for the account. If any product configurations are not included, the New Relic Partnership API provisions the account with the best free product type available. The API automatically selects the product level based on the configuration and custom pricing for the account's partnership. Subscription object attributes Before using this, first read Requirements. Here are the subscription object's attributes: product_id (REQUIRED for new subscriptions) Type: Integer Default: (none) The product ID attribute identifies the New Relic product being defined for this subscription. It is required for Create calls. quantity (REQUIRED for new subscriptions) Type: Integer Default: (none) The quantity attribute is required for Create calls, even if a product level is unlimited. The API will ignore the quantity value entered for unlimited product subscriptions, such as New Relic APM Lite. New Relic Insights, Browser, and Synthetics require you to identify a predefined usage level (product bucket). This allows the API to apply a pricing discount based on the specific quantity you select. The quantity you identify must be an exact match for the product and subscription level. For a list of available product buckets, see: Browser PageViews Insights Events Synthetics Checks promo_code Type: String Default: (none) Any related promotional code for this subscription. Not yet supported through the Partnership API's subscription endpoint. However, you can pass the promo_code as part of the subscription with the account API's Create call. data_retention (required only for Insights subscriptions) Type: Integer Default: (none) Number of weeks the Insights event information will be retained. Mapping for products (product_id) With each account creation call, you must supply at least one New Relic product type. The API only accepts the numeric product_id for the type. Important Reminder that the subscription object only applies for accounts using our original pricing model. Also, creating subscriptions for Serverless, Logs, and Traces is not supported by the Partnership API. If your account has these subscriptions, any attempt to make changes will return an error. Please contact your account executive to modify subscriptions. Important New Startup and Small Business service plans no longer are available through the New Relic Partnership API. APM The number of allowable hosts per account and the data retention period vary by subscription level within New Relic APM's pricing structure. For example, New Relic APM allows an unlimited number of allowable hosts for Lite accounts but only a 24-hour data retention period. In addition, pricing and data retention depend on whether you select pricing models based on hosts or compute units (CU). Use the product ID's integer format to identify the subscription level and type of plan. APM subscription level Product ID Lite 1 Standard 2 Standard Annual 3 Pro (Host) 4 Pro Annual (Host) 5 Enterprise 6 Enterprise Annual 7 APM Essentials (Host) 8 APM Essentials Annual (Host) 9 If you select pricing plans based on compute units (CU), use these product ID integer formats to identify the subscription level and type of plan. APM Compute Units (CU) subscription level Product ID Pro CU 26 Pro Annual CU 27 APM Essentials CU 28 APM Essentials Annual CU 29 Mobile New Relic Mobile's pricing structure allows 100,000 monthly active users per account at the Enterprise subscription level. Data retention varies by subscription level. Use the product ID's integer format to identify the subscription level. Mobile subscription level Product ID Lite 10 Enterprise 13 Enterprise Annual 14 Insights New Relic Insights bases the pricing structure on the number of allowable events stored and the associated data retention policy (for example, data retention for Insights Free is one day). Note that the data_retention attribute is required. Insights subscription level Product ID Free 15 None 16 Pro 18 Pro Annual 19 Browser New Relic Browser's pricing structure allows an unlimited number of app users, regardless of subscription level. However, the number of allowable page views per month and the data retention period vary by subscription level. For example: Lite accounts include an unlimited number of page views per month and 24-hour data retention. Pro account pricing starts at 500,000 page views per month and three months data retention. Use the product ID's integer format to identify the subscription level. Browser subscription level Product ID Lite 20 Pro 21 Pro Annual 22 Synthetics With New Relic Synthetics' pricing structure, the default number of allowable monitoring checks and the data retention period vary by subscription level. Use the product ID's integer format to identify the subscription level. Synthetics subscription level Product ID Lite 23 Pro 24 Pro Annual 25 Tip If you previously used the deprecated Partnership availability monitoring API, you can use the Synthetics API to provision a check and the REST API for New Relic Alerts to create an alert notification for your customers. Infrastructure With New Relic's Infrastructure pricing structure, the default number of instances and the data retention period vary by subscription level. Infrastructure events do not count against your New Relic Insights quota, even though you can query them in Insights. New Relic Infrastructure offers pricing plans based on Compute Units (CU) only. Use the product ID's integer format to identify the subscription level. Infrastructure subscription level Product ID Infrastructure None 31 Infrastructure Pro (CU) 32 Infrastructure Pro Annual (CU) 33 Infrastructure Essentials (CU) 34 Infrastructure Essentials Annual (CU) 35 Subscription API calls Before using this, first read Requirements. Here are the URL patterns for subscription-related API functions. If used, send them along with the JSON object and an HTTP header containing the Partner API key. For example: GET .../api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all subscriptions of an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Show a subscription for an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/ID Copy Replace the current subscription level with a new subscription. POST /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Subscription API examples Here are examples of an API call to create an original pricing model subscription and the JSON response listing subscriptions for the account. Example subscription object { \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 2 }, { \"product_id\": 13, \"quantity\": 2 } ] } Copy Example JSON response { \"id\": 1069012, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 2, \"price\": 218.0 }, { \"product_id\": 13, \"name\": \"Mobile Enterprise\", \"units\": 2, \"price\": 1500.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 15, \"name\": \"Insights Free\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Subscription status Here are some original pricing model subscription status values that the API call may return. Subscription status Description pending The customer has signed up for a New Relic product, but payment still needs to be processed. authorized A credit card has been authorized and the vault key stored, but payment has not been captured. free This subscription is for a free New Relic product. No further processing is required. paid A payment has been captured and the next payment date has been set. payment_declined The last attempt to authorize payment failed. canceled The New Relic account has no active subscription and is not active. No payments should be authorized or captured. replaced This subscription has been superseded by another New Relic subscription. API examples (v2) Here are API example requests and responses to list, show, create, and update original pricing model subscriptions. Line breaks in responses are for readability. The actual responses appear as a continuous line. List Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"subscriptions\": [ { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/SUBSCRIPTION_ID Copy Response: { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Create new (replace existing subscription) Here is an example of how to use the Partnership API create a new subscription (replace the existing subscription level for all products) for the account. Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"subscriptions\":[{\"product_id\":\"1\", \"quantity\":1}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"id\": 1069068, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.46887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> subscription object",
        "sections": "<em>Partnership</em> <em>API</em> subscription object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This doc explains how to use the <em>Partnership</em> <em>API</em> to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you&#x27;re on our original pricing model. It doesn&#x27;t support accounts on our <em>New</em> <em>Relic</em> One pricing model. For more on this, read"
      },
      "id": "603ebc5f28ccbcf81deba7a5"
    },
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2022-01-12T05:53:53Z",
      "updated_at": "2021-11-15T09:43:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing model: ignore this field because it applies to the original pricing model, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing model. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing models. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing model and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " that is on our <em>New</em> <em>Relic</em> One pricing and our <em>New</em> <em>Relic</em> One user model. For more on restrictions on <em>API</em> use, see requirements. curl -X POST \\ -H &#x27;x-<em>api</em>-key:<em>PARTNER</em>_ACCOUNT_KEY&#x27; \\ -H &#x27;Content-Type:application&#x2F;json&#x27; \\ -d &#x27;{&quot;account&quot;:{&quot;name&quot;:&quot;Sample account&quot;}}&#x27; \\ https:&#x2F;&#x2F;rpm.newrelic.com&#x2F;<em>api</em>&#x2F;v2&#x2F;partners"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Product buckets",
        "Requirements",
        "Overview (#overview)",
        "Quantity by product",
        "Insights Events quantity",
        "Browser PageViews quantity",
        "Synthetics Checks quantity"
      ],
      "title": "Product buckets",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "fe7632af0936f9878b04ba0c25f7cf8a7f684399",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/product-buckets/",
      "published_at": "2022-01-12T05:55:20Z",
      "updated_at": "2021-11-15T09:27:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For partnership accounts on our original product pricing, you can use the Partnership API for managing subscriptions. This doc explains some details for using the Browser, Synthetics, and Insights products. Requirements This doc applies only for partnership accounts on our original pricing model. Before using this API, please read the Partnership API requirements. Overview (#overview) When using the Partnership API for Insights, Browser, and Synthetics products, you must provide a valid quantity value. This indicates the number of Insights Events, Browser PageViews, and Synthetics Checks provisioned to that account. New Relic uses this \"bucket\" pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the New Relic Partnership API will return an error response. Quantity by product Here are the valid quantity values by New Relic product. Insights Events quantity Insights Pro Insights Pro Annual 25 25 50 50 75 75 300 300 625 625 1250 1250 2500 2500 5000 5000 10000 10000 20000 20000 40000 40000 60000 60000 80000 80000 100000 100000 120000 120000 140000 140000 Browser PageViews quantity Browser Pro Browser Pro Annual 100000 100000 250000 250000 500000 500000 1000000 1000000 1500000 1500000 2000000 2000000 2500000 2500000 3000000 3000000 4000000 4000000 5000000 5000000 6000000 6000000 7000000 7000000 7500000 7500000 8000000 8000000 9000000 9000000 10000000 10000000 12500000 12500000 15000000 15000000 20000000 20000000 25000000 25000000 30000000 30000000 35000000 35000000 40000000 40000000 50000000 50000000 75000000 75000000 100000000 100000000 125000000 125000000 150000000 150000000 175000000 175000000 200000000 200000000 250000000 250000000 300000000 300000000 350000000 350000000 400000000 400000000 450000000 450000000 500000000 500000000 600000000 600000000 700000000 700000000 800000000 800000000 900000000 900000000 1000000000 1000000000 1250000000 1250000000 1500000000 1500000000 2000000000 2000000000 2500000000 2500000000 3000000000 3000000000 4000000000 4000000000 5000000000 5000000000 10000000000 10000000000 Synthetics Checks quantity Synthetics Pro Synthetics Pro Annual 10000 10000 15000 15000 25000 25000 35000 35000 50000 50000 75000 75000 100000 100000 150000 150000 250000 250000 300000 300000 400000 400000 500000 500000 600000 600000 750000 750000 900000 900000 1000000 1000000 1150000 1150000 1300000 1300000 1500000 1500000 1750000 1750000 2000000 2000000 2500000 2500000 3000000 3000000 3500000 3500000 5000000 5000000 7000000 7000000 8500000 8500000 10000000 10000000 12500000 12500000 14000000 14000000 15000000 15000000 17500000 17500000 20000000 20000000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.95393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " provisioned to that account. <em>New</em> <em>Relic</em> uses this &quot;bucket&quot; pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the <em>New</em> <em>Relic</em> <em>Partnership</em> <em>API</em> will return an error response. Quantity by product Here"
      },
      "id": "6044181d28ccbc2ea42c608a"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-subscription-object": [
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2022-01-12T05:53:53Z",
      "updated_at": "2021-11-15T09:43:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing model: ignore this field because it applies to the original pricing model, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing model. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing models. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing model and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " that is on our <em>New</em> <em>Relic</em> One pricing and our <em>New</em> <em>Relic</em> One user model. For more on restrictions on <em>API</em> use, see requirements. curl -X POST \\ -H &#x27;x-<em>api</em>-key:<em>PARTNER</em>_ACCOUNT_KEY&#x27; \\ -H &#x27;Content-Type:application&#x2F;json&#x27; \\ -d &#x27;{&quot;account&quot;:{&quot;name&quot;:&quot;Sample account&quot;}}&#x27; \\ https:&#x2F;&#x2F;rpm.newrelic.com&#x2F;<em>api</em>&#x2F;v2&#x2F;partners"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Product buckets",
        "Requirements",
        "Overview (#overview)",
        "Quantity by product",
        "Insights Events quantity",
        "Browser PageViews quantity",
        "Synthetics Checks quantity"
      ],
      "title": "Product buckets",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "fe7632af0936f9878b04ba0c25f7cf8a7f684399",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/product-buckets/",
      "published_at": "2022-01-12T05:55:20Z",
      "updated_at": "2021-11-15T09:27:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For partnership accounts on our original product pricing, you can use the Partnership API for managing subscriptions. This doc explains some details for using the Browser, Synthetics, and Insights products. Requirements This doc applies only for partnership accounts on our original pricing model. Before using this API, please read the Partnership API requirements. Overview (#overview) When using the Partnership API for Insights, Browser, and Synthetics products, you must provide a valid quantity value. This indicates the number of Insights Events, Browser PageViews, and Synthetics Checks provisioned to that account. New Relic uses this \"bucket\" pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the New Relic Partnership API will return an error response. Quantity by product Here are the valid quantity values by New Relic product. Insights Events quantity Insights Pro Insights Pro Annual 25 25 50 50 75 75 300 300 625 625 1250 1250 2500 2500 5000 5000 10000 10000 20000 20000 40000 40000 60000 60000 80000 80000 100000 100000 120000 120000 140000 140000 Browser PageViews quantity Browser Pro Browser Pro Annual 100000 100000 250000 250000 500000 500000 1000000 1000000 1500000 1500000 2000000 2000000 2500000 2500000 3000000 3000000 4000000 4000000 5000000 5000000 6000000 6000000 7000000 7000000 7500000 7500000 8000000 8000000 9000000 9000000 10000000 10000000 12500000 12500000 15000000 15000000 20000000 20000000 25000000 25000000 30000000 30000000 35000000 35000000 40000000 40000000 50000000 50000000 75000000 75000000 100000000 100000000 125000000 125000000 150000000 150000000 175000000 175000000 200000000 200000000 250000000 250000000 300000000 300000000 350000000 350000000 400000000 400000000 450000000 450000000 500000000 500000000 600000000 600000000 700000000 700000000 800000000 800000000 900000000 900000000 1000000000 1000000000 1250000000 1250000000 1500000000 1500000000 2000000000 2000000000 2500000000 2500000000 3000000000 3000000000 4000000000 4000000000 5000000000 5000000000 10000000000 10000000000 Synthetics Checks quantity Synthetics Pro Synthetics Pro Annual 10000 10000 15000 15000 25000 25000 35000 35000 50000 50000 75000 75000 100000 100000 150000 150000 250000 250000 300000 300000 400000 400000 500000 500000 600000 600000 750000 750000 900000 900000 1000000 1000000 1150000 1150000 1300000 1300000 1500000 1500000 1750000 1750000 2000000 2000000 2500000 2500000 3000000 3000000 3500000 3500000 5000000 5000000 7000000 7000000 8500000 8500000 10000000 10000000 12500000 12500000 14000000 14000000 15000000 15000000 17500000 17500000 20000000 20000000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.95393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " provisioned to that account. <em>New</em> <em>Relic</em> uses this &quot;bucket&quot; pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the <em>New</em> <em>Relic</em> <em>Partnership</em> <em>API</em> will return an error response. Quantity by product Here"
      },
      "id": "6044181d28ccbc2ea42c608a"
    },
    {
      "sections": [
        "Partnership API child account object",
        "Requirements",
        "Introduction to using child accounts",
        "Child account object attributes",
        "name (REQUIRED)",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "password (REQUIRED)",
        "Child account API calls",
        "JSON example",
        "Child account object JSON request",
        "JSON response",
        "Child account object API examples",
        "Create"
      ],
      "title": "Partnership API child account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "7fb13302d892a5f89c6c9371f35a60bf1ed9f6a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-sub-account-object/",
      "published_at": "2022-01-12T05:53:54Z",
      "updated_at": "2021-07-02T13:14:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage child accounts. For accounts, you'd use the child account object. Requirements You may not have access to using this object. Before using the Partnership API, first read the requirements. Introduction to using child accounts Some notes about using the child account object: To manage existing parent accounts or child accounts, use the Partnership API account object. A parent account may have more than one associated child account, but every chld account must correspond to one and only one parent account. Every child account must have at least a primary_admin user. You cannot create a child account without connecting it to an existing parent account and adding at least one user. Child account object attributes Before using the Partnership API, first read the requirements. Here are the Partnership API child account object's attributes: name (REQUIRED) Type: String Default: (none) This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you create the child account, you can define only one user: the account Owner. To add additional users, use the Partnership API user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user's current password. For some New Relic organizations, child accounts can also be created via the parent account's Account settings page in the New Relic UI. Child account API calls Here is the URL pattern to create child accounts. Notice that the Parent Account ID must be specified. If using this URL pattern, send the JSON object along with an HTTP header containing the Partner API key. For example: POST .../api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts​ x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern Create a child account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy JSON example Here is an example of a JSON request and response using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Child account object JSON request { \"account\": { \"name\": \"Sample child account\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Child account object API examples Here is an example of an API call using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Create Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"sub_account\":{\"name\":\"Sample child account\"}, \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample child account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": false, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.90009,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> child account object",
        "sections": "<em>Partnership</em> <em>API</em> child account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " additional users, use the <em>Partnership</em> <em>API</em> user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user&#x27;s current password. For some <em>New</em> <em>Relic</em>"
      },
      "id": "603eba3ae7b9d2b8e32a07b5"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-user-object": [
    {
      "sections": [
        "Partnership API subscription object",
        "Requirements",
        "Subscription object attributes",
        "product_id (REQUIRED for new subscriptions)",
        "quantity (REQUIRED for new subscriptions)",
        "promo_code",
        "data_retention (required only for Insights subscriptions)",
        "Mapping for products (product_id)",
        "Important",
        "APM",
        "Mobile",
        "Insights",
        "Browser",
        "Synthetics",
        "Tip",
        "Infrastructure",
        "Subscription API calls",
        "Subscription API examples",
        "Example subscription object",
        "Example JSON response",
        "Subscription status",
        "API examples (v2)",
        "List",
        "Show",
        "Create new (replace existing subscription)"
      ],
      "title": "Partnership API subscription object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "05b65e48cf5ed981c3eb79a3b31332f452dd5b2d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-subscription-object/",
      "published_at": "2022-01-12T05:54:34Z",
      "updated_at": "2021-12-10T08:15:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you're on our original pricing model. It doesn't support accounts on our New Relic One pricing model. For more on this, read the Partnership API requirements. The Partnership API doesn't allow you to upgrade or downgrade individual product subscriptions for an account. Instead, the API requires you to replace (add) the configuration for all product subscriptions for the account. If any product configurations are not included, the New Relic Partnership API provisions the account with the best free product type available. The API automatically selects the product level based on the configuration and custom pricing for the account's partnership. Subscription object attributes Before using this, first read Requirements. Here are the subscription object's attributes: product_id (REQUIRED for new subscriptions) Type: Integer Default: (none) The product ID attribute identifies the New Relic product being defined for this subscription. It is required for Create calls. quantity (REQUIRED for new subscriptions) Type: Integer Default: (none) The quantity attribute is required for Create calls, even if a product level is unlimited. The API will ignore the quantity value entered for unlimited product subscriptions, such as New Relic APM Lite. New Relic Insights, Browser, and Synthetics require you to identify a predefined usage level (product bucket). This allows the API to apply a pricing discount based on the specific quantity you select. The quantity you identify must be an exact match for the product and subscription level. For a list of available product buckets, see: Browser PageViews Insights Events Synthetics Checks promo_code Type: String Default: (none) Any related promotional code for this subscription. Not yet supported through the Partnership API's subscription endpoint. However, you can pass the promo_code as part of the subscription with the account API's Create call. data_retention (required only for Insights subscriptions) Type: Integer Default: (none) Number of weeks the Insights event information will be retained. Mapping for products (product_id) With each account creation call, you must supply at least one New Relic product type. The API only accepts the numeric product_id for the type. Important Reminder that the subscription object only applies for accounts using our original pricing model. Also, creating subscriptions for Serverless, Logs, and Traces is not supported by the Partnership API. If your account has these subscriptions, any attempt to make changes will return an error. Please contact your account executive to modify subscriptions. Important New Startup and Small Business service plans no longer are available through the New Relic Partnership API. APM The number of allowable hosts per account and the data retention period vary by subscription level within New Relic APM's pricing structure. For example, New Relic APM allows an unlimited number of allowable hosts for Lite accounts but only a 24-hour data retention period. In addition, pricing and data retention depend on whether you select pricing models based on hosts or compute units (CU). Use the product ID's integer format to identify the subscription level and type of plan. APM subscription level Product ID Lite 1 Standard 2 Standard Annual 3 Pro (Host) 4 Pro Annual (Host) 5 Enterprise 6 Enterprise Annual 7 APM Essentials (Host) 8 APM Essentials Annual (Host) 9 If you select pricing plans based on compute units (CU), use these product ID integer formats to identify the subscription level and type of plan. APM Compute Units (CU) subscription level Product ID Pro CU 26 Pro Annual CU 27 APM Essentials CU 28 APM Essentials Annual CU 29 Mobile New Relic Mobile's pricing structure allows 100,000 monthly active users per account at the Enterprise subscription level. Data retention varies by subscription level. Use the product ID's integer format to identify the subscription level. Mobile subscription level Product ID Lite 10 Enterprise 13 Enterprise Annual 14 Insights New Relic Insights bases the pricing structure on the number of allowable events stored and the associated data retention policy (for example, data retention for Insights Free is one day). Note that the data_retention attribute is required. Insights subscription level Product ID Free 15 None 16 Pro 18 Pro Annual 19 Browser New Relic Browser's pricing structure allows an unlimited number of app users, regardless of subscription level. However, the number of allowable page views per month and the data retention period vary by subscription level. For example: Lite accounts include an unlimited number of page views per month and 24-hour data retention. Pro account pricing starts at 500,000 page views per month and three months data retention. Use the product ID's integer format to identify the subscription level. Browser subscription level Product ID Lite 20 Pro 21 Pro Annual 22 Synthetics With New Relic Synthetics' pricing structure, the default number of allowable monitoring checks and the data retention period vary by subscription level. Use the product ID's integer format to identify the subscription level. Synthetics subscription level Product ID Lite 23 Pro 24 Pro Annual 25 Tip If you previously used the deprecated Partnership availability monitoring API, you can use the Synthetics API to provision a check and the REST API for New Relic Alerts to create an alert notification for your customers. Infrastructure With New Relic's Infrastructure pricing structure, the default number of instances and the data retention period vary by subscription level. Infrastructure events do not count against your New Relic Insights quota, even though you can query them in Insights. New Relic Infrastructure offers pricing plans based on Compute Units (CU) only. Use the product ID's integer format to identify the subscription level. Infrastructure subscription level Product ID Infrastructure None 31 Infrastructure Pro (CU) 32 Infrastructure Pro Annual (CU) 33 Infrastructure Essentials (CU) 34 Infrastructure Essentials Annual (CU) 35 Subscription API calls Before using this, first read Requirements. Here are the URL patterns for subscription-related API functions. If used, send them along with the JSON object and an HTTP header containing the Partner API key. For example: GET .../api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all subscriptions of an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Show a subscription for an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/ID Copy Replace the current subscription level with a new subscription. POST /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Subscription API examples Here are examples of an API call to create an original pricing model subscription and the JSON response listing subscriptions for the account. Example subscription object { \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 2 }, { \"product_id\": 13, \"quantity\": 2 } ] } Copy Example JSON response { \"id\": 1069012, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 2, \"price\": 218.0 }, { \"product_id\": 13, \"name\": \"Mobile Enterprise\", \"units\": 2, \"price\": 1500.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 15, \"name\": \"Insights Free\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Subscription status Here are some original pricing model subscription status values that the API call may return. Subscription status Description pending The customer has signed up for a New Relic product, but payment still needs to be processed. authorized A credit card has been authorized and the vault key stored, but payment has not been captured. free This subscription is for a free New Relic product. No further processing is required. paid A payment has been captured and the next payment date has been set. payment_declined The last attempt to authorize payment failed. canceled The New Relic account has no active subscription and is not active. No payments should be authorized or captured. replaced This subscription has been superseded by another New Relic subscription. API examples (v2) Here are API example requests and responses to list, show, create, and update original pricing model subscriptions. Line breaks in responses are for readability. The actual responses appear as a continuous line. List Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"subscriptions\": [ { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/SUBSCRIPTION_ID Copy Response: { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Create new (replace existing subscription) Here is an example of how to use the Partnership API create a new subscription (replace the existing subscription level for all products) for the account. Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"subscriptions\":[{\"product_id\":\"1\", \"quantity\":1}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"id\": 1069068, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.46887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> subscription object",
        "sections": "<em>Partnership</em> <em>API</em> subscription object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This doc explains how to use the <em>Partnership</em> <em>API</em> to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you&#x27;re on our original pricing model. It doesn&#x27;t support accounts on our <em>New</em> <em>Relic</em> One pricing model. For more on this, read"
      },
      "id": "603ebc5f28ccbcf81deba7a5"
    },
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2022-01-12T05:53:53Z",
      "updated_at": "2021-11-15T09:43:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing model: ignore this field because it applies to the original pricing model, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing model. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing models. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing model and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " that is on our <em>New</em> <em>Relic</em> One pricing and our <em>New</em> <em>Relic</em> One user model. For more on restrictions on <em>API</em> use, see requirements. curl -X POST \\ -H &#x27;x-<em>api</em>-key:<em>PARTNER</em>_ACCOUNT_KEY&#x27; \\ -H &#x27;Content-Type:application&#x2F;json&#x27; \\ -d &#x27;{&quot;account&quot;:{&quot;name&quot;:&quot;Sample account&quot;}}&#x27; \\ https:&#x2F;&#x2F;rpm.newrelic.com&#x2F;<em>api</em>&#x2F;v2&#x2F;partners"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Product buckets",
        "Requirements",
        "Overview (#overview)",
        "Quantity by product",
        "Insights Events quantity",
        "Browser PageViews quantity",
        "Synthetics Checks quantity"
      ],
      "title": "Product buckets",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "fe7632af0936f9878b04ba0c25f7cf8a7f684399",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/product-buckets/",
      "published_at": "2022-01-12T05:55:20Z",
      "updated_at": "2021-11-15T09:27:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For partnership accounts on our original product pricing, you can use the Partnership API for managing subscriptions. This doc explains some details for using the Browser, Synthetics, and Insights products. Requirements This doc applies only for partnership accounts on our original pricing model. Before using this API, please read the Partnership API requirements. Overview (#overview) When using the Partnership API for Insights, Browser, and Synthetics products, you must provide a valid quantity value. This indicates the number of Insights Events, Browser PageViews, and Synthetics Checks provisioned to that account. New Relic uses this \"bucket\" pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the New Relic Partnership API will return an error response. Quantity by product Here are the valid quantity values by New Relic product. Insights Events quantity Insights Pro Insights Pro Annual 25 25 50 50 75 75 300 300 625 625 1250 1250 2500 2500 5000 5000 10000 10000 20000 20000 40000 40000 60000 60000 80000 80000 100000 100000 120000 120000 140000 140000 Browser PageViews quantity Browser Pro Browser Pro Annual 100000 100000 250000 250000 500000 500000 1000000 1000000 1500000 1500000 2000000 2000000 2500000 2500000 3000000 3000000 4000000 4000000 5000000 5000000 6000000 6000000 7000000 7000000 7500000 7500000 8000000 8000000 9000000 9000000 10000000 10000000 12500000 12500000 15000000 15000000 20000000 20000000 25000000 25000000 30000000 30000000 35000000 35000000 40000000 40000000 50000000 50000000 75000000 75000000 100000000 100000000 125000000 125000000 150000000 150000000 175000000 175000000 200000000 200000000 250000000 250000000 300000000 300000000 350000000 350000000 400000000 400000000 450000000 450000000 500000000 500000000 600000000 600000000 700000000 700000000 800000000 800000000 900000000 900000000 1000000000 1000000000 1250000000 1250000000 1500000000 1500000000 2000000000 2000000000 2500000000 2500000000 3000000000 3000000000 4000000000 4000000000 5000000000 5000000000 10000000000 10000000000 Synthetics Checks quantity Synthetics Pro Synthetics Pro Annual 10000 10000 15000 15000 25000 25000 35000 35000 50000 50000 75000 75000 100000 100000 150000 150000 250000 250000 300000 300000 400000 400000 500000 500000 600000 600000 750000 750000 900000 900000 1000000 1000000 1150000 1150000 1300000 1300000 1500000 1500000 1750000 1750000 2000000 2000000 2500000 2500000 3000000 3000000 3500000 3500000 5000000 5000000 7000000 7000000 8500000 8500000 10000000 10000000 12500000 12500000 14000000 14000000 15000000 15000000 17500000 17500000 20000000 20000000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.95393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " provisioned to that account. <em>New</em> <em>Relic</em> uses this &quot;bucket&quot; pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the <em>New</em> <em>Relic</em> <em>Partnership</em> <em>API</em> will return an error response. Quantity by product Here"
      },
      "id": "6044181d28ccbc2ea42c608a"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/partnership-billing-integration-api": [
    {
      "sections": [
        "Partnership API subscription object",
        "Requirements",
        "Subscription object attributes",
        "product_id (REQUIRED for new subscriptions)",
        "quantity (REQUIRED for new subscriptions)",
        "promo_code",
        "data_retention (required only for Insights subscriptions)",
        "Mapping for products (product_id)",
        "Important",
        "APM",
        "Mobile",
        "Insights",
        "Browser",
        "Synthetics",
        "Tip",
        "Infrastructure",
        "Subscription API calls",
        "Subscription API examples",
        "Example subscription object",
        "Example JSON response",
        "Subscription status",
        "API examples (v2)",
        "List",
        "Show",
        "Create new (replace existing subscription)"
      ],
      "title": "Partnership API subscription object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "05b65e48cf5ed981c3eb79a3b31332f452dd5b2d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-subscription-object/",
      "published_at": "2022-01-12T05:54:34Z",
      "updated_at": "2021-12-10T08:15:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you're on our original pricing model. It doesn't support accounts on our New Relic One pricing model. For more on this, read the Partnership API requirements. The Partnership API doesn't allow you to upgrade or downgrade individual product subscriptions for an account. Instead, the API requires you to replace (add) the configuration for all product subscriptions for the account. If any product configurations are not included, the New Relic Partnership API provisions the account with the best free product type available. The API automatically selects the product level based on the configuration and custom pricing for the account's partnership. Subscription object attributes Before using this, first read Requirements. Here are the subscription object's attributes: product_id (REQUIRED for new subscriptions) Type: Integer Default: (none) The product ID attribute identifies the New Relic product being defined for this subscription. It is required for Create calls. quantity (REQUIRED for new subscriptions) Type: Integer Default: (none) The quantity attribute is required for Create calls, even if a product level is unlimited. The API will ignore the quantity value entered for unlimited product subscriptions, such as New Relic APM Lite. New Relic Insights, Browser, and Synthetics require you to identify a predefined usage level (product bucket). This allows the API to apply a pricing discount based on the specific quantity you select. The quantity you identify must be an exact match for the product and subscription level. For a list of available product buckets, see: Browser PageViews Insights Events Synthetics Checks promo_code Type: String Default: (none) Any related promotional code for this subscription. Not yet supported through the Partnership API's subscription endpoint. However, you can pass the promo_code as part of the subscription with the account API's Create call. data_retention (required only for Insights subscriptions) Type: Integer Default: (none) Number of weeks the Insights event information will be retained. Mapping for products (product_id) With each account creation call, you must supply at least one New Relic product type. The API only accepts the numeric product_id for the type. Important Reminder that the subscription object only applies for accounts using our original pricing model. Also, creating subscriptions for Serverless, Logs, and Traces is not supported by the Partnership API. If your account has these subscriptions, any attempt to make changes will return an error. Please contact your account executive to modify subscriptions. Important New Startup and Small Business service plans no longer are available through the New Relic Partnership API. APM The number of allowable hosts per account and the data retention period vary by subscription level within New Relic APM's pricing structure. For example, New Relic APM allows an unlimited number of allowable hosts for Lite accounts but only a 24-hour data retention period. In addition, pricing and data retention depend on whether you select pricing models based on hosts or compute units (CU). Use the product ID's integer format to identify the subscription level and type of plan. APM subscription level Product ID Lite 1 Standard 2 Standard Annual 3 Pro (Host) 4 Pro Annual (Host) 5 Enterprise 6 Enterprise Annual 7 APM Essentials (Host) 8 APM Essentials Annual (Host) 9 If you select pricing plans based on compute units (CU), use these product ID integer formats to identify the subscription level and type of plan. APM Compute Units (CU) subscription level Product ID Pro CU 26 Pro Annual CU 27 APM Essentials CU 28 APM Essentials Annual CU 29 Mobile New Relic Mobile's pricing structure allows 100,000 monthly active users per account at the Enterprise subscription level. Data retention varies by subscription level. Use the product ID's integer format to identify the subscription level. Mobile subscription level Product ID Lite 10 Enterprise 13 Enterprise Annual 14 Insights New Relic Insights bases the pricing structure on the number of allowable events stored and the associated data retention policy (for example, data retention for Insights Free is one day). Note that the data_retention attribute is required. Insights subscription level Product ID Free 15 None 16 Pro 18 Pro Annual 19 Browser New Relic Browser's pricing structure allows an unlimited number of app users, regardless of subscription level. However, the number of allowable page views per month and the data retention period vary by subscription level. For example: Lite accounts include an unlimited number of page views per month and 24-hour data retention. Pro account pricing starts at 500,000 page views per month and three months data retention. Use the product ID's integer format to identify the subscription level. Browser subscription level Product ID Lite 20 Pro 21 Pro Annual 22 Synthetics With New Relic Synthetics' pricing structure, the default number of allowable monitoring checks and the data retention period vary by subscription level. Use the product ID's integer format to identify the subscription level. Synthetics subscription level Product ID Lite 23 Pro 24 Pro Annual 25 Tip If you previously used the deprecated Partnership availability monitoring API, you can use the Synthetics API to provision a check and the REST API for New Relic Alerts to create an alert notification for your customers. Infrastructure With New Relic's Infrastructure pricing structure, the default number of instances and the data retention period vary by subscription level. Infrastructure events do not count against your New Relic Insights quota, even though you can query them in Insights. New Relic Infrastructure offers pricing plans based on Compute Units (CU) only. Use the product ID's integer format to identify the subscription level. Infrastructure subscription level Product ID Infrastructure None 31 Infrastructure Pro (CU) 32 Infrastructure Pro Annual (CU) 33 Infrastructure Essentials (CU) 34 Infrastructure Essentials Annual (CU) 35 Subscription API calls Before using this, first read Requirements. Here are the URL patterns for subscription-related API functions. If used, send them along with the JSON object and an HTTP header containing the Partner API key. For example: GET .../api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all subscriptions of an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Show a subscription for an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/ID Copy Replace the current subscription level with a new subscription. POST /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Subscription API examples Here are examples of an API call to create an original pricing model subscription and the JSON response listing subscriptions for the account. Example subscription object { \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 2 }, { \"product_id\": 13, \"quantity\": 2 } ] } Copy Example JSON response { \"id\": 1069012, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 2, \"price\": 218.0 }, { \"product_id\": 13, \"name\": \"Mobile Enterprise\", \"units\": 2, \"price\": 1500.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 15, \"name\": \"Insights Free\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Subscription status Here are some original pricing model subscription status values that the API call may return. Subscription status Description pending The customer has signed up for a New Relic product, but payment still needs to be processed. authorized A credit card has been authorized and the vault key stored, but payment has not been captured. free This subscription is for a free New Relic product. No further processing is required. paid A payment has been captured and the next payment date has been set. payment_declined The last attempt to authorize payment failed. canceled The New Relic account has no active subscription and is not active. No payments should be authorized or captured. replaced This subscription has been superseded by another New Relic subscription. API examples (v2) Here are API example requests and responses to list, show, create, and update original pricing model subscriptions. Line breaks in responses are for readability. The actual responses appear as a continuous line. List Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"subscriptions\": [ { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/SUBSCRIPTION_ID Copy Response: { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Create new (replace existing subscription) Here is an example of how to use the Partnership API create a new subscription (replace the existing subscription level for all products) for the account. Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"subscriptions\":[{\"product_id\":\"1\", \"quantity\":1}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"id\": 1069068, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.46886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> subscription object",
        "sections": "<em>Partnership</em> <em>API</em> subscription object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This doc explains how to use the <em>Partnership</em> <em>API</em> to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you&#x27;re on our original pricing model. It doesn&#x27;t support accounts on our <em>New</em> <em>Relic</em> One pricing model. For more on this, read"
      },
      "id": "603ebc5f28ccbcf81deba7a5"
    },
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2022-01-12T05:53:53Z",
      "updated_at": "2021-11-15T09:43:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing model: ignore this field because it applies to the original pricing model, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing model. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing models. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing model and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " that is on our <em>New</em> <em>Relic</em> One pricing and our <em>New</em> <em>Relic</em> One user model. For more on restrictions on <em>API</em> use, see requirements. curl -X POST \\ -H &#x27;x-<em>api</em>-key:<em>PARTNER</em>_ACCOUNT_KEY&#x27; \\ -H &#x27;Content-Type:application&#x2F;json&#x27; \\ -d &#x27;{&quot;account&quot;:{&quot;name&quot;:&quot;Sample account&quot;}}&#x27; \\ https:&#x2F;&#x2F;rpm.newrelic.com&#x2F;<em>api</em>&#x2F;v2&#x2F;partners"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Product buckets",
        "Requirements",
        "Overview (#overview)",
        "Quantity by product",
        "Insights Events quantity",
        "Browser PageViews quantity",
        "Synthetics Checks quantity"
      ],
      "title": "Product buckets",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "fe7632af0936f9878b04ba0c25f7cf8a7f684399",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/product-buckets/",
      "published_at": "2022-01-12T05:55:20Z",
      "updated_at": "2021-11-15T09:27:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For partnership accounts on our original product pricing, you can use the Partnership API for managing subscriptions. This doc explains some details for using the Browser, Synthetics, and Insights products. Requirements This doc applies only for partnership accounts on our original pricing model. Before using this API, please read the Partnership API requirements. Overview (#overview) When using the Partnership API for Insights, Browser, and Synthetics products, you must provide a valid quantity value. This indicates the number of Insights Events, Browser PageViews, and Synthetics Checks provisioned to that account. New Relic uses this \"bucket\" pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the New Relic Partnership API will return an error response. Quantity by product Here are the valid quantity values by New Relic product. Insights Events quantity Insights Pro Insights Pro Annual 25 25 50 50 75 75 300 300 625 625 1250 1250 2500 2500 5000 5000 10000 10000 20000 20000 40000 40000 60000 60000 80000 80000 100000 100000 120000 120000 140000 140000 Browser PageViews quantity Browser Pro Browser Pro Annual 100000 100000 250000 250000 500000 500000 1000000 1000000 1500000 1500000 2000000 2000000 2500000 2500000 3000000 3000000 4000000 4000000 5000000 5000000 6000000 6000000 7000000 7000000 7500000 7500000 8000000 8000000 9000000 9000000 10000000 10000000 12500000 12500000 15000000 15000000 20000000 20000000 25000000 25000000 30000000 30000000 35000000 35000000 40000000 40000000 50000000 50000000 75000000 75000000 100000000 100000000 125000000 125000000 150000000 150000000 175000000 175000000 200000000 200000000 250000000 250000000 300000000 300000000 350000000 350000000 400000000 400000000 450000000 450000000 500000000 500000000 600000000 600000000 700000000 700000000 800000000 800000000 900000000 900000000 1000000000 1000000000 1250000000 1250000000 1500000000 1500000000 2000000000 2000000000 2500000000 2500000000 3000000000 3000000000 4000000000 4000000000 5000000000 5000000000 10000000000 10000000000 Synthetics Checks quantity Synthetics Pro Synthetics Pro Annual 10000 10000 15000 15000 25000 25000 35000 35000 50000 50000 75000 75000 100000 100000 150000 150000 250000 250000 300000 300000 400000 400000 500000 500000 600000 600000 750000 750000 900000 900000 1000000 1000000 1150000 1150000 1300000 1300000 1500000 1500000 1750000 1750000 2000000 2000000 2500000 2500000 3000000 3000000 3500000 3500000 5000000 5000000 7000000 7000000 8500000 8500000 10000000 10000000 12500000 12500000 14000000 14000000 15000000 15000000 17500000 17500000 20000000 20000000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.95393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " provisioned to that account. <em>New</em> <em>Relic</em> uses this &quot;bucket&quot; pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the <em>New</em> <em>Relic</em> <em>Partnership</em> <em>API</em> will return an error response. Quantity by product Here"
      },
      "id": "6044181d28ccbc2ea42c608a"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/product-buckets": [
    {
      "sections": [
        "Partnership API subscription object",
        "Requirements",
        "Subscription object attributes",
        "product_id (REQUIRED for new subscriptions)",
        "quantity (REQUIRED for new subscriptions)",
        "promo_code",
        "data_retention (required only for Insights subscriptions)",
        "Mapping for products (product_id)",
        "Important",
        "APM",
        "Mobile",
        "Insights",
        "Browser",
        "Synthetics",
        "Tip",
        "Infrastructure",
        "Subscription API calls",
        "Subscription API examples",
        "Example subscription object",
        "Example JSON response",
        "Subscription status",
        "API examples (v2)",
        "List",
        "Show",
        "Create new (replace existing subscription)"
      ],
      "title": "Partnership API subscription object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "05b65e48cf5ed981c3eb79a3b31332f452dd5b2d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-subscription-object/",
      "published_at": "2022-01-12T05:54:34Z",
      "updated_at": "2021-12-10T08:15:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you're on our original pricing model. It doesn't support accounts on our New Relic One pricing model. For more on this, read the Partnership API requirements. The Partnership API doesn't allow you to upgrade or downgrade individual product subscriptions for an account. Instead, the API requires you to replace (add) the configuration for all product subscriptions for the account. If any product configurations are not included, the New Relic Partnership API provisions the account with the best free product type available. The API automatically selects the product level based on the configuration and custom pricing for the account's partnership. Subscription object attributes Before using this, first read Requirements. Here are the subscription object's attributes: product_id (REQUIRED for new subscriptions) Type: Integer Default: (none) The product ID attribute identifies the New Relic product being defined for this subscription. It is required for Create calls. quantity (REQUIRED for new subscriptions) Type: Integer Default: (none) The quantity attribute is required for Create calls, even if a product level is unlimited. The API will ignore the quantity value entered for unlimited product subscriptions, such as New Relic APM Lite. New Relic Insights, Browser, and Synthetics require you to identify a predefined usage level (product bucket). This allows the API to apply a pricing discount based on the specific quantity you select. The quantity you identify must be an exact match for the product and subscription level. For a list of available product buckets, see: Browser PageViews Insights Events Synthetics Checks promo_code Type: String Default: (none) Any related promotional code for this subscription. Not yet supported through the Partnership API's subscription endpoint. However, you can pass the promo_code as part of the subscription with the account API's Create call. data_retention (required only for Insights subscriptions) Type: Integer Default: (none) Number of weeks the Insights event information will be retained. Mapping for products (product_id) With each account creation call, you must supply at least one New Relic product type. The API only accepts the numeric product_id for the type. Important Reminder that the subscription object only applies for accounts using our original pricing model. Also, creating subscriptions for Serverless, Logs, and Traces is not supported by the Partnership API. If your account has these subscriptions, any attempt to make changes will return an error. Please contact your account executive to modify subscriptions. Important New Startup and Small Business service plans no longer are available through the New Relic Partnership API. APM The number of allowable hosts per account and the data retention period vary by subscription level within New Relic APM's pricing structure. For example, New Relic APM allows an unlimited number of allowable hosts for Lite accounts but only a 24-hour data retention period. In addition, pricing and data retention depend on whether you select pricing models based on hosts or compute units (CU). Use the product ID's integer format to identify the subscription level and type of plan. APM subscription level Product ID Lite 1 Standard 2 Standard Annual 3 Pro (Host) 4 Pro Annual (Host) 5 Enterprise 6 Enterprise Annual 7 APM Essentials (Host) 8 APM Essentials Annual (Host) 9 If you select pricing plans based on compute units (CU), use these product ID integer formats to identify the subscription level and type of plan. APM Compute Units (CU) subscription level Product ID Pro CU 26 Pro Annual CU 27 APM Essentials CU 28 APM Essentials Annual CU 29 Mobile New Relic Mobile's pricing structure allows 100,000 monthly active users per account at the Enterprise subscription level. Data retention varies by subscription level. Use the product ID's integer format to identify the subscription level. Mobile subscription level Product ID Lite 10 Enterprise 13 Enterprise Annual 14 Insights New Relic Insights bases the pricing structure on the number of allowable events stored and the associated data retention policy (for example, data retention for Insights Free is one day). Note that the data_retention attribute is required. Insights subscription level Product ID Free 15 None 16 Pro 18 Pro Annual 19 Browser New Relic Browser's pricing structure allows an unlimited number of app users, regardless of subscription level. However, the number of allowable page views per month and the data retention period vary by subscription level. For example: Lite accounts include an unlimited number of page views per month and 24-hour data retention. Pro account pricing starts at 500,000 page views per month and three months data retention. Use the product ID's integer format to identify the subscription level. Browser subscription level Product ID Lite 20 Pro 21 Pro Annual 22 Synthetics With New Relic Synthetics' pricing structure, the default number of allowable monitoring checks and the data retention period vary by subscription level. Use the product ID's integer format to identify the subscription level. Synthetics subscription level Product ID Lite 23 Pro 24 Pro Annual 25 Tip If you previously used the deprecated Partnership availability monitoring API, you can use the Synthetics API to provision a check and the REST API for New Relic Alerts to create an alert notification for your customers. Infrastructure With New Relic's Infrastructure pricing structure, the default number of instances and the data retention period vary by subscription level. Infrastructure events do not count against your New Relic Insights quota, even though you can query them in Insights. New Relic Infrastructure offers pricing plans based on Compute Units (CU) only. Use the product ID's integer format to identify the subscription level. Infrastructure subscription level Product ID Infrastructure None 31 Infrastructure Pro (CU) 32 Infrastructure Pro Annual (CU) 33 Infrastructure Essentials (CU) 34 Infrastructure Essentials Annual (CU) 35 Subscription API calls Before using this, first read Requirements. Here are the URL patterns for subscription-related API functions. If used, send them along with the JSON object and an HTTP header containing the Partner API key. For example: GET .../api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all subscriptions of an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Show a subscription for an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/ID Copy Replace the current subscription level with a new subscription. POST /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Subscription API examples Here are examples of an API call to create an original pricing model subscription and the JSON response listing subscriptions for the account. Example subscription object { \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 2 }, { \"product_id\": 13, \"quantity\": 2 } ] } Copy Example JSON response { \"id\": 1069012, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 2, \"price\": 218.0 }, { \"product_id\": 13, \"name\": \"Mobile Enterprise\", \"units\": 2, \"price\": 1500.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 15, \"name\": \"Insights Free\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Subscription status Here are some original pricing model subscription status values that the API call may return. Subscription status Description pending The customer has signed up for a New Relic product, but payment still needs to be processed. authorized A credit card has been authorized and the vault key stored, but payment has not been captured. free This subscription is for a free New Relic product. No further processing is required. paid A payment has been captured and the next payment date has been set. payment_declined The last attempt to authorize payment failed. canceled The New Relic account has no active subscription and is not active. No payments should be authorized or captured. replaced This subscription has been superseded by another New Relic subscription. API examples (v2) Here are API example requests and responses to list, show, create, and update original pricing model subscriptions. Line breaks in responses are for readability. The actual responses appear as a continuous line. List Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"subscriptions\": [ { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/SUBSCRIPTION_ID Copy Response: { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Create new (replace existing subscription) Here is an example of how to use the Partnership API create a new subscription (replace the existing subscription level for all products) for the account. Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"subscriptions\":[{\"product_id\":\"1\", \"quantity\":1}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"id\": 1069068, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.46886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> subscription object",
        "sections": "<em>Partnership</em> <em>API</em> subscription object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This doc explains how to use the <em>Partnership</em> <em>API</em> to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you&#x27;re on our original pricing model. It doesn&#x27;t support accounts on our <em>New</em> <em>Relic</em> One pricing model. For more on this, read"
      },
      "id": "603ebc5f28ccbcf81deba7a5"
    },
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2022-01-12T05:53:53Z",
      "updated_at": "2021-11-15T09:43:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing model: ignore this field because it applies to the original pricing model, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing model. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing models. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing model and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " that is on our <em>New</em> <em>Relic</em> One pricing and our <em>New</em> <em>Relic</em> One user model. For more on restrictions on <em>API</em> use, see requirements. curl -X POST \\ -H &#x27;x-<em>api</em>-key:<em>PARTNER</em>_ACCOUNT_KEY&#x27; \\ -H &#x27;Content-Type:application&#x2F;json&#x27; \\ -d &#x27;{&quot;account&quot;:{&quot;name&quot;:&quot;Sample account&quot;}}&#x27; \\ https:&#x2F;&#x2F;rpm.newrelic.com&#x2F;<em>api</em>&#x2F;v2&#x2F;partners"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Partnership API child account object",
        "Requirements",
        "Introduction to using child accounts",
        "Child account object attributes",
        "name (REQUIRED)",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "password (REQUIRED)",
        "Child account API calls",
        "JSON example",
        "Child account object JSON request",
        "JSON response",
        "Child account object API examples",
        "Create"
      ],
      "title": "Partnership API child account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "7fb13302d892a5f89c6c9371f35a60bf1ed9f6a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-sub-account-object/",
      "published_at": "2022-01-12T05:53:54Z",
      "updated_at": "2021-07-02T13:14:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage child accounts. For accounts, you'd use the child account object. Requirements You may not have access to using this object. Before using the Partnership API, first read the requirements. Introduction to using child accounts Some notes about using the child account object: To manage existing parent accounts or child accounts, use the Partnership API account object. A parent account may have more than one associated child account, but every chld account must correspond to one and only one parent account. Every child account must have at least a primary_admin user. You cannot create a child account without connecting it to an existing parent account and adding at least one user. Child account object attributes Before using the Partnership API, first read the requirements. Here are the Partnership API child account object's attributes: name (REQUIRED) Type: String Default: (none) This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you create the child account, you can define only one user: the account Owner. To add additional users, use the Partnership API user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user's current password. For some New Relic organizations, child accounts can also be created via the parent account's Account settings page in the New Relic UI. Child account API calls Here is the URL pattern to create child accounts. Notice that the Parent Account ID must be specified. If using this URL pattern, send the JSON object along with an HTTP header containing the Partner API key. For example: POST .../api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts​ x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern Create a child account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy JSON example Here is an example of a JSON request and response using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Child account object JSON request { \"account\": { \"name\": \"Sample child account\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Child account object API examples Here is an example of an API call using the Partnership API child account object. Note that this is just an example, and that for some accounts, the users attribute is unnecessary and will be ignored. Create Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"sub_account\":{\"name\":\"Sample child account\"}, \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/PARENT_ACCOUNT_ID/sub_accounts Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample child account\", \"status\": \"pending\", \"license_key\": \"XXXXXX\", \"api_key\": \"XXXXXX\", \"browser_monitoring_key\": \"XXXXXX\", \"allow_api_access\": false, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"parent_account_id\":XXXXXX, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.90009,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> child account object",
        "sections": "<em>Partnership</em> <em>API</em> child account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " additional users, use the <em>Partnership</em> <em>API</em> user object. For more about restrictions, read the Requirements. password (REQUIRED) Type: String Default: (none) If you are creating a child account with an existing user as the account Owner, the password must match the user&#x27;s current password. For some <em>New</em> <em>Relic</em>"
      },
      "id": "603eba3ae7b9d2b8e32a07b5"
    }
  ],
  "/docs/new-relic-partnerships/partnerships/partner-api/typical-integration-example": [
    {
      "sections": [
        "Partnership API subscription object",
        "Requirements",
        "Subscription object attributes",
        "product_id (REQUIRED for new subscriptions)",
        "quantity (REQUIRED for new subscriptions)",
        "promo_code",
        "data_retention (required only for Insights subscriptions)",
        "Mapping for products (product_id)",
        "Important",
        "APM",
        "Mobile",
        "Insights",
        "Browser",
        "Synthetics",
        "Tip",
        "Infrastructure",
        "Subscription API calls",
        "Subscription API examples",
        "Example subscription object",
        "Example JSON response",
        "Subscription status",
        "API examples (v2)",
        "List",
        "Show",
        "Create new (replace existing subscription)"
      ],
      "title": "Partnership API subscription object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "05b65e48cf5ed981c3eb79a3b31332f452dd5b2d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-subscription-object/",
      "published_at": "2022-01-12T05:54:34Z",
      "updated_at": "2021-12-10T08:15:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you're on our original pricing model. It doesn't support accounts on our New Relic One pricing model. For more on this, read the Partnership API requirements. The Partnership API doesn't allow you to upgrade or downgrade individual product subscriptions for an account. Instead, the API requires you to replace (add) the configuration for all product subscriptions for the account. If any product configurations are not included, the New Relic Partnership API provisions the account with the best free product type available. The API automatically selects the product level based on the configuration and custom pricing for the account's partnership. Subscription object attributes Before using this, first read Requirements. Here are the subscription object's attributes: product_id (REQUIRED for new subscriptions) Type: Integer Default: (none) The product ID attribute identifies the New Relic product being defined for this subscription. It is required for Create calls. quantity (REQUIRED for new subscriptions) Type: Integer Default: (none) The quantity attribute is required for Create calls, even if a product level is unlimited. The API will ignore the quantity value entered for unlimited product subscriptions, such as New Relic APM Lite. New Relic Insights, Browser, and Synthetics require you to identify a predefined usage level (product bucket). This allows the API to apply a pricing discount based on the specific quantity you select. The quantity you identify must be an exact match for the product and subscription level. For a list of available product buckets, see: Browser PageViews Insights Events Synthetics Checks promo_code Type: String Default: (none) Any related promotional code for this subscription. Not yet supported through the Partnership API's subscription endpoint. However, you can pass the promo_code as part of the subscription with the account API's Create call. data_retention (required only for Insights subscriptions) Type: Integer Default: (none) Number of weeks the Insights event information will be retained. Mapping for products (product_id) With each account creation call, you must supply at least one New Relic product type. The API only accepts the numeric product_id for the type. Important Reminder that the subscription object only applies for accounts using our original pricing model. Also, creating subscriptions for Serverless, Logs, and Traces is not supported by the Partnership API. If your account has these subscriptions, any attempt to make changes will return an error. Please contact your account executive to modify subscriptions. Important New Startup and Small Business service plans no longer are available through the New Relic Partnership API. APM The number of allowable hosts per account and the data retention period vary by subscription level within New Relic APM's pricing structure. For example, New Relic APM allows an unlimited number of allowable hosts for Lite accounts but only a 24-hour data retention period. In addition, pricing and data retention depend on whether you select pricing models based on hosts or compute units (CU). Use the product ID's integer format to identify the subscription level and type of plan. APM subscription level Product ID Lite 1 Standard 2 Standard Annual 3 Pro (Host) 4 Pro Annual (Host) 5 Enterprise 6 Enterprise Annual 7 APM Essentials (Host) 8 APM Essentials Annual (Host) 9 If you select pricing plans based on compute units (CU), use these product ID integer formats to identify the subscription level and type of plan. APM Compute Units (CU) subscription level Product ID Pro CU 26 Pro Annual CU 27 APM Essentials CU 28 APM Essentials Annual CU 29 Mobile New Relic Mobile's pricing structure allows 100,000 monthly active users per account at the Enterprise subscription level. Data retention varies by subscription level. Use the product ID's integer format to identify the subscription level. Mobile subscription level Product ID Lite 10 Enterprise 13 Enterprise Annual 14 Insights New Relic Insights bases the pricing structure on the number of allowable events stored and the associated data retention policy (for example, data retention for Insights Free is one day). Note that the data_retention attribute is required. Insights subscription level Product ID Free 15 None 16 Pro 18 Pro Annual 19 Browser New Relic Browser's pricing structure allows an unlimited number of app users, regardless of subscription level. However, the number of allowable page views per month and the data retention period vary by subscription level. For example: Lite accounts include an unlimited number of page views per month and 24-hour data retention. Pro account pricing starts at 500,000 page views per month and three months data retention. Use the product ID's integer format to identify the subscription level. Browser subscription level Product ID Lite 20 Pro 21 Pro Annual 22 Synthetics With New Relic Synthetics' pricing structure, the default number of allowable monitoring checks and the data retention period vary by subscription level. Use the product ID's integer format to identify the subscription level. Synthetics subscription level Product ID Lite 23 Pro 24 Pro Annual 25 Tip If you previously used the deprecated Partnership availability monitoring API, you can use the Synthetics API to provision a check and the REST API for New Relic Alerts to create an alert notification for your customers. Infrastructure With New Relic's Infrastructure pricing structure, the default number of instances and the data retention period vary by subscription level. Infrastructure events do not count against your New Relic Insights quota, even though you can query them in Insights. New Relic Infrastructure offers pricing plans based on Compute Units (CU) only. Use the product ID's integer format to identify the subscription level. Infrastructure subscription level Product ID Infrastructure None 31 Infrastructure Pro (CU) 32 Infrastructure Pro Annual (CU) 33 Infrastructure Essentials (CU) 34 Infrastructure Essentials Annual (CU) 35 Subscription API calls Before using this, first read Requirements. Here are the URL patterns for subscription-related API functions. If used, send them along with the JSON object and an HTTP header containing the Partner API key. For example: GET .../api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions x-api-key:PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all subscriptions of an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Show a subscription for an account. GET /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/ID Copy Replace the current subscription level with a new subscription. POST /api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Subscription API examples Here are examples of an API call to create an original pricing model subscription and the JSON response listing subscriptions for the account. Example subscription object { \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 2 }, { \"product_id\": 13, \"quantity\": 2 } ] } Copy Example JSON response { \"id\": 1069012, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 2, \"price\": 218.0 }, { \"product_id\": 13, \"name\": \"Mobile Enterprise\", \"units\": 2, \"price\": 1500.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 15, \"name\": \"Insights Free\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Subscription status Here are some original pricing model subscription status values that the API call may return. Subscription status Description pending The customer has signed up for a New Relic product, but payment still needs to be processed. authorized A credit card has been authorized and the vault key stored, but payment has not been captured. free This subscription is for a free New Relic product. No further processing is required. paid A payment has been captured and the next payment date has been set. payment_declined The last attempt to authorize payment failed. canceled The New Relic account has no active subscription and is not active. No payments should be authorized or captured. replaced This subscription has been superseded by another New Relic subscription. API examples (v2) Here are API example requests and responses to list, show, create, and update original pricing model subscriptions. Line breaks in responses are for readability. The actual responses appear as a continuous line. List Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"subscriptions\": [ { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions/SUBSCRIPTION_ID Copy Response: { \"id\": :SUBSCRIPTION_ID, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy Create new (replace existing subscription) Here is an example of how to use the Partnership API create a new subscription (replace the existing subscription level for all products) for the account. Request: curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"subscriptions\":[{\"product_id\":\"1\", \"quantity\":1}]}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID/subscriptions Copy Response: { \"id\": 1069068, \"starts_on\": \"2016-05-16\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 1, \"name\": \"Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 31, \"name\": \"Infrastructure None\", \"units\": 0, \"price\": 0.0 } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.46884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> subscription object",
        "sections": "<em>Partnership</em> <em>API</em> subscription object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": "This doc explains how to use the <em>Partnership</em> <em>API</em> to manage subscriptions for accounts on our original pricing model. Requirements You can use the subscription object only if you&#x27;re on our original pricing model. It doesn&#x27;t support accounts on our <em>New</em> <em>Relic</em> One pricing model. For more on this, read"
      },
      "id": "603ebc5f28ccbcf81deba7a5"
    },
    {
      "sections": [
        "Partnership API account object",
        "Requirements",
        "Account object attributes",
        "name (REQUIRED to create an account)",
        "phone_number",
        "allow_api_access",
        "testing",
        "users (REQUIRED for some accounts)",
        "subscriptions (REQUIRED for some accounts)",
        "Important",
        "Account API calls",
        "Status definitions",
        "JSON example",
        "Account object JSON request",
        "JSON response",
        "Account object API examples",
        "List",
        "Show",
        "Create",
        "Update",
        "Delete"
      ],
      "title": "Partnership API account object",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "0b1fde4800f2f9f355e0381796f55e23e61342c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/partnership-api-account-object/",
      "published_at": "2022-01-12T05:53:53Z",
      "updated_at": "2021-11-15T09:43:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains how to use the Partnership API to manage accounts. For child accounts, you'd use the child account object. Requirements You may not be able to use some aspects of this object. Before using, first read the requirements. Account object attributes Here are the Partnership API account object's attributes. name (REQUIRED to create an account) Type: String Default: (none) The account name attribute is required for new accounts. This name must be unique in New Relic's database. If the specified name is not unique, it will be auto-incremented with a numeric suffix as follows: conflicting_name_1 conflicting_name_2 etc. Copy phone_number Type: String Default: (none) Primary contact phone number for the account. allow_api_access Type: Boolean Default: False This flag allows API access to application data. This must be set to true for partnerships remotely administering accounts. testing Type: Boolean Default: False Use this flag to indicate a test account. Test accounts are assumed to contain garbage data and are ignored by internal systems. The data they generate may be deleted at any time. users (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of users. There are some restrictions in place dependent on the status of your account: For customer partnerships who have switched to the New Relic One user model: do not define users. If you add users with this field, they will be ignored. Instead, to add users, you'd use these user management procedures. For all other accounts, which have users on our original user model: When you first create an account, this field is required, and only one user can be defined: the account Owner. To add additional users, use the Partnership API user object. For more on restrictions, read the Requirements. subscriptions (REQUIRED for some accounts) Type: Array Default: (none) An array defining a list of subscriptions. There are some restrictions in place dependent on the status of your account: For customer partnerships on our New Relic One pricing model: ignore this field because it applies to the original pricing model, not yours. If you use this, it will be ignored. For all other accounts: You are on our original product-based pricing model. The subscriptions attribute is required for new accounts. If it is empty, default product tiers will be used. To update subscription information, use the Partnership API subscription object. Important When creating an account with this object, it can take some time for the account settings to populate. This means that the returned response may initially show aspects that are not true (for example, it may return a response showing default Lite subscriptions). To specify an empty JSON array, don't use subscriptions: [ {} ]. Instead, use this format: subscriptions: [ ] Copy The account API does not include an attribute to create a child account. Instead, to create child accounts, use the parent account's Account settings page in the New Relic UI. Account API calls Here are the URL patterns for account API functions. If using this URL pattern, send an HTTP header containing the Partner API key along with the JSON request body. For example: GET .../api/v2/partners/:PARTNER_ID/accounts/:ID x-api-key: :PARTNER_ACCOUNT_KEY Content-Type: application/json { JSON data } Copy Call Resource URL pattern List (index) all accounts of a partner. GET /api/v2/partners/PARTNER_ID/accounts Copy Show the attributes of an account. GET /api/v2/partners/PARTNER_ID/accounts/:ID Copy Update the attributes of an account. PUT /api/v2/partners/PARTNER_ID/accounts/:ID Copy Create an account with the given parameters. POST /api/v2/partners/PARTNER_ID/accounts Copy Cancel an account. DELETE /api/v2/partners/PARTNER_ID/accounts/:ID Copy Status definitions When an account is created or listed with an API call, the account status is included automatically. Some of these statuses don't apply to all pricing models. Account status Definition pending Free account created, but primary admin is not yet activated. paid_pending Account created with a paid subscription, but the primary admin is not yet activated. new Free account, active primary admin, no application data has been collected. paid_new Paid subscription, active primary admin, no application data has been collected. active Free subscription, receiving application data. paid_active Paid subscription, receiving application data. upgraded Account's subscription was upgraded. downgraded Account's subscription was downgraded. cancelled The New Relic account subscription has been cancelled. suspended The New Relic account has been suspended because the primary admin has not validated their email address. JSON example Here is an example of a JSON request and response using the Partnership API account object. Note that this is just an example, and that for some accounts, the users and subscriptions attributes are unnecessary and are ignored. Account object JSON request { \"account\": { \"name\": \"Sample Account\", \"application_type\": \"ruby\", \"users\": [ { \"email\": \"sample_user@sample.org\", \"password\": \"XXXXXXXX\", \"owner\": true, \"role\": \"admin\", \"first_name\": \"Sample\", \"last_name\": \"User\" } ], \"subscriptions\": [ { \"product_id\": 4, \"quantity\": 10 }, { \"product_id\": 10, \"quantity\": 0 } ], \"allow_api_access\": true, \"phone_number\": \"555-555-5555\" } } Copy JSON response { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Account object API examples Partnerships with more than 1000 accounts return a paginated response. To specify a page, add the following parameter to the query: ?page= Copy Here are examples of calls using the Partnership API account object. Note that these are examples, and that for some accounts, the users and subscriptions attributes don't apply and will be ignored. List List request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts Copy Response (line breaks are for readability): { \"accounts\": [ { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1990.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": null, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } ] } Copy Show Request: curl -X GET \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": 00000, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Create Here's an example of creating an account for an organization on our original pricing model and on our original user model. For an example call of creating an account for organizations with the newer models, see the example after this one. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample Account\", \"users\":[{\"email\":\"sample_user@sample.org\", \"password\":\"XXXXXX\", \"first_name\":\"Sample\", \"last_name\":\"User\", \"role\":\"admin\", \"owner\":\"true\"}],\"subscriptions\":[{\"product_id\": 4,\"quantity\": 10},{\"product_id\": 10,\"quantity\": 0}]}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Sample Account\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Here's an example of creating an account for a customer partnership that is on our New Relic One pricing and our New Relic One user model. For more on restrictions on API use, see requirements. curl -X POST \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ Copy Update You can only use the Partnership API account object to update the name, phone_number, testing and allow_API_access values. To update subscription and users values, you must use the Partnership API subscription object and Partnership API user object. Request: curl -X PUT \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ -d '{\"account\":{\"name\":\"Sample account name\"}}' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response (line breaks are for readability): { \"id\": XXXXXX, \"name\": \"Account New Name\", \"status\": \"pending\", \"license_key\": \"caf8247360d8db295c142c72138fa8fb28df1403\", \"api_key\": \"86f818b6d81668b6c034661396b71c25bb323d8b8df1403\", \"browser_monitoring_key\": \"66617123f5\", \"allow_api_access\": true, \"high_security\": false, \"testing\": null, \"partner_external_identifier\": null, \"subscription\": { \"id\": XXXXXX, \"starts_on\": \"2016-05-17\", \"expires_on\": null, \"annual_renewal_on\": null, \"products\": [ { \"product_id\": 4, \"name\": \"Pro\", \"units\": 10, \"price\": 1999.0 }, { \"product_id\": 10, \"name\": \"Mobile Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 20, \"name\": \"Browser Lite\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 16, \"name\": \"Insights None\", \"units\": 0, \"price\": 0.0 }, { \"product_id\": 23, \"name\": \"Synthetics Lite\", \"units\": 0, \"price\": 0.0 } ] }, \"primary admin\": { \"id\": XXXXXX, \"email\": \"sample_user@sample.org\", \"first_name\": \"Sample\", \"last_name\": \"User\", \"state\": \"active\" } } Copy Delete Request: curl -X DELETE \\ -H 'x-api-key:PARTNER_ACCOUNT_KEY' \\ -H 'Content-Type:application/json' \\ https://rpm.newrelic.com/api/v2/partners/PARTNER_ID/accounts/ACCOUNT_ID Copy Response: No response body.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.95798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Partnership</em> <em>API</em> account object",
        "sections": "<em>Partnership</em> <em>API</em> account object",
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " that is on our <em>New</em> <em>Relic</em> One pricing and our <em>New</em> <em>Relic</em> One user model. For more on restrictions on <em>API</em> use, see requirements. curl -X POST \\ -H &#x27;x-<em>api</em>-key:<em>PARTNER</em>_ACCOUNT_KEY&#x27; \\ -H &#x27;Content-Type:application&#x2F;json&#x27; \\ -d &#x27;{&quot;account&quot;:{&quot;name&quot;:&quot;Sample account&quot;}}&#x27; \\ https:&#x2F;&#x2F;rpm.newrelic.com&#x2F;<em>api</em>&#x2F;v2&#x2F;partners"
      },
      "id": "603ebc5f196a679110a83dd5"
    },
    {
      "sections": [
        "Product buckets",
        "Requirements",
        "Overview (#overview)",
        "Quantity by product",
        "Insights Events quantity",
        "Browser PageViews quantity",
        "Synthetics Checks quantity"
      ],
      "title": "Product buckets",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partnerships",
        "Partner API"
      ],
      "external_id": "fe7632af0936f9878b04ba0c25f7cf8a7f684399",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partnerships/partner-api/product-buckets/",
      "published_at": "2022-01-12T05:55:20Z",
      "updated_at": "2021-11-15T09:27:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For partnership accounts on our original product pricing, you can use the Partnership API for managing subscriptions. This doc explains some details for using the Browser, Synthetics, and Insights products. Requirements This doc applies only for partnership accounts on our original pricing model. Before using this API, please read the Partnership API requirements. Overview (#overview) When using the Partnership API for Insights, Browser, and Synthetics products, you must provide a valid quantity value. This indicates the number of Insights Events, Browser PageViews, and Synthetics Checks provisioned to that account. New Relic uses this \"bucket\" pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the New Relic Partnership API will return an error response. Quantity by product Here are the valid quantity values by New Relic product. Insights Events quantity Insights Pro Insights Pro Annual 25 25 50 50 75 75 300 300 625 625 1250 1250 2500 2500 5000 5000 10000 10000 20000 20000 40000 40000 60000 60000 80000 80000 100000 100000 120000 120000 140000 140000 Browser PageViews quantity Browser Pro Browser Pro Annual 100000 100000 250000 250000 500000 500000 1000000 1000000 1500000 1500000 2000000 2000000 2500000 2500000 3000000 3000000 4000000 4000000 5000000 5000000 6000000 6000000 7000000 7000000 7500000 7500000 8000000 8000000 9000000 9000000 10000000 10000000 12500000 12500000 15000000 15000000 20000000 20000000 25000000 25000000 30000000 30000000 35000000 35000000 40000000 40000000 50000000 50000000 75000000 75000000 100000000 100000000 125000000 125000000 150000000 150000000 175000000 175000000 200000000 200000000 250000000 250000000 300000000 300000000 350000000 350000000 400000000 400000000 450000000 450000000 500000000 500000000 600000000 600000000 700000000 700000000 800000000 800000000 900000000 900000000 1000000000 1000000000 1250000000 1250000000 1500000000 1500000000 2000000000 2000000000 2500000000 2500000000 3000000000 3000000000 4000000000 4000000000 5000000000 5000000000 10000000000 10000000000 Synthetics Checks quantity Synthetics Pro Synthetics Pro Annual 10000 10000 15000 15000 25000 25000 35000 35000 50000 50000 75000 75000 100000 100000 150000 150000 250000 250000 300000 300000 400000 400000 500000 500000 600000 600000 750000 750000 900000 900000 1000000 1000000 1150000 1150000 1300000 1300000 1500000 1500000 1750000 1750000 2000000 2000000 2500000 2500000 3000000 3000000 3500000 3500000 5000000 5000000 7000000 7000000 8500000 8500000 10000000 10000000 12500000 12500000 14000000 14000000 15000000 15000000 17500000 17500000 20000000 20000000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.95392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>partnerships</em>",
        "body": " provisioned to that account. <em>New</em> <em>Relic</em> uses this &quot;bucket&quot; pricing structure based on the quantity value in order to offer discounts on large volume purchases. Be sure to select an available bucket value. Otherwise, the <em>New</em> <em>Relic</em> <em>Partnership</em> <em>API</em> will return an error response. Quantity by product Here"
      },
      "id": "6044181d28ccbc2ea42c608a"
    }
  ],
  "/docs/new-relic-solutions/best-practices-guides/alerts-applied-intelligence/alerts-best-practices": [
    {
      "sections": [
        "Synthetic monitoring best practices guide",
        "1. Match your monitor type to monitoring need",
        "How to do it",
        "2. View all monitors with the Monitors index page",
        "How to view your monitors in the New Relic One:",
        "New Relic Explorer",
        "Monitors index page",
        "3. View individual monitor results",
        "How to do it:",
        "4. Understand the load-time impact of each resource",
        "5. Configure and develop a scripted browser test"
      ],
      "title": "Synthetic monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "e76eb0669a1433bb9d0de70d90413e19749adf61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/synthetic-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T03:20:55Z",
      "updated_at": "2021-12-25T11:14:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need Synthetic monitors are virtual browsers that measure the performance of your website, recording each check in detail. They also capture aggregate numbers for load time, uptime, and average download size, as well as an overview, detailed statistics for each page resource, and downtime incidents. There are four types of synthetic monitors; the ones you deploy will depend on the things you want to monitor: Ping monitors—to ensure that your site is accessible. Simple browser monitors—to ensure end-user performance. Scripted browsers—to ensure that particular resources are present. API monitors—to ensure that your app server works as well as your website. How to do it To add a monitor, go to one.newrelic.com > Synthetics (or one.eu.newrelic.com if you have an EU-based account) and click Create monitor. Specify monitor type, name, and URL. Optional: Add a validation string (available for ping and simple browser) or advanced options, which enable substring monitoring for the following types of response validation: Verify SSL (for ping and simple browser). This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs > /dev/null Copy Bypass HEAD request (for ping). This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure (for ping). If a redirect result occurs when Redirect is Failure is enabled, Synthetics categorizes it as a failure (rather than following the redirect and checking the resulting URL). Select the locations where you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes; then from the Monitors index check your monitor. 2. View all monitors with the Monitors index page Continuous application performance monitoring is essential to ensure that web services are in place, working correctly, and error-free. Synthetic monitoring provides this type of assurance by performing automated tests on your web application for each selected location—noting downtime instances (“violations”) and collecting aggregate numbers, results, and detailed statistics for each page resource. Use the Monitors index page to get a high level view of this information, or select an individual monitor to view the Summary, for ping monitors, or Overview, for simple and scripted monitors, page and get a deeper insight into its performance over time. How to view your monitors in the New Relic One: New Relic Explorer To view a list of monitors using the New Relic One Monitors index page: Go to one.newrelic.com > Explorer > Synthetic monitors. For more information, see the documentation about navigating core UI components in New Relic One. Monitors index page To view a list of monitors using the Monitors index page: Go to one.newrelic.com > Synthetics. 3. View individual monitor results It’s not enough to understand how your web apps are performing for your West Coast customers; you need to be able to view how they’re performing across the country and around the globe. By taking advantage of synthetic monitors and visiting your Results page, you can see how everything from development to production affects user experience. You can locate interesting results by sorting the list to identify slow, fast, or other unusual results. Or filter by location to understand how monitor performance varies with geography. (The “Network timings” graph below provides a snapshot of webpage performance over a given period.) How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors tab, select your monitor. Select Monitor > Results. Gain an up-to-the-minute view of the slowest page loads for every monitored location. 4. Understand the load-time impact of each resource Visit the synthetics Resources page to see how each resource on your website—including CSS, JavaScript, images, HTML and more—is affecting your overall load. You can drill into detailed metrics collected at run time, locate performance information for time spent by third-party resources, and identify HTTP response codes for each resource. How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors drop-down menu, select your monitor. Select Monitor > Resources. 5. Configure and develop a scripted browser test Using scripted browsers, you can build complex monitoring workflows using the Selenium JavaScript Webdriver bindings. For instance, you can log in to the application, navigate to a particular link, and wait for a page element to load and add an assertion. How to do it: Go to one.newrelic.com > Synthetics. Choose your monitor type (for example, scripted browser). Enter the name and details of your monitor (for example, Sitename.com scripted browser) Select the locations from which you want your monitor to run (for example, Mumbai, Seoul, Columbus, and Montreal). Choose a frequency to determine how often each location will run your monitor (for example, five minutes). Set a notification method to alert your team when performance violations occur. You are now ready to write your script. (Below is an example of a script used to test the performance of a main navigation page.) var assert = require('chai').assert; // script-wide timeout for all wait and waitandfind functions (in ms) var default_element_timeout = 190000; //3 mins var default_pageload_timeout = 240000; //4 mins var navlinks = [\"css-locator-1\", \"css-locator-2\"]; //sets element load timeout to 3 mins $browser.manage().timeouts().implicitlyWait(default_element_timeout); //sets page load timoeout to 4 mins $browser.manage().timeouts().pageloadTimeout(default_pageload_timeout); //test all the main nav page performances $browser.get(\"http://www.sitename.com\").then(function() { return $browser.findelement($driver.by.classname(\"site-theme-example\")); }).then(function() { //verifies the nav list has loaded return $browser.findelement($driver.by.classname(\"site-nav-list-example\")); }).then(function() { //loops through the navlinks array navlinks.foreach(function(val, i, arr) { //finds and navigates to each navlink page return $browser.findelement($driver.by.classname(navlinks[i])).click().then(function() { //verifies that the nav list loaded before moving on return $browser.findelement($driver.by.classname(\"site-nav-list-example\")).then(function() { //verifies that the page logo footer at bottom of page has loaded return $browser.findelement($driver.by.classname(\"site-footer-logo\")); }); }); }); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.42834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need"
      },
      "id": "603e84bb28ccbce555eba771"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2022-01-12T03:41:24Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.86588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Application monitoring tips you need to know It&#x27;s one thing to know how to use APM, but it&#x27;s another thing to know how to use <em>New</em> <em>Relic</em>&#x27;s application performance monitoring software well. Here are some <em>best</em> <em>practices</em> designed to help you become an APM pro—and a key asset to your team! Tip To get"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Infrastructure monitoring best practices guide",
        "1. Install the infrastructure agent across your entire environment",
        "How to do it",
        "Tip",
        "2. Configure the native EC2 integration",
        "3. Activate the integrations",
        "4. Create filter sets",
        "5. Create alert conditions",
        "6. View infrastructure data alongside APM data",
        "7. Access Infrastructure data using the Data explorer",
        "8. Update your agents regularly",
        "Want more user tips?"
      ],
      "title": "Infrastructure monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "931ea7767d73381ca0cb3502ec14f88d66ce5eaf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T05:56:02Z",
      "updated_at": "2021-09-14T06:03:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Want even longer periods of uninterrupted sleep? Here are eight best practices to make dynamic infrastructure and server monitoring even easier with New Relic's infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution was designed to help enterprise customers monitor their large and dynamically changing environments at scale. In order to facilitate this, the UI is completely driven by tags that let you visualize aggregated metrics, events, and inventory for a large number of servers. To really get the most out of infrastructure monitoring, we recommend installing it across your entire environment, preferably even across multiple regions and clusters. This will provide a more accurate picture of the health of your host ecosystem and the impact your infrastructure has on your applications. Want to achieve faster Mean Time To Resolution (MTTR)? Install the infrastructure agent on database servers, web servers, and any other host that supports your applications. When deploying the agent, leverage custom attributes to tag your hosts so that you can use those for filtering the data presented in the UI and for setting alerts. This is in addition to any Amazon EC2 tags you may be using which will auto-import when you enable the EC2 integration. You may also prefer to keep the agent logs separate from the system logs, which you can do through the configuration. How to do it Leverage our install modules for config management tools such as Chef, Puppet and Ansible to easily deploy your agent across all your infrastructure. Read the instructions in the github repo for your config management tool referenced in the link above and define the custom_attributes you want to use to tag your hosts. Set the log_file attribute to your preferred location for the infrastructure agent logs. Tip If you are installing the agent on a single host, the process should only take a few minutes and you can find detailed instructions in our documentation. 2. Configure the native EC2 integration If you have an AWS environment, in addition to installing the infrastructure agent on your EC2 instances to monitor them, we also recommend configuring the EC2 integration so that New Relic can automatically import all the tags and metadata associated with your AWS instances. This allows you to filter down to a part of your infrastructure using the same AWS tags (example, ECTag_Role='Kafka'), and slice-and-dice your data in multiple ways. Additionally, our ‘Alerts’ and ‘Saved Filter Sets’ are completely tag-driven and dynamic, so they automatically add/remove instances matching these tags to give our users the most real-time views that scale with your cloud infrastructure. 3. Activate the integrations Monitoring your infrastructure extends beyond just CPU, memory, and storage utilization. That’s why New Relic has out-of-the-box integrations that allow you to monitor all the services that support your hosts as well. Activate any of our integrations, including AWS Billing, AWS ELB, Amazon S3, MySQL, NGINX, and more, to extend monitoring to your AWS or on-host applications, and access the pre-configured dashboards that appear for each of them. 4. Create filter sets With New Relic, users can create filter sets to organize hosts, cluster roles, and other resources based on criteria that matter the most to users. This allows you to optimize your resources by using a focused view to monitor, detect, and resolve any problems proactively. The attributes for filtering are populated from the auto-imported EC2 tags or custom tags that may be applied to hosts. You can combine as many filters as you want in a filter set, and save them to share with other people in your account. You’ll also be able to see the color-coded health status of each host inside the filter set, so you can quickly identify problematic areas of your infrastructure. Additionally, filter sets can be used in the health map to get an overview of your infrastructure performance at a glance based on the filters that matter to your teams. 5. Create alert conditions With New Relic, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are viewing a filter set comprised of a large number of hosts and notice a problem, you don’t need to create an individual alert condition for every host within. Instead, we recommend initiating the alert condition directly from the chart of the metric you are viewing and creating it based on the filter tags. This will create an alert condition for any hosts that match those tags, allowing our infrastructure monitoring to automatically remove hosts that go offline and add new hosts to the alert condition if they match those tags. Alerts configured once for the appropriate tags will scale correctly across all future hosts. And know that you can also leverage existing alert policies for infrastructure alert conditions. 6. View infrastructure data alongside APM data The integration between APM and infrastructure monitoring lets you see your APM data and infrastructure data side by side, so you can find the root cause of problems more quickly, no matter where they originate. This allows users to view the performance relationship of your hosts and the applications running on them, allowing for quicker diagnosis of the issue and impact on the business’ health. Use health maps to quickly spot any issues or alerts related to the health of your applications and how that connects to the supporting infrastructure. The first boxes starting from the top left are those that require your attention. 7. Access Infrastructure data using the Data explorer Teams that use multiple New Relic capabilities find it useful to create a single dashboard to visually correlate the infrastructure’s health with application, browser and synthetics metrics. That’s where New Relic data exploration features comes in. All the granular metrics and events collected by infrastructure monitoring are stored in New Relic and are accessible to you immediately. Having access to the raw metrics means you can run more custom queries using NRQL, and also create dashboards to share infrastructure metrics with your team. 8. Update your agents regularly New Relic’s software engineering team is constantly pushing out improvements and new features to improve our customers’ overall monitoring experience. In order to take advantage of all the awesomeness they’re delivering, we recommend regularly updating to the latest version of the infrastructure agent. Want more user tips? View training videos at New Relic University. Read the documentation. Check out our Tutorials. Ask a question in the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.93152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Want even longer periods of uninterrupted sleep? Here are eight <em>best</em> <em>practices</em> to make dynamic infrastructure and server monitoring even easier with <em>New</em> <em>Relic</em>&#x27;s infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution"
      },
      "id": "6044151c28ccbc4b4f2c60af"
    }
  ],
  "/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide": [
    {
      "sections": [
        "Synthetic monitoring best practices guide",
        "1. Match your monitor type to monitoring need",
        "How to do it",
        "2. View all monitors with the Monitors index page",
        "How to view your monitors in the New Relic One:",
        "New Relic Explorer",
        "Monitors index page",
        "3. View individual monitor results",
        "How to do it:",
        "4. Understand the load-time impact of each resource",
        "5. Configure and develop a scripted browser test"
      ],
      "title": "Synthetic monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "e76eb0669a1433bb9d0de70d90413e19749adf61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/synthetic-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T03:20:55Z",
      "updated_at": "2021-12-25T11:14:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need Synthetic monitors are virtual browsers that measure the performance of your website, recording each check in detail. They also capture aggregate numbers for load time, uptime, and average download size, as well as an overview, detailed statistics for each page resource, and downtime incidents. There are four types of synthetic monitors; the ones you deploy will depend on the things you want to monitor: Ping monitors—to ensure that your site is accessible. Simple browser monitors—to ensure end-user performance. Scripted browsers—to ensure that particular resources are present. API monitors—to ensure that your app server works as well as your website. How to do it To add a monitor, go to one.newrelic.com > Synthetics (or one.eu.newrelic.com if you have an EU-based account) and click Create monitor. Specify monitor type, name, and URL. Optional: Add a validation string (available for ping and simple browser) or advanced options, which enable substring monitoring for the following types of response validation: Verify SSL (for ping and simple browser). This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs > /dev/null Copy Bypass HEAD request (for ping). This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure (for ping). If a redirect result occurs when Redirect is Failure is enabled, Synthetics categorizes it as a failure (rather than following the redirect and checking the resulting URL). Select the locations where you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes; then from the Monitors index check your monitor. 2. View all monitors with the Monitors index page Continuous application performance monitoring is essential to ensure that web services are in place, working correctly, and error-free. Synthetic monitoring provides this type of assurance by performing automated tests on your web application for each selected location—noting downtime instances (“violations”) and collecting aggregate numbers, results, and detailed statistics for each page resource. Use the Monitors index page to get a high level view of this information, or select an individual monitor to view the Summary, for ping monitors, or Overview, for simple and scripted monitors, page and get a deeper insight into its performance over time. How to view your monitors in the New Relic One: New Relic Explorer To view a list of monitors using the New Relic One Monitors index page: Go to one.newrelic.com > Explorer > Synthetic monitors. For more information, see the documentation about navigating core UI components in New Relic One. Monitors index page To view a list of monitors using the Monitors index page: Go to one.newrelic.com > Synthetics. 3. View individual monitor results It’s not enough to understand how your web apps are performing for your West Coast customers; you need to be able to view how they’re performing across the country and around the globe. By taking advantage of synthetic monitors and visiting your Results page, you can see how everything from development to production affects user experience. You can locate interesting results by sorting the list to identify slow, fast, or other unusual results. Or filter by location to understand how monitor performance varies with geography. (The “Network timings” graph below provides a snapshot of webpage performance over a given period.) How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors tab, select your monitor. Select Monitor > Results. Gain an up-to-the-minute view of the slowest page loads for every monitored location. 4. Understand the load-time impact of each resource Visit the synthetics Resources page to see how each resource on your website—including CSS, JavaScript, images, HTML and more—is affecting your overall load. You can drill into detailed metrics collected at run time, locate performance information for time spent by third-party resources, and identify HTTP response codes for each resource. How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors drop-down menu, select your monitor. Select Monitor > Resources. 5. Configure and develop a scripted browser test Using scripted browsers, you can build complex monitoring workflows using the Selenium JavaScript Webdriver bindings. For instance, you can log in to the application, navigate to a particular link, and wait for a page element to load and add an assertion. How to do it: Go to one.newrelic.com > Synthetics. Choose your monitor type (for example, scripted browser). Enter the name and details of your monitor (for example, Sitename.com scripted browser) Select the locations from which you want your monitor to run (for example, Mumbai, Seoul, Columbus, and Montreal). Choose a frequency to determine how often each location will run your monitor (for example, five minutes). Set a notification method to alert your team when performance violations occur. You are now ready to write your script. (Below is an example of a script used to test the performance of a main navigation page.) var assert = require('chai').assert; // script-wide timeout for all wait and waitandfind functions (in ms) var default_element_timeout = 190000; //3 mins var default_pageload_timeout = 240000; //4 mins var navlinks = [\"css-locator-1\", \"css-locator-2\"]; //sets element load timeout to 3 mins $browser.manage().timeouts().implicitlyWait(default_element_timeout); //sets page load timoeout to 4 mins $browser.manage().timeouts().pageloadTimeout(default_pageload_timeout); //test all the main nav page performances $browser.get(\"http://www.sitename.com\").then(function() { return $browser.findelement($driver.by.classname(\"site-theme-example\")); }).then(function() { //verifies the nav list has loaded return $browser.findelement($driver.by.classname(\"site-nav-list-example\")); }).then(function() { //loops through the navlinks array navlinks.foreach(function(val, i, arr) { //finds and navigates to each navlink page return $browser.findelement($driver.by.classname(navlinks[i])).click().then(function() { //verifies that the nav list loaded before moving on return $browser.findelement($driver.by.classname(\"site-nav-list-example\")).then(function() { //verifies that the page logo footer at bottom of page has loaded return $browser.findelement($driver.by.classname(\"site-footer-logo\")); }); }); }); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.42834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need"
      },
      "id": "603e84bb28ccbce555eba771"
    },
    {
      "sections": [
        "Infrastructure monitoring best practices guide",
        "1. Install the infrastructure agent across your entire environment",
        "How to do it",
        "Tip",
        "2. Configure the native EC2 integration",
        "3. Activate the integrations",
        "4. Create filter sets",
        "5. Create alert conditions",
        "6. View infrastructure data alongside APM data",
        "7. Access Infrastructure data using the Data explorer",
        "8. Update your agents regularly",
        "Want more user tips?"
      ],
      "title": "Infrastructure monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "931ea7767d73381ca0cb3502ec14f88d66ce5eaf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T05:56:02Z",
      "updated_at": "2021-09-14T06:03:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Want even longer periods of uninterrupted sleep? Here are eight best practices to make dynamic infrastructure and server monitoring even easier with New Relic's infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution was designed to help enterprise customers monitor their large and dynamically changing environments at scale. In order to facilitate this, the UI is completely driven by tags that let you visualize aggregated metrics, events, and inventory for a large number of servers. To really get the most out of infrastructure monitoring, we recommend installing it across your entire environment, preferably even across multiple regions and clusters. This will provide a more accurate picture of the health of your host ecosystem and the impact your infrastructure has on your applications. Want to achieve faster Mean Time To Resolution (MTTR)? Install the infrastructure agent on database servers, web servers, and any other host that supports your applications. When deploying the agent, leverage custom attributes to tag your hosts so that you can use those for filtering the data presented in the UI and for setting alerts. This is in addition to any Amazon EC2 tags you may be using which will auto-import when you enable the EC2 integration. You may also prefer to keep the agent logs separate from the system logs, which you can do through the configuration. How to do it Leverage our install modules for config management tools such as Chef, Puppet and Ansible to easily deploy your agent across all your infrastructure. Read the instructions in the github repo for your config management tool referenced in the link above and define the custom_attributes you want to use to tag your hosts. Set the log_file attribute to your preferred location for the infrastructure agent logs. Tip If you are installing the agent on a single host, the process should only take a few minutes and you can find detailed instructions in our documentation. 2. Configure the native EC2 integration If you have an AWS environment, in addition to installing the infrastructure agent on your EC2 instances to monitor them, we also recommend configuring the EC2 integration so that New Relic can automatically import all the tags and metadata associated with your AWS instances. This allows you to filter down to a part of your infrastructure using the same AWS tags (example, ECTag_Role='Kafka'), and slice-and-dice your data in multiple ways. Additionally, our ‘Alerts’ and ‘Saved Filter Sets’ are completely tag-driven and dynamic, so they automatically add/remove instances matching these tags to give our users the most real-time views that scale with your cloud infrastructure. 3. Activate the integrations Monitoring your infrastructure extends beyond just CPU, memory, and storage utilization. That’s why New Relic has out-of-the-box integrations that allow you to monitor all the services that support your hosts as well. Activate any of our integrations, including AWS Billing, AWS ELB, Amazon S3, MySQL, NGINX, and more, to extend monitoring to your AWS or on-host applications, and access the pre-configured dashboards that appear for each of them. 4. Create filter sets With New Relic, users can create filter sets to organize hosts, cluster roles, and other resources based on criteria that matter the most to users. This allows you to optimize your resources by using a focused view to monitor, detect, and resolve any problems proactively. The attributes for filtering are populated from the auto-imported EC2 tags or custom tags that may be applied to hosts. You can combine as many filters as you want in a filter set, and save them to share with other people in your account. You’ll also be able to see the color-coded health status of each host inside the filter set, so you can quickly identify problematic areas of your infrastructure. Additionally, filter sets can be used in the health map to get an overview of your infrastructure performance at a glance based on the filters that matter to your teams. 5. Create alert conditions With New Relic, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are viewing a filter set comprised of a large number of hosts and notice a problem, you don’t need to create an individual alert condition for every host within. Instead, we recommend initiating the alert condition directly from the chart of the metric you are viewing and creating it based on the filter tags. This will create an alert condition for any hosts that match those tags, allowing our infrastructure monitoring to automatically remove hosts that go offline and add new hosts to the alert condition if they match those tags. Alerts configured once for the appropriate tags will scale correctly across all future hosts. And know that you can also leverage existing alert policies for infrastructure alert conditions. 6. View infrastructure data alongside APM data The integration between APM and infrastructure monitoring lets you see your APM data and infrastructure data side by side, so you can find the root cause of problems more quickly, no matter where they originate. This allows users to view the performance relationship of your hosts and the applications running on them, allowing for quicker diagnosis of the issue and impact on the business’ health. Use health maps to quickly spot any issues or alerts related to the health of your applications and how that connects to the supporting infrastructure. The first boxes starting from the top left are those that require your attention. 7. Access Infrastructure data using the Data explorer Teams that use multiple New Relic capabilities find it useful to create a single dashboard to visually correlate the infrastructure’s health with application, browser and synthetics metrics. That’s where New Relic data exploration features comes in. All the granular metrics and events collected by infrastructure monitoring are stored in New Relic and are accessible to you immediately. Having access to the raw metrics means you can run more custom queries using NRQL, and also create dashboards to share infrastructure metrics with your team. 8. Update your agents regularly New Relic’s software engineering team is constantly pushing out improvements and new features to improve our customers’ overall monitoring experience. In order to take advantage of all the awesomeness they’re delivering, we recommend regularly updating to the latest version of the infrastructure agent. Want more user tips? View training videos at New Relic University. Read the documentation. Check out our Tutorials. Ask a question in the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.93152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Want even longer periods of uninterrupted sleep? Here are eight <em>best</em> <em>practices</em> to make dynamic infrastructure and server monitoring even easier with <em>New</em> <em>Relic</em>&#x27;s infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution"
      },
      "id": "6044151c28ccbc4b4f2c60af"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T03:28:12Z",
      "updated_at": "2021-08-02T10:17:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Use our metric-based alerts and mobile monitoring UI: Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if you're using our browser monitoring), so that you can compare and contrast performance across end-user channels. The mobile agents track the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.66626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some <em>best</em> <em>practices</em> to take full advantage of mobile monitoring with <em>New</em> <em>Relic</em>. 1. Start collecting data Start collecting data in production. You&#x27;ll see immediate"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    }
  ],
  "/docs/new-relic-solutions/best-practices-guides/full-stack-observability/browser-monitoring-best-practices-guide": [
    {
      "sections": [
        "Synthetic monitoring best practices guide",
        "1. Match your monitor type to monitoring need",
        "How to do it",
        "2. View all monitors with the Monitors index page",
        "How to view your monitors in the New Relic One:",
        "New Relic Explorer",
        "Monitors index page",
        "3. View individual monitor results",
        "How to do it:",
        "4. Understand the load-time impact of each resource",
        "5. Configure and develop a scripted browser test"
      ],
      "title": "Synthetic monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "e76eb0669a1433bb9d0de70d90413e19749adf61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/synthetic-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T03:20:55Z",
      "updated_at": "2021-12-25T11:14:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need Synthetic monitors are virtual browsers that measure the performance of your website, recording each check in detail. They also capture aggregate numbers for load time, uptime, and average download size, as well as an overview, detailed statistics for each page resource, and downtime incidents. There are four types of synthetic monitors; the ones you deploy will depend on the things you want to monitor: Ping monitors—to ensure that your site is accessible. Simple browser monitors—to ensure end-user performance. Scripted browsers—to ensure that particular resources are present. API monitors—to ensure that your app server works as well as your website. How to do it To add a monitor, go to one.newrelic.com > Synthetics (or one.eu.newrelic.com if you have an EU-based account) and click Create monitor. Specify monitor type, name, and URL. Optional: Add a validation string (available for ping and simple browser) or advanced options, which enable substring monitoring for the following types of response validation: Verify SSL (for ping and simple browser). This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs > /dev/null Copy Bypass HEAD request (for ping). This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure (for ping). If a redirect result occurs when Redirect is Failure is enabled, Synthetics categorizes it as a failure (rather than following the redirect and checking the resulting URL). Select the locations where you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes; then from the Monitors index check your monitor. 2. View all monitors with the Monitors index page Continuous application performance monitoring is essential to ensure that web services are in place, working correctly, and error-free. Synthetic monitoring provides this type of assurance by performing automated tests on your web application for each selected location—noting downtime instances (“violations”) and collecting aggregate numbers, results, and detailed statistics for each page resource. Use the Monitors index page to get a high level view of this information, or select an individual monitor to view the Summary, for ping monitors, or Overview, for simple and scripted monitors, page and get a deeper insight into its performance over time. How to view your monitors in the New Relic One: New Relic Explorer To view a list of monitors using the New Relic One Monitors index page: Go to one.newrelic.com > Explorer > Synthetic monitors. For more information, see the documentation about navigating core UI components in New Relic One. Monitors index page To view a list of monitors using the Monitors index page: Go to one.newrelic.com > Synthetics. 3. View individual monitor results It’s not enough to understand how your web apps are performing for your West Coast customers; you need to be able to view how they’re performing across the country and around the globe. By taking advantage of synthetic monitors and visiting your Results page, you can see how everything from development to production affects user experience. You can locate interesting results by sorting the list to identify slow, fast, or other unusual results. Or filter by location to understand how monitor performance varies with geography. (The “Network timings” graph below provides a snapshot of webpage performance over a given period.) How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors tab, select your monitor. Select Monitor > Results. Gain an up-to-the-minute view of the slowest page loads for every monitored location. 4. Understand the load-time impact of each resource Visit the synthetics Resources page to see how each resource on your website—including CSS, JavaScript, images, HTML and more—is affecting your overall load. You can drill into detailed metrics collected at run time, locate performance information for time spent by third-party resources, and identify HTTP response codes for each resource. How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors drop-down menu, select your monitor. Select Monitor > Resources. 5. Configure and develop a scripted browser test Using scripted browsers, you can build complex monitoring workflows using the Selenium JavaScript Webdriver bindings. For instance, you can log in to the application, navigate to a particular link, and wait for a page element to load and add an assertion. How to do it: Go to one.newrelic.com > Synthetics. Choose your monitor type (for example, scripted browser). Enter the name and details of your monitor (for example, Sitename.com scripted browser) Select the locations from which you want your monitor to run (for example, Mumbai, Seoul, Columbus, and Montreal). Choose a frequency to determine how often each location will run your monitor (for example, five minutes). Set a notification method to alert your team when performance violations occur. You are now ready to write your script. (Below is an example of a script used to test the performance of a main navigation page.) var assert = require('chai').assert; // script-wide timeout for all wait and waitandfind functions (in ms) var default_element_timeout = 190000; //3 mins var default_pageload_timeout = 240000; //4 mins var navlinks = [\"css-locator-1\", \"css-locator-2\"]; //sets element load timeout to 3 mins $browser.manage().timeouts().implicitlyWait(default_element_timeout); //sets page load timoeout to 4 mins $browser.manage().timeouts().pageloadTimeout(default_pageload_timeout); //test all the main nav page performances $browser.get(\"http://www.sitename.com\").then(function() { return $browser.findelement($driver.by.classname(\"site-theme-example\")); }).then(function() { //verifies the nav list has loaded return $browser.findelement($driver.by.classname(\"site-nav-list-example\")); }).then(function() { //loops through the navlinks array navlinks.foreach(function(val, i, arr) { //finds and navigates to each navlink page return $browser.findelement($driver.by.classname(navlinks[i])).click().then(function() { //verifies that the nav list loaded before moving on return $browser.findelement($driver.by.classname(\"site-nav-list-example\")).then(function() { //verifies that the page logo footer at bottom of page has loaded return $browser.findelement($driver.by.classname(\"site-footer-logo\")); }); }); }); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.42831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need"
      },
      "id": "603e84bb28ccbce555eba771"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2022-01-12T03:41:24Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.86588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Application monitoring tips you need to know It&#x27;s one thing to know how to use APM, but it&#x27;s another thing to know how to use <em>New</em> <em>Relic</em>&#x27;s application performance monitoring software well. Here are some <em>best</em> <em>practices</em> designed to help you become an APM pro—and a key asset to your team! Tip To get"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Infrastructure monitoring best practices guide",
        "1. Install the infrastructure agent across your entire environment",
        "How to do it",
        "Tip",
        "2. Configure the native EC2 integration",
        "3. Activate the integrations",
        "4. Create filter sets",
        "5. Create alert conditions",
        "6. View infrastructure data alongside APM data",
        "7. Access Infrastructure data using the Data explorer",
        "8. Update your agents regularly",
        "Want more user tips?"
      ],
      "title": "Infrastructure monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "931ea7767d73381ca0cb3502ec14f88d66ce5eaf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T05:56:02Z",
      "updated_at": "2021-09-14T06:03:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Want even longer periods of uninterrupted sleep? Here are eight best practices to make dynamic infrastructure and server monitoring even easier with New Relic's infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution was designed to help enterprise customers monitor their large and dynamically changing environments at scale. In order to facilitate this, the UI is completely driven by tags that let you visualize aggregated metrics, events, and inventory for a large number of servers. To really get the most out of infrastructure monitoring, we recommend installing it across your entire environment, preferably even across multiple regions and clusters. This will provide a more accurate picture of the health of your host ecosystem and the impact your infrastructure has on your applications. Want to achieve faster Mean Time To Resolution (MTTR)? Install the infrastructure agent on database servers, web servers, and any other host that supports your applications. When deploying the agent, leverage custom attributes to tag your hosts so that you can use those for filtering the data presented in the UI and for setting alerts. This is in addition to any Amazon EC2 tags you may be using which will auto-import when you enable the EC2 integration. You may also prefer to keep the agent logs separate from the system logs, which you can do through the configuration. How to do it Leverage our install modules for config management tools such as Chef, Puppet and Ansible to easily deploy your agent across all your infrastructure. Read the instructions in the github repo for your config management tool referenced in the link above and define the custom_attributes you want to use to tag your hosts. Set the log_file attribute to your preferred location for the infrastructure agent logs. Tip If you are installing the agent on a single host, the process should only take a few minutes and you can find detailed instructions in our documentation. 2. Configure the native EC2 integration If you have an AWS environment, in addition to installing the infrastructure agent on your EC2 instances to monitor them, we also recommend configuring the EC2 integration so that New Relic can automatically import all the tags and metadata associated with your AWS instances. This allows you to filter down to a part of your infrastructure using the same AWS tags (example, ECTag_Role='Kafka'), and slice-and-dice your data in multiple ways. Additionally, our ‘Alerts’ and ‘Saved Filter Sets’ are completely tag-driven and dynamic, so they automatically add/remove instances matching these tags to give our users the most real-time views that scale with your cloud infrastructure. 3. Activate the integrations Monitoring your infrastructure extends beyond just CPU, memory, and storage utilization. That’s why New Relic has out-of-the-box integrations that allow you to monitor all the services that support your hosts as well. Activate any of our integrations, including AWS Billing, AWS ELB, Amazon S3, MySQL, NGINX, and more, to extend monitoring to your AWS or on-host applications, and access the pre-configured dashboards that appear for each of them. 4. Create filter sets With New Relic, users can create filter sets to organize hosts, cluster roles, and other resources based on criteria that matter the most to users. This allows you to optimize your resources by using a focused view to monitor, detect, and resolve any problems proactively. The attributes for filtering are populated from the auto-imported EC2 tags or custom tags that may be applied to hosts. You can combine as many filters as you want in a filter set, and save them to share with other people in your account. You’ll also be able to see the color-coded health status of each host inside the filter set, so you can quickly identify problematic areas of your infrastructure. Additionally, filter sets can be used in the health map to get an overview of your infrastructure performance at a glance based on the filters that matter to your teams. 5. Create alert conditions With New Relic, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are viewing a filter set comprised of a large number of hosts and notice a problem, you don’t need to create an individual alert condition for every host within. Instead, we recommend initiating the alert condition directly from the chart of the metric you are viewing and creating it based on the filter tags. This will create an alert condition for any hosts that match those tags, allowing our infrastructure monitoring to automatically remove hosts that go offline and add new hosts to the alert condition if they match those tags. Alerts configured once for the appropriate tags will scale correctly across all future hosts. And know that you can also leverage existing alert policies for infrastructure alert conditions. 6. View infrastructure data alongside APM data The integration between APM and infrastructure monitoring lets you see your APM data and infrastructure data side by side, so you can find the root cause of problems more quickly, no matter where they originate. This allows users to view the performance relationship of your hosts and the applications running on them, allowing for quicker diagnosis of the issue and impact on the business’ health. Use health maps to quickly spot any issues or alerts related to the health of your applications and how that connects to the supporting infrastructure. The first boxes starting from the top left are those that require your attention. 7. Access Infrastructure data using the Data explorer Teams that use multiple New Relic capabilities find it useful to create a single dashboard to visually correlate the infrastructure’s health with application, browser and synthetics metrics. That’s where New Relic data exploration features comes in. All the granular metrics and events collected by infrastructure monitoring are stored in New Relic and are accessible to you immediately. Having access to the raw metrics means you can run more custom queries using NRQL, and also create dashboards to share infrastructure metrics with your team. 8. Update your agents regularly New Relic’s software engineering team is constantly pushing out improvements and new features to improve our customers’ overall monitoring experience. In order to take advantage of all the awesomeness they’re delivering, we recommend regularly updating to the latest version of the infrastructure agent. Want more user tips? View training videos at New Relic University. Read the documentation. Check out our Tutorials. Ask a question in the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.9315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Want even longer periods of uninterrupted sleep? Here are eight <em>best</em> <em>practices</em> to make dynamic infrastructure and server monitoring even easier with <em>New</em> <em>Relic</em>&#x27;s infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution"
      },
      "id": "6044151c28ccbc4b4f2c60af"
    }
  ],
  "/docs/new-relic-solutions/best-practices-guides/full-stack-observability/browser-monitoring-best-practices-java": [
    {
      "sections": [
        "Synthetic monitoring best practices guide",
        "1. Match your monitor type to monitoring need",
        "How to do it",
        "2. View all monitors with the Monitors index page",
        "How to view your monitors in the New Relic One:",
        "New Relic Explorer",
        "Monitors index page",
        "3. View individual monitor results",
        "How to do it:",
        "4. Understand the load-time impact of each resource",
        "5. Configure and develop a scripted browser test"
      ],
      "title": "Synthetic monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "e76eb0669a1433bb9d0de70d90413e19749adf61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/synthetic-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T03:20:55Z",
      "updated_at": "2021-12-25T11:14:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need Synthetic monitors are virtual browsers that measure the performance of your website, recording each check in detail. They also capture aggregate numbers for load time, uptime, and average download size, as well as an overview, detailed statistics for each page resource, and downtime incidents. There are four types of synthetic monitors; the ones you deploy will depend on the things you want to monitor: Ping monitors—to ensure that your site is accessible. Simple browser monitors—to ensure end-user performance. Scripted browsers—to ensure that particular resources are present. API monitors—to ensure that your app server works as well as your website. How to do it To add a monitor, go to one.newrelic.com > Synthetics (or one.eu.newrelic.com if you have an EU-based account) and click Create monitor. Specify monitor type, name, and URL. Optional: Add a validation string (available for ping and simple browser) or advanced options, which enable substring monitoring for the following types of response validation: Verify SSL (for ping and simple browser). This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs > /dev/null Copy Bypass HEAD request (for ping). This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure (for ping). If a redirect result occurs when Redirect is Failure is enabled, Synthetics categorizes it as a failure (rather than following the redirect and checking the resulting URL). Select the locations where you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes; then from the Monitors index check your monitor. 2. View all monitors with the Monitors index page Continuous application performance monitoring is essential to ensure that web services are in place, working correctly, and error-free. Synthetic monitoring provides this type of assurance by performing automated tests on your web application for each selected location—noting downtime instances (“violations”) and collecting aggregate numbers, results, and detailed statistics for each page resource. Use the Monitors index page to get a high level view of this information, or select an individual monitor to view the Summary, for ping monitors, or Overview, for simple and scripted monitors, page and get a deeper insight into its performance over time. How to view your monitors in the New Relic One: New Relic Explorer To view a list of monitors using the New Relic One Monitors index page: Go to one.newrelic.com > Explorer > Synthetic monitors. For more information, see the documentation about navigating core UI components in New Relic One. Monitors index page To view a list of monitors using the Monitors index page: Go to one.newrelic.com > Synthetics. 3. View individual monitor results It’s not enough to understand how your web apps are performing for your West Coast customers; you need to be able to view how they’re performing across the country and around the globe. By taking advantage of synthetic monitors and visiting your Results page, you can see how everything from development to production affects user experience. You can locate interesting results by sorting the list to identify slow, fast, or other unusual results. Or filter by location to understand how monitor performance varies with geography. (The “Network timings” graph below provides a snapshot of webpage performance over a given period.) How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors tab, select your monitor. Select Monitor > Results. Gain an up-to-the-minute view of the slowest page loads for every monitored location. 4. Understand the load-time impact of each resource Visit the synthetics Resources page to see how each resource on your website—including CSS, JavaScript, images, HTML and more—is affecting your overall load. You can drill into detailed metrics collected at run time, locate performance information for time spent by third-party resources, and identify HTTP response codes for each resource. How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors drop-down menu, select your monitor. Select Monitor > Resources. 5. Configure and develop a scripted browser test Using scripted browsers, you can build complex monitoring workflows using the Selenium JavaScript Webdriver bindings. For instance, you can log in to the application, navigate to a particular link, and wait for a page element to load and add an assertion. How to do it: Go to one.newrelic.com > Synthetics. Choose your monitor type (for example, scripted browser). Enter the name and details of your monitor (for example, Sitename.com scripted browser) Select the locations from which you want your monitor to run (for example, Mumbai, Seoul, Columbus, and Montreal). Choose a frequency to determine how often each location will run your monitor (for example, five minutes). Set a notification method to alert your team when performance violations occur. You are now ready to write your script. (Below is an example of a script used to test the performance of a main navigation page.) var assert = require('chai').assert; // script-wide timeout for all wait and waitandfind functions (in ms) var default_element_timeout = 190000; //3 mins var default_pageload_timeout = 240000; //4 mins var navlinks = [\"css-locator-1\", \"css-locator-2\"]; //sets element load timeout to 3 mins $browser.manage().timeouts().implicitlyWait(default_element_timeout); //sets page load timoeout to 4 mins $browser.manage().timeouts().pageloadTimeout(default_pageload_timeout); //test all the main nav page performances $browser.get(\"http://www.sitename.com\").then(function() { return $browser.findelement($driver.by.classname(\"site-theme-example\")); }).then(function() { //verifies the nav list has loaded return $browser.findelement($driver.by.classname(\"site-nav-list-example\")); }).then(function() { //loops through the navlinks array navlinks.foreach(function(val, i, arr) { //finds and navigates to each navlink page return $browser.findelement($driver.by.classname(navlinks[i])).click().then(function() { //verifies that the nav list loaded before moving on return $browser.findelement($driver.by.classname(\"site-nav-list-example\")).then(function() { //verifies that the page logo footer at bottom of page has loaded return $browser.findelement($driver.by.classname(\"site-footer-logo\")); }); }); }); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.42831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need"
      },
      "id": "603e84bb28ccbce555eba771"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2022-01-12T03:41:24Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.86588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Application monitoring tips you need to know It&#x27;s one thing to know how to use APM, but it&#x27;s another thing to know how to use <em>New</em> <em>Relic</em>&#x27;s application performance monitoring software well. Here are some <em>best</em> <em>practices</em> designed to help you become an APM pro—and a key asset to your team! Tip To get"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Infrastructure monitoring best practices guide",
        "1. Install the infrastructure agent across your entire environment",
        "How to do it",
        "Tip",
        "2. Configure the native EC2 integration",
        "3. Activate the integrations",
        "4. Create filter sets",
        "5. Create alert conditions",
        "6. View infrastructure data alongside APM data",
        "7. Access Infrastructure data using the Data explorer",
        "8. Update your agents regularly",
        "Want more user tips?"
      ],
      "title": "Infrastructure monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "931ea7767d73381ca0cb3502ec14f88d66ce5eaf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T05:56:02Z",
      "updated_at": "2021-09-14T06:03:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Want even longer periods of uninterrupted sleep? Here are eight best practices to make dynamic infrastructure and server monitoring even easier with New Relic's infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution was designed to help enterprise customers monitor their large and dynamically changing environments at scale. In order to facilitate this, the UI is completely driven by tags that let you visualize aggregated metrics, events, and inventory for a large number of servers. To really get the most out of infrastructure monitoring, we recommend installing it across your entire environment, preferably even across multiple regions and clusters. This will provide a more accurate picture of the health of your host ecosystem and the impact your infrastructure has on your applications. Want to achieve faster Mean Time To Resolution (MTTR)? Install the infrastructure agent on database servers, web servers, and any other host that supports your applications. When deploying the agent, leverage custom attributes to tag your hosts so that you can use those for filtering the data presented in the UI and for setting alerts. This is in addition to any Amazon EC2 tags you may be using which will auto-import when you enable the EC2 integration. You may also prefer to keep the agent logs separate from the system logs, which you can do through the configuration. How to do it Leverage our install modules for config management tools such as Chef, Puppet and Ansible to easily deploy your agent across all your infrastructure. Read the instructions in the github repo for your config management tool referenced in the link above and define the custom_attributes you want to use to tag your hosts. Set the log_file attribute to your preferred location for the infrastructure agent logs. Tip If you are installing the agent on a single host, the process should only take a few minutes and you can find detailed instructions in our documentation. 2. Configure the native EC2 integration If you have an AWS environment, in addition to installing the infrastructure agent on your EC2 instances to monitor them, we also recommend configuring the EC2 integration so that New Relic can automatically import all the tags and metadata associated with your AWS instances. This allows you to filter down to a part of your infrastructure using the same AWS tags (example, ECTag_Role='Kafka'), and slice-and-dice your data in multiple ways. Additionally, our ‘Alerts’ and ‘Saved Filter Sets’ are completely tag-driven and dynamic, so they automatically add/remove instances matching these tags to give our users the most real-time views that scale with your cloud infrastructure. 3. Activate the integrations Monitoring your infrastructure extends beyond just CPU, memory, and storage utilization. That’s why New Relic has out-of-the-box integrations that allow you to monitor all the services that support your hosts as well. Activate any of our integrations, including AWS Billing, AWS ELB, Amazon S3, MySQL, NGINX, and more, to extend monitoring to your AWS or on-host applications, and access the pre-configured dashboards that appear for each of them. 4. Create filter sets With New Relic, users can create filter sets to organize hosts, cluster roles, and other resources based on criteria that matter the most to users. This allows you to optimize your resources by using a focused view to monitor, detect, and resolve any problems proactively. The attributes for filtering are populated from the auto-imported EC2 tags or custom tags that may be applied to hosts. You can combine as many filters as you want in a filter set, and save them to share with other people in your account. You’ll also be able to see the color-coded health status of each host inside the filter set, so you can quickly identify problematic areas of your infrastructure. Additionally, filter sets can be used in the health map to get an overview of your infrastructure performance at a glance based on the filters that matter to your teams. 5. Create alert conditions With New Relic, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are viewing a filter set comprised of a large number of hosts and notice a problem, you don’t need to create an individual alert condition for every host within. Instead, we recommend initiating the alert condition directly from the chart of the metric you are viewing and creating it based on the filter tags. This will create an alert condition for any hosts that match those tags, allowing our infrastructure monitoring to automatically remove hosts that go offline and add new hosts to the alert condition if they match those tags. Alerts configured once for the appropriate tags will scale correctly across all future hosts. And know that you can also leverage existing alert policies for infrastructure alert conditions. 6. View infrastructure data alongside APM data The integration between APM and infrastructure monitoring lets you see your APM data and infrastructure data side by side, so you can find the root cause of problems more quickly, no matter where they originate. This allows users to view the performance relationship of your hosts and the applications running on them, allowing for quicker diagnosis of the issue and impact on the business’ health. Use health maps to quickly spot any issues or alerts related to the health of your applications and how that connects to the supporting infrastructure. The first boxes starting from the top left are those that require your attention. 7. Access Infrastructure data using the Data explorer Teams that use multiple New Relic capabilities find it useful to create a single dashboard to visually correlate the infrastructure’s health with application, browser and synthetics metrics. That’s where New Relic data exploration features comes in. All the granular metrics and events collected by infrastructure monitoring are stored in New Relic and are accessible to you immediately. Having access to the raw metrics means you can run more custom queries using NRQL, and also create dashboards to share infrastructure metrics with your team. 8. Update your agents regularly New Relic’s software engineering team is constantly pushing out improvements and new features to improve our customers’ overall monitoring experience. In order to take advantage of all the awesomeness they’re delivering, we recommend regularly updating to the latest version of the infrastructure agent. Want more user tips? View training videos at New Relic University. Read the documentation. Check out our Tutorials. Ask a question in the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.9315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Want even longer periods of uninterrupted sleep? Here are eight <em>best</em> <em>practices</em> to make dynamic infrastructure and server monitoring even easier with <em>New</em> <em>Relic</em>&#x27;s infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution"
      },
      "id": "6044151c28ccbc4b4f2c60af"
    }
  ],
  "/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide": [
    {
      "sections": [
        "Synthetic monitoring best practices guide",
        "1. Match your monitor type to monitoring need",
        "How to do it",
        "2. View all monitors with the Monitors index page",
        "How to view your monitors in the New Relic One:",
        "New Relic Explorer",
        "Monitors index page",
        "3. View individual monitor results",
        "How to do it:",
        "4. Understand the load-time impact of each resource",
        "5. Configure and develop a scripted browser test"
      ],
      "title": "Synthetic monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "e76eb0669a1433bb9d0de70d90413e19749adf61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/synthetic-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T03:20:55Z",
      "updated_at": "2021-12-25T11:14:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need Synthetic monitors are virtual browsers that measure the performance of your website, recording each check in detail. They also capture aggregate numbers for load time, uptime, and average download size, as well as an overview, detailed statistics for each page resource, and downtime incidents. There are four types of synthetic monitors; the ones you deploy will depend on the things you want to monitor: Ping monitors—to ensure that your site is accessible. Simple browser monitors—to ensure end-user performance. Scripted browsers—to ensure that particular resources are present. API monitors—to ensure that your app server works as well as your website. How to do it To add a monitor, go to one.newrelic.com > Synthetics (or one.eu.newrelic.com if you have an EU-based account) and click Create monitor. Specify monitor type, name, and URL. Optional: Add a validation string (available for ping and simple browser) or advanced options, which enable substring monitoring for the following types of response validation: Verify SSL (for ping and simple browser). This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs > /dev/null Copy Bypass HEAD request (for ping). This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure (for ping). If a redirect result occurs when Redirect is Failure is enabled, Synthetics categorizes it as a failure (rather than following the redirect and checking the resulting URL). Select the locations where you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes; then from the Monitors index check your monitor. 2. View all monitors with the Monitors index page Continuous application performance monitoring is essential to ensure that web services are in place, working correctly, and error-free. Synthetic monitoring provides this type of assurance by performing automated tests on your web application for each selected location—noting downtime instances (“violations”) and collecting aggregate numbers, results, and detailed statistics for each page resource. Use the Monitors index page to get a high level view of this information, or select an individual monitor to view the Summary, for ping monitors, or Overview, for simple and scripted monitors, page and get a deeper insight into its performance over time. How to view your monitors in the New Relic One: New Relic Explorer To view a list of monitors using the New Relic One Monitors index page: Go to one.newrelic.com > Explorer > Synthetic monitors. For more information, see the documentation about navigating core UI components in New Relic One. Monitors index page To view a list of monitors using the Monitors index page: Go to one.newrelic.com > Synthetics. 3. View individual monitor results It’s not enough to understand how your web apps are performing for your West Coast customers; you need to be able to view how they’re performing across the country and around the globe. By taking advantage of synthetic monitors and visiting your Results page, you can see how everything from development to production affects user experience. You can locate interesting results by sorting the list to identify slow, fast, or other unusual results. Or filter by location to understand how monitor performance varies with geography. (The “Network timings” graph below provides a snapshot of webpage performance over a given period.) How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors tab, select your monitor. Select Monitor > Results. Gain an up-to-the-minute view of the slowest page loads for every monitored location. 4. Understand the load-time impact of each resource Visit the synthetics Resources page to see how each resource on your website—including CSS, JavaScript, images, HTML and more—is affecting your overall load. You can drill into detailed metrics collected at run time, locate performance information for time spent by third-party resources, and identify HTTP response codes for each resource. How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors drop-down menu, select your monitor. Select Monitor > Resources. 5. Configure and develop a scripted browser test Using scripted browsers, you can build complex monitoring workflows using the Selenium JavaScript Webdriver bindings. For instance, you can log in to the application, navigate to a particular link, and wait for a page element to load and add an assertion. How to do it: Go to one.newrelic.com > Synthetics. Choose your monitor type (for example, scripted browser). Enter the name and details of your monitor (for example, Sitename.com scripted browser) Select the locations from which you want your monitor to run (for example, Mumbai, Seoul, Columbus, and Montreal). Choose a frequency to determine how often each location will run your monitor (for example, five minutes). Set a notification method to alert your team when performance violations occur. You are now ready to write your script. (Below is an example of a script used to test the performance of a main navigation page.) var assert = require('chai').assert; // script-wide timeout for all wait and waitandfind functions (in ms) var default_element_timeout = 190000; //3 mins var default_pageload_timeout = 240000; //4 mins var navlinks = [\"css-locator-1\", \"css-locator-2\"]; //sets element load timeout to 3 mins $browser.manage().timeouts().implicitlyWait(default_element_timeout); //sets page load timoeout to 4 mins $browser.manage().timeouts().pageloadTimeout(default_pageload_timeout); //test all the main nav page performances $browser.get(\"http://www.sitename.com\").then(function() { return $browser.findelement($driver.by.classname(\"site-theme-example\")); }).then(function() { //verifies the nav list has loaded return $browser.findelement($driver.by.classname(\"site-nav-list-example\")); }).then(function() { //loops through the navlinks array navlinks.foreach(function(val, i, arr) { //finds and navigates to each navlink page return $browser.findelement($driver.by.classname(navlinks[i])).click().then(function() { //verifies that the nav list loaded before moving on return $browser.findelement($driver.by.classname(\"site-nav-list-example\")).then(function() { //verifies that the page logo footer at bottom of page has loaded return $browser.findelement($driver.by.classname(\"site-footer-logo\")); }); }); }); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.42828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need"
      },
      "id": "603e84bb28ccbce555eba771"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2022-01-12T03:41:24Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.86588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Application monitoring tips you need to know It&#x27;s one thing to know how to use APM, but it&#x27;s another thing to know how to use <em>New</em> <em>Relic</em>&#x27;s application performance monitoring software well. Here are some <em>best</em> <em>practices</em> designed to help you become an APM pro—and a key asset to your team! Tip To get"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T03:28:12Z",
      "updated_at": "2021-08-02T10:17:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Use our metric-based alerts and mobile monitoring UI: Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if you're using our browser monitoring), so that you can compare and contrast performance across end-user channels. The mobile agents track the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.66626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some <em>best</em> <em>practices</em> to take full advantage of mobile monitoring with <em>New</em> <em>Relic</em>. 1. Start collecting data Start collecting data in production. You&#x27;ll see immediate"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    }
  ],
  "/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide": [
    {
      "sections": [
        "Synthetic monitoring best practices guide",
        "1. Match your monitor type to monitoring need",
        "How to do it",
        "2. View all monitors with the Monitors index page",
        "How to view your monitors in the New Relic One:",
        "New Relic Explorer",
        "Monitors index page",
        "3. View individual monitor results",
        "How to do it:",
        "4. Understand the load-time impact of each resource",
        "5. Configure and develop a scripted browser test"
      ],
      "title": "Synthetic monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "e76eb0669a1433bb9d0de70d90413e19749adf61",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/synthetic-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T03:20:55Z",
      "updated_at": "2021-12-25T11:14:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need Synthetic monitors are virtual browsers that measure the performance of your website, recording each check in detail. They also capture aggregate numbers for load time, uptime, and average download size, as well as an overview, detailed statistics for each page resource, and downtime incidents. There are four types of synthetic monitors; the ones you deploy will depend on the things you want to monitor: Ping monitors—to ensure that your site is accessible. Simple browser monitors—to ensure end-user performance. Scripted browsers—to ensure that particular resources are present. API monitors—to ensure that your app server works as well as your website. How to do it To add a monitor, go to one.newrelic.com > Synthetics (or one.eu.newrelic.com if you have an EU-based account) and click Create monitor. Specify monitor type, name, and URL. Optional: Add a validation string (available for ping and simple browser) or advanced options, which enable substring monitoring for the following types of response validation: Verify SSL (for ping and simple browser). This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs > /dev/null Copy Bypass HEAD request (for ping). This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure (for ping). If a redirect result occurs when Redirect is Failure is enabled, Synthetics categorizes it as a failure (rather than following the redirect and checking the resulting URL). Select the locations where you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes; then from the Monitors index check your monitor. 2. View all monitors with the Monitors index page Continuous application performance monitoring is essential to ensure that web services are in place, working correctly, and error-free. Synthetic monitoring provides this type of assurance by performing automated tests on your web application for each selected location—noting downtime instances (“violations”) and collecting aggregate numbers, results, and detailed statistics for each page resource. Use the Monitors index page to get a high level view of this information, or select an individual monitor to view the Summary, for ping monitors, or Overview, for simple and scripted monitors, page and get a deeper insight into its performance over time. How to view your monitors in the New Relic One: New Relic Explorer To view a list of monitors using the New Relic One Monitors index page: Go to one.newrelic.com > Explorer > Synthetic monitors. For more information, see the documentation about navigating core UI components in New Relic One. Monitors index page To view a list of monitors using the Monitors index page: Go to one.newrelic.com > Synthetics. 3. View individual monitor results It’s not enough to understand how your web apps are performing for your West Coast customers; you need to be able to view how they’re performing across the country and around the globe. By taking advantage of synthetic monitors and visiting your Results page, you can see how everything from development to production affects user experience. You can locate interesting results by sorting the list to identify slow, fast, or other unusual results. Or filter by location to understand how monitor performance varies with geography. (The “Network timings” graph below provides a snapshot of webpage performance over a given period.) How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors tab, select your monitor. Select Monitor > Results. Gain an up-to-the-minute view of the slowest page loads for every monitored location. 4. Understand the load-time impact of each resource Visit the synthetics Resources page to see how each resource on your website—including CSS, JavaScript, images, HTML and more—is affecting your overall load. You can drill into detailed metrics collected at run time, locate performance information for time spent by third-party resources, and identify HTTP response codes for each resource. How to do it: Go to one.newrelic.com > Synthetics and, from the Monitors drop-down menu, select your monitor. Select Monitor > Resources. 5. Configure and develop a scripted browser test Using scripted browsers, you can build complex monitoring workflows using the Selenium JavaScript Webdriver bindings. For instance, you can log in to the application, navigate to a particular link, and wait for a page element to load and add an assertion. How to do it: Go to one.newrelic.com > Synthetics. Choose your monitor type (for example, scripted browser). Enter the name and details of your monitor (for example, Sitename.com scripted browser) Select the locations from which you want your monitor to run (for example, Mumbai, Seoul, Columbus, and Montreal). Choose a frequency to determine how often each location will run your monitor (for example, five minutes). Set a notification method to alert your team when performance violations occur. You are now ready to write your script. (Below is an example of a script used to test the performance of a main navigation page.) var assert = require('chai').assert; // script-wide timeout for all wait and waitandfind functions (in ms) var default_element_timeout = 190000; //3 mins var default_pageload_timeout = 240000; //4 mins var navlinks = [\"css-locator-1\", \"css-locator-2\"]; //sets element load timeout to 3 mins $browser.manage().timeouts().implicitlyWait(default_element_timeout); //sets page load timoeout to 4 mins $browser.manage().timeouts().pageloadTimeout(default_pageload_timeout); //test all the main nav page performances $browser.get(\"http://www.sitename.com\").then(function() { return $browser.findelement($driver.by.classname(\"site-theme-example\")); }).then(function() { //verifies the nav list has loaded return $browser.findelement($driver.by.classname(\"site-nav-list-example\")); }).then(function() { //loops through the navlinks array navlinks.foreach(function(val, i, arr) { //finds and navigates to each navlink page return $browser.findelement($driver.by.classname(navlinks[i])).click().then(function() { //verifies that the nav list loaded before moving on return $browser.findelement($driver.by.classname(\"site-nav-list-example\")).then(function() { //verifies that the page logo footer at bottom of page has loaded return $browser.findelement($driver.by.classname(\"site-footer-logo\")); }); }); }); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.42828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Synthetic monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s synthetic monitoring—powered by a Selenium-driven Chrome browser—allows you to monitor and test your apps and address issues before they affect your end users. Here are five tips to help you take immediate advantage of its full power. 1. Match your monitor type to monitoring need"
      },
      "id": "603e84bb28ccbce555eba771"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2022-01-12T03:41:24Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.86588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Application monitoring tips you need to know It&#x27;s one thing to know how to use APM, but it&#x27;s another thing to know how to use <em>New</em> <em>Relic</em>&#x27;s application performance monitoring software well. Here are some <em>best</em> <em>practices</em> designed to help you become an APM pro—and a key asset to your team! Tip To get"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Infrastructure monitoring best practices guide",
        "1. Install the infrastructure agent across your entire environment",
        "How to do it",
        "Tip",
        "2. Configure the native EC2 integration",
        "3. Activate the integrations",
        "4. Create filter sets",
        "5. Create alert conditions",
        "6. View infrastructure data alongside APM data",
        "7. Access Infrastructure data using the Data explorer",
        "8. Update your agents regularly",
        "Want more user tips?"
      ],
      "title": "Infrastructure monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "931ea7767d73381ca0cb3502ec14f88d66ce5eaf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T05:56:02Z",
      "updated_at": "2021-09-14T06:03:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Want even longer periods of uninterrupted sleep? Here are eight best practices to make dynamic infrastructure and server monitoring even easier with New Relic's infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution was designed to help enterprise customers monitor their large and dynamically changing environments at scale. In order to facilitate this, the UI is completely driven by tags that let you visualize aggregated metrics, events, and inventory for a large number of servers. To really get the most out of infrastructure monitoring, we recommend installing it across your entire environment, preferably even across multiple regions and clusters. This will provide a more accurate picture of the health of your host ecosystem and the impact your infrastructure has on your applications. Want to achieve faster Mean Time To Resolution (MTTR)? Install the infrastructure agent on database servers, web servers, and any other host that supports your applications. When deploying the agent, leverage custom attributes to tag your hosts so that you can use those for filtering the data presented in the UI and for setting alerts. This is in addition to any Amazon EC2 tags you may be using which will auto-import when you enable the EC2 integration. You may also prefer to keep the agent logs separate from the system logs, which you can do through the configuration. How to do it Leverage our install modules for config management tools such as Chef, Puppet and Ansible to easily deploy your agent across all your infrastructure. Read the instructions in the github repo for your config management tool referenced in the link above and define the custom_attributes you want to use to tag your hosts. Set the log_file attribute to your preferred location for the infrastructure agent logs. Tip If you are installing the agent on a single host, the process should only take a few minutes and you can find detailed instructions in our documentation. 2. Configure the native EC2 integration If you have an AWS environment, in addition to installing the infrastructure agent on your EC2 instances to monitor them, we also recommend configuring the EC2 integration so that New Relic can automatically import all the tags and metadata associated with your AWS instances. This allows you to filter down to a part of your infrastructure using the same AWS tags (example, ECTag_Role='Kafka'), and slice-and-dice your data in multiple ways. Additionally, our ‘Alerts’ and ‘Saved Filter Sets’ are completely tag-driven and dynamic, so they automatically add/remove instances matching these tags to give our users the most real-time views that scale with your cloud infrastructure. 3. Activate the integrations Monitoring your infrastructure extends beyond just CPU, memory, and storage utilization. That’s why New Relic has out-of-the-box integrations that allow you to monitor all the services that support your hosts as well. Activate any of our integrations, including AWS Billing, AWS ELB, Amazon S3, MySQL, NGINX, and more, to extend monitoring to your AWS or on-host applications, and access the pre-configured dashboards that appear for each of them. 4. Create filter sets With New Relic, users can create filter sets to organize hosts, cluster roles, and other resources based on criteria that matter the most to users. This allows you to optimize your resources by using a focused view to monitor, detect, and resolve any problems proactively. The attributes for filtering are populated from the auto-imported EC2 tags or custom tags that may be applied to hosts. You can combine as many filters as you want in a filter set, and save them to share with other people in your account. You’ll also be able to see the color-coded health status of each host inside the filter set, so you can quickly identify problematic areas of your infrastructure. Additionally, filter sets can be used in the health map to get an overview of your infrastructure performance at a glance based on the filters that matter to your teams. 5. Create alert conditions With New Relic, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are viewing a filter set comprised of a large number of hosts and notice a problem, you don’t need to create an individual alert condition for every host within. Instead, we recommend initiating the alert condition directly from the chart of the metric you are viewing and creating it based on the filter tags. This will create an alert condition for any hosts that match those tags, allowing our infrastructure monitoring to automatically remove hosts that go offline and add new hosts to the alert condition if they match those tags. Alerts configured once for the appropriate tags will scale correctly across all future hosts. And know that you can also leverage existing alert policies for infrastructure alert conditions. 6. View infrastructure data alongside APM data The integration between APM and infrastructure monitoring lets you see your APM data and infrastructure data side by side, so you can find the root cause of problems more quickly, no matter where they originate. This allows users to view the performance relationship of your hosts and the applications running on them, allowing for quicker diagnosis of the issue and impact on the business’ health. Use health maps to quickly spot any issues or alerts related to the health of your applications and how that connects to the supporting infrastructure. The first boxes starting from the top left are those that require your attention. 7. Access Infrastructure data using the Data explorer Teams that use multiple New Relic capabilities find it useful to create a single dashboard to visually correlate the infrastructure’s health with application, browser and synthetics metrics. That’s where New Relic data exploration features comes in. All the granular metrics and events collected by infrastructure monitoring are stored in New Relic and are accessible to you immediately. Having access to the raw metrics means you can run more custom queries using NRQL, and also create dashboards to share infrastructure metrics with your team. 8. Update your agents regularly New Relic’s software engineering team is constantly pushing out improvements and new features to improve our customers’ overall monitoring experience. In order to take advantage of all the awesomeness they’re delivering, we recommend regularly updating to the latest version of the infrastructure agent. Want more user tips? View training videos at New Relic University. Read the documentation. Check out our Tutorials. Ask a question in the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.9315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Want even longer periods of uninterrupted sleep? Here are eight <em>best</em> <em>practices</em> to make dynamic infrastructure and server monitoring even easier with <em>New</em> <em>Relic</em>&#x27;s infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution"
      },
      "id": "6044151c28ccbc4b4f2c60af"
    }
  ],
  "/docs/new-relic-solutions/best-practices-guides/full-stack-observability/synthetic-monitoring-best-practices-guide": [
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2022-01-12T03:41:24Z",
      "updated_at": "2021-09-30T19:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application monitoring tips you need to know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM pro—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, APM apps, browser monitoring apps, or hosts) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > Service maps. To get started, see Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access How you manage your users depends on which user model your users are on: See original user management docs See New Relic One user management docs",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.86588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "APM <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Application monitoring tips you need to know It&#x27;s one thing to know how to use APM, but it&#x27;s another thing to know how to use <em>New</em> <em>Relic</em>&#x27;s application performance monitoring software well. Here are some <em>best</em> <em>practices</em> designed to help you become an APM pro—and a key asset to your team! Tip To get"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Infrastructure monitoring best practices guide",
        "1. Install the infrastructure agent across your entire environment",
        "How to do it",
        "Tip",
        "2. Configure the native EC2 integration",
        "3. Activate the integrations",
        "4. Create filter sets",
        "5. Create alert conditions",
        "6. View infrastructure data alongside APM data",
        "7. Access Infrastructure data using the Data explorer",
        "8. Update your agents regularly",
        "Want more user tips?"
      ],
      "title": "Infrastructure monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "931ea7767d73381ca0cb3502ec14f88d66ce5eaf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/infrastructure-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T05:56:02Z",
      "updated_at": "2021-09-14T06:03:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Want even longer periods of uninterrupted sleep? Here are eight best practices to make dynamic infrastructure and server monitoring even easier with New Relic's infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution was designed to help enterprise customers monitor their large and dynamically changing environments at scale. In order to facilitate this, the UI is completely driven by tags that let you visualize aggregated metrics, events, and inventory for a large number of servers. To really get the most out of infrastructure monitoring, we recommend installing it across your entire environment, preferably even across multiple regions and clusters. This will provide a more accurate picture of the health of your host ecosystem and the impact your infrastructure has on your applications. Want to achieve faster Mean Time To Resolution (MTTR)? Install the infrastructure agent on database servers, web servers, and any other host that supports your applications. When deploying the agent, leverage custom attributes to tag your hosts so that you can use those for filtering the data presented in the UI and for setting alerts. This is in addition to any Amazon EC2 tags you may be using which will auto-import when you enable the EC2 integration. You may also prefer to keep the agent logs separate from the system logs, which you can do through the configuration. How to do it Leverage our install modules for config management tools such as Chef, Puppet and Ansible to easily deploy your agent across all your infrastructure. Read the instructions in the github repo for your config management tool referenced in the link above and define the custom_attributes you want to use to tag your hosts. Set the log_file attribute to your preferred location for the infrastructure agent logs. Tip If you are installing the agent on a single host, the process should only take a few minutes and you can find detailed instructions in our documentation. 2. Configure the native EC2 integration If you have an AWS environment, in addition to installing the infrastructure agent on your EC2 instances to monitor them, we also recommend configuring the EC2 integration so that New Relic can automatically import all the tags and metadata associated with your AWS instances. This allows you to filter down to a part of your infrastructure using the same AWS tags (example, ECTag_Role='Kafka'), and slice-and-dice your data in multiple ways. Additionally, our ‘Alerts’ and ‘Saved Filter Sets’ are completely tag-driven and dynamic, so they automatically add/remove instances matching these tags to give our users the most real-time views that scale with your cloud infrastructure. 3. Activate the integrations Monitoring your infrastructure extends beyond just CPU, memory, and storage utilization. That’s why New Relic has out-of-the-box integrations that allow you to monitor all the services that support your hosts as well. Activate any of our integrations, including AWS Billing, AWS ELB, Amazon S3, MySQL, NGINX, and more, to extend monitoring to your AWS or on-host applications, and access the pre-configured dashboards that appear for each of them. 4. Create filter sets With New Relic, users can create filter sets to organize hosts, cluster roles, and other resources based on criteria that matter the most to users. This allows you to optimize your resources by using a focused view to monitor, detect, and resolve any problems proactively. The attributes for filtering are populated from the auto-imported EC2 tags or custom tags that may be applied to hosts. You can combine as many filters as you want in a filter set, and save them to share with other people in your account. You’ll also be able to see the color-coded health status of each host inside the filter set, so you can quickly identify problematic areas of your infrastructure. Additionally, filter sets can be used in the health map to get an overview of your infrastructure performance at a glance based on the filters that matter to your teams. 5. Create alert conditions With New Relic, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are viewing a filter set comprised of a large number of hosts and notice a problem, you don’t need to create an individual alert condition for every host within. Instead, we recommend initiating the alert condition directly from the chart of the metric you are viewing and creating it based on the filter tags. This will create an alert condition for any hosts that match those tags, allowing our infrastructure monitoring to automatically remove hosts that go offline and add new hosts to the alert condition if they match those tags. Alerts configured once for the appropriate tags will scale correctly across all future hosts. And know that you can also leverage existing alert policies for infrastructure alert conditions. 6. View infrastructure data alongside APM data The integration between APM and infrastructure monitoring lets you see your APM data and infrastructure data side by side, so you can find the root cause of problems more quickly, no matter where they originate. This allows users to view the performance relationship of your hosts and the applications running on them, allowing for quicker diagnosis of the issue and impact on the business’ health. Use health maps to quickly spot any issues or alerts related to the health of your applications and how that connects to the supporting infrastructure. The first boxes starting from the top left are those that require your attention. 7. Access Infrastructure data using the Data explorer Teams that use multiple New Relic capabilities find it useful to create a single dashboard to visually correlate the infrastructure’s health with application, browser and synthetics metrics. That’s where New Relic data exploration features comes in. All the granular metrics and events collected by infrastructure monitoring are stored in New Relic and are accessible to you immediately. Having access to the raw metrics means you can run more custom queries using NRQL, and also create dashboards to share infrastructure metrics with your team. 8. Update your agents regularly New Relic’s software engineering team is constantly pushing out improvements and new features to improve our customers’ overall monitoring experience. In order to take advantage of all the awesomeness they’re delivering, we recommend regularly updating to the latest version of the infrastructure agent. Want more user tips? View training videos at New Relic University. Read the documentation. Check out our Tutorials. Ask a question in the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.9315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Infrastructure monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "Want even longer periods of uninterrupted sleep? Here are eight <em>best</em> <em>practices</em> to make dynamic infrastructure and server monitoring even easier with <em>New</em> <em>Relic</em>&#x27;s infrastructure monitoring. 1. Install the infrastructure agent across your entire environment Our infrastructure monitoring solution"
      },
      "id": "6044151c28ccbc4b4f2c60af"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2022-01-12T03:28:12Z",
      "updated_at": "2021-08-02T10:17:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Use our metric-based alerts and mobile monitoring UI: Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if you're using our browser monitoring), so that you can compare and contrast performance across end-user channels. The mobile agents track the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.66626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "sections": "Mobile monitoring <em>best</em> <em>practices</em> <em>guide</em>",
        "tags": "<em>Best</em> <em>practices</em> <em>guides</em>",
        "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some <em>best</em> <em>practices</em> to take full advantage of mobile monitoring with <em>New</em> <em>Relic</em>. 1. Start collecting data Start collecting data in production. You&#x27;ll see immediate"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/automate-instrumentation": [
    {
      "sections": [
        "Establish objectives and baselines: define team SLOs",
        "Service level components",
        "Resources",
        "1. Build an inventory of services requiring SLOs",
        "2. Research customer expectations for SLOs",
        "3. Define SLOs",
        "4. Determine what can be instrumented",
        "New Relic products",
        "APM installation",
        "Infrastructure installation",
        "Infrastructure on-host integrations",
        "Synthetics",
        "Browser monitoring",
        "Mobile monitoring",
        "5. Review the default metrics",
        "6. Set up custom instrumentation",
        "7. Create dashboards to track SLIs"
      ],
      "title": "Establish objectives and baselines: define team SLOs",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6bfd37ee90b6890a53bfcf5ca688bbf72d551b70",
      "image": "https://docs.newrelic.com/static/5a07ed4ece7f7732b279460ca80f946d/c1b63/new-relic-logs-alerts.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/establish-objectives-baselines-define-team-slos/",
      "published_at": "2022-01-12T01:49:03Z",
      "updated_at": "2022-01-08T01:56:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A DevOps transformation requires a cultural shift so that teams can build new skills and motivations for the type of cross-team work required in a true DevOps practice. The transformation can be difficult when the people involved do not see the benefits of change as a clear objective. Service level objectives (SLOs) provide a powerful mechanism to codify the goals of a DevOps team in a way that can be measured and shared. They also provide clear boundaries on service expectations that help teams achieve greater velocity and freedom in experimenting with new approaches. This tutorial defines SLOs for successful service delivery objectives and utilize New Relic instrumentation to surface the current performance metrics relative to those objectives. Measurable SLOs and visibility into your current progress against those SLOs ensure that you will be able to properly assess future optimization efforts. See also our service level management feature. Service level components An SLO is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI); for example: Average response time Response time percentile Application availability SLOs clarify a target value for SLIs; for example: Average response time should be less than 200 ms 95% of requests should be completed within 250 ms Availability of the service should be 99.99% Logically group SLOs together to provide an overall boolean indicator of whether or not the service is meeting expectations. For example, a helpful SLO for alerting purposes could be: 95% of requests completed within 250 ms AND availability is 99.99% Copy Service level components Example values SLI (Indicator) HTTP status codes SLO (Objective) < 1% HTTP 500s over 30 days SLA (Agreement) For every additional .1% of HTTP 500s, 5% refund of total contract Resources Value stream mapping can be a useful exercise to work through before setting SLOs. Work with your teams to clarify key components of your service and the appropriate metrics. Use these inputs as starting points for this tutorial. In addition: Learn about SLOs, SLIs, and SLAs from the Google Cloud Platform blog. Learn how New Relic has applied SLOs and SLIs into its reliability practices form this SREcon18 Americas presentation (approximately 21 minutes). 1. Build an inventory of services requiring SLOs Start defining SLOs for your application by first taking an inventory of the services that your application provides to both your internal and external customers. Draft a list of services. Make the scope of services you consider as comprehensive as possible. Engage your team members and other stakeholders to validate the list for completeness. Segment your application stack to understand the potential components that might require SLOs. For example, most applications can be segmented as: Application (backend/microservices) Dependency services (such as the message queue) Database Website Underlying servers This example lists components that would benefit from SLOs: Customer type Component name Owner Language stack Operating system External Service 1 John D. Java RHEL 6 Internal Service 2 Jane A. .NET Win2003 R2 Internal ActiveMQ John D. Java AIX External Website Jane A. Classic ASP Win2000 Internal MS SQL Dave Z. n/a Win2003 R2 Building a definitive list of services that require an SLO can be challenging, because an application often consists of many endpoints with complex interdependencies. Begin your SLO journey with pragmatism. Start by defining a broader, simpler set of SLOs that are driven by what your customers care about most and what your team can control. As your teams better align around SLOs, you can then begin to fine-tune and add more complexity. 2. Research customer expectations for SLOs Once you have an inventory of services, begin to gather the information you need to define the SLOs for those services. Interviews with customers that depend on your services are often valuable for understanding service expectations. For example, to define SLOs for internal teams, New Relic, ask questions such as: If possible, can you broadly categorize the types of requests we can expect from you and your service? To what extent do you or your service depend on timely responses to requests? Are there requests for which response time is not critical? How does your service handle unavailable dependencies or data? What is the maximum amount of unavailable data that your service can handle? At what threshold does your service fail if a request takes too long? What are acceptable rates of errors? What would a SLA look like between our product and yours? Existing usage data can also be a helpful research input. 3. Define SLOs Using the research on customer expectations that you gathered, draft a focused set of SLOs. New Relic recommends setting SLOs against one or more of the following SLIs: Application availability percentage Average response time Response percentile Error rate Apdex value Also, consider instrumenting and tracking the following SLIs: Throughput (peak and trough) Database call count and duration DNS and SSL timing DOM processing and page rendering Mean-time-to-detection (MTTD) For a more comprehensive list of potential areas to measure, see Measuring DevOps. Recommendation: To determine if your application is performing to customer expectations: Consider combining multiple SLIs (for example, availability and response time) into one SLO. Aim to define a consistent set of conditions across all of the services in your list. Consult your team and stakeholders to validate that the SLOs you set are reasonable, consistently attainable (even if you are not currently meeting them), and aligned to customer expectations. After you finish this step, you should have a set of well-defined SLOs and SLIs. 4. Determine what can be instrumented Now you're ready to deploy agents or monitors to establish a performance baseline for the SLIs you created. With proper instrumentation in place, you'll have visibility into the performance indicators that matter for your team and your customers. In addition, you'll also have a clear understanding of how to meet your SLOs. Identify the service components your team will optimize. Verify which application tiers meet New Relic monitoring requirements. To ensure you have robust baselines from which to work, determine the level of instrumentation that is possible (or allowed) within your organization. It's best practice to instrument everything you can, but there may be situations where instrumentation isn't viable. In that case, you should determine what other data is available or can be created. For example, you can gather logs to query them for SLO data and set alerts for them. one.newrelic.com > Logs: Use the New Relic log management UI to leverage your logs. If the application has a web front end in these situations, use New Relic synthetic monitors. Our synthetic monitors offer non-agent monitoring while still providing the ability to establish a baseline. To instrument the example applications and components in this tutorial, use these New Relic features: New Relic products Customer type Component name Tier owner Language stack Server OS New Relic products External Service 1 John D. Java RHEL 6 APM, infrastructure monitoring, synthetic monitors Internal Service 2 Jane A. .Net Win2003 R2 APM, infrastructure monitoring Internal ActiveMQ John D. Java AIX APM External Website Jane A. Classic ASP Win2000 Synthetic monitors Internal MS SQL Dave Z. NA Win2003 R2 Infrastructure monitoring, on-host integrations APM installation After reviewing the compatibility and requirements for APM, install an APM agent on your application stack. Steps for installing APM agents vary based on language agent type. Follow the install procedures for a specific APM agents. Infrastructure installation After reviewing the requirements for New Relic infrastructure monitoring, follow the install procedures to install the infrastructure agent on instances that host your applications. The infrastructure agent requires the following host permissions: Linux: To install and run the agent, you must have root privileges. Windows: To install and run the agent, you must have Administrator privileges. Infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations based on their availability. New Relic supports several commonly used application components, including MySQL, Apache, NGINX, and more. For more information, see our on-host integration docs. Synthetics New Relic synthetic monitoring gives you a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. Follow the procedures to create a simple browser check. Be sure to verify that your website URL is accessible from the Synthetics public network locations. Browser monitoring New Relic browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how DevOps efforts are ultimately improving the experience for the customer. For more information, see the compatibility and requirements, then install the New Relic browser agent. Mobile monitoring The growing role of mobile apps in customer experience often spurs new performance data needs. Installation of New Relic mobile monitoring lets DevOps teams instrument iOS and Android applications to gain a fuller understanding of service delivery quality. 5. Review the default metrics After you deploy the agents and monitors, use service maps to review the default metrics that New Relic captures. For example, a typical service map show many of the common SLIs that application teams rely on, including response time, Apdex, throughput, and error rate metrics from APM. It also shows page load time, Ajax response, throughput, and error rate from browser monitoring. 6. Set up custom instrumentation To close any remaining gaps in visibility for your SLIs, use custom instrumentation. New Relic provides several avenues for adding custom instrumentation, including: Making API calls to agents from inside your source code Packaging XML-based custom instrumentation modules with deployed applications Adding UI-based instrumentation without a code deploy In addition, you can add custom attributes to each transaction event that match application performance factors to critical business information. Then you can track those attributes in Insights dashboards. For more information, see the custom instrumentation documentation for your application: APM Browser Infrastructure Mobile Synthetics 7. Create dashboards to track SLIs Once you implement the appropriate instrumentation, it's easy to visualize your service level indicators with New Relic dashboards, which provide a single location to query and view all the data that New Relic tools gather. To learn more about how to run queries to produce charts and dashboards, see Introduction to query builder. For more about the data you can query, see New Relic data types. The metrics you capture will become your application's baseline. Share dashboards with your application team and stakeholders to provide visibility into what is happening with your application and to monitor future performance.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 453.63876,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>New</em> <em>Relic</em> products",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " monitoring <em>New</em> <em>Relic</em> browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how <em>DevOps</em> efforts are ultimately improving"
      },
      "id": "6044151ee7b9d259ef5799ea"
    },
    {
      "sections": [
        "Iterate and measure impact: track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "Tip",
        "3. Test your pipeline with infrastructure"
      ],
      "title": "Iterate and measure impact: track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "06e2013529667ec66bde080abc3623ac6b6a6695",
      "image": "https://docs.newrelic.com/static/886d79f19e7b5576a06f8cc6016d053d/c1b63/apm-deployments.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2022-01-12T07:55:33Z",
      "updated_at": "2022-01-03T18:36:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A properly instrumented system gives teams full visibility into the impact of the changes they make. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation, and reduce the impact to other ongoing changes. Prerequisite Before starting this tutorial, be sure to complete the Establish objectives and baselines tutorial and set the appropriate KPI targets for your applications. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and to prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they’re consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make are correct across them, and eliminate any anomalies before pushing code to production. 2. Add automated deployment markers It’s important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. APM’s deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change-log, etc.). APM displays a vertical line, or “marker”, on charts and graphs at the deployment event’s timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application, and additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful DevOps transformation is a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. Our infrastructure agent helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names which fits this model quite nicely. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.87494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Iterate and <em>measure</em> impact: track metrics before and after deployments",
        "sections": "1. Integrate <em>measurements</em> into your <em>development</em> process",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful <em>DevOps</em> transformation is a cultural shift toward smaller, more"
      },
      "id": "60450efc64441fb48e378eee"
    },
    {
      "sections": [
        "Measure code pipelines",
        "Prerequisite",
        "1. Identify what to track",
        "2. Capture the events required to instrument your pipeline"
      ],
      "title": "Measure code pipelines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "da5ac3dfed1bb4ab89bff1f3fd8e6d392767ce01",
      "image": "https://docs.newrelic.com/static/6cfae62440efb84aa5c9126e6a33cc8f/508ef/codepipeline2NR.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-code-pipelines/",
      "published_at": "2022-01-12T08:05:38Z",
      "updated_at": "2022-01-03T18:36:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "High functioning DevOps teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make improvements. Prerequisite Before starting this tutorial, be sure to complete the Establish team dashboards tutorial. 1. Identify what to track Look at your CI/CD system and determine the stats you'd like to gather. We recommend, at a minimum, starting with commit metadata, build status, test results, deploy status, and performance metrics. Determine which stats you want to report to New Relic. 2. Capture the events required to instrument your pipeline Capture timestamped state changes to your pipeline/CI/CD system indicating when a given stage started; and whether it succeeded or failed. This step, in turn, makes it easy to track your deployment process over time—looking for trends in the frequency of deployments, build quality, and other performance indicators. For easiest tracking, capture timestamped changes to your source code management system (SCM) with at least the author and a hash or unique change ID. Propagate this information wherever possible. If you have your own build system, add code to emit custom events at each stage. For hosted services, create a lightweight intermediary service/function-as-a-service (FaaS) to format and forward these custom events. The example below uses AWS CodePipeline to manage the flow of an application that is sourced in GitHub, built and tested with AWS CodeBuild, and deployed with Elastic Beanstalk. It utilizes a simple service written in Node.js, plus some \"glue code\" and event handlers needed to push data from GitHub and AWS to New Relic. Code for this example is available at github.com/newrelic/webinar. Use AWS CodePipeline to understand different parts of your flow. We chose the tools and products used here as examples—with the goal of illustrating the concepts around the types of data and events you should be thinking about when instrumenting your own code pipeline. The sample code, however, should be generic enough to adapt readily to almost any toolset.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.87482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Measure</em> code pipelines",
        "sections": "<em>Measure</em> code pipelines",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "High functioning <em>DevOps</em> teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make"
      },
      "id": "603ea2f7e7b9d26d4c2a080a"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/create-application-baselines": [
    {
      "sections": [
        "Establish objectives and baselines: define team SLOs",
        "Service level components",
        "Resources",
        "1. Build an inventory of services requiring SLOs",
        "2. Research customer expectations for SLOs",
        "3. Define SLOs",
        "4. Determine what can be instrumented",
        "New Relic products",
        "APM installation",
        "Infrastructure installation",
        "Infrastructure on-host integrations",
        "Synthetics",
        "Browser monitoring",
        "Mobile monitoring",
        "5. Review the default metrics",
        "6. Set up custom instrumentation",
        "7. Create dashboards to track SLIs"
      ],
      "title": "Establish objectives and baselines: define team SLOs",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6bfd37ee90b6890a53bfcf5ca688bbf72d551b70",
      "image": "https://docs.newrelic.com/static/5a07ed4ece7f7732b279460ca80f946d/c1b63/new-relic-logs-alerts.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/establish-objectives-baselines-define-team-slos/",
      "published_at": "2022-01-12T01:49:03Z",
      "updated_at": "2022-01-08T01:56:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A DevOps transformation requires a cultural shift so that teams can build new skills and motivations for the type of cross-team work required in a true DevOps practice. The transformation can be difficult when the people involved do not see the benefits of change as a clear objective. Service level objectives (SLOs) provide a powerful mechanism to codify the goals of a DevOps team in a way that can be measured and shared. They also provide clear boundaries on service expectations that help teams achieve greater velocity and freedom in experimenting with new approaches. This tutorial defines SLOs for successful service delivery objectives and utilize New Relic instrumentation to surface the current performance metrics relative to those objectives. Measurable SLOs and visibility into your current progress against those SLOs ensure that you will be able to properly assess future optimization efforts. See also our service level management feature. Service level components An SLO is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI); for example: Average response time Response time percentile Application availability SLOs clarify a target value for SLIs; for example: Average response time should be less than 200 ms 95% of requests should be completed within 250 ms Availability of the service should be 99.99% Logically group SLOs together to provide an overall boolean indicator of whether or not the service is meeting expectations. For example, a helpful SLO for alerting purposes could be: 95% of requests completed within 250 ms AND availability is 99.99% Copy Service level components Example values SLI (Indicator) HTTP status codes SLO (Objective) < 1% HTTP 500s over 30 days SLA (Agreement) For every additional .1% of HTTP 500s, 5% refund of total contract Resources Value stream mapping can be a useful exercise to work through before setting SLOs. Work with your teams to clarify key components of your service and the appropriate metrics. Use these inputs as starting points for this tutorial. In addition: Learn about SLOs, SLIs, and SLAs from the Google Cloud Platform blog. Learn how New Relic has applied SLOs and SLIs into its reliability practices form this SREcon18 Americas presentation (approximately 21 minutes). 1. Build an inventory of services requiring SLOs Start defining SLOs for your application by first taking an inventory of the services that your application provides to both your internal and external customers. Draft a list of services. Make the scope of services you consider as comprehensive as possible. Engage your team members and other stakeholders to validate the list for completeness. Segment your application stack to understand the potential components that might require SLOs. For example, most applications can be segmented as: Application (backend/microservices) Dependency services (such as the message queue) Database Website Underlying servers This example lists components that would benefit from SLOs: Customer type Component name Owner Language stack Operating system External Service 1 John D. Java RHEL 6 Internal Service 2 Jane A. .NET Win2003 R2 Internal ActiveMQ John D. Java AIX External Website Jane A. Classic ASP Win2000 Internal MS SQL Dave Z. n/a Win2003 R2 Building a definitive list of services that require an SLO can be challenging, because an application often consists of many endpoints with complex interdependencies. Begin your SLO journey with pragmatism. Start by defining a broader, simpler set of SLOs that are driven by what your customers care about most and what your team can control. As your teams better align around SLOs, you can then begin to fine-tune and add more complexity. 2. Research customer expectations for SLOs Once you have an inventory of services, begin to gather the information you need to define the SLOs for those services. Interviews with customers that depend on your services are often valuable for understanding service expectations. For example, to define SLOs for internal teams, New Relic, ask questions such as: If possible, can you broadly categorize the types of requests we can expect from you and your service? To what extent do you or your service depend on timely responses to requests? Are there requests for which response time is not critical? How does your service handle unavailable dependencies or data? What is the maximum amount of unavailable data that your service can handle? At what threshold does your service fail if a request takes too long? What are acceptable rates of errors? What would a SLA look like between our product and yours? Existing usage data can also be a helpful research input. 3. Define SLOs Using the research on customer expectations that you gathered, draft a focused set of SLOs. New Relic recommends setting SLOs against one or more of the following SLIs: Application availability percentage Average response time Response percentile Error rate Apdex value Also, consider instrumenting and tracking the following SLIs: Throughput (peak and trough) Database call count and duration DNS and SSL timing DOM processing and page rendering Mean-time-to-detection (MTTD) For a more comprehensive list of potential areas to measure, see Measuring DevOps. Recommendation: To determine if your application is performing to customer expectations: Consider combining multiple SLIs (for example, availability and response time) into one SLO. Aim to define a consistent set of conditions across all of the services in your list. Consult your team and stakeholders to validate that the SLOs you set are reasonable, consistently attainable (even if you are not currently meeting them), and aligned to customer expectations. After you finish this step, you should have a set of well-defined SLOs and SLIs. 4. Determine what can be instrumented Now you're ready to deploy agents or monitors to establish a performance baseline for the SLIs you created. With proper instrumentation in place, you'll have visibility into the performance indicators that matter for your team and your customers. In addition, you'll also have a clear understanding of how to meet your SLOs. Identify the service components your team will optimize. Verify which application tiers meet New Relic monitoring requirements. To ensure you have robust baselines from which to work, determine the level of instrumentation that is possible (or allowed) within your organization. It's best practice to instrument everything you can, but there may be situations where instrumentation isn't viable. In that case, you should determine what other data is available or can be created. For example, you can gather logs to query them for SLO data and set alerts for them. one.newrelic.com > Logs: Use the New Relic log management UI to leverage your logs. If the application has a web front end in these situations, use New Relic synthetic monitors. Our synthetic monitors offer non-agent monitoring while still providing the ability to establish a baseline. To instrument the example applications and components in this tutorial, use these New Relic features: New Relic products Customer type Component name Tier owner Language stack Server OS New Relic products External Service 1 John D. Java RHEL 6 APM, infrastructure monitoring, synthetic monitors Internal Service 2 Jane A. .Net Win2003 R2 APM, infrastructure monitoring Internal ActiveMQ John D. Java AIX APM External Website Jane A. Classic ASP Win2000 Synthetic monitors Internal MS SQL Dave Z. NA Win2003 R2 Infrastructure monitoring, on-host integrations APM installation After reviewing the compatibility and requirements for APM, install an APM agent on your application stack. Steps for installing APM agents vary based on language agent type. Follow the install procedures for a specific APM agents. Infrastructure installation After reviewing the requirements for New Relic infrastructure monitoring, follow the install procedures to install the infrastructure agent on instances that host your applications. The infrastructure agent requires the following host permissions: Linux: To install and run the agent, you must have root privileges. Windows: To install and run the agent, you must have Administrator privileges. Infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations based on their availability. New Relic supports several commonly used application components, including MySQL, Apache, NGINX, and more. For more information, see our on-host integration docs. Synthetics New Relic synthetic monitoring gives you a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. Follow the procedures to create a simple browser check. Be sure to verify that your website URL is accessible from the Synthetics public network locations. Browser monitoring New Relic browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how DevOps efforts are ultimately improving the experience for the customer. For more information, see the compatibility and requirements, then install the New Relic browser agent. Mobile monitoring The growing role of mobile apps in customer experience often spurs new performance data needs. Installation of New Relic mobile monitoring lets DevOps teams instrument iOS and Android applications to gain a fuller understanding of service delivery quality. 5. Review the default metrics After you deploy the agents and monitors, use service maps to review the default metrics that New Relic captures. For example, a typical service map show many of the common SLIs that application teams rely on, including response time, Apdex, throughput, and error rate metrics from APM. It also shows page load time, Ajax response, throughput, and error rate from browser monitoring. 6. Set up custom instrumentation To close any remaining gaps in visibility for your SLIs, use custom instrumentation. New Relic provides several avenues for adding custom instrumentation, including: Making API calls to agents from inside your source code Packaging XML-based custom instrumentation modules with deployed applications Adding UI-based instrumentation without a code deploy In addition, you can add custom attributes to each transaction event that match application performance factors to critical business information. Then you can track those attributes in Insights dashboards. For more information, see the custom instrumentation documentation for your application: APM Browser Infrastructure Mobile Synthetics 7. Create dashboards to track SLIs Once you implement the appropriate instrumentation, it's easy to visualize your service level indicators with New Relic dashboards, which provide a single location to query and view all the data that New Relic tools gather. To learn more about how to run queries to produce charts and dashboards, see Introduction to query builder. For more about the data you can query, see New Relic data types. The metrics you capture will become your application's baseline. Share dashboards with your application team and stakeholders to provide visibility into what is happening with your application and to monitor future performance.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 277.17145,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>New</em> <em>Relic</em> products",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": ". Use these inputs as starting points for this tutorial. In addition: Learn about SLOs, SLIs, and SLAs from the Google <em>Cloud</em> Platform blog. Learn how <em>New</em> <em>Relic</em> has applied SLOs and SLIs into its reliability practices form this SREcon18 Americas presentation (approximately 21 minutes). 1. Build"
      },
      "id": "6044151ee7b9d259ef5799ea"
    },
    {
      "sections": [
        "Iterate and measure impact: track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "Tip",
        "3. Test your pipeline with infrastructure"
      ],
      "title": "Iterate and measure impact: track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "06e2013529667ec66bde080abc3623ac6b6a6695",
      "image": "https://docs.newrelic.com/static/886d79f19e7b5576a06f8cc6016d053d/c1b63/apm-deployments.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2022-01-12T07:55:33Z",
      "updated_at": "2022-01-03T18:36:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A properly instrumented system gives teams full visibility into the impact of the changes they make. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation, and reduce the impact to other ongoing changes. Prerequisite Before starting this tutorial, be sure to complete the Establish objectives and baselines tutorial and set the appropriate KPI targets for your applications. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and to prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they’re consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make are correct across them, and eliminate any anomalies before pushing code to production. 2. Add automated deployment markers It’s important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. APM’s deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change-log, etc.). APM displays a vertical line, or “marker”, on charts and graphs at the deployment event’s timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application, and additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful DevOps transformation is a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. Our infrastructure agent helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names which fits this model quite nicely. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.10004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": ") &gt; Events &gt; Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip <em>New</em> <em>Relic</em> recommends that you make POST requests to the <em>New</em> <em>Relic</em> REST API as the final step of a successful CI&#x2F;CD deployment"
      },
      "id": "60450efc64441fb48e378eee"
    },
    {
      "sections": [
        "Measure code pipelines",
        "Prerequisite",
        "1. Identify what to track",
        "2. Capture the events required to instrument your pipeline"
      ],
      "title": "Measure code pipelines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "da5ac3dfed1bb4ab89bff1f3fd8e6d392767ce01",
      "image": "https://docs.newrelic.com/static/6cfae62440efb84aa5c9126e6a33cc8f/508ef/codepipeline2NR.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-code-pipelines/",
      "published_at": "2022-01-12T08:05:38Z",
      "updated_at": "2022-01-03T18:36:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "High functioning DevOps teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make improvements. Prerequisite Before starting this tutorial, be sure to complete the Establish team dashboards tutorial. 1. Identify what to track Look at your CI/CD system and determine the stats you'd like to gather. We recommend, at a minimum, starting with commit metadata, build status, test results, deploy status, and performance metrics. Determine which stats you want to report to New Relic. 2. Capture the events required to instrument your pipeline Capture timestamped state changes to your pipeline/CI/CD system indicating when a given stage started; and whether it succeeded or failed. This step, in turn, makes it easy to track your deployment process over time—looking for trends in the frequency of deployments, build quality, and other performance indicators. For easiest tracking, capture timestamped changes to your source code management system (SCM) with at least the author and a hash or unique change ID. Propagate this information wherever possible. If you have your own build system, add code to emit custom events at each stage. For hosted services, create a lightweight intermediary service/function-as-a-service (FaaS) to format and forward these custom events. The example below uses AWS CodePipeline to manage the flow of an application that is sourced in GitHub, built and tested with AWS CodeBuild, and deployed with Elastic Beanstalk. It utilizes a simple service written in Node.js, plus some \"glue code\" and event handlers needed to push data from GitHub and AWS to New Relic. Code for this example is available at github.com/newrelic/webinar. Use AWS CodePipeline to understand different parts of your flow. We chose the tools and products used here as examples—with the goal of illustrating the concepts around the types of data and events you should be thinking about when instrumenting your own code pipeline. The sample code, however, should be generic enough to adapt readily to almost any toolset.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.09998,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " status, and performance metrics. Determine which stats you want to report to <em>New</em> <em>Relic</em>. 2. Capture the events required to instrument your pipeline Capture timestamped state changes to your pipeline&#x2F;CI&#x2F;CD system indicating when a given stage started; and whether it succeeded or failed. This step"
      },
      "id": "603ea2f7e7b9d26d4c2a080a"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/customer-experience-improvement-track-experience-indicators": [
    {
      "sections": [
        "Establish objectives and baselines: define team SLOs",
        "Service level components",
        "Resources",
        "1. Build an inventory of services requiring SLOs",
        "2. Research customer expectations for SLOs",
        "3. Define SLOs",
        "4. Determine what can be instrumented",
        "New Relic products",
        "APM installation",
        "Infrastructure installation",
        "Infrastructure on-host integrations",
        "Synthetics",
        "Browser monitoring",
        "Mobile monitoring",
        "5. Review the default metrics",
        "6. Set up custom instrumentation",
        "7. Create dashboards to track SLIs"
      ],
      "title": "Establish objectives and baselines: define team SLOs",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6bfd37ee90b6890a53bfcf5ca688bbf72d551b70",
      "image": "https://docs.newrelic.com/static/5a07ed4ece7f7732b279460ca80f946d/c1b63/new-relic-logs-alerts.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/establish-objectives-baselines-define-team-slos/",
      "published_at": "2022-01-12T01:49:03Z",
      "updated_at": "2022-01-08T01:56:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A DevOps transformation requires a cultural shift so that teams can build new skills and motivations for the type of cross-team work required in a true DevOps practice. The transformation can be difficult when the people involved do not see the benefits of change as a clear objective. Service level objectives (SLOs) provide a powerful mechanism to codify the goals of a DevOps team in a way that can be measured and shared. They also provide clear boundaries on service expectations that help teams achieve greater velocity and freedom in experimenting with new approaches. This tutorial defines SLOs for successful service delivery objectives and utilize New Relic instrumentation to surface the current performance metrics relative to those objectives. Measurable SLOs and visibility into your current progress against those SLOs ensure that you will be able to properly assess future optimization efforts. See also our service level management feature. Service level components An SLO is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI); for example: Average response time Response time percentile Application availability SLOs clarify a target value for SLIs; for example: Average response time should be less than 200 ms 95% of requests should be completed within 250 ms Availability of the service should be 99.99% Logically group SLOs together to provide an overall boolean indicator of whether or not the service is meeting expectations. For example, a helpful SLO for alerting purposes could be: 95% of requests completed within 250 ms AND availability is 99.99% Copy Service level components Example values SLI (Indicator) HTTP status codes SLO (Objective) < 1% HTTP 500s over 30 days SLA (Agreement) For every additional .1% of HTTP 500s, 5% refund of total contract Resources Value stream mapping can be a useful exercise to work through before setting SLOs. Work with your teams to clarify key components of your service and the appropriate metrics. Use these inputs as starting points for this tutorial. In addition: Learn about SLOs, SLIs, and SLAs from the Google Cloud Platform blog. Learn how New Relic has applied SLOs and SLIs into its reliability practices form this SREcon18 Americas presentation (approximately 21 minutes). 1. Build an inventory of services requiring SLOs Start defining SLOs for your application by first taking an inventory of the services that your application provides to both your internal and external customers. Draft a list of services. Make the scope of services you consider as comprehensive as possible. Engage your team members and other stakeholders to validate the list for completeness. Segment your application stack to understand the potential components that might require SLOs. For example, most applications can be segmented as: Application (backend/microservices) Dependency services (such as the message queue) Database Website Underlying servers This example lists components that would benefit from SLOs: Customer type Component name Owner Language stack Operating system External Service 1 John D. Java RHEL 6 Internal Service 2 Jane A. .NET Win2003 R2 Internal ActiveMQ John D. Java AIX External Website Jane A. Classic ASP Win2000 Internal MS SQL Dave Z. n/a Win2003 R2 Building a definitive list of services that require an SLO can be challenging, because an application often consists of many endpoints with complex interdependencies. Begin your SLO journey with pragmatism. Start by defining a broader, simpler set of SLOs that are driven by what your customers care about most and what your team can control. As your teams better align around SLOs, you can then begin to fine-tune and add more complexity. 2. Research customer expectations for SLOs Once you have an inventory of services, begin to gather the information you need to define the SLOs for those services. Interviews with customers that depend on your services are often valuable for understanding service expectations. For example, to define SLOs for internal teams, New Relic, ask questions such as: If possible, can you broadly categorize the types of requests we can expect from you and your service? To what extent do you or your service depend on timely responses to requests? Are there requests for which response time is not critical? How does your service handle unavailable dependencies or data? What is the maximum amount of unavailable data that your service can handle? At what threshold does your service fail if a request takes too long? What are acceptable rates of errors? What would a SLA look like between our product and yours? Existing usage data can also be a helpful research input. 3. Define SLOs Using the research on customer expectations that you gathered, draft a focused set of SLOs. New Relic recommends setting SLOs against one or more of the following SLIs: Application availability percentage Average response time Response percentile Error rate Apdex value Also, consider instrumenting and tracking the following SLIs: Throughput (peak and trough) Database call count and duration DNS and SSL timing DOM processing and page rendering Mean-time-to-detection (MTTD) For a more comprehensive list of potential areas to measure, see Measuring DevOps. Recommendation: To determine if your application is performing to customer expectations: Consider combining multiple SLIs (for example, availability and response time) into one SLO. Aim to define a consistent set of conditions across all of the services in your list. Consult your team and stakeholders to validate that the SLOs you set are reasonable, consistently attainable (even if you are not currently meeting them), and aligned to customer expectations. After you finish this step, you should have a set of well-defined SLOs and SLIs. 4. Determine what can be instrumented Now you're ready to deploy agents or monitors to establish a performance baseline for the SLIs you created. With proper instrumentation in place, you'll have visibility into the performance indicators that matter for your team and your customers. In addition, you'll also have a clear understanding of how to meet your SLOs. Identify the service components your team will optimize. Verify which application tiers meet New Relic monitoring requirements. To ensure you have robust baselines from which to work, determine the level of instrumentation that is possible (or allowed) within your organization. It's best practice to instrument everything you can, but there may be situations where instrumentation isn't viable. In that case, you should determine what other data is available or can be created. For example, you can gather logs to query them for SLO data and set alerts for them. one.newrelic.com > Logs: Use the New Relic log management UI to leverage your logs. If the application has a web front end in these situations, use New Relic synthetic monitors. Our synthetic monitors offer non-agent monitoring while still providing the ability to establish a baseline. To instrument the example applications and components in this tutorial, use these New Relic features: New Relic products Customer type Component name Tier owner Language stack Server OS New Relic products External Service 1 John D. Java RHEL 6 APM, infrastructure monitoring, synthetic monitors Internal Service 2 Jane A. .Net Win2003 R2 APM, infrastructure monitoring Internal ActiveMQ John D. Java AIX APM External Website Jane A. Classic ASP Win2000 Synthetic monitors Internal MS SQL Dave Z. NA Win2003 R2 Infrastructure monitoring, on-host integrations APM installation After reviewing the compatibility and requirements for APM, install an APM agent on your application stack. Steps for installing APM agents vary based on language agent type. Follow the install procedures for a specific APM agents. Infrastructure installation After reviewing the requirements for New Relic infrastructure monitoring, follow the install procedures to install the infrastructure agent on instances that host your applications. The infrastructure agent requires the following host permissions: Linux: To install and run the agent, you must have root privileges. Windows: To install and run the agent, you must have Administrator privileges. Infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations based on their availability. New Relic supports several commonly used application components, including MySQL, Apache, NGINX, and more. For more information, see our on-host integration docs. Synthetics New Relic synthetic monitoring gives you a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. Follow the procedures to create a simple browser check. Be sure to verify that your website URL is accessible from the Synthetics public network locations. Browser monitoring New Relic browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how DevOps efforts are ultimately improving the experience for the customer. For more information, see the compatibility and requirements, then install the New Relic browser agent. Mobile monitoring The growing role of mobile apps in customer experience often spurs new performance data needs. Installation of New Relic mobile monitoring lets DevOps teams instrument iOS and Android applications to gain a fuller understanding of service delivery quality. 5. Review the default metrics After you deploy the agents and monitors, use service maps to review the default metrics that New Relic captures. For example, a typical service map show many of the common SLIs that application teams rely on, including response time, Apdex, throughput, and error rate metrics from APM. It also shows page load time, Ajax response, throughput, and error rate from browser monitoring. 6. Set up custom instrumentation To close any remaining gaps in visibility for your SLIs, use custom instrumentation. New Relic provides several avenues for adding custom instrumentation, including: Making API calls to agents from inside your source code Packaging XML-based custom instrumentation modules with deployed applications Adding UI-based instrumentation without a code deploy In addition, you can add custom attributes to each transaction event that match application performance factors to critical business information. Then you can track those attributes in Insights dashboards. For more information, see the custom instrumentation documentation for your application: APM Browser Infrastructure Mobile Synthetics 7. Create dashboards to track SLIs Once you implement the appropriate instrumentation, it's easy to visualize your service level indicators with New Relic dashboards, which provide a single location to query and view all the data that New Relic tools gather. To learn more about how to run queries to produce charts and dashboards, see Introduction to query builder. For more about the data you can query, see New Relic data types. The metrics you capture will become your application's baseline. Share dashboards with your application team and stakeholders to provide visibility into what is happening with your application and to monitor future performance.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 453.63855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>New</em> <em>Relic</em> products",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " monitoring <em>New</em> <em>Relic</em> browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how <em>DevOps</em> efforts are ultimately improving"
      },
      "id": "6044151ee7b9d259ef5799ea"
    },
    {
      "sections": [
        "Iterate and measure impact: track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "Tip",
        "3. Test your pipeline with infrastructure"
      ],
      "title": "Iterate and measure impact: track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "06e2013529667ec66bde080abc3623ac6b6a6695",
      "image": "https://docs.newrelic.com/static/886d79f19e7b5576a06f8cc6016d053d/c1b63/apm-deployments.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2022-01-12T07:55:33Z",
      "updated_at": "2022-01-03T18:36:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A properly instrumented system gives teams full visibility into the impact of the changes they make. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation, and reduce the impact to other ongoing changes. Prerequisite Before starting this tutorial, be sure to complete the Establish objectives and baselines tutorial and set the appropriate KPI targets for your applications. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and to prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they’re consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make are correct across them, and eliminate any anomalies before pushing code to production. 2. Add automated deployment markers It’s important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. APM’s deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change-log, etc.). APM displays a vertical line, or “marker”, on charts and graphs at the deployment event’s timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application, and additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful DevOps transformation is a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. Our infrastructure agent helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names which fits this model quite nicely. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.87482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Iterate and <em>measure</em> impact: track metrics before and after deployments",
        "sections": "1. Integrate <em>measurements</em> into your <em>development</em> process",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful <em>DevOps</em> transformation is a cultural shift toward smaller, more"
      },
      "id": "60450efc64441fb48e378eee"
    },
    {
      "sections": [
        "Measure code pipelines",
        "Prerequisite",
        "1. Identify what to track",
        "2. Capture the events required to instrument your pipeline"
      ],
      "title": "Measure code pipelines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "da5ac3dfed1bb4ab89bff1f3fd8e6d392767ce01",
      "image": "https://docs.newrelic.com/static/6cfae62440efb84aa5c9126e6a33cc8f/508ef/codepipeline2NR.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-code-pipelines/",
      "published_at": "2022-01-12T08:05:38Z",
      "updated_at": "2022-01-03T18:36:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "High functioning DevOps teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make improvements. Prerequisite Before starting this tutorial, be sure to complete the Establish team dashboards tutorial. 1. Identify what to track Look at your CI/CD system and determine the stats you'd like to gather. We recommend, at a minimum, starting with commit metadata, build status, test results, deploy status, and performance metrics. Determine which stats you want to report to New Relic. 2. Capture the events required to instrument your pipeline Capture timestamped state changes to your pipeline/CI/CD system indicating when a given stage started; and whether it succeeded or failed. This step, in turn, makes it easy to track your deployment process over time—looking for trends in the frequency of deployments, build quality, and other performance indicators. For easiest tracking, capture timestamped changes to your source code management system (SCM) with at least the author and a hash or unique change ID. Propagate this information wherever possible. If you have your own build system, add code to emit custom events at each stage. For hosted services, create a lightweight intermediary service/function-as-a-service (FaaS) to format and forward these custom events. The example below uses AWS CodePipeline to manage the flow of an application that is sourced in GitHub, built and tested with AWS CodeBuild, and deployed with Elastic Beanstalk. It utilizes a simple service written in Node.js, plus some \"glue code\" and event handlers needed to push data from GitHub and AWS to New Relic. Code for this example is available at github.com/newrelic/webinar. Use AWS CodePipeline to understand different parts of your flow. We chose the tools and products used here as examples—with the goal of illustrating the concepts around the types of data and events you should be thinking about when instrumenting your own code pipeline. The sample code, however, should be generic enough to adapt readily to almost any toolset.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.87473,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Measure</em> code pipelines",
        "sections": "<em>Measure</em> code pipelines",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "High functioning <em>DevOps</em> teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make"
      },
      "id": "603ea2f7e7b9d26d4c2a080a"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/establish-objectives-baselines-define-team-slos": [
    {
      "sections": [
        "Iterate and measure impact: track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "Tip",
        "3. Test your pipeline with infrastructure"
      ],
      "title": "Iterate and measure impact: track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "06e2013529667ec66bde080abc3623ac6b6a6695",
      "image": "https://docs.newrelic.com/static/886d79f19e7b5576a06f8cc6016d053d/c1b63/apm-deployments.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2022-01-12T07:55:33Z",
      "updated_at": "2022-01-03T18:36:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A properly instrumented system gives teams full visibility into the impact of the changes they make. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation, and reduce the impact to other ongoing changes. Prerequisite Before starting this tutorial, be sure to complete the Establish objectives and baselines tutorial and set the appropriate KPI targets for your applications. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and to prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they’re consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make are correct across them, and eliminate any anomalies before pushing code to production. 2. Add automated deployment markers It’s important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. APM’s deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change-log, etc.). APM displays a vertical line, or “marker”, on charts and graphs at the deployment event’s timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application, and additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful DevOps transformation is a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. Our infrastructure agent helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names which fits this model quite nicely. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.87473,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Iterate and <em>measure</em> impact: track metrics before and after deployments",
        "sections": "1. Integrate <em>measurements</em> into your <em>development</em> process",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful <em>DevOps</em> transformation is a cultural shift toward smaller, more"
      },
      "id": "60450efc64441fb48e378eee"
    },
    {
      "sections": [
        "Measure code pipelines",
        "Prerequisite",
        "1. Identify what to track",
        "2. Capture the events required to instrument your pipeline"
      ],
      "title": "Measure code pipelines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "da5ac3dfed1bb4ab89bff1f3fd8e6d392767ce01",
      "image": "https://docs.newrelic.com/static/6cfae62440efb84aa5c9126e6a33cc8f/508ef/codepipeline2NR.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-code-pipelines/",
      "published_at": "2022-01-12T08:05:38Z",
      "updated_at": "2022-01-03T18:36:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "High functioning DevOps teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make improvements. Prerequisite Before starting this tutorial, be sure to complete the Establish team dashboards tutorial. 1. Identify what to track Look at your CI/CD system and determine the stats you'd like to gather. We recommend, at a minimum, starting with commit metadata, build status, test results, deploy status, and performance metrics. Determine which stats you want to report to New Relic. 2. Capture the events required to instrument your pipeline Capture timestamped state changes to your pipeline/CI/CD system indicating when a given stage started; and whether it succeeded or failed. This step, in turn, makes it easy to track your deployment process over time—looking for trends in the frequency of deployments, build quality, and other performance indicators. For easiest tracking, capture timestamped changes to your source code management system (SCM) with at least the author and a hash or unique change ID. Propagate this information wherever possible. If you have your own build system, add code to emit custom events at each stage. For hosted services, create a lightweight intermediary service/function-as-a-service (FaaS) to format and forward these custom events. The example below uses AWS CodePipeline to manage the flow of an application that is sourced in GitHub, built and tested with AWS CodeBuild, and deployed with Elastic Beanstalk. It utilizes a simple service written in Node.js, plus some \"glue code\" and event handlers needed to push data from GitHub and AWS to New Relic. Code for this example is available at github.com/newrelic/webinar. Use AWS CodePipeline to understand different parts of your flow. We chose the tools and products used here as examples—with the goal of illustrating the concepts around the types of data and events you should be thinking about when instrumenting your own code pipeline. The sample code, however, should be generic enough to adapt readily to almost any toolset.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.87463,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Measure</em> code pipelines",
        "sections": "<em>Measure</em> code pipelines",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "High functioning <em>DevOps</em> teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make"
      },
      "id": "603ea2f7e7b9d26d4c2a080a"
    },
    {
      "sections": [
        "Customer experience improvement: track experience indicators",
        "Prerequisites",
        "1. Use custom attributes to associate performance data",
        "Tip",
        "2. Create dashboards with performance and business metrics",
        "3. Share dashboards across departments",
        "4. Utilize data to separate performance by cohort and debug issues at the customer level"
      ],
      "title": "Customer experience improvement: track experience indicators",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "78b347edcf28e1492126b1df1a82fb78ba147483",
      "image": "https://docs.newrelic.com/static/65dadbef1fe9c07817f7ead13e12e05e/302a4/Insights-catalyst-dashbaord-1.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/customer-experience-improvement-track-experience-indicators/",
      "published_at": "2022-01-12T07:55:33Z",
      "updated_at": "2022-01-03T18:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This tutorial covers methods to identify and track the key indicators of customer experience and clarifies the effect of application performance on your business. A clear understanding of what creates successful customer experience helps DevOps teams drive greater efficiencies in work efforts and deliver greater productivity. An efficient, well-functioning DevOps culture enables organizations to make rapid, frequent releases and product changes. A strong DevOps culture also democratizes data beyond the typical backend users, and makes it available to groups like customer service, support, sales, and marketing. However, this data information enablement is only useful if its purpose is to improve and optimize customer experience. Prerequisites This tutorial assumes you’ve reviewed the Establish team dashboards tutorial. 1. Use custom attributes to associate performance data In order to relate performance data to user experience, you need to capture information that ties a particular user or customer to the front- and back-end transactions that are responsible for their interactions with your application. In New Relic, you collect this data with custom attributes. Tip If you plan to collect this information in both frontend and backend, be sure to forward custom attributes from APM to browser. Here are some common attributes to collect: User ID Organization or customer ID A/B testing cohort value High-value customer indicator Purchase value or product IDs (for e-commerce) If you’ve completed the Iterate and measure impact or Establish objectives and baselines tutorials, consider what service level objectives (SLOs) or key metrics you defined in those stages. New Relic recommends including attributes like the above to measure the impact of your changes and optimizations at a customer level—not only a performance level. 2. Create dashboards with performance and business metrics Using the attributes collected in Step 1, build dashboards to examine the impact of performance issues on your users. Additionally, to drive visibility across your teams, add dedicated widgets to the team dashboards you built in the Establish team dashboards . insights.newrelic.com > Dashboards For example, if you were collecting a custom username attribute, you could use NRQL queries like these to create your widgets for your New Relic Insights dashboard: Number of errors by username: SELECT count(*) FROM TransactionError FACET username Copy Median response time by username: SELECT percentile(duration,50) FROM Transaction FACET username Copy Total purchase value in transactions with errors: SELECT sum(purchaseTotal) FROM TransactionError FACET username Copy Tip If you include a FACET clause in your queries, you'll be able to click into metric results to see corresponding change in the performance data. For more information on faceting, see Linking Between Dashboards to Drill Into Your Data. 3. Share dashboards across departments Dashboards, data, and metrics that nobody looks at or knows about might as well not exist. When considering how, or with whom, to share your dashboards, consider the following questions: Which teams are responsible for applications that have high levels of end-user interaction? What non-engineering teams could benefit from this information? Customer support: Could customer issues be resolved faster? Product/engineering: Could product make more informed roadmap decisions? Customer success: Can this data be used to make our customers more successful? Are there other teams that can benefit from cohort analysis that includes performance metrics? 4. Utilize data to separate performance by cohort and debug issues at the customer level After you create your dashboards, use them to scope issues affecting particular customers or sets of customers. For example, the following widget shows which apps have errors for a particular user: Use attributes that track user and performance to set alerts on high priority users or customers. For example, you could include a WHERE clause in your NRQL queries to scope the results to a set of user IDs or customer IDs. Set alerts on any performance or business metric that is tied to these attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.87006,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "This tutorial covers methods to identify and track the key indicators of customer experience and clarifies the effect of application performance on your business. A clear understanding of what creates successful customer experience helps <em>DevOps</em> teams drive greater efficiencies in work efforts"
      },
      "id": "60440f5f28ccbcf7dc2c60b2"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/establish-team-dashboards-gather-visualize-key-metrics": [
    {
      "sections": [
        "Establish objectives and baselines: define team SLOs",
        "Service level components",
        "Resources",
        "1. Build an inventory of services requiring SLOs",
        "2. Research customer expectations for SLOs",
        "3. Define SLOs",
        "4. Determine what can be instrumented",
        "New Relic products",
        "APM installation",
        "Infrastructure installation",
        "Infrastructure on-host integrations",
        "Synthetics",
        "Browser monitoring",
        "Mobile monitoring",
        "5. Review the default metrics",
        "6. Set up custom instrumentation",
        "7. Create dashboards to track SLIs"
      ],
      "title": "Establish objectives and baselines: define team SLOs",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6bfd37ee90b6890a53bfcf5ca688bbf72d551b70",
      "image": "https://docs.newrelic.com/static/5a07ed4ece7f7732b279460ca80f946d/c1b63/new-relic-logs-alerts.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/establish-objectives-baselines-define-team-slos/",
      "published_at": "2022-01-12T01:49:03Z",
      "updated_at": "2022-01-08T01:56:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A DevOps transformation requires a cultural shift so that teams can build new skills and motivations for the type of cross-team work required in a true DevOps practice. The transformation can be difficult when the people involved do not see the benefits of change as a clear objective. Service level objectives (SLOs) provide a powerful mechanism to codify the goals of a DevOps team in a way that can be measured and shared. They also provide clear boundaries on service expectations that help teams achieve greater velocity and freedom in experimenting with new approaches. This tutorial defines SLOs for successful service delivery objectives and utilize New Relic instrumentation to surface the current performance metrics relative to those objectives. Measurable SLOs and visibility into your current progress against those SLOs ensure that you will be able to properly assess future optimization efforts. See also our service level management feature. Service level components An SLO is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI); for example: Average response time Response time percentile Application availability SLOs clarify a target value for SLIs; for example: Average response time should be less than 200 ms 95% of requests should be completed within 250 ms Availability of the service should be 99.99% Logically group SLOs together to provide an overall boolean indicator of whether or not the service is meeting expectations. For example, a helpful SLO for alerting purposes could be: 95% of requests completed within 250 ms AND availability is 99.99% Copy Service level components Example values SLI (Indicator) HTTP status codes SLO (Objective) < 1% HTTP 500s over 30 days SLA (Agreement) For every additional .1% of HTTP 500s, 5% refund of total contract Resources Value stream mapping can be a useful exercise to work through before setting SLOs. Work with your teams to clarify key components of your service and the appropriate metrics. Use these inputs as starting points for this tutorial. In addition: Learn about SLOs, SLIs, and SLAs from the Google Cloud Platform blog. Learn how New Relic has applied SLOs and SLIs into its reliability practices form this SREcon18 Americas presentation (approximately 21 minutes). 1. Build an inventory of services requiring SLOs Start defining SLOs for your application by first taking an inventory of the services that your application provides to both your internal and external customers. Draft a list of services. Make the scope of services you consider as comprehensive as possible. Engage your team members and other stakeholders to validate the list for completeness. Segment your application stack to understand the potential components that might require SLOs. For example, most applications can be segmented as: Application (backend/microservices) Dependency services (such as the message queue) Database Website Underlying servers This example lists components that would benefit from SLOs: Customer type Component name Owner Language stack Operating system External Service 1 John D. Java RHEL 6 Internal Service 2 Jane A. .NET Win2003 R2 Internal ActiveMQ John D. Java AIX External Website Jane A. Classic ASP Win2000 Internal MS SQL Dave Z. n/a Win2003 R2 Building a definitive list of services that require an SLO can be challenging, because an application often consists of many endpoints with complex interdependencies. Begin your SLO journey with pragmatism. Start by defining a broader, simpler set of SLOs that are driven by what your customers care about most and what your team can control. As your teams better align around SLOs, you can then begin to fine-tune and add more complexity. 2. Research customer expectations for SLOs Once you have an inventory of services, begin to gather the information you need to define the SLOs for those services. Interviews with customers that depend on your services are often valuable for understanding service expectations. For example, to define SLOs for internal teams, New Relic, ask questions such as: If possible, can you broadly categorize the types of requests we can expect from you and your service? To what extent do you or your service depend on timely responses to requests? Are there requests for which response time is not critical? How does your service handle unavailable dependencies or data? What is the maximum amount of unavailable data that your service can handle? At what threshold does your service fail if a request takes too long? What are acceptable rates of errors? What would a SLA look like between our product and yours? Existing usage data can also be a helpful research input. 3. Define SLOs Using the research on customer expectations that you gathered, draft a focused set of SLOs. New Relic recommends setting SLOs against one or more of the following SLIs: Application availability percentage Average response time Response percentile Error rate Apdex value Also, consider instrumenting and tracking the following SLIs: Throughput (peak and trough) Database call count and duration DNS and SSL timing DOM processing and page rendering Mean-time-to-detection (MTTD) For a more comprehensive list of potential areas to measure, see Measuring DevOps. Recommendation: To determine if your application is performing to customer expectations: Consider combining multiple SLIs (for example, availability and response time) into one SLO. Aim to define a consistent set of conditions across all of the services in your list. Consult your team and stakeholders to validate that the SLOs you set are reasonable, consistently attainable (even if you are not currently meeting them), and aligned to customer expectations. After you finish this step, you should have a set of well-defined SLOs and SLIs. 4. Determine what can be instrumented Now you're ready to deploy agents or monitors to establish a performance baseline for the SLIs you created. With proper instrumentation in place, you'll have visibility into the performance indicators that matter for your team and your customers. In addition, you'll also have a clear understanding of how to meet your SLOs. Identify the service components your team will optimize. Verify which application tiers meet New Relic monitoring requirements. To ensure you have robust baselines from which to work, determine the level of instrumentation that is possible (or allowed) within your organization. It's best practice to instrument everything you can, but there may be situations where instrumentation isn't viable. In that case, you should determine what other data is available or can be created. For example, you can gather logs to query them for SLO data and set alerts for them. one.newrelic.com > Logs: Use the New Relic log management UI to leverage your logs. If the application has a web front end in these situations, use New Relic synthetic monitors. Our synthetic monitors offer non-agent monitoring while still providing the ability to establish a baseline. To instrument the example applications and components in this tutorial, use these New Relic features: New Relic products Customer type Component name Tier owner Language stack Server OS New Relic products External Service 1 John D. Java RHEL 6 APM, infrastructure monitoring, synthetic monitors Internal Service 2 Jane A. .Net Win2003 R2 APM, infrastructure monitoring Internal ActiveMQ John D. Java AIX APM External Website Jane A. Classic ASP Win2000 Synthetic monitors Internal MS SQL Dave Z. NA Win2003 R2 Infrastructure monitoring, on-host integrations APM installation After reviewing the compatibility and requirements for APM, install an APM agent on your application stack. Steps for installing APM agents vary based on language agent type. Follow the install procedures for a specific APM agents. Infrastructure installation After reviewing the requirements for New Relic infrastructure monitoring, follow the install procedures to install the infrastructure agent on instances that host your applications. The infrastructure agent requires the following host permissions: Linux: To install and run the agent, you must have root privileges. Windows: To install and run the agent, you must have Administrator privileges. Infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations based on their availability. New Relic supports several commonly used application components, including MySQL, Apache, NGINX, and more. For more information, see our on-host integration docs. Synthetics New Relic synthetic monitoring gives you a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. Follow the procedures to create a simple browser check. Be sure to verify that your website URL is accessible from the Synthetics public network locations. Browser monitoring New Relic browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how DevOps efforts are ultimately improving the experience for the customer. For more information, see the compatibility and requirements, then install the New Relic browser agent. Mobile monitoring The growing role of mobile apps in customer experience often spurs new performance data needs. Installation of New Relic mobile monitoring lets DevOps teams instrument iOS and Android applications to gain a fuller understanding of service delivery quality. 5. Review the default metrics After you deploy the agents and monitors, use service maps to review the default metrics that New Relic captures. For example, a typical service map show many of the common SLIs that application teams rely on, including response time, Apdex, throughput, and error rate metrics from APM. It also shows page load time, Ajax response, throughput, and error rate from browser monitoring. 6. Set up custom instrumentation To close any remaining gaps in visibility for your SLIs, use custom instrumentation. New Relic provides several avenues for adding custom instrumentation, including: Making API calls to agents from inside your source code Packaging XML-based custom instrumentation modules with deployed applications Adding UI-based instrumentation without a code deploy In addition, you can add custom attributes to each transaction event that match application performance factors to critical business information. Then you can track those attributes in Insights dashboards. For more information, see the custom instrumentation documentation for your application: APM Browser Infrastructure Mobile Synthetics 7. Create dashboards to track SLIs Once you implement the appropriate instrumentation, it's easy to visualize your service level indicators with New Relic dashboards, which provide a single location to query and view all the data that New Relic tools gather. To learn more about how to run queries to produce charts and dashboards, see Introduction to query builder. For more about the data you can query, see New Relic data types. The metrics you capture will become your application's baseline. Share dashboards with your application team and stakeholders to provide visibility into what is happening with your application and to monitor future performance.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 453.63837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>New</em> <em>Relic</em> products",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " monitoring <em>New</em> <em>Relic</em> browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how <em>DevOps</em> efforts are ultimately improving"
      },
      "id": "6044151ee7b9d259ef5799ea"
    },
    {
      "sections": [
        "Iterate and measure impact: track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "Tip",
        "3. Test your pipeline with infrastructure"
      ],
      "title": "Iterate and measure impact: track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "06e2013529667ec66bde080abc3623ac6b6a6695",
      "image": "https://docs.newrelic.com/static/886d79f19e7b5576a06f8cc6016d053d/c1b63/apm-deployments.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2022-01-12T07:55:33Z",
      "updated_at": "2022-01-03T18:36:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A properly instrumented system gives teams full visibility into the impact of the changes they make. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation, and reduce the impact to other ongoing changes. Prerequisite Before starting this tutorial, be sure to complete the Establish objectives and baselines tutorial and set the appropriate KPI targets for your applications. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and to prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they’re consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make are correct across them, and eliminate any anomalies before pushing code to production. 2. Add automated deployment markers It’s important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. APM’s deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change-log, etc.). APM displays a vertical line, or “marker”, on charts and graphs at the deployment event’s timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application, and additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful DevOps transformation is a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. Our infrastructure agent helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names which fits this model quite nicely. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.87473,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Iterate and <em>measure</em> impact: track metrics before and after deployments",
        "sections": "1. Integrate <em>measurements</em> into your <em>development</em> process",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful <em>DevOps</em> transformation is a cultural shift toward smaller, more"
      },
      "id": "60450efc64441fb48e378eee"
    },
    {
      "sections": [
        "Measure code pipelines",
        "Prerequisite",
        "1. Identify what to track",
        "2. Capture the events required to instrument your pipeline"
      ],
      "title": "Measure code pipelines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "da5ac3dfed1bb4ab89bff1f3fd8e6d392767ce01",
      "image": "https://docs.newrelic.com/static/6cfae62440efb84aa5c9126e6a33cc8f/508ef/codepipeline2NR.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-code-pipelines/",
      "published_at": "2022-01-12T08:05:38Z",
      "updated_at": "2022-01-03T18:36:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "High functioning DevOps teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make improvements. Prerequisite Before starting this tutorial, be sure to complete the Establish team dashboards tutorial. 1. Identify what to track Look at your CI/CD system and determine the stats you'd like to gather. We recommend, at a minimum, starting with commit metadata, build status, test results, deploy status, and performance metrics. Determine which stats you want to report to New Relic. 2. Capture the events required to instrument your pipeline Capture timestamped state changes to your pipeline/CI/CD system indicating when a given stage started; and whether it succeeded or failed. This step, in turn, makes it easy to track your deployment process over time—looking for trends in the frequency of deployments, build quality, and other performance indicators. For easiest tracking, capture timestamped changes to your source code management system (SCM) with at least the author and a hash or unique change ID. Propagate this information wherever possible. If you have your own build system, add code to emit custom events at each stage. For hosted services, create a lightweight intermediary service/function-as-a-service (FaaS) to format and forward these custom events. The example below uses AWS CodePipeline to manage the flow of an application that is sourced in GitHub, built and tested with AWS CodeBuild, and deployed with Elastic Beanstalk. It utilizes a simple service written in Node.js, plus some \"glue code\" and event handlers needed to push data from GitHub and AWS to New Relic. Code for this example is available at github.com/newrelic/webinar. Use AWS CodePipeline to understand different parts of your flow. We chose the tools and products used here as examples—with the goal of illustrating the concepts around the types of data and events you should be thinking about when instrumenting your own code pipeline. The sample code, however, should be generic enough to adapt readily to almost any toolset.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.87463,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Measure</em> code pipelines",
        "sections": "<em>Measure</em> code pipelines",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "High functioning <em>DevOps</em> teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make"
      },
      "id": "603ea2f7e7b9d26d4c2a080a"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/infrastructure-resource-sizing-analyze-operation-metrics": [
    {
      "sections": [
        "Establish objectives and baselines: define team SLOs",
        "Service level components",
        "Resources",
        "1. Build an inventory of services requiring SLOs",
        "2. Research customer expectations for SLOs",
        "3. Define SLOs",
        "4. Determine what can be instrumented",
        "New Relic products",
        "APM installation",
        "Infrastructure installation",
        "Infrastructure on-host integrations",
        "Synthetics",
        "Browser monitoring",
        "Mobile monitoring",
        "5. Review the default metrics",
        "6. Set up custom instrumentation",
        "7. Create dashboards to track SLIs"
      ],
      "title": "Establish objectives and baselines: define team SLOs",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6bfd37ee90b6890a53bfcf5ca688bbf72d551b70",
      "image": "https://docs.newrelic.com/static/5a07ed4ece7f7732b279460ca80f946d/c1b63/new-relic-logs-alerts.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/establish-objectives-baselines-define-team-slos/",
      "published_at": "2022-01-12T01:49:03Z",
      "updated_at": "2022-01-08T01:56:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A DevOps transformation requires a cultural shift so that teams can build new skills and motivations for the type of cross-team work required in a true DevOps practice. The transformation can be difficult when the people involved do not see the benefits of change as a clear objective. Service level objectives (SLOs) provide a powerful mechanism to codify the goals of a DevOps team in a way that can be measured and shared. They also provide clear boundaries on service expectations that help teams achieve greater velocity and freedom in experimenting with new approaches. This tutorial defines SLOs for successful service delivery objectives and utilize New Relic instrumentation to surface the current performance metrics relative to those objectives. Measurable SLOs and visibility into your current progress against those SLOs ensure that you will be able to properly assess future optimization efforts. See also our service level management feature. Service level components An SLO is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI); for example: Average response time Response time percentile Application availability SLOs clarify a target value for SLIs; for example: Average response time should be less than 200 ms 95% of requests should be completed within 250 ms Availability of the service should be 99.99% Logically group SLOs together to provide an overall boolean indicator of whether or not the service is meeting expectations. For example, a helpful SLO for alerting purposes could be: 95% of requests completed within 250 ms AND availability is 99.99% Copy Service level components Example values SLI (Indicator) HTTP status codes SLO (Objective) < 1% HTTP 500s over 30 days SLA (Agreement) For every additional .1% of HTTP 500s, 5% refund of total contract Resources Value stream mapping can be a useful exercise to work through before setting SLOs. Work with your teams to clarify key components of your service and the appropriate metrics. Use these inputs as starting points for this tutorial. In addition: Learn about SLOs, SLIs, and SLAs from the Google Cloud Platform blog. Learn how New Relic has applied SLOs and SLIs into its reliability practices form this SREcon18 Americas presentation (approximately 21 minutes). 1. Build an inventory of services requiring SLOs Start defining SLOs for your application by first taking an inventory of the services that your application provides to both your internal and external customers. Draft a list of services. Make the scope of services you consider as comprehensive as possible. Engage your team members and other stakeholders to validate the list for completeness. Segment your application stack to understand the potential components that might require SLOs. For example, most applications can be segmented as: Application (backend/microservices) Dependency services (such as the message queue) Database Website Underlying servers This example lists components that would benefit from SLOs: Customer type Component name Owner Language stack Operating system External Service 1 John D. Java RHEL 6 Internal Service 2 Jane A. .NET Win2003 R2 Internal ActiveMQ John D. Java AIX External Website Jane A. Classic ASP Win2000 Internal MS SQL Dave Z. n/a Win2003 R2 Building a definitive list of services that require an SLO can be challenging, because an application often consists of many endpoints with complex interdependencies. Begin your SLO journey with pragmatism. Start by defining a broader, simpler set of SLOs that are driven by what your customers care about most and what your team can control. As your teams better align around SLOs, you can then begin to fine-tune and add more complexity. 2. Research customer expectations for SLOs Once you have an inventory of services, begin to gather the information you need to define the SLOs for those services. Interviews with customers that depend on your services are often valuable for understanding service expectations. For example, to define SLOs for internal teams, New Relic, ask questions such as: If possible, can you broadly categorize the types of requests we can expect from you and your service? To what extent do you or your service depend on timely responses to requests? Are there requests for which response time is not critical? How does your service handle unavailable dependencies or data? What is the maximum amount of unavailable data that your service can handle? At what threshold does your service fail if a request takes too long? What are acceptable rates of errors? What would a SLA look like between our product and yours? Existing usage data can also be a helpful research input. 3. Define SLOs Using the research on customer expectations that you gathered, draft a focused set of SLOs. New Relic recommends setting SLOs against one or more of the following SLIs: Application availability percentage Average response time Response percentile Error rate Apdex value Also, consider instrumenting and tracking the following SLIs: Throughput (peak and trough) Database call count and duration DNS and SSL timing DOM processing and page rendering Mean-time-to-detection (MTTD) For a more comprehensive list of potential areas to measure, see Measuring DevOps. Recommendation: To determine if your application is performing to customer expectations: Consider combining multiple SLIs (for example, availability and response time) into one SLO. Aim to define a consistent set of conditions across all of the services in your list. Consult your team and stakeholders to validate that the SLOs you set are reasonable, consistently attainable (even if you are not currently meeting them), and aligned to customer expectations. After you finish this step, you should have a set of well-defined SLOs and SLIs. 4. Determine what can be instrumented Now you're ready to deploy agents or monitors to establish a performance baseline for the SLIs you created. With proper instrumentation in place, you'll have visibility into the performance indicators that matter for your team and your customers. In addition, you'll also have a clear understanding of how to meet your SLOs. Identify the service components your team will optimize. Verify which application tiers meet New Relic monitoring requirements. To ensure you have robust baselines from which to work, determine the level of instrumentation that is possible (or allowed) within your organization. It's best practice to instrument everything you can, but there may be situations where instrumentation isn't viable. In that case, you should determine what other data is available or can be created. For example, you can gather logs to query them for SLO data and set alerts for them. one.newrelic.com > Logs: Use the New Relic log management UI to leverage your logs. If the application has a web front end in these situations, use New Relic synthetic monitors. Our synthetic monitors offer non-agent monitoring while still providing the ability to establish a baseline. To instrument the example applications and components in this tutorial, use these New Relic features: New Relic products Customer type Component name Tier owner Language stack Server OS New Relic products External Service 1 John D. Java RHEL 6 APM, infrastructure monitoring, synthetic monitors Internal Service 2 Jane A. .Net Win2003 R2 APM, infrastructure monitoring Internal ActiveMQ John D. Java AIX APM External Website Jane A. Classic ASP Win2000 Synthetic monitors Internal MS SQL Dave Z. NA Win2003 R2 Infrastructure monitoring, on-host integrations APM installation After reviewing the compatibility and requirements for APM, install an APM agent on your application stack. Steps for installing APM agents vary based on language agent type. Follow the install procedures for a specific APM agents. Infrastructure installation After reviewing the requirements for New Relic infrastructure monitoring, follow the install procedures to install the infrastructure agent on instances that host your applications. The infrastructure agent requires the following host permissions: Linux: To install and run the agent, you must have root privileges. Windows: To install and run the agent, you must have Administrator privileges. Infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations based on their availability. New Relic supports several commonly used application components, including MySQL, Apache, NGINX, and more. For more information, see our on-host integration docs. Synthetics New Relic synthetic monitoring gives you a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. Follow the procedures to create a simple browser check. Be sure to verify that your website URL is accessible from the Synthetics public network locations. Browser monitoring New Relic browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how DevOps efforts are ultimately improving the experience for the customer. For more information, see the compatibility and requirements, then install the New Relic browser agent. Mobile monitoring The growing role of mobile apps in customer experience often spurs new performance data needs. Installation of New Relic mobile monitoring lets DevOps teams instrument iOS and Android applications to gain a fuller understanding of service delivery quality. 5. Review the default metrics After you deploy the agents and monitors, use service maps to review the default metrics that New Relic captures. For example, a typical service map show many of the common SLIs that application teams rely on, including response time, Apdex, throughput, and error rate metrics from APM. It also shows page load time, Ajax response, throughput, and error rate from browser monitoring. 6. Set up custom instrumentation To close any remaining gaps in visibility for your SLIs, use custom instrumentation. New Relic provides several avenues for adding custom instrumentation, including: Making API calls to agents from inside your source code Packaging XML-based custom instrumentation modules with deployed applications Adding UI-based instrumentation without a code deploy In addition, you can add custom attributes to each transaction event that match application performance factors to critical business information. Then you can track those attributes in Insights dashboards. For more information, see the custom instrumentation documentation for your application: APM Browser Infrastructure Mobile Synthetics 7. Create dashboards to track SLIs Once you implement the appropriate instrumentation, it's easy to visualize your service level indicators with New Relic dashboards, which provide a single location to query and view all the data that New Relic tools gather. To learn more about how to run queries to produce charts and dashboards, see Introduction to query builder. For more about the data you can query, see New Relic data types. The metrics you capture will become your application's baseline. Share dashboards with your application team and stakeholders to provide visibility into what is happening with your application and to monitor future performance.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 453.63815,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>New</em> <em>Relic</em> products",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " monitoring <em>New</em> <em>Relic</em> browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how <em>DevOps</em> efforts are ultimately improving"
      },
      "id": "6044151ee7b9d259ef5799ea"
    },
    {
      "sections": [
        "Iterate and measure impact: track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "Tip",
        "3. Test your pipeline with infrastructure"
      ],
      "title": "Iterate and measure impact: track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "06e2013529667ec66bde080abc3623ac6b6a6695",
      "image": "https://docs.newrelic.com/static/886d79f19e7b5576a06f8cc6016d053d/c1b63/apm-deployments.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2022-01-12T07:55:33Z",
      "updated_at": "2022-01-03T18:36:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A properly instrumented system gives teams full visibility into the impact of the changes they make. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation, and reduce the impact to other ongoing changes. Prerequisite Before starting this tutorial, be sure to complete the Establish objectives and baselines tutorial and set the appropriate KPI targets for your applications. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and to prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they’re consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make are correct across them, and eliminate any anomalies before pushing code to production. 2. Add automated deployment markers It’s important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. APM’s deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change-log, etc.). APM displays a vertical line, or “marker”, on charts and graphs at the deployment event’s timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application, and additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful DevOps transformation is a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. Our infrastructure agent helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names which fits this model quite nicely. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.87463,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Iterate and <em>measure</em> impact: track metrics before and after deployments",
        "sections": "1. Integrate <em>measurements</em> into your <em>development</em> process",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful <em>DevOps</em> transformation is a cultural shift toward smaller, more"
      },
      "id": "60450efc64441fb48e378eee"
    },
    {
      "sections": [
        "Measure code pipelines",
        "Prerequisite",
        "1. Identify what to track",
        "2. Capture the events required to instrument your pipeline"
      ],
      "title": "Measure code pipelines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "da5ac3dfed1bb4ab89bff1f3fd8e6d392767ce01",
      "image": "https://docs.newrelic.com/static/6cfae62440efb84aa5c9126e6a33cc8f/508ef/codepipeline2NR.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-code-pipelines/",
      "published_at": "2022-01-12T08:05:38Z",
      "updated_at": "2022-01-03T18:36:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "High functioning DevOps teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make improvements. Prerequisite Before starting this tutorial, be sure to complete the Establish team dashboards tutorial. 1. Identify what to track Look at your CI/CD system and determine the stats you'd like to gather. We recommend, at a minimum, starting with commit metadata, build status, test results, deploy status, and performance metrics. Determine which stats you want to report to New Relic. 2. Capture the events required to instrument your pipeline Capture timestamped state changes to your pipeline/CI/CD system indicating when a given stage started; and whether it succeeded or failed. This step, in turn, makes it easy to track your deployment process over time—looking for trends in the frequency of deployments, build quality, and other performance indicators. For easiest tracking, capture timestamped changes to your source code management system (SCM) with at least the author and a hash or unique change ID. Propagate this information wherever possible. If you have your own build system, add code to emit custom events at each stage. For hosted services, create a lightweight intermediary service/function-as-a-service (FaaS) to format and forward these custom events. The example below uses AWS CodePipeline to manage the flow of an application that is sourced in GitHub, built and tested with AWS CodeBuild, and deployed with Elastic Beanstalk. It utilizes a simple service written in Node.js, plus some \"glue code\" and event handlers needed to push data from GitHub and AWS to New Relic. Code for this example is available at github.com/newrelic/webinar. Use AWS CodePipeline to understand different parts of your flow. We chose the tools and products used here as examples—with the goal of illustrating the concepts around the types of data and events you should be thinking about when instrumenting your own code pipeline. The sample code, however, should be generic enough to adapt readily to almost any toolset.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.8745,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Measure</em> code pipelines",
        "sections": "<em>Measure</em> code pipelines",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "High functioning <em>DevOps</em> teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make"
      },
      "id": "603ea2f7e7b9d26d4c2a080a"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/iterate-measure-impact-track-metrics-after-deployments": [
    {
      "sections": [
        "Establish objectives and baselines: define team SLOs",
        "Service level components",
        "Resources",
        "1. Build an inventory of services requiring SLOs",
        "2. Research customer expectations for SLOs",
        "3. Define SLOs",
        "4. Determine what can be instrumented",
        "New Relic products",
        "APM installation",
        "Infrastructure installation",
        "Infrastructure on-host integrations",
        "Synthetics",
        "Browser monitoring",
        "Mobile monitoring",
        "5. Review the default metrics",
        "6. Set up custom instrumentation",
        "7. Create dashboards to track SLIs"
      ],
      "title": "Establish objectives and baselines: define team SLOs",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6bfd37ee90b6890a53bfcf5ca688bbf72d551b70",
      "image": "https://docs.newrelic.com/static/5a07ed4ece7f7732b279460ca80f946d/c1b63/new-relic-logs-alerts.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/establish-objectives-baselines-define-team-slos/",
      "published_at": "2022-01-12T01:49:03Z",
      "updated_at": "2022-01-08T01:56:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A DevOps transformation requires a cultural shift so that teams can build new skills and motivations for the type of cross-team work required in a true DevOps practice. The transformation can be difficult when the people involved do not see the benefits of change as a clear objective. Service level objectives (SLOs) provide a powerful mechanism to codify the goals of a DevOps team in a way that can be measured and shared. They also provide clear boundaries on service expectations that help teams achieve greater velocity and freedom in experimenting with new approaches. This tutorial defines SLOs for successful service delivery objectives and utilize New Relic instrumentation to surface the current performance metrics relative to those objectives. Measurable SLOs and visibility into your current progress against those SLOs ensure that you will be able to properly assess future optimization efforts. See also our service level management feature. Service level components An SLO is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI); for example: Average response time Response time percentile Application availability SLOs clarify a target value for SLIs; for example: Average response time should be less than 200 ms 95% of requests should be completed within 250 ms Availability of the service should be 99.99% Logically group SLOs together to provide an overall boolean indicator of whether or not the service is meeting expectations. For example, a helpful SLO for alerting purposes could be: 95% of requests completed within 250 ms AND availability is 99.99% Copy Service level components Example values SLI (Indicator) HTTP status codes SLO (Objective) < 1% HTTP 500s over 30 days SLA (Agreement) For every additional .1% of HTTP 500s, 5% refund of total contract Resources Value stream mapping can be a useful exercise to work through before setting SLOs. Work with your teams to clarify key components of your service and the appropriate metrics. Use these inputs as starting points for this tutorial. In addition: Learn about SLOs, SLIs, and SLAs from the Google Cloud Platform blog. Learn how New Relic has applied SLOs and SLIs into its reliability practices form this SREcon18 Americas presentation (approximately 21 minutes). 1. Build an inventory of services requiring SLOs Start defining SLOs for your application by first taking an inventory of the services that your application provides to both your internal and external customers. Draft a list of services. Make the scope of services you consider as comprehensive as possible. Engage your team members and other stakeholders to validate the list for completeness. Segment your application stack to understand the potential components that might require SLOs. For example, most applications can be segmented as: Application (backend/microservices) Dependency services (such as the message queue) Database Website Underlying servers This example lists components that would benefit from SLOs: Customer type Component name Owner Language stack Operating system External Service 1 John D. Java RHEL 6 Internal Service 2 Jane A. .NET Win2003 R2 Internal ActiveMQ John D. Java AIX External Website Jane A. Classic ASP Win2000 Internal MS SQL Dave Z. n/a Win2003 R2 Building a definitive list of services that require an SLO can be challenging, because an application often consists of many endpoints with complex interdependencies. Begin your SLO journey with pragmatism. Start by defining a broader, simpler set of SLOs that are driven by what your customers care about most and what your team can control. As your teams better align around SLOs, you can then begin to fine-tune and add more complexity. 2. Research customer expectations for SLOs Once you have an inventory of services, begin to gather the information you need to define the SLOs for those services. Interviews with customers that depend on your services are often valuable for understanding service expectations. For example, to define SLOs for internal teams, New Relic, ask questions such as: If possible, can you broadly categorize the types of requests we can expect from you and your service? To what extent do you or your service depend on timely responses to requests? Are there requests for which response time is not critical? How does your service handle unavailable dependencies or data? What is the maximum amount of unavailable data that your service can handle? At what threshold does your service fail if a request takes too long? What are acceptable rates of errors? What would a SLA look like between our product and yours? Existing usage data can also be a helpful research input. 3. Define SLOs Using the research on customer expectations that you gathered, draft a focused set of SLOs. New Relic recommends setting SLOs against one or more of the following SLIs: Application availability percentage Average response time Response percentile Error rate Apdex value Also, consider instrumenting and tracking the following SLIs: Throughput (peak and trough) Database call count and duration DNS and SSL timing DOM processing and page rendering Mean-time-to-detection (MTTD) For a more comprehensive list of potential areas to measure, see Measuring DevOps. Recommendation: To determine if your application is performing to customer expectations: Consider combining multiple SLIs (for example, availability and response time) into one SLO. Aim to define a consistent set of conditions across all of the services in your list. Consult your team and stakeholders to validate that the SLOs you set are reasonable, consistently attainable (even if you are not currently meeting them), and aligned to customer expectations. After you finish this step, you should have a set of well-defined SLOs and SLIs. 4. Determine what can be instrumented Now you're ready to deploy agents or monitors to establish a performance baseline for the SLIs you created. With proper instrumentation in place, you'll have visibility into the performance indicators that matter for your team and your customers. In addition, you'll also have a clear understanding of how to meet your SLOs. Identify the service components your team will optimize. Verify which application tiers meet New Relic monitoring requirements. To ensure you have robust baselines from which to work, determine the level of instrumentation that is possible (or allowed) within your organization. It's best practice to instrument everything you can, but there may be situations where instrumentation isn't viable. In that case, you should determine what other data is available or can be created. For example, you can gather logs to query them for SLO data and set alerts for them. one.newrelic.com > Logs: Use the New Relic log management UI to leverage your logs. If the application has a web front end in these situations, use New Relic synthetic monitors. Our synthetic monitors offer non-agent monitoring while still providing the ability to establish a baseline. To instrument the example applications and components in this tutorial, use these New Relic features: New Relic products Customer type Component name Tier owner Language stack Server OS New Relic products External Service 1 John D. Java RHEL 6 APM, infrastructure monitoring, synthetic monitors Internal Service 2 Jane A. .Net Win2003 R2 APM, infrastructure monitoring Internal ActiveMQ John D. Java AIX APM External Website Jane A. Classic ASP Win2000 Synthetic monitors Internal MS SQL Dave Z. NA Win2003 R2 Infrastructure monitoring, on-host integrations APM installation After reviewing the compatibility and requirements for APM, install an APM agent on your application stack. Steps for installing APM agents vary based on language agent type. Follow the install procedures for a specific APM agents. Infrastructure installation After reviewing the requirements for New Relic infrastructure monitoring, follow the install procedures to install the infrastructure agent on instances that host your applications. The infrastructure agent requires the following host permissions: Linux: To install and run the agent, you must have root privileges. Windows: To install and run the agent, you must have Administrator privileges. Infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations based on their availability. New Relic supports several commonly used application components, including MySQL, Apache, NGINX, and more. For more information, see our on-host integration docs. Synthetics New Relic synthetic monitoring gives you a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. Follow the procedures to create a simple browser check. Be sure to verify that your website URL is accessible from the Synthetics public network locations. Browser monitoring New Relic browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how DevOps efforts are ultimately improving the experience for the customer. For more information, see the compatibility and requirements, then install the New Relic browser agent. Mobile monitoring The growing role of mobile apps in customer experience often spurs new performance data needs. Installation of New Relic mobile monitoring lets DevOps teams instrument iOS and Android applications to gain a fuller understanding of service delivery quality. 5. Review the default metrics After you deploy the agents and monitors, use service maps to review the default metrics that New Relic captures. For example, a typical service map show many of the common SLIs that application teams rely on, including response time, Apdex, throughput, and error rate metrics from APM. It also shows page load time, Ajax response, throughput, and error rate from browser monitoring. 6. Set up custom instrumentation To close any remaining gaps in visibility for your SLIs, use custom instrumentation. New Relic provides several avenues for adding custom instrumentation, including: Making API calls to agents from inside your source code Packaging XML-based custom instrumentation modules with deployed applications Adding UI-based instrumentation without a code deploy In addition, you can add custom attributes to each transaction event that match application performance factors to critical business information. Then you can track those attributes in Insights dashboards. For more information, see the custom instrumentation documentation for your application: APM Browser Infrastructure Mobile Synthetics 7. Create dashboards to track SLIs Once you implement the appropriate instrumentation, it's easy to visualize your service level indicators with New Relic dashboards, which provide a single location to query and view all the data that New Relic tools gather. To learn more about how to run queries to produce charts and dashboards, see Introduction to query builder. For more about the data you can query, see New Relic data types. The metrics you capture will become your application's baseline. Share dashboards with your application team and stakeholders to provide visibility into what is happening with your application and to monitor future performance.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 453.63815,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>New</em> <em>Relic</em> products",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " monitoring <em>New</em> <em>Relic</em> browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how <em>DevOps</em> efforts are ultimately improving"
      },
      "id": "6044151ee7b9d259ef5799ea"
    },
    {
      "sections": [
        "Measure code pipelines",
        "Prerequisite",
        "1. Identify what to track",
        "2. Capture the events required to instrument your pipeline"
      ],
      "title": "Measure code pipelines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "da5ac3dfed1bb4ab89bff1f3fd8e6d392767ce01",
      "image": "https://docs.newrelic.com/static/6cfae62440efb84aa5c9126e6a33cc8f/508ef/codepipeline2NR.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-code-pipelines/",
      "published_at": "2022-01-12T08:05:38Z",
      "updated_at": "2022-01-03T18:36:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "High functioning DevOps teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make improvements. Prerequisite Before starting this tutorial, be sure to complete the Establish team dashboards tutorial. 1. Identify what to track Look at your CI/CD system and determine the stats you'd like to gather. We recommend, at a minimum, starting with commit metadata, build status, test results, deploy status, and performance metrics. Determine which stats you want to report to New Relic. 2. Capture the events required to instrument your pipeline Capture timestamped state changes to your pipeline/CI/CD system indicating when a given stage started; and whether it succeeded or failed. This step, in turn, makes it easy to track your deployment process over time—looking for trends in the frequency of deployments, build quality, and other performance indicators. For easiest tracking, capture timestamped changes to your source code management system (SCM) with at least the author and a hash or unique change ID. Propagate this information wherever possible. If you have your own build system, add code to emit custom events at each stage. For hosted services, create a lightweight intermediary service/function-as-a-service (FaaS) to format and forward these custom events. The example below uses AWS CodePipeline to manage the flow of an application that is sourced in GitHub, built and tested with AWS CodeBuild, and deployed with Elastic Beanstalk. It utilizes a simple service written in Node.js, plus some \"glue code\" and event handlers needed to push data from GitHub and AWS to New Relic. Code for this example is available at github.com/newrelic/webinar. Use AWS CodePipeline to understand different parts of your flow. We chose the tools and products used here as examples—with the goal of illustrating the concepts around the types of data and events you should be thinking about when instrumenting your own code pipeline. The sample code, however, should be generic enough to adapt readily to almost any toolset.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.8745,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Measure</em> code pipelines",
        "sections": "<em>Measure</em> code pipelines",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "High functioning <em>DevOps</em> teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make"
      },
      "id": "603ea2f7e7b9d26d4c2a080a"
    },
    {
      "sections": [
        "Customer experience improvement: track experience indicators",
        "Prerequisites",
        "1. Use custom attributes to associate performance data",
        "Tip",
        "2. Create dashboards with performance and business metrics",
        "3. Share dashboards across departments",
        "4. Utilize data to separate performance by cohort and debug issues at the customer level"
      ],
      "title": "Customer experience improvement: track experience indicators",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "78b347edcf28e1492126b1df1a82fb78ba147483",
      "image": "https://docs.newrelic.com/static/65dadbef1fe9c07817f7ead13e12e05e/302a4/Insights-catalyst-dashbaord-1.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/customer-experience-improvement-track-experience-indicators/",
      "published_at": "2022-01-12T07:55:33Z",
      "updated_at": "2022-01-03T18:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This tutorial covers methods to identify and track the key indicators of customer experience and clarifies the effect of application performance on your business. A clear understanding of what creates successful customer experience helps DevOps teams drive greater efficiencies in work efforts and deliver greater productivity. An efficient, well-functioning DevOps culture enables organizations to make rapid, frequent releases and product changes. A strong DevOps culture also democratizes data beyond the typical backend users, and makes it available to groups like customer service, support, sales, and marketing. However, this data information enablement is only useful if its purpose is to improve and optimize customer experience. Prerequisites This tutorial assumes you’ve reviewed the Establish team dashboards tutorial. 1. Use custom attributes to associate performance data In order to relate performance data to user experience, you need to capture information that ties a particular user or customer to the front- and back-end transactions that are responsible for their interactions with your application. In New Relic, you collect this data with custom attributes. Tip If you plan to collect this information in both frontend and backend, be sure to forward custom attributes from APM to browser. Here are some common attributes to collect: User ID Organization or customer ID A/B testing cohort value High-value customer indicator Purchase value or product IDs (for e-commerce) If you’ve completed the Iterate and measure impact or Establish objectives and baselines tutorials, consider what service level objectives (SLOs) or key metrics you defined in those stages. New Relic recommends including attributes like the above to measure the impact of your changes and optimizations at a customer level—not only a performance level. 2. Create dashboards with performance and business metrics Using the attributes collected in Step 1, build dashboards to examine the impact of performance issues on your users. Additionally, to drive visibility across your teams, add dedicated widgets to the team dashboards you built in the Establish team dashboards . insights.newrelic.com > Dashboards For example, if you were collecting a custom username attribute, you could use NRQL queries like these to create your widgets for your New Relic Insights dashboard: Number of errors by username: SELECT count(*) FROM TransactionError FACET username Copy Median response time by username: SELECT percentile(duration,50) FROM Transaction FACET username Copy Total purchase value in transactions with errors: SELECT sum(purchaseTotal) FROM TransactionError FACET username Copy Tip If you include a FACET clause in your queries, you'll be able to click into metric results to see corresponding change in the performance data. For more information on faceting, see Linking Between Dashboards to Drill Into Your Data. 3. Share dashboards across departments Dashboards, data, and metrics that nobody looks at or knows about might as well not exist. When considering how, or with whom, to share your dashboards, consider the following questions: Which teams are responsible for applications that have high levels of end-user interaction? What non-engineering teams could benefit from this information? Customer support: Could customer issues be resolved faster? Product/engineering: Could product make more informed roadmap decisions? Customer success: Can this data be used to make our customers more successful? Are there other teams that can benefit from cohort analysis that includes performance metrics? 4. Utilize data to separate performance by cohort and debug issues at the customer level After you create your dashboards, use them to scope issues affecting particular customers or sets of customers. For example, the following widget shows which apps have errors for a particular user: Use attributes that track user and performance to set alerts on high priority users or customers. For example, you could include a WHERE clause in your NRQL queries to scope the results to a set of user IDs or customer IDs. Set alerts on any performance or business metric that is tied to these attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.86996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "This tutorial covers methods to identify and track the key indicators of customer experience and clarifies the effect of application performance on your business. A clear understanding of what creates successful customer experience helps <em>DevOps</em> teams drive greater efficiencies in work efforts"
      },
      "id": "60440f5f28ccbcf7dc2c60b2"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/measure-code-pipelines": [
    {
      "sections": [
        "Establish objectives and baselines: define team SLOs",
        "Service level components",
        "Resources",
        "1. Build an inventory of services requiring SLOs",
        "2. Research customer expectations for SLOs",
        "3. Define SLOs",
        "4. Determine what can be instrumented",
        "New Relic products",
        "APM installation",
        "Infrastructure installation",
        "Infrastructure on-host integrations",
        "Synthetics",
        "Browser monitoring",
        "Mobile monitoring",
        "5. Review the default metrics",
        "6. Set up custom instrumentation",
        "7. Create dashboards to track SLIs"
      ],
      "title": "Establish objectives and baselines: define team SLOs",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6bfd37ee90b6890a53bfcf5ca688bbf72d551b70",
      "image": "https://docs.newrelic.com/static/5a07ed4ece7f7732b279460ca80f946d/c1b63/new-relic-logs-alerts.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/establish-objectives-baselines-define-team-slos/",
      "published_at": "2022-01-12T01:49:03Z",
      "updated_at": "2022-01-08T01:56:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A DevOps transformation requires a cultural shift so that teams can build new skills and motivations for the type of cross-team work required in a true DevOps practice. The transformation can be difficult when the people involved do not see the benefits of change as a clear objective. Service level objectives (SLOs) provide a powerful mechanism to codify the goals of a DevOps team in a way that can be measured and shared. They also provide clear boundaries on service expectations that help teams achieve greater velocity and freedom in experimenting with new approaches. This tutorial defines SLOs for successful service delivery objectives and utilize New Relic instrumentation to surface the current performance metrics relative to those objectives. Measurable SLOs and visibility into your current progress against those SLOs ensure that you will be able to properly assess future optimization efforts. See also our service level management feature. Service level components An SLO is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI); for example: Average response time Response time percentile Application availability SLOs clarify a target value for SLIs; for example: Average response time should be less than 200 ms 95% of requests should be completed within 250 ms Availability of the service should be 99.99% Logically group SLOs together to provide an overall boolean indicator of whether or not the service is meeting expectations. For example, a helpful SLO for alerting purposes could be: 95% of requests completed within 250 ms AND availability is 99.99% Copy Service level components Example values SLI (Indicator) HTTP status codes SLO (Objective) < 1% HTTP 500s over 30 days SLA (Agreement) For every additional .1% of HTTP 500s, 5% refund of total contract Resources Value stream mapping can be a useful exercise to work through before setting SLOs. Work with your teams to clarify key components of your service and the appropriate metrics. Use these inputs as starting points for this tutorial. In addition: Learn about SLOs, SLIs, and SLAs from the Google Cloud Platform blog. Learn how New Relic has applied SLOs and SLIs into its reliability practices form this SREcon18 Americas presentation (approximately 21 minutes). 1. Build an inventory of services requiring SLOs Start defining SLOs for your application by first taking an inventory of the services that your application provides to both your internal and external customers. Draft a list of services. Make the scope of services you consider as comprehensive as possible. Engage your team members and other stakeholders to validate the list for completeness. Segment your application stack to understand the potential components that might require SLOs. For example, most applications can be segmented as: Application (backend/microservices) Dependency services (such as the message queue) Database Website Underlying servers This example lists components that would benefit from SLOs: Customer type Component name Owner Language stack Operating system External Service 1 John D. Java RHEL 6 Internal Service 2 Jane A. .NET Win2003 R2 Internal ActiveMQ John D. Java AIX External Website Jane A. Classic ASP Win2000 Internal MS SQL Dave Z. n/a Win2003 R2 Building a definitive list of services that require an SLO can be challenging, because an application often consists of many endpoints with complex interdependencies. Begin your SLO journey with pragmatism. Start by defining a broader, simpler set of SLOs that are driven by what your customers care about most and what your team can control. As your teams better align around SLOs, you can then begin to fine-tune and add more complexity. 2. Research customer expectations for SLOs Once you have an inventory of services, begin to gather the information you need to define the SLOs for those services. Interviews with customers that depend on your services are often valuable for understanding service expectations. For example, to define SLOs for internal teams, New Relic, ask questions such as: If possible, can you broadly categorize the types of requests we can expect from you and your service? To what extent do you or your service depend on timely responses to requests? Are there requests for which response time is not critical? How does your service handle unavailable dependencies or data? What is the maximum amount of unavailable data that your service can handle? At what threshold does your service fail if a request takes too long? What are acceptable rates of errors? What would a SLA look like between our product and yours? Existing usage data can also be a helpful research input. 3. Define SLOs Using the research on customer expectations that you gathered, draft a focused set of SLOs. New Relic recommends setting SLOs against one or more of the following SLIs: Application availability percentage Average response time Response percentile Error rate Apdex value Also, consider instrumenting and tracking the following SLIs: Throughput (peak and trough) Database call count and duration DNS and SSL timing DOM processing and page rendering Mean-time-to-detection (MTTD) For a more comprehensive list of potential areas to measure, see Measuring DevOps. Recommendation: To determine if your application is performing to customer expectations: Consider combining multiple SLIs (for example, availability and response time) into one SLO. Aim to define a consistent set of conditions across all of the services in your list. Consult your team and stakeholders to validate that the SLOs you set are reasonable, consistently attainable (even if you are not currently meeting them), and aligned to customer expectations. After you finish this step, you should have a set of well-defined SLOs and SLIs. 4. Determine what can be instrumented Now you're ready to deploy agents or monitors to establish a performance baseline for the SLIs you created. With proper instrumentation in place, you'll have visibility into the performance indicators that matter for your team and your customers. In addition, you'll also have a clear understanding of how to meet your SLOs. Identify the service components your team will optimize. Verify which application tiers meet New Relic monitoring requirements. To ensure you have robust baselines from which to work, determine the level of instrumentation that is possible (or allowed) within your organization. It's best practice to instrument everything you can, but there may be situations where instrumentation isn't viable. In that case, you should determine what other data is available or can be created. For example, you can gather logs to query them for SLO data and set alerts for them. one.newrelic.com > Logs: Use the New Relic log management UI to leverage your logs. If the application has a web front end in these situations, use New Relic synthetic monitors. Our synthetic monitors offer non-agent monitoring while still providing the ability to establish a baseline. To instrument the example applications and components in this tutorial, use these New Relic features: New Relic products Customer type Component name Tier owner Language stack Server OS New Relic products External Service 1 John D. Java RHEL 6 APM, infrastructure monitoring, synthetic monitors Internal Service 2 Jane A. .Net Win2003 R2 APM, infrastructure monitoring Internal ActiveMQ John D. Java AIX APM External Website Jane A. Classic ASP Win2000 Synthetic monitors Internal MS SQL Dave Z. NA Win2003 R2 Infrastructure monitoring, on-host integrations APM installation After reviewing the compatibility and requirements for APM, install an APM agent on your application stack. Steps for installing APM agents vary based on language agent type. Follow the install procedures for a specific APM agents. Infrastructure installation After reviewing the requirements for New Relic infrastructure monitoring, follow the install procedures to install the infrastructure agent on instances that host your applications. The infrastructure agent requires the following host permissions: Linux: To install and run the agent, you must have root privileges. Windows: To install and run the agent, you must have Administrator privileges. Infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations based on their availability. New Relic supports several commonly used application components, including MySQL, Apache, NGINX, and more. For more information, see our on-host integration docs. Synthetics New Relic synthetic monitoring gives you a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. Follow the procedures to create a simple browser check. Be sure to verify that your website URL is accessible from the Synthetics public network locations. Browser monitoring New Relic browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how DevOps efforts are ultimately improving the experience for the customer. For more information, see the compatibility and requirements, then install the New Relic browser agent. Mobile monitoring The growing role of mobile apps in customer experience often spurs new performance data needs. Installation of New Relic mobile monitoring lets DevOps teams instrument iOS and Android applications to gain a fuller understanding of service delivery quality. 5. Review the default metrics After you deploy the agents and monitors, use service maps to review the default metrics that New Relic captures. For example, a typical service map show many of the common SLIs that application teams rely on, including response time, Apdex, throughput, and error rate metrics from APM. It also shows page load time, Ajax response, throughput, and error rate from browser monitoring. 6. Set up custom instrumentation To close any remaining gaps in visibility for your SLIs, use custom instrumentation. New Relic provides several avenues for adding custom instrumentation, including: Making API calls to agents from inside your source code Packaging XML-based custom instrumentation modules with deployed applications Adding UI-based instrumentation without a code deploy In addition, you can add custom attributes to each transaction event that match application performance factors to critical business information. Then you can track those attributes in Insights dashboards. For more information, see the custom instrumentation documentation for your application: APM Browser Infrastructure Mobile Synthetics 7. Create dashboards to track SLIs Once you implement the appropriate instrumentation, it's easy to visualize your service level indicators with New Relic dashboards, which provide a single location to query and view all the data that New Relic tools gather. To learn more about how to run queries to produce charts and dashboards, see Introduction to query builder. For more about the data you can query, see New Relic data types. The metrics you capture will become your application's baseline. Share dashboards with your application team and stakeholders to provide visibility into what is happening with your application and to monitor future performance.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 453.63794,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>New</em> <em>Relic</em> products",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " monitoring <em>New</em> <em>Relic</em> browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how <em>DevOps</em> efforts are ultimately improving"
      },
      "id": "6044151ee7b9d259ef5799ea"
    },
    {
      "sections": [
        "Iterate and measure impact: track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "Tip",
        "3. Test your pipeline with infrastructure"
      ],
      "title": "Iterate and measure impact: track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "06e2013529667ec66bde080abc3623ac6b6a6695",
      "image": "https://docs.newrelic.com/static/886d79f19e7b5576a06f8cc6016d053d/c1b63/apm-deployments.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2022-01-12T07:55:33Z",
      "updated_at": "2022-01-03T18:36:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A properly instrumented system gives teams full visibility into the impact of the changes they make. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation, and reduce the impact to other ongoing changes. Prerequisite Before starting this tutorial, be sure to complete the Establish objectives and baselines tutorial and set the appropriate KPI targets for your applications. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and to prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they’re consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make are correct across them, and eliminate any anomalies before pushing code to production. 2. Add automated deployment markers It’s important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. APM’s deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change-log, etc.). APM displays a vertical line, or “marker”, on charts and graphs at the deployment event’s timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application, and additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful DevOps transformation is a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. Our infrastructure agent helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names which fits this model quite nicely. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.8745,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Iterate and <em>measure</em> impact: track metrics before and after deployments",
        "sections": "1. Integrate <em>measurements</em> into your <em>development</em> process",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful <em>DevOps</em> transformation is a cultural shift toward smaller, more"
      },
      "id": "60450efc64441fb48e378eee"
    },
    {
      "sections": [
        "Customer experience improvement: track experience indicators",
        "Prerequisites",
        "1. Use custom attributes to associate performance data",
        "Tip",
        "2. Create dashboards with performance and business metrics",
        "3. Share dashboards across departments",
        "4. Utilize data to separate performance by cohort and debug issues at the customer level"
      ],
      "title": "Customer experience improvement: track experience indicators",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "78b347edcf28e1492126b1df1a82fb78ba147483",
      "image": "https://docs.newrelic.com/static/65dadbef1fe9c07817f7ead13e12e05e/302a4/Insights-catalyst-dashbaord-1.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/customer-experience-improvement-track-experience-indicators/",
      "published_at": "2022-01-12T07:55:33Z",
      "updated_at": "2022-01-03T18:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This tutorial covers methods to identify and track the key indicators of customer experience and clarifies the effect of application performance on your business. A clear understanding of what creates successful customer experience helps DevOps teams drive greater efficiencies in work efforts and deliver greater productivity. An efficient, well-functioning DevOps culture enables organizations to make rapid, frequent releases and product changes. A strong DevOps culture also democratizes data beyond the typical backend users, and makes it available to groups like customer service, support, sales, and marketing. However, this data information enablement is only useful if its purpose is to improve and optimize customer experience. Prerequisites This tutorial assumes you’ve reviewed the Establish team dashboards tutorial. 1. Use custom attributes to associate performance data In order to relate performance data to user experience, you need to capture information that ties a particular user or customer to the front- and back-end transactions that are responsible for their interactions with your application. In New Relic, you collect this data with custom attributes. Tip If you plan to collect this information in both frontend and backend, be sure to forward custom attributes from APM to browser. Here are some common attributes to collect: User ID Organization or customer ID A/B testing cohort value High-value customer indicator Purchase value or product IDs (for e-commerce) If you’ve completed the Iterate and measure impact or Establish objectives and baselines tutorials, consider what service level objectives (SLOs) or key metrics you defined in those stages. New Relic recommends including attributes like the above to measure the impact of your changes and optimizations at a customer level—not only a performance level. 2. Create dashboards with performance and business metrics Using the attributes collected in Step 1, build dashboards to examine the impact of performance issues on your users. Additionally, to drive visibility across your teams, add dedicated widgets to the team dashboards you built in the Establish team dashboards . insights.newrelic.com > Dashboards For example, if you were collecting a custom username attribute, you could use NRQL queries like these to create your widgets for your New Relic Insights dashboard: Number of errors by username: SELECT count(*) FROM TransactionError FACET username Copy Median response time by username: SELECT percentile(duration,50) FROM Transaction FACET username Copy Total purchase value in transactions with errors: SELECT sum(purchaseTotal) FROM TransactionError FACET username Copy Tip If you include a FACET clause in your queries, you'll be able to click into metric results to see corresponding change in the performance data. For more information on faceting, see Linking Between Dashboards to Drill Into Your Data. 3. Share dashboards across departments Dashboards, data, and metrics that nobody looks at or knows about might as well not exist. When considering how, or with whom, to share your dashboards, consider the following questions: Which teams are responsible for applications that have high levels of end-user interaction? What non-engineering teams could benefit from this information? Customer support: Could customer issues be resolved faster? Product/engineering: Could product make more informed roadmap decisions? Customer success: Can this data be used to make our customers more successful? Are there other teams that can benefit from cohort analysis that includes performance metrics? 4. Utilize data to separate performance by cohort and debug issues at the customer level After you create your dashboards, use them to scope issues affecting particular customers or sets of customers. For example, the following widget shows which apps have errors for a particular user: Use attributes that track user and performance to set alerts on high priority users or customers. For example, you could include a WHERE clause in your NRQL queries to scope the results to a set of user IDs or customer IDs. Set alerts on any performance or business metric that is tied to these attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.86984,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "This tutorial covers methods to identify and track the key indicators of customer experience and clarifies the effect of application performance on your business. A clear understanding of what creates successful customer experience helps <em>DevOps</em> teams drive greater efficiencies in work efforts"
      },
      "id": "60440f5f28ccbcf7dc2c60b2"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/optimize-cloud-architecture-spend-continuously-improve-your-modern-cloud-environment": [
    {
      "sections": [
        "Establish objectives and baselines: define team SLOs",
        "Service level components",
        "Resources",
        "1. Build an inventory of services requiring SLOs",
        "2. Research customer expectations for SLOs",
        "3. Define SLOs",
        "4. Determine what can be instrumented",
        "New Relic products",
        "APM installation",
        "Infrastructure installation",
        "Infrastructure on-host integrations",
        "Synthetics",
        "Browser monitoring",
        "Mobile monitoring",
        "5. Review the default metrics",
        "6. Set up custom instrumentation",
        "7. Create dashboards to track SLIs"
      ],
      "title": "Establish objectives and baselines: define team SLOs",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6bfd37ee90b6890a53bfcf5ca688bbf72d551b70",
      "image": "https://docs.newrelic.com/static/5a07ed4ece7f7732b279460ca80f946d/c1b63/new-relic-logs-alerts.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/establish-objectives-baselines-define-team-slos/",
      "published_at": "2022-01-12T01:49:03Z",
      "updated_at": "2022-01-08T01:56:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A DevOps transformation requires a cultural shift so that teams can build new skills and motivations for the type of cross-team work required in a true DevOps practice. The transformation can be difficult when the people involved do not see the benefits of change as a clear objective. Service level objectives (SLOs) provide a powerful mechanism to codify the goals of a DevOps team in a way that can be measured and shared. They also provide clear boundaries on service expectations that help teams achieve greater velocity and freedom in experimenting with new approaches. This tutorial defines SLOs for successful service delivery objectives and utilize New Relic instrumentation to surface the current performance metrics relative to those objectives. Measurable SLOs and visibility into your current progress against those SLOs ensure that you will be able to properly assess future optimization efforts. See also our service level management feature. Service level components An SLO is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI); for example: Average response time Response time percentile Application availability SLOs clarify a target value for SLIs; for example: Average response time should be less than 200 ms 95% of requests should be completed within 250 ms Availability of the service should be 99.99% Logically group SLOs together to provide an overall boolean indicator of whether or not the service is meeting expectations. For example, a helpful SLO for alerting purposes could be: 95% of requests completed within 250 ms AND availability is 99.99% Copy Service level components Example values SLI (Indicator) HTTP status codes SLO (Objective) < 1% HTTP 500s over 30 days SLA (Agreement) For every additional .1% of HTTP 500s, 5% refund of total contract Resources Value stream mapping can be a useful exercise to work through before setting SLOs. Work with your teams to clarify key components of your service and the appropriate metrics. Use these inputs as starting points for this tutorial. In addition: Learn about SLOs, SLIs, and SLAs from the Google Cloud Platform blog. Learn how New Relic has applied SLOs and SLIs into its reliability practices form this SREcon18 Americas presentation (approximately 21 minutes). 1. Build an inventory of services requiring SLOs Start defining SLOs for your application by first taking an inventory of the services that your application provides to both your internal and external customers. Draft a list of services. Make the scope of services you consider as comprehensive as possible. Engage your team members and other stakeholders to validate the list for completeness. Segment your application stack to understand the potential components that might require SLOs. For example, most applications can be segmented as: Application (backend/microservices) Dependency services (such as the message queue) Database Website Underlying servers This example lists components that would benefit from SLOs: Customer type Component name Owner Language stack Operating system External Service 1 John D. Java RHEL 6 Internal Service 2 Jane A. .NET Win2003 R2 Internal ActiveMQ John D. Java AIX External Website Jane A. Classic ASP Win2000 Internal MS SQL Dave Z. n/a Win2003 R2 Building a definitive list of services that require an SLO can be challenging, because an application often consists of many endpoints with complex interdependencies. Begin your SLO journey with pragmatism. Start by defining a broader, simpler set of SLOs that are driven by what your customers care about most and what your team can control. As your teams better align around SLOs, you can then begin to fine-tune and add more complexity. 2. Research customer expectations for SLOs Once you have an inventory of services, begin to gather the information you need to define the SLOs for those services. Interviews with customers that depend on your services are often valuable for understanding service expectations. For example, to define SLOs for internal teams, New Relic, ask questions such as: If possible, can you broadly categorize the types of requests we can expect from you and your service? To what extent do you or your service depend on timely responses to requests? Are there requests for which response time is not critical? How does your service handle unavailable dependencies or data? What is the maximum amount of unavailable data that your service can handle? At what threshold does your service fail if a request takes too long? What are acceptable rates of errors? What would a SLA look like between our product and yours? Existing usage data can also be a helpful research input. 3. Define SLOs Using the research on customer expectations that you gathered, draft a focused set of SLOs. New Relic recommends setting SLOs against one or more of the following SLIs: Application availability percentage Average response time Response percentile Error rate Apdex value Also, consider instrumenting and tracking the following SLIs: Throughput (peak and trough) Database call count and duration DNS and SSL timing DOM processing and page rendering Mean-time-to-detection (MTTD) For a more comprehensive list of potential areas to measure, see Measuring DevOps. Recommendation: To determine if your application is performing to customer expectations: Consider combining multiple SLIs (for example, availability and response time) into one SLO. Aim to define a consistent set of conditions across all of the services in your list. Consult your team and stakeholders to validate that the SLOs you set are reasonable, consistently attainable (even if you are not currently meeting them), and aligned to customer expectations. After you finish this step, you should have a set of well-defined SLOs and SLIs. 4. Determine what can be instrumented Now you're ready to deploy agents or monitors to establish a performance baseline for the SLIs you created. With proper instrumentation in place, you'll have visibility into the performance indicators that matter for your team and your customers. In addition, you'll also have a clear understanding of how to meet your SLOs. Identify the service components your team will optimize. Verify which application tiers meet New Relic monitoring requirements. To ensure you have robust baselines from which to work, determine the level of instrumentation that is possible (or allowed) within your organization. It's best practice to instrument everything you can, but there may be situations where instrumentation isn't viable. In that case, you should determine what other data is available or can be created. For example, you can gather logs to query them for SLO data and set alerts for them. one.newrelic.com > Logs: Use the New Relic log management UI to leverage your logs. If the application has a web front end in these situations, use New Relic synthetic monitors. Our synthetic monitors offer non-agent monitoring while still providing the ability to establish a baseline. To instrument the example applications and components in this tutorial, use these New Relic features: New Relic products Customer type Component name Tier owner Language stack Server OS New Relic products External Service 1 John D. Java RHEL 6 APM, infrastructure monitoring, synthetic monitors Internal Service 2 Jane A. .Net Win2003 R2 APM, infrastructure monitoring Internal ActiveMQ John D. Java AIX APM External Website Jane A. Classic ASP Win2000 Synthetic monitors Internal MS SQL Dave Z. NA Win2003 R2 Infrastructure monitoring, on-host integrations APM installation After reviewing the compatibility and requirements for APM, install an APM agent on your application stack. Steps for installing APM agents vary based on language agent type. Follow the install procedures for a specific APM agents. Infrastructure installation After reviewing the requirements for New Relic infrastructure monitoring, follow the install procedures to install the infrastructure agent on instances that host your applications. The infrastructure agent requires the following host permissions: Linux: To install and run the agent, you must have root privileges. Windows: To install and run the agent, you must have Administrator privileges. Infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations based on their availability. New Relic supports several commonly used application components, including MySQL, Apache, NGINX, and more. For more information, see our on-host integration docs. Synthetics New Relic synthetic monitoring gives you a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. Follow the procedures to create a simple browser check. Be sure to verify that your website URL is accessible from the Synthetics public network locations. Browser monitoring New Relic browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how DevOps efforts are ultimately improving the experience for the customer. For more information, see the compatibility and requirements, then install the New Relic browser agent. Mobile monitoring The growing role of mobile apps in customer experience often spurs new performance data needs. Installation of New Relic mobile monitoring lets DevOps teams instrument iOS and Android applications to gain a fuller understanding of service delivery quality. 5. Review the default metrics After you deploy the agents and monitors, use service maps to review the default metrics that New Relic captures. For example, a typical service map show many of the common SLIs that application teams rely on, including response time, Apdex, throughput, and error rate metrics from APM. It also shows page load time, Ajax response, throughput, and error rate from browser monitoring. 6. Set up custom instrumentation To close any remaining gaps in visibility for your SLIs, use custom instrumentation. New Relic provides several avenues for adding custom instrumentation, including: Making API calls to agents from inside your source code Packaging XML-based custom instrumentation modules with deployed applications Adding UI-based instrumentation without a code deploy In addition, you can add custom attributes to each transaction event that match application performance factors to critical business information. Then you can track those attributes in Insights dashboards. For more information, see the custom instrumentation documentation for your application: APM Browser Infrastructure Mobile Synthetics 7. Create dashboards to track SLIs Once you implement the appropriate instrumentation, it's easy to visualize your service level indicators with New Relic dashboards, which provide a single location to query and view all the data that New Relic tools gather. To learn more about how to run queries to produce charts and dashboards, see Introduction to query builder. For more about the data you can query, see New Relic data types. The metrics you capture will become your application's baseline. Share dashboards with your application team and stakeholders to provide visibility into what is happening with your application and to monitor future performance.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 277.17108,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>New</em> <em>Relic</em> products",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " will <em>optimize</em>. Verify which application tiers meet <em>New</em> <em>Relic</em> monitoring requirements. To ensure you have robust baselines from which to work, determine the level of instrumentation that is possible (or allowed) within <em>your</em> organization. It&#x27;s best practice to instrument everything you can"
      },
      "id": "6044151ee7b9d259ef5799ea"
    },
    {
      "sections": [
        "Create application baselines",
        "1. Identify components",
        "Tip",
        "Example: List of components",
        "2. Determine compatibility",
        "Example: Components matched to New Relic products",
        "3. Deploy monitoring",
        "Deploy APM",
        "Deploy infrastructure",
        "Deploy infrastructure on-host integrations",
        "Create synthetic monitors",
        "4. Gather metrics",
        "5. Set up dashboards",
        "Example: Component performance compared against baselines",
        "Expert tips"
      ],
      "title": "Create application baselines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "9ddad276285ff4458594478dfd25b2b09aa6a5d2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/create-application-baselines/",
      "published_at": "2022-01-12T07:54:58Z",
      "updated_at": "2022-01-04T01:54:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Cloud migrations can take many forms. Some companies choose to port their applications directly from their data center to the cloud (a “Lift and Shift” migration) while others focus on completely re-architecting their applications to take advantage of benefits available only in the cloud. No matter your approach, there are three primary questions you want to answer after your migration: Has my application gotten slower? Is my application less stable than before? Am I losing customers due to either of the previous questions? To answer these questions, start by performing some basic testing to establish a baseline for the performance and availability of your systems. A baseline is a measurement of the current performance and availability of your application, which you then use as a comparison after your migration to validate your business case. In some cases, you may change a baseline when you perform migration acceptance testing. You can also use a baseline as a comparison point during your migration to make sure that you are on track. 1. Identify components Before you begin a cloud migration, identify all the tiers of your entire application stack. List all of the components (applications, services, etc.) that you want to migrate. Segment the application stack as follows: Application (backend/microservices/cron jobs) Dependency services, such as the message queue Database Website Underlying server and infrastructure Tip Make sure that you have access to applications and instances before you start creating application baselines. Engage your application owners, DevOps engineers, and product managers for access. Example: List of components Here is an example of the list of components in an application stack: Component Name Owner Language Stack Accessibility (Internet, Intranet) Operating System Service 1 John Doe Java Internet RHEL 6 Service 2 Maya Wiz .NET Intranet Win2003 R2 RabbitMQ John Doe Java Intranet AIX Website Maya Wiz Classic ASP Internet Win2000 MS SQL Dave Z NA Intranet Win2003 R2 2. Determine compatibility Once you identify the applications that you want to migrate, it is time to verify which application tiers to monitor with the New Relic platform. Work with stakeholders in your organization to determine the amount of instrumentation that is possible–or allowed–within your organization. This is an important step and one that will pay off, as the more you can instrument, the better your baselines. Here are the New Relic products to use for baselining, depending on the components that you identified: APM: Monitor your web apps with APM. See Compatibility and requirements for New Relic agents and products to learn precise compatibility details for each supported language. Infrastructure: Monitor your hosts with infrastructure. See Compatibility and requirements for infrastructure for supported operating systems and environments. You can also instrument other products and services with on-host integrations. Synthetics: Monitor web frontends and APIs with synthetics. Sometimes, you may not be able to instrument your on-premise environment with APM or infrastructure. For example, maybe your organization's policy forbids installing an agent behind a firewall. In these cases, if the application has a web frontend, use Synthetics, as it offers non-agent monitoring while still providing the ability to establish a baseline. Example: Components matched to New Relic products Match the components that you identified with their corresponding products: Component Name Tier Owner Language Stack Accessibility (Internet/ Intranet) Operating System New Relic products Service 1 John Doe Java Internet RHEL 6 APM, Infrastructure, Synthetics Service 2 Maya Wiz .NET Intranet Win2003 R2 APM, Infrastructure ActiveMQ John Doe Java Intranet AIX APM Website Maya Wiz Classic ASP Internet Win2000 Synthetics MS SQL Dave Z n/a Intranet Win2003 R2 Infrastructure, On-host Integration 3. Deploy monitoring Based on the component-product matches you made, deploy agents or monitors across your architecture: Deploy APM Install the APM agent on your application stack. The steps to install the APM agent are different based on language. Deploy infrastructure After reviewing the requirements for infrastructure, follow the instructions to install the infrastructure agent on your hosts: Install for Linux Install for Windows Server Install on AWS Elastic Beanstalk Install with a configuration management tool Deploy infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations. Available integrations include Apache, MySQL, NGINX, and others. Create synthetic monitors Synthetics is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. To get started add a monitor. Tip Make sure to verify that your website URL is accessible from the public network. You may also need to add New Relic IPs to your allow list. 4. Gather metrics After you deploy the agents and monitors, identify which metrics are the most important to your business and use these metrics to define your KPIs. Some recommendations include: Response time: Time taken to respond to a request. Throughput: Number of requests that came in through the application. Requesting queuing (Apache, IIS, NGINX): Duration of time taken for a request to reach your application. Database call duration: Duration of time taken to complete a database call. DB call counts: Number of calls made by application code to the database. Error rate: Percent of errors reported. Apdex score: An industry standard to measure user satisfaction with the response time of web applications and services. DNS setup timing: The time it takes to connect and receive data from DNS. SSL setup timing: The time it takes to establish an SSL connection. You can find some of these metrics in service maps, as well as on APM, and [browser] (/docs/ /new-relic-browser/getting-started/browser-overview-page-website-performance-summary) overview pages. For more detailed information about navigating, interpreting, and using APM, check out these New Relic University's tutorials: Overview dashboard tour Transactions dashboard Understanding Apdex 5. Set up dashboards After you define your KPIs, it's easy to visualize them in dashboards. Dashboards provide a single location to view all the data that New Relic products gather. Dashboards data consists of events, and each event has an event type, a timestamp, and key-value attributes. For more information about events, see Data collection and Default events for New Relic products. You can locate your KPIs and business metrics data in New Relic using the data explorer and the NRQL query language. You can also build dashboards to track the performance of those KPIs: Example: Component performance compared against baselines Continuing the examples in this document, the following table illustrates the maturity of your application performance over a period of time based on deployment milestones. Each milestone will serve as a new baseline for your applications: Component Milestone 1 Milestone 2 Milestone N Environment Component Name Response Time SLA Apdex Response Time SLA Apdex Response On-Prem Service 1 1.5 secs 80% 70% 1.5 secs 68% 0.65 1.4 secs Cloud Service 1 0.9 secs 96.8% 95% 0.9 secs 98% 0.99 0.7 secs On-Prem Service 2 0.7 secs 73% 68% 0.7 secs 80% 0.78 0.85 secs Cloud Service 2 0.6 secs 90% 92% 0.6 secs 89% 0.90 0.5 secs After your migration, compare these baselines against your migration acceptance testing baselines. Expert tips If you find that you need data that is not captured by default instrumentation, we make it easy for you to capture custom data: APM custom instrumentation Browser custom data Infrastructure custom attributes Custom event data Mobile custom data Synthetics custom attributes You can also learn more about APM custom instrumentation with the New Relic University Custom data tutorial series.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.91449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Example: Components matched to <em>New</em> <em>Relic</em> products",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " want to migrate, it is time to verify which application tiers to monitor with the <em>New</em> <em>Relic</em> platform. Work with stakeholders in <em>your</em> organization to determine the amount of instrumentation that is possible–or allowed–within <em>your</em> organization. This is an important step and one that will pay off"
      },
      "id": "6044605c64441f1d15378edf"
    },
    {
      "sections": [
        "Iterate and measure impact: track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "Tip",
        "3. Test your pipeline with infrastructure"
      ],
      "title": "Iterate and measure impact: track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "06e2013529667ec66bde080abc3623ac6b6a6695",
      "image": "https://docs.newrelic.com/static/886d79f19e7b5576a06f8cc6016d053d/c1b63/apm-deployments.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2022-01-12T07:55:33Z",
      "updated_at": "2022-01-03T18:36:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A properly instrumented system gives teams full visibility into the impact of the changes they make. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation, and reduce the impact to other ongoing changes. Prerequisite Before starting this tutorial, be sure to complete the Establish objectives and baselines tutorial and set the appropriate KPI targets for your applications. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and to prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they’re consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make are correct across them, and eliminate any anomalies before pushing code to production. 2. Add automated deployment markers It’s important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. APM’s deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change-log, etc.). APM displays a vertical line, or “marker”, on charts and graphs at the deployment event’s timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application, and additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful DevOps transformation is a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. Our infrastructure agent helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names which fits this model quite nicely. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.09984,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "1. Integrate measurements into <em>your</em> development process",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": ") &gt; Events &gt; Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in <em>your</em> application. Tip <em>New</em> <em>Relic</em> recommends that you make POST requests to the <em>New</em> <em>Relic</em> REST API as the final step of a successful CI&#x2F;CD deployment"
      },
      "id": "60450efc64441fb48e378eee"
    }
  ],
  "/docs/new-relic-solutions/new-relic-solutions/resolve-dependency-risk-identify-analyze-potential-issues": [
    {
      "sections": [
        "Establish objectives and baselines: define team SLOs",
        "Service level components",
        "Resources",
        "1. Build an inventory of services requiring SLOs",
        "2. Research customer expectations for SLOs",
        "3. Define SLOs",
        "4. Determine what can be instrumented",
        "New Relic products",
        "APM installation",
        "Infrastructure installation",
        "Infrastructure on-host integrations",
        "Synthetics",
        "Browser monitoring",
        "Mobile monitoring",
        "5. Review the default metrics",
        "6. Set up custom instrumentation",
        "7. Create dashboards to track SLIs"
      ],
      "title": "Establish objectives and baselines: define team SLOs",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6bfd37ee90b6890a53bfcf5ca688bbf72d551b70",
      "image": "https://docs.newrelic.com/static/5a07ed4ece7f7732b279460ca80f946d/c1b63/new-relic-logs-alerts.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/establish-objectives-baselines-define-team-slos/",
      "published_at": "2022-01-12T01:49:03Z",
      "updated_at": "2022-01-08T01:56:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A DevOps transformation requires a cultural shift so that teams can build new skills and motivations for the type of cross-team work required in a true DevOps practice. The transformation can be difficult when the people involved do not see the benefits of change as a clear objective. Service level objectives (SLOs) provide a powerful mechanism to codify the goals of a DevOps team in a way that can be measured and shared. They also provide clear boundaries on service expectations that help teams achieve greater velocity and freedom in experimenting with new approaches. This tutorial defines SLOs for successful service delivery objectives and utilize New Relic instrumentation to surface the current performance metrics relative to those objectives. Measurable SLOs and visibility into your current progress against those SLOs ensure that you will be able to properly assess future optimization efforts. See also our service level management feature. Service level components An SLO is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI); for example: Average response time Response time percentile Application availability SLOs clarify a target value for SLIs; for example: Average response time should be less than 200 ms 95% of requests should be completed within 250 ms Availability of the service should be 99.99% Logically group SLOs together to provide an overall boolean indicator of whether or not the service is meeting expectations. For example, a helpful SLO for alerting purposes could be: 95% of requests completed within 250 ms AND availability is 99.99% Copy Service level components Example values SLI (Indicator) HTTP status codes SLO (Objective) < 1% HTTP 500s over 30 days SLA (Agreement) For every additional .1% of HTTP 500s, 5% refund of total contract Resources Value stream mapping can be a useful exercise to work through before setting SLOs. Work with your teams to clarify key components of your service and the appropriate metrics. Use these inputs as starting points for this tutorial. In addition: Learn about SLOs, SLIs, and SLAs from the Google Cloud Platform blog. Learn how New Relic has applied SLOs and SLIs into its reliability practices form this SREcon18 Americas presentation (approximately 21 minutes). 1. Build an inventory of services requiring SLOs Start defining SLOs for your application by first taking an inventory of the services that your application provides to both your internal and external customers. Draft a list of services. Make the scope of services you consider as comprehensive as possible. Engage your team members and other stakeholders to validate the list for completeness. Segment your application stack to understand the potential components that might require SLOs. For example, most applications can be segmented as: Application (backend/microservices) Dependency services (such as the message queue) Database Website Underlying servers This example lists components that would benefit from SLOs: Customer type Component name Owner Language stack Operating system External Service 1 John D. Java RHEL 6 Internal Service 2 Jane A. .NET Win2003 R2 Internal ActiveMQ John D. Java AIX External Website Jane A. Classic ASP Win2000 Internal MS SQL Dave Z. n/a Win2003 R2 Building a definitive list of services that require an SLO can be challenging, because an application often consists of many endpoints with complex interdependencies. Begin your SLO journey with pragmatism. Start by defining a broader, simpler set of SLOs that are driven by what your customers care about most and what your team can control. As your teams better align around SLOs, you can then begin to fine-tune and add more complexity. 2. Research customer expectations for SLOs Once you have an inventory of services, begin to gather the information you need to define the SLOs for those services. Interviews with customers that depend on your services are often valuable for understanding service expectations. For example, to define SLOs for internal teams, New Relic, ask questions such as: If possible, can you broadly categorize the types of requests we can expect from you and your service? To what extent do you or your service depend on timely responses to requests? Are there requests for which response time is not critical? How does your service handle unavailable dependencies or data? What is the maximum amount of unavailable data that your service can handle? At what threshold does your service fail if a request takes too long? What are acceptable rates of errors? What would a SLA look like between our product and yours? Existing usage data can also be a helpful research input. 3. Define SLOs Using the research on customer expectations that you gathered, draft a focused set of SLOs. New Relic recommends setting SLOs against one or more of the following SLIs: Application availability percentage Average response time Response percentile Error rate Apdex value Also, consider instrumenting and tracking the following SLIs: Throughput (peak and trough) Database call count and duration DNS and SSL timing DOM processing and page rendering Mean-time-to-detection (MTTD) For a more comprehensive list of potential areas to measure, see Measuring DevOps. Recommendation: To determine if your application is performing to customer expectations: Consider combining multiple SLIs (for example, availability and response time) into one SLO. Aim to define a consistent set of conditions across all of the services in your list. Consult your team and stakeholders to validate that the SLOs you set are reasonable, consistently attainable (even if you are not currently meeting them), and aligned to customer expectations. After you finish this step, you should have a set of well-defined SLOs and SLIs. 4. Determine what can be instrumented Now you're ready to deploy agents or monitors to establish a performance baseline for the SLIs you created. With proper instrumentation in place, you'll have visibility into the performance indicators that matter for your team and your customers. In addition, you'll also have a clear understanding of how to meet your SLOs. Identify the service components your team will optimize. Verify which application tiers meet New Relic monitoring requirements. To ensure you have robust baselines from which to work, determine the level of instrumentation that is possible (or allowed) within your organization. It's best practice to instrument everything you can, but there may be situations where instrumentation isn't viable. In that case, you should determine what other data is available or can be created. For example, you can gather logs to query them for SLO data and set alerts for them. one.newrelic.com > Logs: Use the New Relic log management UI to leverage your logs. If the application has a web front end in these situations, use New Relic synthetic monitors. Our synthetic monitors offer non-agent monitoring while still providing the ability to establish a baseline. To instrument the example applications and components in this tutorial, use these New Relic features: New Relic products Customer type Component name Tier owner Language stack Server OS New Relic products External Service 1 John D. Java RHEL 6 APM, infrastructure monitoring, synthetic monitors Internal Service 2 Jane A. .Net Win2003 R2 APM, infrastructure monitoring Internal ActiveMQ John D. Java AIX APM External Website Jane A. Classic ASP Win2000 Synthetic monitors Internal MS SQL Dave Z. NA Win2003 R2 Infrastructure monitoring, on-host integrations APM installation After reviewing the compatibility and requirements for APM, install an APM agent on your application stack. Steps for installing APM agents vary based on language agent type. Follow the install procedures for a specific APM agents. Infrastructure installation After reviewing the requirements for New Relic infrastructure monitoring, follow the install procedures to install the infrastructure agent on instances that host your applications. The infrastructure agent requires the following host permissions: Linux: To install and run the agent, you must have root privileges. Windows: To install and run the agent, you must have Administrator privileges. Infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations based on their availability. New Relic supports several commonly used application components, including MySQL, Apache, NGINX, and more. For more information, see our on-host integration docs. Synthetics New Relic synthetic monitoring gives you a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. Follow the procedures to create a simple browser check. Be sure to verify that your website URL is accessible from the Synthetics public network locations. Browser monitoring New Relic browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how DevOps efforts are ultimately improving the experience for the customer. For more information, see the compatibility and requirements, then install the New Relic browser agent. Mobile monitoring The growing role of mobile apps in customer experience often spurs new performance data needs. Installation of New Relic mobile monitoring lets DevOps teams instrument iOS and Android applications to gain a fuller understanding of service delivery quality. 5. Review the default metrics After you deploy the agents and monitors, use service maps to review the default metrics that New Relic captures. For example, a typical service map show many of the common SLIs that application teams rely on, including response time, Apdex, throughput, and error rate metrics from APM. It also shows page load time, Ajax response, throughput, and error rate from browser monitoring. 6. Set up custom instrumentation To close any remaining gaps in visibility for your SLIs, use custom instrumentation. New Relic provides several avenues for adding custom instrumentation, including: Making API calls to agents from inside your source code Packaging XML-based custom instrumentation modules with deployed applications Adding UI-based instrumentation without a code deploy In addition, you can add custom attributes to each transaction event that match application performance factors to critical business information. Then you can track those attributes in Insights dashboards. For more information, see the custom instrumentation documentation for your application: APM Browser Infrastructure Mobile Synthetics 7. Create dashboards to track SLIs Once you implement the appropriate instrumentation, it's easy to visualize your service level indicators with New Relic dashboards, which provide a single location to query and view all the data that New Relic tools gather. To learn more about how to run queries to produce charts and dashboards, see Introduction to query builder. For more about the data you can query, see New Relic data types. The metrics you capture will become your application's baseline. Share dashboards with your application team and stakeholders to provide visibility into what is happening with your application and to monitor future performance.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 453.63794,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>New</em> <em>Relic</em> products",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " monitoring <em>New</em> <em>Relic</em> browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how <em>DevOps</em> efforts are ultimately improving"
      },
      "id": "6044151ee7b9d259ef5799ea"
    },
    {
      "sections": [
        "Iterate and measure impact: track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "Tip",
        "3. Test your pipeline with infrastructure"
      ],
      "title": "Iterate and measure impact: track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "06e2013529667ec66bde080abc3623ac6b6a6695",
      "image": "https://docs.newrelic.com/static/886d79f19e7b5576a06f8cc6016d053d/c1b63/apm-deployments.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2022-01-12T07:55:33Z",
      "updated_at": "2022-01-03T18:36:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A properly instrumented system gives teams full visibility into the impact of the changes they make. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation, and reduce the impact to other ongoing changes. Prerequisite Before starting this tutorial, be sure to complete the Establish objectives and baselines tutorial and set the appropriate KPI targets for your applications. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and to prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they’re consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make are correct across them, and eliminate any anomalies before pushing code to production. 2. Add automated deployment markers It’s important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. APM’s deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change-log, etc.). APM displays a vertical line, or “marker”, on charts and graphs at the deployment event’s timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application, and additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful DevOps transformation is a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. Our infrastructure agent helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names which fits this model quite nicely. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.8745,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Iterate and <em>measure</em> impact: track metrics before and after deployments",
        "sections": "1. Integrate <em>measurements</em> into your <em>development</em> process",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": " as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful <em>DevOps</em> transformation is a cultural shift toward smaller, more"
      },
      "id": "60450efc64441fb48e378eee"
    },
    {
      "sections": [
        "Measure code pipelines",
        "Prerequisite",
        "1. Identify what to track",
        "2. Capture the events required to instrument your pipeline"
      ],
      "title": "Measure code pipelines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "da5ac3dfed1bb4ab89bff1f3fd8e6d392767ce01",
      "image": "https://docs.newrelic.com/static/6cfae62440efb84aa5c9126e6a33cc8f/508ef/codepipeline2NR.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/measure-code-pipelines/",
      "published_at": "2022-01-12T08:05:38Z",
      "updated_at": "2022-01-03T18:36:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "High functioning DevOps teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make improvements. Prerequisite Before starting this tutorial, be sure to complete the Establish team dashboards tutorial. 1. Identify what to track Look at your CI/CD system and determine the stats you'd like to gather. We recommend, at a minimum, starting with commit metadata, build status, test results, deploy status, and performance metrics. Determine which stats you want to report to New Relic. 2. Capture the events required to instrument your pipeline Capture timestamped state changes to your pipeline/CI/CD system indicating when a given stage started; and whether it succeeded or failed. This step, in turn, makes it easy to track your deployment process over time—looking for trends in the frequency of deployments, build quality, and other performance indicators. For easiest tracking, capture timestamped changes to your source code management system (SCM) with at least the author and a hash or unique change ID. Propagate this information wherever possible. If you have your own build system, add code to emit custom events at each stage. For hosted services, create a lightweight intermediary service/function-as-a-service (FaaS) to format and forward these custom events. The example below uses AWS CodePipeline to manage the flow of an application that is sourced in GitHub, built and tested with AWS CodeBuild, and deployed with Elastic Beanstalk. It utilizes a simple service written in Node.js, plus some \"glue code\" and event handlers needed to push data from GitHub and AWS to New Relic. Code for this example is available at github.com/newrelic/webinar. Use AWS CodePipeline to understand different parts of your flow. We chose the tools and products used here as examples—with the goal of illustrating the concepts around the types of data and events you should be thinking about when instrumenting your own code pipeline. The sample code, however, should be generic enough to adapt readily to almost any toolset.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 397.8744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Measure</em> code pipelines",
        "sections": "<em>Measure</em> code pipelines",
        "tags": "<em>Measure</em> <em>DevOps</em> <em>success</em>",
        "body": "High functioning <em>DevOps</em> teams use instrumentation to push changes to production more frequently and with less risk. This process yields important insights: How is your build pipeline performing? Where are the issues? They key is to instrument your pipeline in order to track it and to make"
      },
      "id": "603ea2f7e7b9d26d4c2a080a"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/customer-experience/bofta-implementation-guide": [
    {
      "sections": [
        "Quality foundation implementation guide",
        "Overview",
        "Desired Outcome",
        "Key Performance Indicators",
        "Availability",
        "Largest contentful paint (LCP)",
        "First input delay (FID)",
        "Cumulative layout shift (CLS)",
        "Time to first byte (TTFB)",
        "Ajax response times",
        "HTTP error rate",
        "JavaScript error rate",
        "Prerequisites",
        "Required knowledge",
        "Required Installation and Configuration",
        "Establish current state",
        "Review instrumented pages",
        "Validate Browser URL grouping",
        "Understand how you will segment your data",
        "Import the quality foundation dashboard",
        "Capture current performance for each dashboard page",
        "Improvement Process",
        "Plan your work",
        "Decide which KPIs to improve",
        "Improve targeted KPIs",
        "Improve page load performance",
        "Improve AJAX response times",
        "Improve the AJAX error rate",
        "Improve JavaScript errors",
        "Conclusion"
      ],
      "title": "Quality foundation implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Quality Foundation"
      ],
      "external_id": "91186ed56e33e040c73d1fff940cec0644c199f6",
      "image": "https://docs.newrelic.com/static/9238160720501f4423dff703746fb59d/d9199/cx-what-you-can-measure-nr.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/quality-foundation-implementation-guide/",
      "published_at": "2022-01-12T05:56:50Z",
      "updated_at": "2022-01-12T05:56:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Digital customer experience is your end user’s experience across all your digital touch points. There are four core factors that impact a user’s experience: Availability (Is it reachable?) Performance (Does it perform well enough to be usable?) Content quality (Does it have what users need and can they find it?) Product and content relevance (Does it have what users care about?) Digital customer experience includes web, mobile, and IoT. The first version of this guide is focused on measuring the end user web experience. Quality Foundation is about creating a standard practice to help you understand your digital customer experience in a meaningful way. This implementation guide will help you: Look at customer experience in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about Prioritize what you work on Create a repeatable practice Desired Outcome Improve customer engagement and retention by measuring and improving performance in a way that better aligns to the end user experience. Key Performance Indicators Quality Foundation measures the following KPIs: Availability This KPI measures whether or not your application or its pages can be accessed by your users Goal: Improve uptime and availablity Thresholds: < 99% warning < 95% critical 99% or \"2 9's\" is a good minimum standard of availability, even for employee applications or sub-pages. We configure these default thresholds into the dashboards. You can easily change this to better suit expectations for your application. Largest contentful paint (LCP) Part of Core Web Vitals. Largest Contentful Paint (LCP) measures the time it takes to load the largest image after a user has navigated to a new page. Goal: Reduce LCP to 2.5 seconds or better for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 2.5 seconds Critical: > 4.0 seconds LCP thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. First input delay (FID) Part of Core Web Vitals. Measures the interactivity of a page by tracking the time between user interaction (such as clicking a link or entering text) when the browser begins processing the event. Goal: Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 100 milliseconds Critical: > 300 milliseconds FID thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. Cumulative layout shift (CLS) Part of Core Web Vitals. Measures how much the page layout shifts during render. Goal: Maintain a score of 0.1 or less for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 0.1 score Critical: > 0.25 score CLS thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. Time to first byte (TTFB) This KPI measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. Google considers TTFB secondary to Core Web Vitals. We recommend measuring it for a more complete picture. It can be revealing if you see a change in LCP, because it answers the question as to whether the change occurred server side or client side. Goal: Reduce the time to first byte by improving CDN, network, and service performance. Thresholds: Warning > 0.5 seconds Critical > 1.0 seconds According to Google and Search Engine People, 500 milliseconds is a decent TTFB for pages with dynamic content. You can find mention of these recommendations here. Ajax response times Slow ajax calls can make the user feel as though nothing is happening or the page is broken. If the response time is slow enough, users may even abandon the journey. Goal: Measure and improve ajax response times. Thresholds: Warning > 2 seconds Critical > 2.5 seconds These thresholds come from experience with customers across a variety of industries. HTTP error rate HTTP errors (or HTTP 4xx and 5xx responses) happen when calls to the backend are not successful. Goal: Measure and reduce the HTTP error rate to ensure your customers are able to do what they came to your site to do. Thresholds: Warning < 99% of requests are successful Critical < 97% of requests are successful These thresholds come from experience with customers across a variety of industries. We made the assumption that every ajax request is associated with something the user is trying to achieve and treat it accordingly. Because users will often retry failed actions, we allowed for space between warning and critical thresholds. If the ajax requests being measured are an important part of the user journey, we recommended aiming for higher success rates, such as 99.5% or 99.9%. If the ajax requests are tied to login requests, separate 4xx response codes from 5xx response codes and set a much lower threshold for the 4xx responses. You can look to historical response code rates to determine a reasonable threshold. JavaScript error rate This KPI measures the number of JavaScript errors per page view. Goal: Remove irrelevant JavaScript errors being tracked either by tuning ingest or using filtering. Reduce JavaScript errors that impact customer performance. Thresholds: Warning: > 5% errors per page view Critical: > 10% errors per page view These thresholds come from experience with customers across a variety of industries. For each KPI, we defined thresholds - one for warning, another for critical. You might ask where these values come from or how you can be sure they should apply to your application. Our thresholds are the ones recommended by Google (as with Core Web Vitals) or by us, based on our experience across a large number of customers and applications. If you feel strongly that they should be different, you can adjust them, but you should do this at the organizational level rather than on an application by application basis. Quality Foundation helps you identify where in your application you need to make improvements that will optimize user retention, conversion and satisfaction. It is less about where things are and more about where to get to. It also shows you what you should be measuring going forward. You can use this to define SLOs (in a service level dashboard) and alert on them. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required Installation and Configuration Browser Pro installed in all pages SPA enabled for single page applications Synthetics monitors configured: Ping monitors configured for anonymous users Scripted synthetics check configured for login flow Monitors should be configured to test from all regions applicable to your users Monitors should be configured for each domain and each login flow Data retention for browser events greater than or equal to 2x an average sprint Establish current state Review instrumented pages Validate Browser URL grouping Understand how you will segment your data Import the quality foundation dashboard Capture current performance for each dashboard page Review instrumented pages Review Browser apps and pages to make sure that everything you expect to report back to New Relic is. You can do this by reviewing the Page Views tab in the Browser UI or running the following query: SELECT uniques(pageUrl) from PageView LIMIT MAX Copy You may need to filter out URLs that contain request or customer ID. Validate Browser URL grouping Ensure Browser segments are captured correctly so user experience performance is measurable in both the NewRelic UI as well as at the aggregate level when querying via NRQL. A segment is the text between two / in a URL or between . of a domain name. For example, in the URL website.com/product/widget-name, the segments are: website .com product widget-name When there are a lot of URLs with a lot of segments, URLs can get crushed, so that website.com/product/widget-name becomes website.com/ or website.com/product/. In this example, the first crushed URL is not particularly useful, but the second one may be a useful way of aggregating customer experience data for the product. Not sure whether you need to tune your configuration? Import the Segment Allow List Investigation dashboard in GitHub to help. Once you’ve identified which segments to add, you can add them using Segment allow lists in Browser. Understand how you will segment your data Make Customer Experience data understandable and actionable by breaking it out into different segments. In this case, segments refer to groups of data. It does not refer to sections of URLs, as in segment allow lists. Consider the following statements: Most of our users experience 3 seconds or better to first input delay. On average, we see 2 seconds to the largest contentful paint. Last week, there were 1 million page views. Compared to: Most of the users in the US, Canada, and EMEA experience 2 seconds or better to first input delay. Malaysia and Indonesia users experience 4 seconds; we are looking into this. Customers buying car insurance typically see 1 second to largest contentful paint. For home insurance, it’s 4 seconds. Last week, there were 700,000 page views on mobile browser apps compared to 300,000 on desktop. Let’s make sure we’re optimizing our mobile experience. Typical segmentation involves breaking down user experience into the following categories: Segment Guidance Region/Location Basic: Group by country. Browser events automatically contain the country code of requests, so there is nothing you need to do to break it out further. Advanced: Make regional grouping match regional SLO groups by creating your own region attribute using custom attributes in Browser. Facet by countryCode. Related attributes: regionCode city asnLatitude asnLongitude Device Break out performance and engagement device type so you can understand: Typical breakdown of desktop vs mobile browser users Experience of desktop vs mobile browser users Facet by deviceType. Related attributes: userAgentName userAgentOS userAgentVersion Product/Line of Business In this scenario, a product is a separate line of business or service provided by your organization. Some examples of industries and respective products: An insurance company that sells both car and house insurance A media company that has multiple streaming services or channels A travel company that provides car rental as well as hotel bookings Basic: Break out performance by product by: Faceting on pageUrl: Use this approach when multiple products are grouped into one browser app in New Relic. Faceting by appName: Use this approach when each product is instrumented as a separate web app. Grouping by appName and then facet: Use this approach when there are multiple apps in browser supporting one product. Advanced: Add product offering as a custom attribute to browser pages using custom attributes. Environment During instrumentation or afterwards, follow a naming convention that specifies the environment in Browser. Well named browser apps specify product and/or function as well as environment. Examples: account-management.prod hotels-book.prod car-insurance.uat Using app naming conventions to specify the environment supports filtering data in both the UI and in dashboards. For more information, see the documentation for how to rename Browser apps. Team In some organizations, a single team supports multiple products, while in others, a product is big enough to be supported by multiple teams. Report on team performance against customer experience or engagement by either adding the team name to the Browser app name (for example, account-management.prod.unicorn-squad) or by using custom attributes. Import the quality foundation dashboard This step creates the dashboard that you will use to measure your customer experience and improve it. Clone the GitHub repository. Follow the GitHub repository README instructions to implement the dashboard. Make sure to align the dashboard to lines of business or customer facing offerings rather than teams. This ensures optimization time is spent where it is most impactful. Capture current performance for each dashboard page Follow the GitHub README instructions. Use the dashboard from the previous step to understand the overall performance for each line of business. If relevant, apply filters to see performance across region or device. If values drop below targets and it matters, add it to the sheet as a candidate for improvement. Not worth tracking: A company that sells insurance in the US only notices poor performance in Malaysia. Worth tracking: A company that sells insurance in the US only notices poor performance with respect to mobile users in the US. Improvement Process Plan your work Decide which KPIs to improve Improve targeted KPIs Improve page load performance Improve AJAX response times Improve the AJAX error rate Improve JavaScript errors Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. Decide which KPIs to improve You now know what your user experience looks like across multiple lines of business. Where should you be improving? Start with business priorities. If you have clear business directives or have access to a senior manager above who does, you should focus on what matters most to your organization. For example, let’s say your company has recently launched a new initiative around a line of business but the KPIs associated with the UI are below target. This is where you should focus time initially. Next, focus on KPIs for each line of business. Finally, filter each line of business by device, region, etc., to see if additional focus is needed for specific regions or devices. Improve targeted KPIs To track your progress, create a new dashboard or add a new page to the existing dashboard and name it Quality Foundation KPI Improvement. For more information, see Improve Web Uptime. Improve page load performance Narrow your focus to specific pages that aren’t meeting target KPI values. For each page load KPI result that is out of bounds in the Quality Foundation Dashboard, remove the COMPARE WITH clause and add FACET pageUrl/targetGroupedUrl LIMIT MAX to find which pages are the poor performers. Use targetGroupedUrl when there are many results; for example, when the customer ID is part of the URL. Otherwise, use pageUrl. Original Dashboard query: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' SINCE 1 week AGO COMPARE WITH 1 week AGO Copy New query to identify problem pages: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' FACET targetGroupedUrl LIMIT MAX Copy Once you have identified which pages to improve, improve them following these best practices. Improve AJAX response times Find the slow requests. Go to the Ajax duration widget on the dashboard. View query, then open in query builder. Add facet requestUrl LIMIT MAX to the end of the query. Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - AjaxResponseTimes. Focus improving requests with a timeToSettle > 2.5s. Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve the AJAX error rate Find the failing requests. Go to Dashboards > Query builder. Enter FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND <Ajax Request filter> SINCE 1 week AGO facet pageUrl, appName Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Pages with AjaxErrors. Run the query again for the most problematic pages to find the requests that are failing: FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND pageUrl=<problematic page> AND appName = <corresponding app> <Ajax Request filter> SINCE 1 week AGO facet requestUrl Copy Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve JavaScript errors Find the most common failures. Go to Dashboards > Query builder Enter FROM JavaScriptError SELECT count(errorClass) SINCE 1 week AGO WHERE <PageView filter> FACET transactionName, errorClass, errorMessage, domain Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Javascript Errors. Use this information to figure out which errors need to be addressed Use New Relic’s recommended best practices to resolve errors that need addressing. See JavaScript errors page: Detect and analyze errors. Remove third party errors that do not add value. You may be using a third party JavaScript that is noisy but works as expected. You can take a couple of approaches: Remove the domain name from the JavaScript error/Pageview ratio widget and add it as its own widget so you can see unexpected changes. You can alert on this using Baseline NRQL alerts. Drop the JavaScript error using drop filters. Only use this option if the volume of errors is impacting your data ingest in a significant way. Be as specific as you can in the drop filter. Conclusion Best practices to adopt Revisit performance metrics (shared in this document as Quality Foundation KPIs) at the end of each sprint. Incorporate performance improvements into developer sprints. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Define Customer Experience SLOs. Create alerts for business critical drops in Quality Foundation KPIs. Value Realization At the end of this process you should now: Have an understanding of your end user experience in a way that is tangible, actionable, and easy for engineers as well as the business to understand. Know how releases impact your end customers. Know how your customers are impacted by service, infrastructure, or network level events. See latency issues caused by backend services if they exist. Have created, or be on the path to create, a common language with business owners so you are working together. This can open new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 527.7035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Quality foundation <em>implementation</em> <em>guide</em>",
        "sections": "Quality foundation <em>implementation</em> <em>guide</em>",
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": " you understand your <em>digital</em> <em>customer</em> <em>experience</em> in a meaningful way. This <em>implementation</em> <em>guide</em> will help you: Look at <em>customer</em> <em>experience</em> in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about Prioritize what"
      },
      "id": "61461531e7b9d25774b6f22d"
    },
    {
      "sections": [
        "Improve web uptime",
        "1. Investigate Synthetics checks",
        "2. Create workloads",
        "3. Investigate outages at lowest tier first"
      ],
      "title": "Improve web uptime",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Uptime",
        "Availability"
      ],
      "external_id": "5893b26accc8f1ebcb41ca1ccd7f50f1a2f4f7d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-web-uptime/",
      "published_at": "2022-01-12T05:56:51Z",
      "updated_at": "2021-09-07T09:17:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Steps to follow to improve web uptime: 1. Investigate Synthetics checks Investigate and resolve failed Synthetics checks when they occur. Check multiple locations. Set up an alert to notify you when multiple locations fail. 2. Create workloads Create workloads that correlate synthetic monitors with browser applications, services, and infrastructure. Include a link to the workload in the alert runbook. You can also find the correlated workload for a synthetic using global search. Make sure that alerts are configured for each tier of your workload. This way you can see the health of each of the tiers in one view. This will save you time in troubleshooting. You do not need to create alert notifications for each tier to benefit from this view. 3. Investigate outages at lowest tier first When an outage occurs, start investigating at the lowest tier that is alerting. For instance, if you see that you have an infrastructure issue and a JavaScript issue, investigate infrastructure prior to javascript unless you have a second person or team you can delegate that to. Use the tools that are available to you for troubleshooting: Make sure that distributed tracing is enabled for browser monitoring as well as APM. Use the Browser UI to help you understand what is happening at the end user tier. Use Lookout to help you understand what’s causing flapping or reoccurring issues.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.9391,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>"
      },
      "id": "61372e1728ccbcf13b56a862"
    },
    {
      "sections": [
        "Improve page load performance",
        "Page Load KPI",
        "Cumulative Layout Shift (CLS)",
        "Largest Contentful Paint (LCP)",
        "First Input Delay (FID)"
      ],
      "title": "Improve page load performance",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Core web vitals",
        "Page load",
        "Page render"
      ],
      "external_id": "a6c3e400d5c99451f900a3edee1fa19149b5f82c",
      "image": "https://docs.newrelic.com/static/a73f684466bda769a52da48dc9a4e4cc/d9199/cx_page_load_render_timings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-page-load/",
      "published_at": "2022-01-12T05:56:02Z",
      "updated_at": "2021-09-07T09:17:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Page load performance measurement continues to evolve. In order to improve the overall performance and user experience, it helps to understand the different metrics and how they relate to each other. Before following the guidance below, narrow your scope to specific pages that you are trying to improve. For maximum impact, focus on pages that are frequently accessed but have a lower than accepted score for the 75th percentile of users. Page Load KPI How to improve time to first byte (TTFB): Time to first byte measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. If users in the 75th percentile are experiencing a TTFB of greater than 0.5s for one or more of your pages, you can break timings down further by querying the following attributes in PageView: backendDuration connectionSetupDuration dnsLookupDuration networkDuration Frequently slowness prior to rendering is caused by slowness in the backend, either from third party APIs or backend applications. Synthetics monitoring for third party APIs helps operations and development teams understand when the root cause is outside of their control. Even if you cannot control the code, you can influence the outcome by sharing synthetics results with the third party to help them understand what your customers are experiencing. If the backend applications are owned by you or your team, you can use APM agents, Pixie, or OpenTelemetry to understand and manage performance. To make cross team communication easier, we recommend implementing Service Level Management boundaries. Cumulative Layout Shift (CLS) Cumulative layout shift is a score that indicates how much content shifts once it has already loaded. General tips and tricks for improving CLS: Specify dimensions for stylesheets and let the browser’s default CSS control the aspect ratio. Statically reserve space for ad slots. Avoid ads near the top of the viewport. Avoid inserting new content above existing content. Precompute sufficient space for embeds. Additional resources: Google’s approach to CLS optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS. Largest Contentful Paint (LCP) Largest contentful paint measures the difference between the start of page render until the time to paint the largest content element. Common causes for a slow lcp, according to web.dev: Slow server response times Render-blocking JavaScript and CSS Slow resource load times Client-side rendering Use Browser session trace information to understand which of the common causes above factor into the particular page you are trying to optimize. Approaches to improve LCP: Making use of CDNs and paying attention to caching and edge server performance Establishing third party connections early Delaying non-critical Javascript and CSS Additional resources: Google’s approach to LCP optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS. First Input Delay (FID) First input delay is the time between when a user first interacts with a page to the time when the browser is able to respond. It’s a field metric that varies based on real user behavior (results vary based on user impatience and action timing) but can be optimized by reducing TBT, total blocking time. To do this, you need to: Break up long blocking tasks. Optimize bloated JavaScript. Look at moving logic server side and/or use web workers to run threads in the background. Use Browser session trace information to understand where your blocking intervals are occurring and for how long they last. Additional resources: Google’s approach to FID optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.47803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": "Page load performance measurement continues to evolve. In order to improve the overall performance and user <em>experience</em>, it helps to understand the different metrics and how they relate to each other. Before following the guidance below, narrow your scope to specific pages that you are trying"
      },
      "id": "61372e19196a67f4814948d7"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-page-load": [
    {
      "sections": [
        "Quality foundation implementation guide",
        "Overview",
        "Desired Outcome",
        "Key Performance Indicators",
        "Availability",
        "Largest contentful paint (LCP)",
        "First input delay (FID)",
        "Cumulative layout shift (CLS)",
        "Time to first byte (TTFB)",
        "Ajax response times",
        "HTTP error rate",
        "JavaScript error rate",
        "Prerequisites",
        "Required knowledge",
        "Required Installation and Configuration",
        "Establish current state",
        "Review instrumented pages",
        "Validate Browser URL grouping",
        "Understand how you will segment your data",
        "Import the quality foundation dashboard",
        "Capture current performance for each dashboard page",
        "Improvement Process",
        "Plan your work",
        "Decide which KPIs to improve",
        "Improve targeted KPIs",
        "Improve page load performance",
        "Improve AJAX response times",
        "Improve the AJAX error rate",
        "Improve JavaScript errors",
        "Conclusion"
      ],
      "title": "Quality foundation implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Quality Foundation"
      ],
      "external_id": "91186ed56e33e040c73d1fff940cec0644c199f6",
      "image": "https://docs.newrelic.com/static/9238160720501f4423dff703746fb59d/d9199/cx-what-you-can-measure-nr.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/quality-foundation-implementation-guide/",
      "published_at": "2022-01-12T05:56:50Z",
      "updated_at": "2022-01-12T05:56:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Digital customer experience is your end user’s experience across all your digital touch points. There are four core factors that impact a user’s experience: Availability (Is it reachable?) Performance (Does it perform well enough to be usable?) Content quality (Does it have what users need and can they find it?) Product and content relevance (Does it have what users care about?) Digital customer experience includes web, mobile, and IoT. The first version of this guide is focused on measuring the end user web experience. Quality Foundation is about creating a standard practice to help you understand your digital customer experience in a meaningful way. This implementation guide will help you: Look at customer experience in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about Prioritize what you work on Create a repeatable practice Desired Outcome Improve customer engagement and retention by measuring and improving performance in a way that better aligns to the end user experience. Key Performance Indicators Quality Foundation measures the following KPIs: Availability This KPI measures whether or not your application or its pages can be accessed by your users Goal: Improve uptime and availablity Thresholds: < 99% warning < 95% critical 99% or \"2 9's\" is a good minimum standard of availability, even for employee applications or sub-pages. We configure these default thresholds into the dashboards. You can easily change this to better suit expectations for your application. Largest contentful paint (LCP) Part of Core Web Vitals. Largest Contentful Paint (LCP) measures the time it takes to load the largest image after a user has navigated to a new page. Goal: Reduce LCP to 2.5 seconds or better for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 2.5 seconds Critical: > 4.0 seconds LCP thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. First input delay (FID) Part of Core Web Vitals. Measures the interactivity of a page by tracking the time between user interaction (such as clicking a link or entering text) when the browser begins processing the event. Goal: Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 100 milliseconds Critical: > 300 milliseconds FID thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. Cumulative layout shift (CLS) Part of Core Web Vitals. Measures how much the page layout shifts during render. Goal: Maintain a score of 0.1 or less for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 0.1 score Critical: > 0.25 score CLS thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. Time to first byte (TTFB) This KPI measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. Google considers TTFB secondary to Core Web Vitals. We recommend measuring it for a more complete picture. It can be revealing if you see a change in LCP, because it answers the question as to whether the change occurred server side or client side. Goal: Reduce the time to first byte by improving CDN, network, and service performance. Thresholds: Warning > 0.5 seconds Critical > 1.0 seconds According to Google and Search Engine People, 500 milliseconds is a decent TTFB for pages with dynamic content. You can find mention of these recommendations here. Ajax response times Slow ajax calls can make the user feel as though nothing is happening or the page is broken. If the response time is slow enough, users may even abandon the journey. Goal: Measure and improve ajax response times. Thresholds: Warning > 2 seconds Critical > 2.5 seconds These thresholds come from experience with customers across a variety of industries. HTTP error rate HTTP errors (or HTTP 4xx and 5xx responses) happen when calls to the backend are not successful. Goal: Measure and reduce the HTTP error rate to ensure your customers are able to do what they came to your site to do. Thresholds: Warning < 99% of requests are successful Critical < 97% of requests are successful These thresholds come from experience with customers across a variety of industries. We made the assumption that every ajax request is associated with something the user is trying to achieve and treat it accordingly. Because users will often retry failed actions, we allowed for space between warning and critical thresholds. If the ajax requests being measured are an important part of the user journey, we recommended aiming for higher success rates, such as 99.5% or 99.9%. If the ajax requests are tied to login requests, separate 4xx response codes from 5xx response codes and set a much lower threshold for the 4xx responses. You can look to historical response code rates to determine a reasonable threshold. JavaScript error rate This KPI measures the number of JavaScript errors per page view. Goal: Remove irrelevant JavaScript errors being tracked either by tuning ingest or using filtering. Reduce JavaScript errors that impact customer performance. Thresholds: Warning: > 5% errors per page view Critical: > 10% errors per page view These thresholds come from experience with customers across a variety of industries. For each KPI, we defined thresholds - one for warning, another for critical. You might ask where these values come from or how you can be sure they should apply to your application. Our thresholds are the ones recommended by Google (as with Core Web Vitals) or by us, based on our experience across a large number of customers and applications. If you feel strongly that they should be different, you can adjust them, but you should do this at the organizational level rather than on an application by application basis. Quality Foundation helps you identify where in your application you need to make improvements that will optimize user retention, conversion and satisfaction. It is less about where things are and more about where to get to. It also shows you what you should be measuring going forward. You can use this to define SLOs (in a service level dashboard) and alert on them. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required Installation and Configuration Browser Pro installed in all pages SPA enabled for single page applications Synthetics monitors configured: Ping monitors configured for anonymous users Scripted synthetics check configured for login flow Monitors should be configured to test from all regions applicable to your users Monitors should be configured for each domain and each login flow Data retention for browser events greater than or equal to 2x an average sprint Establish current state Review instrumented pages Validate Browser URL grouping Understand how you will segment your data Import the quality foundation dashboard Capture current performance for each dashboard page Review instrumented pages Review Browser apps and pages to make sure that everything you expect to report back to New Relic is. You can do this by reviewing the Page Views tab in the Browser UI or running the following query: SELECT uniques(pageUrl) from PageView LIMIT MAX Copy You may need to filter out URLs that contain request or customer ID. Validate Browser URL grouping Ensure Browser segments are captured correctly so user experience performance is measurable in both the NewRelic UI as well as at the aggregate level when querying via NRQL. A segment is the text between two / in a URL or between . of a domain name. For example, in the URL website.com/product/widget-name, the segments are: website .com product widget-name When there are a lot of URLs with a lot of segments, URLs can get crushed, so that website.com/product/widget-name becomes website.com/ or website.com/product/. In this example, the first crushed URL is not particularly useful, but the second one may be a useful way of aggregating customer experience data for the product. Not sure whether you need to tune your configuration? Import the Segment Allow List Investigation dashboard in GitHub to help. Once you’ve identified which segments to add, you can add them using Segment allow lists in Browser. Understand how you will segment your data Make Customer Experience data understandable and actionable by breaking it out into different segments. In this case, segments refer to groups of data. It does not refer to sections of URLs, as in segment allow lists. Consider the following statements: Most of our users experience 3 seconds or better to first input delay. On average, we see 2 seconds to the largest contentful paint. Last week, there were 1 million page views. Compared to: Most of the users in the US, Canada, and EMEA experience 2 seconds or better to first input delay. Malaysia and Indonesia users experience 4 seconds; we are looking into this. Customers buying car insurance typically see 1 second to largest contentful paint. For home insurance, it’s 4 seconds. Last week, there were 700,000 page views on mobile browser apps compared to 300,000 on desktop. Let’s make sure we’re optimizing our mobile experience. Typical segmentation involves breaking down user experience into the following categories: Segment Guidance Region/Location Basic: Group by country. Browser events automatically contain the country code of requests, so there is nothing you need to do to break it out further. Advanced: Make regional grouping match regional SLO groups by creating your own region attribute using custom attributes in Browser. Facet by countryCode. Related attributes: regionCode city asnLatitude asnLongitude Device Break out performance and engagement device type so you can understand: Typical breakdown of desktop vs mobile browser users Experience of desktop vs mobile browser users Facet by deviceType. Related attributes: userAgentName userAgentOS userAgentVersion Product/Line of Business In this scenario, a product is a separate line of business or service provided by your organization. Some examples of industries and respective products: An insurance company that sells both car and house insurance A media company that has multiple streaming services or channels A travel company that provides car rental as well as hotel bookings Basic: Break out performance by product by: Faceting on pageUrl: Use this approach when multiple products are grouped into one browser app in New Relic. Faceting by appName: Use this approach when each product is instrumented as a separate web app. Grouping by appName and then facet: Use this approach when there are multiple apps in browser supporting one product. Advanced: Add product offering as a custom attribute to browser pages using custom attributes. Environment During instrumentation or afterwards, follow a naming convention that specifies the environment in Browser. Well named browser apps specify product and/or function as well as environment. Examples: account-management.prod hotels-book.prod car-insurance.uat Using app naming conventions to specify the environment supports filtering data in both the UI and in dashboards. For more information, see the documentation for how to rename Browser apps. Team In some organizations, a single team supports multiple products, while in others, a product is big enough to be supported by multiple teams. Report on team performance against customer experience or engagement by either adding the team name to the Browser app name (for example, account-management.prod.unicorn-squad) or by using custom attributes. Import the quality foundation dashboard This step creates the dashboard that you will use to measure your customer experience and improve it. Clone the GitHub repository. Follow the GitHub repository README instructions to implement the dashboard. Make sure to align the dashboard to lines of business or customer facing offerings rather than teams. This ensures optimization time is spent where it is most impactful. Capture current performance for each dashboard page Follow the GitHub README instructions. Use the dashboard from the previous step to understand the overall performance for each line of business. If relevant, apply filters to see performance across region or device. If values drop below targets and it matters, add it to the sheet as a candidate for improvement. Not worth tracking: A company that sells insurance in the US only notices poor performance in Malaysia. Worth tracking: A company that sells insurance in the US only notices poor performance with respect to mobile users in the US. Improvement Process Plan your work Decide which KPIs to improve Improve targeted KPIs Improve page load performance Improve AJAX response times Improve the AJAX error rate Improve JavaScript errors Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. Decide which KPIs to improve You now know what your user experience looks like across multiple lines of business. Where should you be improving? Start with business priorities. If you have clear business directives or have access to a senior manager above who does, you should focus on what matters most to your organization. For example, let’s say your company has recently launched a new initiative around a line of business but the KPIs associated with the UI are below target. This is where you should focus time initially. Next, focus on KPIs for each line of business. Finally, filter each line of business by device, region, etc., to see if additional focus is needed for specific regions or devices. Improve targeted KPIs To track your progress, create a new dashboard or add a new page to the existing dashboard and name it Quality Foundation KPI Improvement. For more information, see Improve Web Uptime. Improve page load performance Narrow your focus to specific pages that aren’t meeting target KPI values. For each page load KPI result that is out of bounds in the Quality Foundation Dashboard, remove the COMPARE WITH clause and add FACET pageUrl/targetGroupedUrl LIMIT MAX to find which pages are the poor performers. Use targetGroupedUrl when there are many results; for example, when the customer ID is part of the URL. Otherwise, use pageUrl. Original Dashboard query: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' SINCE 1 week AGO COMPARE WITH 1 week AGO Copy New query to identify problem pages: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' FACET targetGroupedUrl LIMIT MAX Copy Once you have identified which pages to improve, improve them following these best practices. Improve AJAX response times Find the slow requests. Go to the Ajax duration widget on the dashboard. View query, then open in query builder. Add facet requestUrl LIMIT MAX to the end of the query. Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - AjaxResponseTimes. Focus improving requests with a timeToSettle > 2.5s. Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve the AJAX error rate Find the failing requests. Go to Dashboards > Query builder. Enter FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND <Ajax Request filter> SINCE 1 week AGO facet pageUrl, appName Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Pages with AjaxErrors. Run the query again for the most problematic pages to find the requests that are failing: FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND pageUrl=<problematic page> AND appName = <corresponding app> <Ajax Request filter> SINCE 1 week AGO facet requestUrl Copy Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve JavaScript errors Find the most common failures. Go to Dashboards > Query builder Enter FROM JavaScriptError SELECT count(errorClass) SINCE 1 week AGO WHERE <PageView filter> FACET transactionName, errorClass, errorMessage, domain Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Javascript Errors. Use this information to figure out which errors need to be addressed Use New Relic’s recommended best practices to resolve errors that need addressing. See JavaScript errors page: Detect and analyze errors. Remove third party errors that do not add value. You may be using a third party JavaScript that is noisy but works as expected. You can take a couple of approaches: Remove the domain name from the JavaScript error/Pageview ratio widget and add it as its own widget so you can see unexpected changes. You can alert on this using Baseline NRQL alerts. Drop the JavaScript error using drop filters. Only use this option if the volume of errors is impacting your data ingest in a significant way. Be as specific as you can in the drop filter. Conclusion Best practices to adopt Revisit performance metrics (shared in this document as Quality Foundation KPIs) at the end of each sprint. Incorporate performance improvements into developer sprints. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Define Customer Experience SLOs. Create alerts for business critical drops in Quality Foundation KPIs. Value Realization At the end of this process you should now: Have an understanding of your end user experience in a way that is tangible, actionable, and easy for engineers as well as the business to understand. Know how releases impact your end customers. Know how your customers are impacted by service, infrastructure, or network level events. See latency issues caused by backend services if they exist. Have created, or be on the path to create, a common language with business owners so you are working together. This can open new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 712.6891,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Quality foundation <em>implementation</em> <em>guide</em>",
        "sections": "Quality foundation <em>implementation</em> <em>guide</em>",
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": " and can they find it?) Product and content relevance (Does it have what users care about?) <em>Digital</em> <em>customer</em> <em>experience</em> includes <em>web</em>, mobile, and IoT. The first version of this <em>guide</em> is focused on measuring the end user <em>web</em> <em>experience</em>. Quality Foundation is about creating a standard practice to help"
      },
      "id": "61461531e7b9d25774b6f22d"
    },
    {
      "sections": [
        "Bottom of the funnel analysis implementation guide",
        "Overview",
        "What if I have performance issues in the middle of the funnel?",
        "Desired outcome",
        "Key performance indicators",
        "Prerequisites",
        "Required knowledge",
        "Required installation and configuration",
        "Establish current state",
        "Identify where the bottom of the funnel starts",
        "Ecommerce user journey",
        "Car insurance purchase user journey",
        "Distinguish between pages and actions",
        "Create a scripted monitor for the bottom of the funnel",
        "Import the Bottom of the Funnel Dashboard",
        "Capture Current Performance",
        "Improvement process",
        "Plan your work",
        "Advanced topics",
        "Conclusion",
        "Best practices going forward",
        "Value realization"
      ],
      "title": "Bottom of the funnel analysis implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Conversions",
        "Funnel",
        "Bottom of the funnel"
      ],
      "external_id": "d1a470e689225e2241cc6946e36f123491bae202",
      "image": "https://docs.newrelic.com/static/26e75075995b4b56b0fc8586ab71c3f9/2bef9/cx-botfa-funnel.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/bofta-implementation-guide/",
      "published_at": "2022-01-12T03:21:30Z",
      "updated_at": "2021-11-25T12:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Bottom of the funnel analysis is about improving conversion by focusing on performance at the end of the user journey. Most sites and apps are built with one or more purposes in mind. If there is a purpose, there is likely to be a user journey. Some examples: Purpose User journey Brand awareness Download a whitepaper Customer support Raise a support ticket Customer services (registration, forms, payments) Make a payment Entertainment Stream a movie Goods Buy clothes and accessories Informational purposes Find a support program in your state Lead generation Join distribution list to get promotions and coupons Outreach Get information about events in your town Services (Travel, rentals, bookings) Book a flight Social media Share a selfie When a user completes a journey, we think of it as a conversion. All conversions have a value - from a few dollars to thousands. The best way to improve the conversion rate is to start at the bottom of the funnel, when the intent to complete the user journey is clear. What if I have performance issues in the middle of the funnel? Any glaring issues with your app or site should be addressed, no matter where they occur. When it comes to optimizing conversion, it's better to start at the bottom of the funnel for two reasons: Higher return on investment. Users at this stage are already more likely to convert. Addressing performance issues here will see an immediate impact on the bottom line. If you have issues at the bottom of the funnel, optimizing earlier stages may not have much of an impact on the conversion rate. Once you've optimized the bottom of the funnel you can use the same techniques to optimize earlier stages of the user journey. Optimizing the top or the middle of the funnel without focusing on the bottom first is a bit like fishing with a holey net. You can get more fish into the net by optimizing when and where you fish but you risk losing all that optimization as soon as you take the net out of the water. Desired outcome Increase revenue by resolving issues that appear when a user attempts to complete an action. Key performance indicators Bottom of the Funnel Analysis measures the following KPIs: KPI Description Goal Bottom of the Funnel Success Rate/Conversion Rate The rate of conversion once a user has gone far enough to demonstrate intent to complete an action to actual completion. Examples of this are rate of: Checkout -> Order submission Insurance form review -> submission Completing sign up details -> submission Increase the rate of conversion by addressing errors and latency at the bottom of the funnel Revenue at Risk due to Latency Value of a conversion * number of pages or interactions in the bottom of the funnel that are slower than the industry threshold. Focus on reducing this value by improving page KPIs Revenue at Risk due to Errors Value of a conversion * number of backend errors in the bottom of the funnel interactions Tune this value to make it meaningful by filtering out errors that aren't visible to the end user. Once this is meaningful, focus on reducing it. Create an alert to notify you if it suddenly trends upward. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required installation and configuration Browser Pro installed in relevant pages SPA enabled for single page applications Data retention for browser events greater than or equal to 2x an average sprint Establish current state Identify where the bottom of the funnel starts Distinguish between pages and actions Create a scripted synthetics monitor for the bottom of the funnel Import the bottom of the funnel dashboard Capture current performance Identify where the bottom of the funnel starts The Bottom of the Funnel is focused on the final steps of a user journey where a user has gone far enough to show intent to complete the journey. Some examples: Ecommerce user journey The user journey is simplified so you can focus on where the bottom of the funnel begins - at checkout. Most users entering the checkout phase plan to purchase something. Reducing errors and latency from this point onward is more likely to improve conversions than focusing on any other part of the funnel. Car insurance purchase user journey In the example above, you have the user’s interest in car insurance as they enter information, but you do not know their intent until they see the quote and continue to proceed. Distinguish between pages and actions The final steps of a user’s journey is likely to be a mix of full page loads and AJAX calls. You will need to know all pages and Ajax requests for the next step. If you are not sure which requests are running from the page in question, you can run: SELECT count(*) FROM AjaxRequest WHERE pageUrl like ‘%FILTER%’ FACET groupedRequestUrl SINCE 1 DAY AGO Copy Create a scripted monitor for the bottom of the funnel Make sure you have a scripted monitor for each path through the bottom of the funnel. The goal is to make sure your bottom of the funnel services are working around the clock. For example, you may have a checkout flow that calls a different payment API depending on the customer’s payment preferences. Import the Bottom of the Funnel Dashboard Follow the instructions documented in the public GitHub README. Capture Current Performance Follow the GitHub repository README instructions. Use the dashboard from the previous step to understand the bottom of the funnel performance. Create a plan to improve KPIs that don’t meet target values as well as reduce revenue at risk. Improvement process Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. For detailed information, see: Improve uptime Improve page load performance Improve AJAX performance Advanced topics Should I apply segmentation? Segmentation (breaking out performance into cohorts, such as region and device type) is a good idea if: Your organization has initiatives tied to addressing a target audience from a particular cohort that you can segment by using either custom attributes or data that is already available in New Relic. You are already familiar with Bottom of the Funnel Analysis and there is a significant enough difference in performance among different cohorts to warrant tracking and/or developer focus. Conclusion Best practices going forward Revisit performance metrics at the end of each sprint. Any time the user journey changes, revisit if the steps at the Bottom of the Funnel are the same. Incorporate changes in developer sprints as needed. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Revisit your Customer Experience SLOs. Do you need to define more ambitious SLOs for the end of the funnel? Create alerts for business critical drops in Quality Foundation KPIs. Value realization At the end of this process you should: Know your user conversion rate and have addressed errors or performance issues that negatively impact it. Increased revenue for your company. Created, or be on the path to create, a common language with business owners so you are working together; opening new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 294.8323,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Bottom of the funnel analysis <em>implementation</em> <em>guide</em>",
        "sections": "Bottom of the funnel analysis <em>implementation</em> <em>guide</em>",
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": " the user journey changes, revisit if the steps at the Bottom of the Funnel are the same. Incorporate changes in developer sprints as needed. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Revisit your <em>Customer</em> <em>Experience</em> SLOs. Do you need to define"
      },
      "id": "61372e1964441f16fa42438e"
    },
    {
      "sections": [
        "Improve web uptime",
        "1. Investigate Synthetics checks",
        "2. Create workloads",
        "3. Investigate outages at lowest tier first"
      ],
      "title": "Improve web uptime",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Uptime",
        "Availability"
      ],
      "external_id": "5893b26accc8f1ebcb41ca1ccd7f50f1a2f4f7d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-web-uptime/",
      "published_at": "2022-01-12T05:56:51Z",
      "updated_at": "2021-09-07T09:17:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Steps to follow to improve web uptime: 1. Investigate Synthetics checks Investigate and resolve failed Synthetics checks when they occur. Check multiple locations. Set up an alert to notify you when multiple locations fail. 2. Create workloads Create workloads that correlate synthetic monitors with browser applications, services, and infrastructure. Include a link to the workload in the alert runbook. You can also find the correlated workload for a synthetic using global search. Make sure that alerts are configured for each tier of your workload. This way you can see the health of each of the tiers in one view. This will save you time in troubleshooting. You do not need to create alert notifications for each tier to benefit from this view. 3. Investigate outages at lowest tier first When an outage occurs, start investigating at the lowest tier that is alerting. For instance, if you see that you have an infrastructure issue and a JavaScript issue, investigate infrastructure prior to javascript unless you have a second person or team you can delegate that to. Use the tools that are available to you for troubleshooting: Make sure that distributed tracing is enabled for browser monitoring as well as APM. Use the Browser UI to help you understand what is happening at the end user tier. Use Lookout to help you understand what’s causing flapping or reoccurring issues.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.77594,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Improve <em>web</em> uptime",
        "sections": "Improve <em>web</em> uptime",
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": "Steps to follow to improve <em>web</em> uptime: 1. Investigate Synthetics checks Investigate and resolve failed Synthetics checks when they occur. Check multiple locations. Set up an alert to notify you when multiple locations fail. 2. Create workloads Create workloads that correlate synthetic monitors"
      },
      "id": "61372e1728ccbcf13b56a862"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-web-uptime": [
    {
      "sections": [
        "Quality foundation implementation guide",
        "Overview",
        "Desired Outcome",
        "Key Performance Indicators",
        "Availability",
        "Largest contentful paint (LCP)",
        "First input delay (FID)",
        "Cumulative layout shift (CLS)",
        "Time to first byte (TTFB)",
        "Ajax response times",
        "HTTP error rate",
        "JavaScript error rate",
        "Prerequisites",
        "Required knowledge",
        "Required Installation and Configuration",
        "Establish current state",
        "Review instrumented pages",
        "Validate Browser URL grouping",
        "Understand how you will segment your data",
        "Import the quality foundation dashboard",
        "Capture current performance for each dashboard page",
        "Improvement Process",
        "Plan your work",
        "Decide which KPIs to improve",
        "Improve targeted KPIs",
        "Improve page load performance",
        "Improve AJAX response times",
        "Improve the AJAX error rate",
        "Improve JavaScript errors",
        "Conclusion"
      ],
      "title": "Quality foundation implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Quality Foundation"
      ],
      "external_id": "91186ed56e33e040c73d1fff940cec0644c199f6",
      "image": "https://docs.newrelic.com/static/9238160720501f4423dff703746fb59d/d9199/cx-what-you-can-measure-nr.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/quality-foundation-implementation-guide/",
      "published_at": "2022-01-12T05:56:50Z",
      "updated_at": "2022-01-12T05:56:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Digital customer experience is your end user’s experience across all your digital touch points. There are four core factors that impact a user’s experience: Availability (Is it reachable?) Performance (Does it perform well enough to be usable?) Content quality (Does it have what users need and can they find it?) Product and content relevance (Does it have what users care about?) Digital customer experience includes web, mobile, and IoT. The first version of this guide is focused on measuring the end user web experience. Quality Foundation is about creating a standard practice to help you understand your digital customer experience in a meaningful way. This implementation guide will help you: Look at customer experience in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about Prioritize what you work on Create a repeatable practice Desired Outcome Improve customer engagement and retention by measuring and improving performance in a way that better aligns to the end user experience. Key Performance Indicators Quality Foundation measures the following KPIs: Availability This KPI measures whether or not your application or its pages can be accessed by your users Goal: Improve uptime and availablity Thresholds: < 99% warning < 95% critical 99% or \"2 9's\" is a good minimum standard of availability, even for employee applications or sub-pages. We configure these default thresholds into the dashboards. You can easily change this to better suit expectations for your application. Largest contentful paint (LCP) Part of Core Web Vitals. Largest Contentful Paint (LCP) measures the time it takes to load the largest image after a user has navigated to a new page. Goal: Reduce LCP to 2.5 seconds or better for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 2.5 seconds Critical: > 4.0 seconds LCP thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. First input delay (FID) Part of Core Web Vitals. Measures the interactivity of a page by tracking the time between user interaction (such as clicking a link or entering text) when the browser begins processing the event. Goal: Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 100 milliseconds Critical: > 300 milliseconds FID thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. Cumulative layout shift (CLS) Part of Core Web Vitals. Measures how much the page layout shifts during render. Goal: Maintain a score of 0.1 or less for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 0.1 score Critical: > 0.25 score CLS thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. Time to first byte (TTFB) This KPI measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. Google considers TTFB secondary to Core Web Vitals. We recommend measuring it for a more complete picture. It can be revealing if you see a change in LCP, because it answers the question as to whether the change occurred server side or client side. Goal: Reduce the time to first byte by improving CDN, network, and service performance. Thresholds: Warning > 0.5 seconds Critical > 1.0 seconds According to Google and Search Engine People, 500 milliseconds is a decent TTFB for pages with dynamic content. You can find mention of these recommendations here. Ajax response times Slow ajax calls can make the user feel as though nothing is happening or the page is broken. If the response time is slow enough, users may even abandon the journey. Goal: Measure and improve ajax response times. Thresholds: Warning > 2 seconds Critical > 2.5 seconds These thresholds come from experience with customers across a variety of industries. HTTP error rate HTTP errors (or HTTP 4xx and 5xx responses) happen when calls to the backend are not successful. Goal: Measure and reduce the HTTP error rate to ensure your customers are able to do what they came to your site to do. Thresholds: Warning < 99% of requests are successful Critical < 97% of requests are successful These thresholds come from experience with customers across a variety of industries. We made the assumption that every ajax request is associated with something the user is trying to achieve and treat it accordingly. Because users will often retry failed actions, we allowed for space between warning and critical thresholds. If the ajax requests being measured are an important part of the user journey, we recommended aiming for higher success rates, such as 99.5% or 99.9%. If the ajax requests are tied to login requests, separate 4xx response codes from 5xx response codes and set a much lower threshold for the 4xx responses. You can look to historical response code rates to determine a reasonable threshold. JavaScript error rate This KPI measures the number of JavaScript errors per page view. Goal: Remove irrelevant JavaScript errors being tracked either by tuning ingest or using filtering. Reduce JavaScript errors that impact customer performance. Thresholds: Warning: > 5% errors per page view Critical: > 10% errors per page view These thresholds come from experience with customers across a variety of industries. For each KPI, we defined thresholds - one for warning, another for critical. You might ask where these values come from or how you can be sure they should apply to your application. Our thresholds are the ones recommended by Google (as with Core Web Vitals) or by us, based on our experience across a large number of customers and applications. If you feel strongly that they should be different, you can adjust them, but you should do this at the organizational level rather than on an application by application basis. Quality Foundation helps you identify where in your application you need to make improvements that will optimize user retention, conversion and satisfaction. It is less about where things are and more about where to get to. It also shows you what you should be measuring going forward. You can use this to define SLOs (in a service level dashboard) and alert on them. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required Installation and Configuration Browser Pro installed in all pages SPA enabled for single page applications Synthetics monitors configured: Ping monitors configured for anonymous users Scripted synthetics check configured for login flow Monitors should be configured to test from all regions applicable to your users Monitors should be configured for each domain and each login flow Data retention for browser events greater than or equal to 2x an average sprint Establish current state Review instrumented pages Validate Browser URL grouping Understand how you will segment your data Import the quality foundation dashboard Capture current performance for each dashboard page Review instrumented pages Review Browser apps and pages to make sure that everything you expect to report back to New Relic is. You can do this by reviewing the Page Views tab in the Browser UI or running the following query: SELECT uniques(pageUrl) from PageView LIMIT MAX Copy You may need to filter out URLs that contain request or customer ID. Validate Browser URL grouping Ensure Browser segments are captured correctly so user experience performance is measurable in both the NewRelic UI as well as at the aggregate level when querying via NRQL. A segment is the text between two / in a URL or between . of a domain name. For example, in the URL website.com/product/widget-name, the segments are: website .com product widget-name When there are a lot of URLs with a lot of segments, URLs can get crushed, so that website.com/product/widget-name becomes website.com/ or website.com/product/. In this example, the first crushed URL is not particularly useful, but the second one may be a useful way of aggregating customer experience data for the product. Not sure whether you need to tune your configuration? Import the Segment Allow List Investigation dashboard in GitHub to help. Once you’ve identified which segments to add, you can add them using Segment allow lists in Browser. Understand how you will segment your data Make Customer Experience data understandable and actionable by breaking it out into different segments. In this case, segments refer to groups of data. It does not refer to sections of URLs, as in segment allow lists. Consider the following statements: Most of our users experience 3 seconds or better to first input delay. On average, we see 2 seconds to the largest contentful paint. Last week, there were 1 million page views. Compared to: Most of the users in the US, Canada, and EMEA experience 2 seconds or better to first input delay. Malaysia and Indonesia users experience 4 seconds; we are looking into this. Customers buying car insurance typically see 1 second to largest contentful paint. For home insurance, it’s 4 seconds. Last week, there were 700,000 page views on mobile browser apps compared to 300,000 on desktop. Let’s make sure we’re optimizing our mobile experience. Typical segmentation involves breaking down user experience into the following categories: Segment Guidance Region/Location Basic: Group by country. Browser events automatically contain the country code of requests, so there is nothing you need to do to break it out further. Advanced: Make regional grouping match regional SLO groups by creating your own region attribute using custom attributes in Browser. Facet by countryCode. Related attributes: regionCode city asnLatitude asnLongitude Device Break out performance and engagement device type so you can understand: Typical breakdown of desktop vs mobile browser users Experience of desktop vs mobile browser users Facet by deviceType. Related attributes: userAgentName userAgentOS userAgentVersion Product/Line of Business In this scenario, a product is a separate line of business or service provided by your organization. Some examples of industries and respective products: An insurance company that sells both car and house insurance A media company that has multiple streaming services or channels A travel company that provides car rental as well as hotel bookings Basic: Break out performance by product by: Faceting on pageUrl: Use this approach when multiple products are grouped into one browser app in New Relic. Faceting by appName: Use this approach when each product is instrumented as a separate web app. Grouping by appName and then facet: Use this approach when there are multiple apps in browser supporting one product. Advanced: Add product offering as a custom attribute to browser pages using custom attributes. Environment During instrumentation or afterwards, follow a naming convention that specifies the environment in Browser. Well named browser apps specify product and/or function as well as environment. Examples: account-management.prod hotels-book.prod car-insurance.uat Using app naming conventions to specify the environment supports filtering data in both the UI and in dashboards. For more information, see the documentation for how to rename Browser apps. Team In some organizations, a single team supports multiple products, while in others, a product is big enough to be supported by multiple teams. Report on team performance against customer experience or engagement by either adding the team name to the Browser app name (for example, account-management.prod.unicorn-squad) or by using custom attributes. Import the quality foundation dashboard This step creates the dashboard that you will use to measure your customer experience and improve it. Clone the GitHub repository. Follow the GitHub repository README instructions to implement the dashboard. Make sure to align the dashboard to lines of business or customer facing offerings rather than teams. This ensures optimization time is spent where it is most impactful. Capture current performance for each dashboard page Follow the GitHub README instructions. Use the dashboard from the previous step to understand the overall performance for each line of business. If relevant, apply filters to see performance across region or device. If values drop below targets and it matters, add it to the sheet as a candidate for improvement. Not worth tracking: A company that sells insurance in the US only notices poor performance in Malaysia. Worth tracking: A company that sells insurance in the US only notices poor performance with respect to mobile users in the US. Improvement Process Plan your work Decide which KPIs to improve Improve targeted KPIs Improve page load performance Improve AJAX response times Improve the AJAX error rate Improve JavaScript errors Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. Decide which KPIs to improve You now know what your user experience looks like across multiple lines of business. Where should you be improving? Start with business priorities. If you have clear business directives or have access to a senior manager above who does, you should focus on what matters most to your organization. For example, let’s say your company has recently launched a new initiative around a line of business but the KPIs associated with the UI are below target. This is where you should focus time initially. Next, focus on KPIs for each line of business. Finally, filter each line of business by device, region, etc., to see if additional focus is needed for specific regions or devices. Improve targeted KPIs To track your progress, create a new dashboard or add a new page to the existing dashboard and name it Quality Foundation KPI Improvement. For more information, see Improve Web Uptime. Improve page load performance Narrow your focus to specific pages that aren’t meeting target KPI values. For each page load KPI result that is out of bounds in the Quality Foundation Dashboard, remove the COMPARE WITH clause and add FACET pageUrl/targetGroupedUrl LIMIT MAX to find which pages are the poor performers. Use targetGroupedUrl when there are many results; for example, when the customer ID is part of the URL. Otherwise, use pageUrl. Original Dashboard query: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' SINCE 1 week AGO COMPARE WITH 1 week AGO Copy New query to identify problem pages: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' FACET targetGroupedUrl LIMIT MAX Copy Once you have identified which pages to improve, improve them following these best practices. Improve AJAX response times Find the slow requests. Go to the Ajax duration widget on the dashboard. View query, then open in query builder. Add facet requestUrl LIMIT MAX to the end of the query. Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - AjaxResponseTimes. Focus improving requests with a timeToSettle > 2.5s. Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve the AJAX error rate Find the failing requests. Go to Dashboards > Query builder. Enter FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND <Ajax Request filter> SINCE 1 week AGO facet pageUrl, appName Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Pages with AjaxErrors. Run the query again for the most problematic pages to find the requests that are failing: FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND pageUrl=<problematic page> AND appName = <corresponding app> <Ajax Request filter> SINCE 1 week AGO facet requestUrl Copy Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve JavaScript errors Find the most common failures. Go to Dashboards > Query builder Enter FROM JavaScriptError SELECT count(errorClass) SINCE 1 week AGO WHERE <PageView filter> FACET transactionName, errorClass, errorMessage, domain Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Javascript Errors. Use this information to figure out which errors need to be addressed Use New Relic’s recommended best practices to resolve errors that need addressing. See JavaScript errors page: Detect and analyze errors. Remove third party errors that do not add value. You may be using a third party JavaScript that is noisy but works as expected. You can take a couple of approaches: Remove the domain name from the JavaScript error/Pageview ratio widget and add it as its own widget so you can see unexpected changes. You can alert on this using Baseline NRQL alerts. Drop the JavaScript error using drop filters. Only use this option if the volume of errors is impacting your data ingest in a significant way. Be as specific as you can in the drop filter. Conclusion Best practices to adopt Revisit performance metrics (shared in this document as Quality Foundation KPIs) at the end of each sprint. Incorporate performance improvements into developer sprints. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Define Customer Experience SLOs. Create alerts for business critical drops in Quality Foundation KPIs. Value Realization At the end of this process you should now: Have an understanding of your end user experience in a way that is tangible, actionable, and easy for engineers as well as the business to understand. Know how releases impact your end customers. Know how your customers are impacted by service, infrastructure, or network level events. See latency issues caused by backend services if they exist. Have created, or be on the path to create, a common language with business owners so you are working together. This can open new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 613.34314,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Quality foundation <em>implementation</em> <em>guide</em>",
        "sections": "Quality foundation <em>implementation</em> <em>guide</em>",
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": " you understand your <em>digital</em> <em>customer</em> <em>experience</em> in a meaningful way. This <em>implementation</em> <em>guide</em> will help you: Look at <em>customer</em> <em>experience</em> in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about Prioritize what"
      },
      "id": "61461531e7b9d25774b6f22d"
    },
    {
      "sections": [
        "Bottom of the funnel analysis implementation guide",
        "Overview",
        "What if I have performance issues in the middle of the funnel?",
        "Desired outcome",
        "Key performance indicators",
        "Prerequisites",
        "Required knowledge",
        "Required installation and configuration",
        "Establish current state",
        "Identify where the bottom of the funnel starts",
        "Ecommerce user journey",
        "Car insurance purchase user journey",
        "Distinguish between pages and actions",
        "Create a scripted monitor for the bottom of the funnel",
        "Import the Bottom of the Funnel Dashboard",
        "Capture Current Performance",
        "Improvement process",
        "Plan your work",
        "Advanced topics",
        "Conclusion",
        "Best practices going forward",
        "Value realization"
      ],
      "title": "Bottom of the funnel analysis implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Conversions",
        "Funnel",
        "Bottom of the funnel"
      ],
      "external_id": "d1a470e689225e2241cc6946e36f123491bae202",
      "image": "https://docs.newrelic.com/static/26e75075995b4b56b0fc8586ab71c3f9/2bef9/cx-botfa-funnel.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/bofta-implementation-guide/",
      "published_at": "2022-01-12T03:21:30Z",
      "updated_at": "2021-11-25T12:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Bottom of the funnel analysis is about improving conversion by focusing on performance at the end of the user journey. Most sites and apps are built with one or more purposes in mind. If there is a purpose, there is likely to be a user journey. Some examples: Purpose User journey Brand awareness Download a whitepaper Customer support Raise a support ticket Customer services (registration, forms, payments) Make a payment Entertainment Stream a movie Goods Buy clothes and accessories Informational purposes Find a support program in your state Lead generation Join distribution list to get promotions and coupons Outreach Get information about events in your town Services (Travel, rentals, bookings) Book a flight Social media Share a selfie When a user completes a journey, we think of it as a conversion. All conversions have a value - from a few dollars to thousands. The best way to improve the conversion rate is to start at the bottom of the funnel, when the intent to complete the user journey is clear. What if I have performance issues in the middle of the funnel? Any glaring issues with your app or site should be addressed, no matter where they occur. When it comes to optimizing conversion, it's better to start at the bottom of the funnel for two reasons: Higher return on investment. Users at this stage are already more likely to convert. Addressing performance issues here will see an immediate impact on the bottom line. If you have issues at the bottom of the funnel, optimizing earlier stages may not have much of an impact on the conversion rate. Once you've optimized the bottom of the funnel you can use the same techniques to optimize earlier stages of the user journey. Optimizing the top or the middle of the funnel without focusing on the bottom first is a bit like fishing with a holey net. You can get more fish into the net by optimizing when and where you fish but you risk losing all that optimization as soon as you take the net out of the water. Desired outcome Increase revenue by resolving issues that appear when a user attempts to complete an action. Key performance indicators Bottom of the Funnel Analysis measures the following KPIs: KPI Description Goal Bottom of the Funnel Success Rate/Conversion Rate The rate of conversion once a user has gone far enough to demonstrate intent to complete an action to actual completion. Examples of this are rate of: Checkout -> Order submission Insurance form review -> submission Completing sign up details -> submission Increase the rate of conversion by addressing errors and latency at the bottom of the funnel Revenue at Risk due to Latency Value of a conversion * number of pages or interactions in the bottom of the funnel that are slower than the industry threshold. Focus on reducing this value by improving page KPIs Revenue at Risk due to Errors Value of a conversion * number of backend errors in the bottom of the funnel interactions Tune this value to make it meaningful by filtering out errors that aren't visible to the end user. Once this is meaningful, focus on reducing it. Create an alert to notify you if it suddenly trends upward. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required installation and configuration Browser Pro installed in relevant pages SPA enabled for single page applications Data retention for browser events greater than or equal to 2x an average sprint Establish current state Identify where the bottom of the funnel starts Distinguish between pages and actions Create a scripted synthetics monitor for the bottom of the funnel Import the bottom of the funnel dashboard Capture current performance Identify where the bottom of the funnel starts The Bottom of the Funnel is focused on the final steps of a user journey where a user has gone far enough to show intent to complete the journey. Some examples: Ecommerce user journey The user journey is simplified so you can focus on where the bottom of the funnel begins - at checkout. Most users entering the checkout phase plan to purchase something. Reducing errors and latency from this point onward is more likely to improve conversions than focusing on any other part of the funnel. Car insurance purchase user journey In the example above, you have the user’s interest in car insurance as they enter information, but you do not know their intent until they see the quote and continue to proceed. Distinguish between pages and actions The final steps of a user’s journey is likely to be a mix of full page loads and AJAX calls. You will need to know all pages and Ajax requests for the next step. If you are not sure which requests are running from the page in question, you can run: SELECT count(*) FROM AjaxRequest WHERE pageUrl like ‘%FILTER%’ FACET groupedRequestUrl SINCE 1 DAY AGO Copy Create a scripted monitor for the bottom of the funnel Make sure you have a scripted monitor for each path through the bottom of the funnel. The goal is to make sure your bottom of the funnel services are working around the clock. For example, you may have a checkout flow that calls a different payment API depending on the customer’s payment preferences. Import the Bottom of the Funnel Dashboard Follow the instructions documented in the public GitHub README. Capture Current Performance Follow the GitHub repository README instructions. Use the dashboard from the previous step to understand the bottom of the funnel performance. Create a plan to improve KPIs that don’t meet target values as well as reduce revenue at risk. Improvement process Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. For detailed information, see: Improve uptime Improve page load performance Improve AJAX performance Advanced topics Should I apply segmentation? Segmentation (breaking out performance into cohorts, such as region and device type) is a good idea if: Your organization has initiatives tied to addressing a target audience from a particular cohort that you can segment by using either custom attributes or data that is already available in New Relic. You are already familiar with Bottom of the Funnel Analysis and there is a significant enough difference in performance among different cohorts to warrant tracking and/or developer focus. Conclusion Best practices going forward Revisit performance metrics at the end of each sprint. Any time the user journey changes, revisit if the steps at the Bottom of the Funnel are the same. Incorporate changes in developer sprints as needed. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Revisit your Customer Experience SLOs. Do you need to define more ambitious SLOs for the end of the funnel? Create alerts for business critical drops in Quality Foundation KPIs. Value realization At the end of this process you should: Know your user conversion rate and have addressed errors or performance issues that negatively impact it. Increased revenue for your company. Created, or be on the path to create, a common language with business owners so you are working together; opening new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.10788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Bottom of the funnel analysis <em>implementation</em> <em>guide</em>",
        "sections": "Bottom of the funnel analysis <em>implementation</em> <em>guide</em>",
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": " the user journey changes, revisit if the steps at the Bottom of the Funnel are the same. Incorporate changes in developer sprints as needed. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Revisit your <em>Customer</em> <em>Experience</em> SLOs. Do you need to define"
      },
      "id": "61372e1964441f16fa42438e"
    },
    {
      "sections": [
        "Improve page load performance",
        "Page Load KPI",
        "Cumulative Layout Shift (CLS)",
        "Largest Contentful Paint (LCP)",
        "First Input Delay (FID)"
      ],
      "title": "Improve page load performance",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Core web vitals",
        "Page load",
        "Page render"
      ],
      "external_id": "a6c3e400d5c99451f900a3edee1fa19149b5f82c",
      "image": "https://docs.newrelic.com/static/a73f684466bda769a52da48dc9a4e4cc/d9199/cx_page_load_render_timings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-page-load/",
      "published_at": "2022-01-12T05:56:02Z",
      "updated_at": "2021-09-07T09:17:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Page load performance measurement continues to evolve. In order to improve the overall performance and user experience, it helps to understand the different metrics and how they relate to each other. Before following the guidance below, narrow your scope to specific pages that you are trying to improve. For maximum impact, focus on pages that are frequently accessed but have a lower than accepted score for the 75th percentile of users. Page Load KPI How to improve time to first byte (TTFB): Time to first byte measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. If users in the 75th percentile are experiencing a TTFB of greater than 0.5s for one or more of your pages, you can break timings down further by querying the following attributes in PageView: backendDuration connectionSetupDuration dnsLookupDuration networkDuration Frequently slowness prior to rendering is caused by slowness in the backend, either from third party APIs or backend applications. Synthetics monitoring for third party APIs helps operations and development teams understand when the root cause is outside of their control. Even if you cannot control the code, you can influence the outcome by sharing synthetics results with the third party to help them understand what your customers are experiencing. If the backend applications are owned by you or your team, you can use APM agents, Pixie, or OpenTelemetry to understand and manage performance. To make cross team communication easier, we recommend implementing Service Level Management boundaries. Cumulative Layout Shift (CLS) Cumulative layout shift is a score that indicates how much content shifts once it has already loaded. General tips and tricks for improving CLS: Specify dimensions for stylesheets and let the browser’s default CSS control the aspect ratio. Statically reserve space for ad slots. Avoid ads near the top of the viewport. Avoid inserting new content above existing content. Precompute sufficient space for embeds. Additional resources: Google’s approach to CLS optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS. Largest Contentful Paint (LCP) Largest contentful paint measures the difference between the start of page render until the time to paint the largest content element. Common causes for a slow lcp, according to web.dev: Slow server response times Render-blocking JavaScript and CSS Slow resource load times Client-side rendering Use Browser session trace information to understand which of the common causes above factor into the particular page you are trying to optimize. Approaches to improve LCP: Making use of CDNs and paying attention to caching and edge server performance Establishing third party connections early Delaying non-critical Javascript and CSS Additional resources: Google’s approach to LCP optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS. First Input Delay (FID) First input delay is the time between when a user first interacts with a page to the time when the browser is able to respond. It’s a field metric that varies based on real user behavior (results vary based on user impatience and action timing) but can be optimized by reducing TBT, total blocking time. To do this, you need to: Break up long blocking tasks. Optimize bloated JavaScript. Look at moving logic server side and/or use web workers to run threads in the background. Use Browser session trace information to understand where your blocking intervals are occurring and for how long they last. Additional resources: Google’s approach to FID optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.4068,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": "Page load performance measurement continues to evolve. In order to improve the overall performance and user <em>experience</em>, it helps to understand the different metrics and how they relate to each other. Before following the guidance below, narrow your scope to specific pages that you are trying"
      },
      "id": "61372e19196a67f4814948d7"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/customer-experience/quality-foundation-implementation-guide": [
    {
      "sections": [
        "Bottom of the funnel analysis implementation guide",
        "Overview",
        "What if I have performance issues in the middle of the funnel?",
        "Desired outcome",
        "Key performance indicators",
        "Prerequisites",
        "Required knowledge",
        "Required installation and configuration",
        "Establish current state",
        "Identify where the bottom of the funnel starts",
        "Ecommerce user journey",
        "Car insurance purchase user journey",
        "Distinguish between pages and actions",
        "Create a scripted monitor for the bottom of the funnel",
        "Import the Bottom of the Funnel Dashboard",
        "Capture Current Performance",
        "Improvement process",
        "Plan your work",
        "Advanced topics",
        "Conclusion",
        "Best practices going forward",
        "Value realization"
      ],
      "title": "Bottom of the funnel analysis implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Conversions",
        "Funnel",
        "Bottom of the funnel"
      ],
      "external_id": "d1a470e689225e2241cc6946e36f123491bae202",
      "image": "https://docs.newrelic.com/static/26e75075995b4b56b0fc8586ab71c3f9/2bef9/cx-botfa-funnel.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/bofta-implementation-guide/",
      "published_at": "2022-01-12T03:21:30Z",
      "updated_at": "2021-11-25T12:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Bottom of the funnel analysis is about improving conversion by focusing on performance at the end of the user journey. Most sites and apps are built with one or more purposes in mind. If there is a purpose, there is likely to be a user journey. Some examples: Purpose User journey Brand awareness Download a whitepaper Customer support Raise a support ticket Customer services (registration, forms, payments) Make a payment Entertainment Stream a movie Goods Buy clothes and accessories Informational purposes Find a support program in your state Lead generation Join distribution list to get promotions and coupons Outreach Get information about events in your town Services (Travel, rentals, bookings) Book a flight Social media Share a selfie When a user completes a journey, we think of it as a conversion. All conversions have a value - from a few dollars to thousands. The best way to improve the conversion rate is to start at the bottom of the funnel, when the intent to complete the user journey is clear. What if I have performance issues in the middle of the funnel? Any glaring issues with your app or site should be addressed, no matter where they occur. When it comes to optimizing conversion, it's better to start at the bottom of the funnel for two reasons: Higher return on investment. Users at this stage are already more likely to convert. Addressing performance issues here will see an immediate impact on the bottom line. If you have issues at the bottom of the funnel, optimizing earlier stages may not have much of an impact on the conversion rate. Once you've optimized the bottom of the funnel you can use the same techniques to optimize earlier stages of the user journey. Optimizing the top or the middle of the funnel without focusing on the bottom first is a bit like fishing with a holey net. You can get more fish into the net by optimizing when and where you fish but you risk losing all that optimization as soon as you take the net out of the water. Desired outcome Increase revenue by resolving issues that appear when a user attempts to complete an action. Key performance indicators Bottom of the Funnel Analysis measures the following KPIs: KPI Description Goal Bottom of the Funnel Success Rate/Conversion Rate The rate of conversion once a user has gone far enough to demonstrate intent to complete an action to actual completion. Examples of this are rate of: Checkout -> Order submission Insurance form review -> submission Completing sign up details -> submission Increase the rate of conversion by addressing errors and latency at the bottom of the funnel Revenue at Risk due to Latency Value of a conversion * number of pages or interactions in the bottom of the funnel that are slower than the industry threshold. Focus on reducing this value by improving page KPIs Revenue at Risk due to Errors Value of a conversion * number of backend errors in the bottom of the funnel interactions Tune this value to make it meaningful by filtering out errors that aren't visible to the end user. Once this is meaningful, focus on reducing it. Create an alert to notify you if it suddenly trends upward. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required installation and configuration Browser Pro installed in relevant pages SPA enabled for single page applications Data retention for browser events greater than or equal to 2x an average sprint Establish current state Identify where the bottom of the funnel starts Distinguish between pages and actions Create a scripted synthetics monitor for the bottom of the funnel Import the bottom of the funnel dashboard Capture current performance Identify where the bottom of the funnel starts The Bottom of the Funnel is focused on the final steps of a user journey where a user has gone far enough to show intent to complete the journey. Some examples: Ecommerce user journey The user journey is simplified so you can focus on where the bottom of the funnel begins - at checkout. Most users entering the checkout phase plan to purchase something. Reducing errors and latency from this point onward is more likely to improve conversions than focusing on any other part of the funnel. Car insurance purchase user journey In the example above, you have the user’s interest in car insurance as they enter information, but you do not know their intent until they see the quote and continue to proceed. Distinguish between pages and actions The final steps of a user’s journey is likely to be a mix of full page loads and AJAX calls. You will need to know all pages and Ajax requests for the next step. If you are not sure which requests are running from the page in question, you can run: SELECT count(*) FROM AjaxRequest WHERE pageUrl like ‘%FILTER%’ FACET groupedRequestUrl SINCE 1 DAY AGO Copy Create a scripted monitor for the bottom of the funnel Make sure you have a scripted monitor for each path through the bottom of the funnel. The goal is to make sure your bottom of the funnel services are working around the clock. For example, you may have a checkout flow that calls a different payment API depending on the customer’s payment preferences. Import the Bottom of the Funnel Dashboard Follow the instructions documented in the public GitHub README. Capture Current Performance Follow the GitHub repository README instructions. Use the dashboard from the previous step to understand the bottom of the funnel performance. Create a plan to improve KPIs that don’t meet target values as well as reduce revenue at risk. Improvement process Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. For detailed information, see: Improve uptime Improve page load performance Improve AJAX performance Advanced topics Should I apply segmentation? Segmentation (breaking out performance into cohorts, such as region and device type) is a good idea if: Your organization has initiatives tied to addressing a target audience from a particular cohort that you can segment by using either custom attributes or data that is already available in New Relic. You are already familiar with Bottom of the Funnel Analysis and there is a significant enough difference in performance among different cohorts to warrant tracking and/or developer focus. Conclusion Best practices going forward Revisit performance metrics at the end of each sprint. Any time the user journey changes, revisit if the steps at the Bottom of the Funnel are the same. Incorporate changes in developer sprints as needed. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Revisit your Customer Experience SLOs. Do you need to define more ambitious SLOs for the end of the funnel? Create alerts for business critical drops in Quality Foundation KPIs. Value realization At the end of this process you should: Know your user conversion rate and have addressed errors or performance issues that negatively impact it. Increased revenue for your company. Created, or be on the path to create, a common language with business owners so you are working together; opening new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.43054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Bottom of the funnel analysis <em>implementation</em> <em>guide</em>",
        "sections": "Bottom of the funnel analysis <em>implementation</em> <em>guide</em>",
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": " the user journey changes, revisit if the steps at the Bottom of the Funnel are the same. Incorporate changes in developer sprints as needed. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Revisit your <em>Customer</em> <em>Experience</em> SLOs. Do you need to define"
      },
      "id": "61372e1964441f16fa42438e"
    },
    {
      "sections": [
        "Improve web uptime",
        "1. Investigate Synthetics checks",
        "2. Create workloads",
        "3. Investigate outages at lowest tier first"
      ],
      "title": "Improve web uptime",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Uptime",
        "Availability"
      ],
      "external_id": "5893b26accc8f1ebcb41ca1ccd7f50f1a2f4f7d5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-web-uptime/",
      "published_at": "2022-01-12T05:56:51Z",
      "updated_at": "2021-09-07T09:17:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Steps to follow to improve web uptime: 1. Investigate Synthetics checks Investigate and resolve failed Synthetics checks when they occur. Check multiple locations. Set up an alert to notify you when multiple locations fail. 2. Create workloads Create workloads that correlate synthetic monitors with browser applications, services, and infrastructure. Include a link to the workload in the alert runbook. You can also find the correlated workload for a synthetic using global search. Make sure that alerts are configured for each tier of your workload. This way you can see the health of each of the tiers in one view. This will save you time in troubleshooting. You do not need to create alert notifications for each tier to benefit from this view. 3. Investigate outages at lowest tier first When an outage occurs, start investigating at the lowest tier that is alerting. For instance, if you see that you have an infrastructure issue and a JavaScript issue, investigate infrastructure prior to javascript unless you have a second person or team you can delegate that to. Use the tools that are available to you for troubleshooting: Make sure that distributed tracing is enabled for browser monitoring as well as APM. Use the Browser UI to help you understand what is happening at the end user tier. Use Lookout to help you understand what’s causing flapping or reoccurring issues.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.68546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>"
      },
      "id": "61372e1728ccbcf13b56a862"
    },
    {
      "sections": [
        "Improve page load performance",
        "Page Load KPI",
        "Cumulative Layout Shift (CLS)",
        "Largest Contentful Paint (LCP)",
        "First Input Delay (FID)"
      ],
      "title": "Improve page load performance",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Core web vitals",
        "Page load",
        "Page render"
      ],
      "external_id": "a6c3e400d5c99451f900a3edee1fa19149b5f82c",
      "image": "https://docs.newrelic.com/static/a73f684466bda769a52da48dc9a4e4cc/d9199/cx_page_load_render_timings.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/cx-improve-page-load/",
      "published_at": "2022-01-12T05:56:02Z",
      "updated_at": "2021-09-07T09:17:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Page load performance measurement continues to evolve. In order to improve the overall performance and user experience, it helps to understand the different metrics and how they relate to each other. Before following the guidance below, narrow your scope to specific pages that you are trying to improve. For maximum impact, focus on pages that are frequently accessed but have a lower than accepted score for the 75th percentile of users. Page Load KPI How to improve time to first byte (TTFB): Time to first byte measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. If users in the 75th percentile are experiencing a TTFB of greater than 0.5s for one or more of your pages, you can break timings down further by querying the following attributes in PageView: backendDuration connectionSetupDuration dnsLookupDuration networkDuration Frequently slowness prior to rendering is caused by slowness in the backend, either from third party APIs or backend applications. Synthetics monitoring for third party APIs helps operations and development teams understand when the root cause is outside of their control. Even if you cannot control the code, you can influence the outcome by sharing synthetics results with the third party to help them understand what your customers are experiencing. If the backend applications are owned by you or your team, you can use APM agents, Pixie, or OpenTelemetry to understand and manage performance. To make cross team communication easier, we recommend implementing Service Level Management boundaries. Cumulative Layout Shift (CLS) Cumulative layout shift is a score that indicates how much content shifts once it has already loaded. General tips and tricks for improving CLS: Specify dimensions for stylesheets and let the browser’s default CSS control the aspect ratio. Statically reserve space for ad slots. Avoid ads near the top of the viewport. Avoid inserting new content above existing content. Precompute sufficient space for embeds. Additional resources: Google’s approach to CLS optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS. Largest Contentful Paint (LCP) Largest contentful paint measures the difference between the start of page render until the time to paint the largest content element. Common causes for a slow lcp, according to web.dev: Slow server response times Render-blocking JavaScript and CSS Slow resource load times Client-side rendering Use Browser session trace information to understand which of the common causes above factor into the particular page you are trying to optimize. Approaches to improve LCP: Making use of CDNs and paying attention to caching and edge server performance Establishing third party connections early Delaying non-critical Javascript and CSS Additional resources: Google’s approach to LCP optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS. First Input Delay (FID) First input delay is the time between when a user first interacts with a page to the time when the browser is able to respond. It’s a field metric that varies based on real user behavior (results vary based on user impatience and action timing) but can be optimized by reducing TBT, total blocking time. To do this, you need to: Break up long blocking tasks. Optimize bloated JavaScript. Look at moving logic server side and/or use web workers to run threads in the background. Use Browser session trace information to understand where your blocking intervals are occurring and for how long they last. Additional resources: Google’s approach to FID optimization Lighthouse is a tool by Google that runs a synthetic test against a specific page and provides a list of recommendations that include how to optimize CLS.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.68546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Digital</em> <em>customer</em> <em>experience</em>",
        "body": "Page load performance measurement continues to evolve. In order to improve the overall performance and user <em>experience</em>, it helps to understand the different metrics and how they relate to each other. Before following the guidance below, narrow your scope to specific pages that you are trying"
      },
      "id": "61372e19196a67f4814948d7"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/introduction": [
    {
      "sections": [
        "Quality foundation implementation guide",
        "Overview",
        "Desired Outcome",
        "Key Performance Indicators",
        "Availability",
        "Largest contentful paint (LCP)",
        "First input delay (FID)",
        "Cumulative layout shift (CLS)",
        "Time to first byte (TTFB)",
        "Ajax response times",
        "HTTP error rate",
        "JavaScript error rate",
        "Prerequisites",
        "Required knowledge",
        "Required Installation and Configuration",
        "Establish current state",
        "Review instrumented pages",
        "Validate Browser URL grouping",
        "Understand how you will segment your data",
        "Import the quality foundation dashboard",
        "Capture current performance for each dashboard page",
        "Improvement Process",
        "Plan your work",
        "Decide which KPIs to improve",
        "Improve targeted KPIs",
        "Improve page load performance",
        "Improve AJAX response times",
        "Improve the AJAX error rate",
        "Improve JavaScript errors",
        "Conclusion"
      ],
      "title": "Quality foundation implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Quality Foundation"
      ],
      "external_id": "91186ed56e33e040c73d1fff940cec0644c199f6",
      "image": "https://docs.newrelic.com/static/9238160720501f4423dff703746fb59d/d9199/cx-what-you-can-measure-nr.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/quality-foundation-implementation-guide/",
      "published_at": "2022-01-12T05:56:50Z",
      "updated_at": "2022-01-12T05:56:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Digital customer experience is your end user’s experience across all your digital touch points. There are four core factors that impact a user’s experience: Availability (Is it reachable?) Performance (Does it perform well enough to be usable?) Content quality (Does it have what users need and can they find it?) Product and content relevance (Does it have what users care about?) Digital customer experience includes web, mobile, and IoT. The first version of this guide is focused on measuring the end user web experience. Quality Foundation is about creating a standard practice to help you understand your digital customer experience in a meaningful way. This implementation guide will help you: Look at customer experience in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about Prioritize what you work on Create a repeatable practice Desired Outcome Improve customer engagement and retention by measuring and improving performance in a way that better aligns to the end user experience. Key Performance Indicators Quality Foundation measures the following KPIs: Availability This KPI measures whether or not your application or its pages can be accessed by your users Goal: Improve uptime and availablity Thresholds: < 99% warning < 95% critical 99% or \"2 9's\" is a good minimum standard of availability, even for employee applications or sub-pages. We configure these default thresholds into the dashboards. You can easily change this to better suit expectations for your application. Largest contentful paint (LCP) Part of Core Web Vitals. Largest Contentful Paint (LCP) measures the time it takes to load the largest image after a user has navigated to a new page. Goal: Reduce LCP to 2.5 seconds or better for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 2.5 seconds Critical: > 4.0 seconds LCP thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. First input delay (FID) Part of Core Web Vitals. Measures the interactivity of a page by tracking the time between user interaction (such as clicking a link or entering text) when the browser begins processing the event. Goal: Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 100 milliseconds Critical: > 300 milliseconds FID thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. Cumulative layout shift (CLS) Part of Core Web Vitals. Measures how much the page layout shifts during render. Goal: Maintain a score of 0.1 or less for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 0.1 score Critical: > 0.25 score CLS thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. Time to first byte (TTFB) This KPI measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. Google considers TTFB secondary to Core Web Vitals. We recommend measuring it for a more complete picture. It can be revealing if you see a change in LCP, because it answers the question as to whether the change occurred server side or client side. Goal: Reduce the time to first byte by improving CDN, network, and service performance. Thresholds: Warning > 0.5 seconds Critical > 1.0 seconds According to Google and Search Engine People, 500 milliseconds is a decent TTFB for pages with dynamic content. You can find mention of these recommendations here. Ajax response times Slow ajax calls can make the user feel as though nothing is happening or the page is broken. If the response time is slow enough, users may even abandon the journey. Goal: Measure and improve ajax response times. Thresholds: Warning > 2 seconds Critical > 2.5 seconds These thresholds come from experience with customers across a variety of industries. HTTP error rate HTTP errors (or HTTP 4xx and 5xx responses) happen when calls to the backend are not successful. Goal: Measure and reduce the HTTP error rate to ensure your customers are able to do what they came to your site to do. Thresholds: Warning < 99% of requests are successful Critical < 97% of requests are successful These thresholds come from experience with customers across a variety of industries. We made the assumption that every ajax request is associated with something the user is trying to achieve and treat it accordingly. Because users will often retry failed actions, we allowed for space between warning and critical thresholds. If the ajax requests being measured are an important part of the user journey, we recommended aiming for higher success rates, such as 99.5% or 99.9%. If the ajax requests are tied to login requests, separate 4xx response codes from 5xx response codes and set a much lower threshold for the 4xx responses. You can look to historical response code rates to determine a reasonable threshold. JavaScript error rate This KPI measures the number of JavaScript errors per page view. Goal: Remove irrelevant JavaScript errors being tracked either by tuning ingest or using filtering. Reduce JavaScript errors that impact customer performance. Thresholds: Warning: > 5% errors per page view Critical: > 10% errors per page view These thresholds come from experience with customers across a variety of industries. For each KPI, we defined thresholds - one for warning, another for critical. You might ask where these values come from or how you can be sure they should apply to your application. Our thresholds are the ones recommended by Google (as with Core Web Vitals) or by us, based on our experience across a large number of customers and applications. If you feel strongly that they should be different, you can adjust them, but you should do this at the organizational level rather than on an application by application basis. Quality Foundation helps you identify where in your application you need to make improvements that will optimize user retention, conversion and satisfaction. It is less about where things are and more about where to get to. It also shows you what you should be measuring going forward. You can use this to define SLOs (in a service level dashboard) and alert on them. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required Installation and Configuration Browser Pro installed in all pages SPA enabled for single page applications Synthetics monitors configured: Ping monitors configured for anonymous users Scripted synthetics check configured for login flow Monitors should be configured to test from all regions applicable to your users Monitors should be configured for each domain and each login flow Data retention for browser events greater than or equal to 2x an average sprint Establish current state Review instrumented pages Validate Browser URL grouping Understand how you will segment your data Import the quality foundation dashboard Capture current performance for each dashboard page Review instrumented pages Review Browser apps and pages to make sure that everything you expect to report back to New Relic is. You can do this by reviewing the Page Views tab in the Browser UI or running the following query: SELECT uniques(pageUrl) from PageView LIMIT MAX Copy You may need to filter out URLs that contain request or customer ID. Validate Browser URL grouping Ensure Browser segments are captured correctly so user experience performance is measurable in both the NewRelic UI as well as at the aggregate level when querying via NRQL. A segment is the text between two / in a URL or between . of a domain name. For example, in the URL website.com/product/widget-name, the segments are: website .com product widget-name When there are a lot of URLs with a lot of segments, URLs can get crushed, so that website.com/product/widget-name becomes website.com/ or website.com/product/. In this example, the first crushed URL is not particularly useful, but the second one may be a useful way of aggregating customer experience data for the product. Not sure whether you need to tune your configuration? Import the Segment Allow List Investigation dashboard in GitHub to help. Once you’ve identified which segments to add, you can add them using Segment allow lists in Browser. Understand how you will segment your data Make Customer Experience data understandable and actionable by breaking it out into different segments. In this case, segments refer to groups of data. It does not refer to sections of URLs, as in segment allow lists. Consider the following statements: Most of our users experience 3 seconds or better to first input delay. On average, we see 2 seconds to the largest contentful paint. Last week, there were 1 million page views. Compared to: Most of the users in the US, Canada, and EMEA experience 2 seconds or better to first input delay. Malaysia and Indonesia users experience 4 seconds; we are looking into this. Customers buying car insurance typically see 1 second to largest contentful paint. For home insurance, it’s 4 seconds. Last week, there were 700,000 page views on mobile browser apps compared to 300,000 on desktop. Let’s make sure we’re optimizing our mobile experience. Typical segmentation involves breaking down user experience into the following categories: Segment Guidance Region/Location Basic: Group by country. Browser events automatically contain the country code of requests, so there is nothing you need to do to break it out further. Advanced: Make regional grouping match regional SLO groups by creating your own region attribute using custom attributes in Browser. Facet by countryCode. Related attributes: regionCode city asnLatitude asnLongitude Device Break out performance and engagement device type so you can understand: Typical breakdown of desktop vs mobile browser users Experience of desktop vs mobile browser users Facet by deviceType. Related attributes: userAgentName userAgentOS userAgentVersion Product/Line of Business In this scenario, a product is a separate line of business or service provided by your organization. Some examples of industries and respective products: An insurance company that sells both car and house insurance A media company that has multiple streaming services or channels A travel company that provides car rental as well as hotel bookings Basic: Break out performance by product by: Faceting on pageUrl: Use this approach when multiple products are grouped into one browser app in New Relic. Faceting by appName: Use this approach when each product is instrumented as a separate web app. Grouping by appName and then facet: Use this approach when there are multiple apps in browser supporting one product. Advanced: Add product offering as a custom attribute to browser pages using custom attributes. Environment During instrumentation or afterwards, follow a naming convention that specifies the environment in Browser. Well named browser apps specify product and/or function as well as environment. Examples: account-management.prod hotels-book.prod car-insurance.uat Using app naming conventions to specify the environment supports filtering data in both the UI and in dashboards. For more information, see the documentation for how to rename Browser apps. Team In some organizations, a single team supports multiple products, while in others, a product is big enough to be supported by multiple teams. Report on team performance against customer experience or engagement by either adding the team name to the Browser app name (for example, account-management.prod.unicorn-squad) or by using custom attributes. Import the quality foundation dashboard This step creates the dashboard that you will use to measure your customer experience and improve it. Clone the GitHub repository. Follow the GitHub repository README instructions to implement the dashboard. Make sure to align the dashboard to lines of business or customer facing offerings rather than teams. This ensures optimization time is spent where it is most impactful. Capture current performance for each dashboard page Follow the GitHub README instructions. Use the dashboard from the previous step to understand the overall performance for each line of business. If relevant, apply filters to see performance across region or device. If values drop below targets and it matters, add it to the sheet as a candidate for improvement. Not worth tracking: A company that sells insurance in the US only notices poor performance in Malaysia. Worth tracking: A company that sells insurance in the US only notices poor performance with respect to mobile users in the US. Improvement Process Plan your work Decide which KPIs to improve Improve targeted KPIs Improve page load performance Improve AJAX response times Improve the AJAX error rate Improve JavaScript errors Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. Decide which KPIs to improve You now know what your user experience looks like across multiple lines of business. Where should you be improving? Start with business priorities. If you have clear business directives or have access to a senior manager above who does, you should focus on what matters most to your organization. For example, let’s say your company has recently launched a new initiative around a line of business but the KPIs associated with the UI are below target. This is where you should focus time initially. Next, focus on KPIs for each line of business. Finally, filter each line of business by device, region, etc., to see if additional focus is needed for specific regions or devices. Improve targeted KPIs To track your progress, create a new dashboard or add a new page to the existing dashboard and name it Quality Foundation KPI Improvement. For more information, see Improve Web Uptime. Improve page load performance Narrow your focus to specific pages that aren’t meeting target KPI values. For each page load KPI result that is out of bounds in the Quality Foundation Dashboard, remove the COMPARE WITH clause and add FACET pageUrl/targetGroupedUrl LIMIT MAX to find which pages are the poor performers. Use targetGroupedUrl when there are many results; for example, when the customer ID is part of the URL. Otherwise, use pageUrl. Original Dashboard query: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' SINCE 1 week AGO COMPARE WITH 1 week AGO Copy New query to identify problem pages: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' FACET targetGroupedUrl LIMIT MAX Copy Once you have identified which pages to improve, improve them following these best practices. Improve AJAX response times Find the slow requests. Go to the Ajax duration widget on the dashboard. View query, then open in query builder. Add facet requestUrl LIMIT MAX to the end of the query. Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - AjaxResponseTimes. Focus improving requests with a timeToSettle > 2.5s. Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve the AJAX error rate Find the failing requests. Go to Dashboards > Query builder. Enter FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND <Ajax Request filter> SINCE 1 week AGO facet pageUrl, appName Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Pages with AjaxErrors. Run the query again for the most problematic pages to find the requests that are failing: FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND pageUrl=<problematic page> AND appName = <corresponding app> <Ajax Request filter> SINCE 1 week AGO facet requestUrl Copy Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve JavaScript errors Find the most common failures. Go to Dashboards > Query builder Enter FROM JavaScriptError SELECT count(errorClass) SINCE 1 week AGO WHERE <PageView filter> FACET transactionName, errorClass, errorMessage, domain Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Javascript Errors. Use this information to figure out which errors need to be addressed Use New Relic’s recommended best practices to resolve errors that need addressing. See JavaScript errors page: Detect and analyze errors. Remove third party errors that do not add value. You may be using a third party JavaScript that is noisy but works as expected. You can take a couple of approaches: Remove the domain name from the JavaScript error/Pageview ratio widget and add it as its own widget so you can see unexpected changes. You can alert on this using Baseline NRQL alerts. Drop the JavaScript error using drop filters. Only use this option if the volume of errors is impacting your data ingest in a significant way. Be as specific as you can in the drop filter. Conclusion Best practices to adopt Revisit performance metrics (shared in this document as Quality Foundation KPIs) at the end of each sprint. Incorporate performance improvements into developer sprints. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Define Customer Experience SLOs. Create alerts for business critical drops in Quality Foundation KPIs. Value Realization At the end of this process you should now: Have an understanding of your end user experience in a way that is tangible, actionable, and easy for engineers as well as the business to understand. Know how releases impact your end customers. Know how your customers are impacted by service, infrastructure, or network level events. See latency issues caused by backend services if they exist. Have created, or be on the path to create, a common language with business owners so you are working together. This can open new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.6847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Key <em>Performance</em> Indicators",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": "Overview Digital <em>customer</em> <em>experience</em> is your end user’s <em>experience</em> across all your digital touch points. There are four core factors that impact a user’s <em>experience</em>: Availability (Is it reachable?) <em>Performance</em> (Does it <em>perform</em> well enough to be usable?) Content quality (Does it have what users need"
      },
      "id": "61461531e7b9d25774b6f22d"
    },
    {
      "sections": [
        "Service level management use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Service response time",
        "Service quality",
        "Service level objective attainment",
        "Service uptime",
        "Prerequisites",
        "Establish current state",
        "Determine in-scope services",
        "Identify service boundaries",
        "Deploy instrumentation",
        "Perform SLM educational workshops",
        "Analyze KPIs and set baseline SLOs",
        "Establish or optimize alerting",
        "Build problem resolution workflows",
        "Execute continuous improvement review",
        "Next steps",
        "Value realization",
        "Additional resources"
      ],
      "title": "Service level management use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Uptime, performance, and reliability",
        "Service level management",
        "Implementation guide"
      ],
      "external_id": "e3c4da80186b6d33a301db4a15c0b0cff2034131",
      "image": "https://docs.newrelic.com/static/e2478328e46923877c6dd58993aecf5f/d9199/nrSLMServiceMap.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/slm-implementation-guide/",
      "published_at": "2022-01-12T05:57:34Z",
      "updated_at": "2021-11-25T05:19:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview IT Operations is expected to provide services that meet the business’s requirements for performance and reliability. However, many ops teams attempt to measure performance and reliability using legacy methods, like measuring resource consumption. That, in turn, requires that they create complex dashboards of granular metrics which they then try to correlate with application performance and reliability. These complex dashboards require subject matter experts to interpret the results for business stakeholders. Legacy methods create barriers to understanding what a good system state looks like and how bad system states impact the business. Essentially, IT ends up not sharing a common metric vocabulary with the business. This fundamental disconnect will result in the perception that IT is not able to deliver the services that the business requires, with all the implications and impacts that perception carries. Service Level Management (SLM) eliminates that disconnect by better explaining the overall performance of a system in terms that are easily understood by both IT and the business. The intent is to show whether or not the system is meeting its performance and reliability expectations, and if it is trending toward or away from improvement, so proactive steps can be taken. The end goal is that systems are better oriented toward desired business outcomes with IT’s attention focused on issues in areas with the highest business impact. You are a good candidate for SLM if any of the following are true: The business impact of performance and reliability issues are not well understood by all stakeholders. Your MTTx is too high. You are collecting many resource consumption metrics (such as CPU, disk, or memory) or are maintaining many metric correlation rules in order to identify system problems. You can’t see the value of your observability tool(s). Desired outcome Service Level Management’s overall goal is to easily measure and communicate the overall health, performance, and quality of your digital products and services to all stakeholders. By implementing SLM at key output points in your systems, you will have a simpler and more responsive observability practice, tighter alignment with the business, and faster paths to improvement. The SLM process described in this guide will help you to identify the points in your systems where you should measure the key performance metrics of service performance and quality. It will also define and drive a simpler alerting strategy, continuous improvement methodologies, and improved problem resolution workflows. Key performance indicators You will use the SLM process to collect and measure the following KPIs, often referred to as the “Golden Signals”: Service response time Service response time measures the amount of time a service requires to process a transaction. It starts when a transaction request is received by the service and ends when the response is sent. Goal: Reduce transaction response time. Best practices: Measure response time at service boundaries. Use continuous improvement processes to drive down response times. Ensure that non-business transactions (such as health checks) are not included or measured. Map this KPI back to business impact. Report KPIs to all stakeholders. Service quality Service quality is the number of transactions that result in an unhandled error. Typically, these are transactions whose HTTP response code is greater than or equal to 400. Goal: Reduce the number of unhandled errors. Best practices: Measure error rates at service boundaries. Continually identify and remediate sources of high error volumes. Map this KPI back to business impact. Report KPIs to all stakeholders. Service level objective attainment SLO attainment is the percentage of time a business service is meeting its response time and quality goals. Goal: Improve response time and quality to ensure high SLO attainment. Best practices: Use continuous improvement processes to maintain / improve SLO attainment. Map this KPI back to business impact. Report KPIs to all stakeholders. Service uptime Service uptime is the percentage of time a service can be reached by at least one client. Typically this is measured using synthetic transactions from representative remote locations. Goal: Use continuous improvement processes to watch uptime metrics and take appropriate steps to ensure uptime meets business requirements. Best practices: Use continuous improvement processes to maintain / improve SLO attainment. Map this KPI back to business impact Report KPIs to all stakeholders. These KPIs directly measure the most important aspects of an IT service, speed and quality, in a way that is easy and intuitive to understand and communicate to technical and non-technical stakeholders. Prerequisites Before you begin, if you don’t have equivalent experience, you should complete the New Relic University (NRU) Overview Course. You should also have a basic understanding of: New Relic One APM and infrastructure monitoring New Relic One Dashboards and NRQL New Relic One alerting best practices Establish current state As with any continuous improvement process, the first step of SLM is to establish the current state of your KPIs. To do so, you will need to perform the following tasks: Determine in-scope services Identify service boundaries Deploy instrumentation Perform SLM educational workshops Analyze KPIs and set baseline SLOs Establish / optimize Alerting Build problem resolution workflows Execute continuous improvement review To help illustrate this process, we are going to apply it to an example IT service, an ecommerce site for a cellular telephone provider. Determine in-scope services You should first identify the IT services that are going to be in-scope for the initial iteration of the SLM process. These services should be key to ongoing business operations and as close to your customers as possible. Most commonly, you will be applying the SLM process to an application, since that is the service your customers are expecting you to deliver. SLM can be applied to infrastructure-based services; however, it is a more advanced application of SLM which is applicable to a much smaller set of organizations. If you are considering implementing SLM for infrastructure, you should ensure that the service(s) you are instrumenting are actually the closest to your organization’s end-customer. If your infrastructure is hosting a customer-facing app, then the app should be the target of SLM. Absent anything else, a good methodology for identifying in-scope services is to consult your disaster recovery plan. Typically, the most critical business services are prioritized there. Identify service boundaries Next, you should identify each service’s boundary, which is the service component that is closest to the client sending transaction requests. This should be the application receiving the request from the client, browser, or mobile device, and may also be known as the \"external API.\" Reverse proxies, CDNs, and load balancers are not part of the service boundary. Their service level compliance should be measured via the Uptime KPI (external test requests for connectivity). If your services are using APM, you can identify service boundaries using the service map or dependencies features. A service component is on a boundary if it has no inbound connections. In the example below (from a service map), you can see that the WebPortal is on the boundary. An example of using service maps in New Relic One to identify service boundaries. In contrast, the following screenshot (from the dependencies page) shows that the Inventory Service is not on a boundary since it has incoming connections from the WebPortal. Subsequent examples in this guide will build on the WebPortal service boundary. An example of using the dependencies UI in New Relic One to identify service boundaries. You should understand that the SLM process defines a service boundary as being downstream of any dependencies. The service boundary is the point where all the effects and impacts of dependent services are measured as they contribute to the total response time and quality of the service. By measuring service level compliance at the boundary, you will be able to see the impact that all service components upstream of the boundary have on service delivery. This means that your initial steps into SLM can focus on the services that are closest to your users, yet still capture the contribution of more distant services. As your practice matures, you will be able to identify the next round of upstream services that would benefit from direct SLM instrumentation. In our example, the WebService is downstream of the Fulfillment, Plan, Promo, Login, and Inventory services (among others). By applying SLM at the WebService, we will be seeing the impact of the upstream services on the WebService. Any impactful issues with an upstream service will be reflected in the WebService’s service level KPIs. By instrumenting one service, we are capturing the contribution of five additional services. This greatly simplifies our observability practice. In time, problematic upstream services will self-identify themselves as candidates for direct SLM instrumentation. Deploy instrumentation To collect SLM service response time and transaction success KPIs, you need to deploy instrumentation into the components of your production apps on the service boundary. If you don’t have instrumentation that can do this in production already, then you will need to engage the teams and stakeholders that can help you to get this done. For detailed information on deploying the New Relic instrumentation that can gather this information, see our APM install documentation. The uptime KPIs can be collected using synthetic transactions, which don’t require any instrumentation to be added to the service. If needed, you can start your SLM journey there while waiting for the direct instrumentation to be deployed. The uptime tests should perform a basic, yet realistic, check of the service’s functionality. For detailed information on this capability, see our synthetic monitoring documentation. Perform SLM educational workshops You should share the self-paced New Relic Essentials training course with the appropriate stakeholders so they can understand how the New Relic technology platform will aid in the SLM process. Analyze KPIs and set baseline SLOs The SLM process uses speed and quality as its key performance indicators. In technical terms, speed means response time and quality means error rate. At the end of this phase, you will have created baseline service level objectives for each service in the form of a percentage. For example: “98% of service X’s transactions will be error free and occur in less than 500 milliseconds.” For each in-scope service, you should analyze speed and quality at the service boundary. This will give you an overall understanding of how the entire service and all of its dependencies are performing. As you iterate through the SLM process, you can then identify and prioritize the upstream service components that require direct SLM instrumentation. To analyze KPIs, you should do the following for each service: Identify the volume and 95th percentile response time for each of the service’s transactions over a relatively long period of time, typically between seven days and one month. It is important that you use percentile rather than average, so you can see the entire range of response times, including outliers. If you use averages, you will hide outliers. The following is an example of the initial baseline report. Here you can see the volume, p95 response time, and error volume for the WebPortal and a few other services. The WebPortal’s p95 response time is .36 seconds (or 36 milliseconds), so we have decided to set the SLO target to 0.4 seconds. Example of an initial baseline report measuring volume and 95th percentile response time. Next you should review and identify any non-business transactions, since they should not be included in the SLO attainment calculation. For example, you should not include health check / keep alive transactions and you may not want to include administrative transactions. In the example below, we are looking at some of the transactions from the WebPortal service. We have decided that the about.jsp transaction is a non-business transaction that should not be tracked in our SLO attainment calculation. Example showing transaction breakdowns from the initial baseline report to help identify what to track (or not track) for SLO. Finally, import and edit the SLM template dashboard to exclude non-business transactions. Then use the p95 response time as your baseline response time service level objective. For the example chart, we chose 0.4 seconds as our response time threshold and set our service level objective to 95%. This means that we are expecting 95% of the WebPortal’s business transactions to complete in 0.4 seconds or less and without an error. The red line on the chart shows us our 95% service level objective. Example chart now excluding the non-business transactions. As you can see, there are periods of hours where the app is not meeting its SLOs. If we are going to maintain the 95% target, we would need to identify and fix the service components or dependencies that are causing these problems. Establish or optimize alerting After you have set your service level objectives, you will then configure alerts that will inform you when your SLO attainment has dipped below your goal. These alerts will show you when incidents with a high business impact are occurring. When they are triggered, they should be given a high priority and you should engage the proper teams to start the process of diagnosing the source of the problem. A basic starting point is to configure an alert that triggers when your SLO attainment has dipped under your baseline for more than 10 minutes. For more information, see our documentation on configuring alerts. Build problem resolution workflows As we’ve been discussing, the intent of the SLM process is to identify when business impacting issues occur in your IT services. When this occurs, a diagnostic investigation should be launched. The goal of the investigation is to identify what service element is causing the business impacting issue. SLM tells you that there is a problem with business impact, the diagnostic process helps you to find where the problem is. Typically, your high level diagnostic workflow will start at the service boundary and go as follows: Look at the service’s individual transactions and see which one(s) are departing from their performance and/or response time SLOs. Look at each service component responsible for delivering that transaction until you find the component that is failing. Use in-depth diagnostics to identify the root cause of the problem and then resolve it. Execute continuous improvement review This is an ongoing phase of the SLM process where data is reviewed and adjustments are made as required. Your KPIs should be reported to upper management to ensure that stakeholder teams are appropriately prioritizing work and that you are meeting the SLO goals you’ve set. Periodic KPIs should be recorded and retained over periods of months to years to establish a baseline and to show the rate of improvement. In addition, each time you execute the continuous improvement process, you should: Review each service’s architecture to ensure your instrumentation is deployed at the boundary and that there are no observabilty gaps. Review each service’s transactions to confirm that only business transactions are included in your SLO calculations. Review each service’s SLO and determine if it meets the business’s performance and quality requirements. If it does not, then the SLO should be changed and the appropriate stakeholders notified so they can work to improve performance and quality. Review your SLO attainment and determine if any upstream services should be added to the SLM process. Next steps After you’ve established the SLM process, you should identify other services that would benefit from SLM instrumentation. These may be other front-line services or upstream dependencies of services that are covered by SLOs that have shown themselves to be frequent contributors to SLO attainment failures. As you do this, you should start to measure and report your SLM coverage as a percentage of applications covered by SLOs. For example, you may say that 20% of your apps have established SLOs. As SLM expands into your organization and as its value is seen by management and other stakeholders, you may find that you need a dedicated team to manage the SLM process. The SLM process should also become a primary driver to help you prioritize issue resolution activities. SLO attainment failures are a direct indicator that your IT services are having a negative business impact which is visible to your customers as poor performance and/or unhandled errors. Value realization Once the SLM process is established, you will see a reduction in the effort required to identify business impacting issues, a better ability to communicate with your business stakeholders, and an easier time proving the business’ return on investment in IT services. Your SLM KPIs will provide quantifiable proof of these improvements. In addtion, you should be able to simplify your observability strategy by removing or reducing your dependency on legacy consumption metrics and the logic required to correlate them against your true goal of measuring performance and quality. Once you are firmly on the path to SLM's goals, consider moving to other use cases within the Uptime, Performance, and Reliability value stream, such as Service Level Management, or Reliability Engineering. You can also move to other observability maturity value streams, such as Customer Experience. Additional resources Need help getting started? Check out the self-paced service level management training",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.00923,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Key <em>performance</em> indicators",
        "tags": "<em>Uptime</em>, <em>performance</em>, <em>and</em> <em>reliability</em>",
        "body": " on the path to SLM&#x27;s goals, consider moving to other use cases within the <em>Uptime</em>, <em>Performance</em>, and <em>Reliability</em> value stream, such as Service Level Management, or <em>Reliability</em> Engineering. You can also move to other <em>observability</em> <em>maturity</em> value streams, such as <em>Customer</em> <em>Experience</em>. Additional resources Need help getting started? Check out the self-paced service level management training"
      },
      "id": "61403d0464441f0457424337"
    },
    {
      "sections": [
        "Alert quality management use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Incident volume",
        "Incident count KPI",
        "Accumulated incident duration KPI",
        "Mean time to close (MTTC) KPI",
        "Percent under 5 minutes KPI",
        "User engagement",
        "Percentage Acknowledged KPI",
        "Mean time to investigate (MTTI) KPI",
        "Prerequisites",
        "Establish current state",
        "Install and configure the incident event webhook",
        "Install the AQM dashboard",
        "Perform initial AQM orientation and enablement",
        "Accumulate AQM data",
        "Perform second enablement session",
        "Improvement process",
        "Value realization",
        "KPI reference",
        "Incident engagement",
        "Additional resources"
      ],
      "title": "Alert quality management use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Uptime, performance, and reliability",
        "Alert quality management",
        "Implementation guide"
      ],
      "external_id": "b69abb6b9b6c1257482958e12952dc189aecec2a",
      "image": "https://docs.newrelic.com/static/2be50db00a885e2d8ada51aa391f60d1/748b0/nrAQMIncidentFlow.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/aqm-implementation-guide/",
      "published_at": "2022-01-12T05:57:34Z",
      "updated_at": "2021-11-25T05:13:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Teams suffer from alert fatigue when they experience high alert volumes and alerts that are not aligned to business impact. As they start to believe that most alerts are false, they may prioritize easy to resolve alerts over others.  Also, they may close unresolved incidents so they can stay within their SLA targets. The result will be slower incident responses, magnified issue scope, and increased severity when true business impacting issues occur. Alert Quality Management (AQM) focuses on reducing the number of nuisance incidents so that you focus only on alerts with true business impact.  This reduces alert fatigue and ensures that you and your team focus your attention on the right places at the right times. You are a good candidate for AQM if: You have too many alerts. You have alerts that stay open for long time periods. Your alerts are not relevant. Your customers discover your issues before your monitoring tools do. You can't see the value of your observability tool(s). Desired outcome An alert strategy based on measuring business impact will result in faster response times and greater proactive awareness of critical events.  An improved alert signal to noise ratio reduces confusion and improves rapid identification and problem isolation. AQM's overall goal is to ensure that fewer, more valuable, incidents are created, resulting in: Increased uptime and availability Reduced MTTR Decreased alert volume The ability to easily identify alerts that are not valuable, so you can either make them valuable or remove them. The AQM process described in this guide generates the key performance indicators and metrics that you will use to measure progress towards these goals.  The metrics are measured in real time, published in a dashboard, and are used to drive a continuous improvement process that identifies and reduces nuisance alerts and increases user engagement in incident investigation. AQM does not encompass anomaly detection or AIOps, which are designed to detect unknown or unexpected modes of failure.  The two practices (AQM and ML/AI) work hand in hand, they are not mutually exclusive. Key performance indicators You will use the AQM process to collect and measure the following KPIs: Incident volume Incident Count Accumulated incident time Mean Time to Close (MTTC) Percent Under 5 Minutes User Engagement Mean Time to Investigate  (MTTI) % of Incidents Investigated These KPIs will help you to find the noisiest and least valuable alerts so you can improve their value or eliminate them.  You will then use the long term metric trends to show real business impact to management and stakeholders.  Detailed information on each metric follows. Incident volume You should treat incidents (with or without alerts) like a queue of tasks.  Just like a queue, the number of alerts should spend time near zero. Each incident should be a trigger for action to resolve the condition.  If an alert does not result in action, then you should question the value of the alert condition. If you see a constant rate of incidents or specific incidents that are \"always-on\", then you should question why. Are you in a constant state of business impact, or do you simply have a large volume of noise? The alert volume KPIs help you to answer those questions and to measure progress towards a healthy state of high quality alerting. Incident count KPI Incident Count is the number of incidents generated over a period of time. Typically you should compare the current and previous weeks. Goal: Reduce the number of low value / nuisance incidents. Best practices: Ensure condition settings are intended to detect real business impact. Ensure condition settings are detecting abnormal behavior. Communicate that the incident details \"Acknowledge\" feature helps measure meaningful and actionable alerts. See Percentage Incident Acknowledge KPI. Report AQM KPIs to all stakeholders. Accumulated incident duration KPI Accumulated incident duration is the total sum of minutes that all the incidents accumulated over a period of time. Typically you should compare the current and previous weeks. Goal: Reduce the total accumulated minutes of incidents. Best practices: Do not manually close incidents. Manual closure will skew the real duration of incident length. Eliminate alerts that do not result in any remediation actions from the recipients. Improve percent investigated and mean-time-to-investigate KPIs by communicating their importance in improving detection and response times. Report AQM KPIs to all Stakeholders. Mean time to close (MTTC) KPI Average duration of incidents within the period of time measured. Goal: Reduce MTTC Best practices: Do not manually close incidents. Manual closure will skew the real duration of incident length. Improve Reliability Engineering skills. Report AQM KPIs to all stakeholders. Percent under 5 minutes KPI Percentage of incidents where the duration of the incident is under five minutes. This can be an indicator of incident flapping. Goal: Minimize percentage of incidents with short durations Best practices: Ensure that conditions are detecting legitimate deviations from expected behavior. See Baselining and Service Level Management. Ensure that conditions are detecting legitimate deviations that correlate to business impact or impending business impact. User engagement You should measure the value of an incident by the amount of attention it receives.  Engagement in this context is measured by whether or not an incident has been acknowledged. The amount of engagement an individual alert receives is a direct measurement of its value.  More engagement implies a valuable alert, less (or zero) engagement implies a nuisance alert that should be modified or disabled. There is a significant difference between measuring the moment of incident awareness vs. acknowledging the moment resolution activity begins. If you are using an integration with New Relic Alerting, be sure that the \"acknowledge\" event that is sent to New Relic is triggered when resolution activity begins, not when the incident is sent to the external incident management tool.  For more information regarding the standard Incident Management process, see \"Incident Management Process: 5 Steps to Effective Resolution Posted on August 31, 2020 by OnPage Corporation. -- in reference to ITIL4\" Percentage Acknowledged KPI Incidents acknowledged identifies the percentage of incidents that have been engaged with and had their acknowledged property set to true. Typically you should compare the current and previous weeks. Goal: Increase the percentage of incident engagement. Best practices: Educate the DevOps team on when it is appropriate to acknowledge an incident alert. Gamify alert acknowledgement to drive usage. Discourage mass acknowledgement exercises. Mean time to investigate (MTTI) KPI Mean time to investigate identifies the average time it takes for an incident to be triaged. Typically you should compare the current and previous weeks. Goal: Reduce the mean time to investigate Best practices: Work at building incident responder's confidence in alerts. Ensure that valuable alerts are acknowledged. Incentivize response teams to respond quickly to alerts. Prerequisites Before you begin, if you don't have equivalent experience, complete the New Relic University (NRU) Overview Course. Also, make sure you have a basic understanding of: NR1 Alert policy and conditions configuration NR1 incident notification channel webhook configuration NR1 NRQL NR1 alerting best practices NR1 APM & Infrastructure How to baseline data in order to determine anomalies vs. normal behavior. Establish current state As with any continuous improvement process, the first step of AQM is to establish the current state of your KPIs. To do so, perform the following tasks: Install and configure the incident event webhook Install the AQM Dashboard Perform initial AQM orientation and enablement Accumulate AQM data Perform second enablement session Install and configure the incident event webhook The webhook will create New Relic events for each incident as it proceeds through its lifecycle (open, acknowledge, close). To ensure that the AQM process generates accurate and valuable findings, this webhook must be added as a notification channel to every alert policy. The AQM process requires incident, not violation data. This is why you will not be using the default NrAiIncident event, which provides violation data only.  Instead, you will use this webhook to send the required incident data to New Relic. To use the webhook, do the following: Identify your primary production account and each of your accounts that you will be analyzing with the AQM process. Install the incident event webhook into each account that will participate in the AQM process and configure the webhook to report nrAQMIncident events to your primary production account. Assign the webhook as a notification channel to every alert policy in each account. This example shows a webhook notification channel assigned to each alert policy for a New Relic account with multiple sub-accounts. The webhook, AQM dashboard, and detailed installation instructions can be found in the New Relic OMA resource center on GitHub. Install the AQM dashboard The AQM dashboard is the primary asset that drives the AQM process.  You need to install the AQM dashboard into the primary production account you identified in the \"Install and configure incident event webhook\" step you previously performed by doing the following: Download the dashboard definition JSON file from the New Relic OMA resource center GitHub repo. Import the definition into your primary production account. For more details on importing dashboards, see the New Relic Introduction to dashboards documentation Perform initial AQM orientation and enablement During this phase, your incident management team(s) and other stakeholders will learn the goals of the AQM process and the scope of their involvement in it. The most critical portion of this task is educating your team on the importance of acknowledging incident alerts, since that's how the alert's value is determined.  In general, instruct them to follow these guidelines: If you look at an alert and decide to take any sort of further investigative action, acknowledge the alert. If you typically close an alert without doing anything else, do not acknowledge the alert. If the incident alert is always on, do not close or acknowledge it. For further details, see Second Enablement Session. You can use the first session template presentation to communicate this material to your stakeholders. Accumulate AQM data The overall process requires at least two weeks of data before it can proceed.  During this time, you should periodically check the following items: Confirm that incident alert event data is accumulating. Confirm that the webhook is attached to every alert policy. Ensure that incident responders are following the alert acknowledgement guidelines. Perform second enablement session During this phase, you will introduce incident management teams and other stakeholders to the initial AQM data and the ongoing continuous  improvement process you'll be following. The process consists of four activities: Review AQM Dashboard and KPI Trending: Here you and the stakeholders will look at the AQM KPIs and identify their week over week trends.  The team should identify areas where KPIs are not improving and develop strategies to drive improvement. Identify Achievements, Challenges, and Opportunities: Here you and the stakeholders will map the current state of alert quality to business impact, identifying areas where improvement has resulted in better business outcomes and areas where problems are impacting business outcomes. Incident Policy Review: Using the AQM dashboard, you and the stakeholders will identify the noisiest incident policies.  Once identified, those policies should be evaluated as detailed in step 4 below. Alert Policy Recommendations: In this step, you and the stakeholders will review the noisiest policies using the following criteria: Do the alerts have any business impact? Are the policies properly configured? Are they telling us something about the resource that needs to be fixed? Are the policies necessary? Do they have business impact? Are the thresholds set properly? Technical recommendations: Here, you and the stakeholders will review any technical recommendations, including: Are there application / system problems for engineering to review? Are there poorly constructed policies that need to be fixed? Are there instrumentation gaps? You can use the second session template presentation to keep this part of the AQM process organized. Improvement process This is the ongoing phase of the continuous improvement process where you periodically review your accumulated AQM data and make adjustments as needed to alert policies. You should perform this step once a week until your alert volume is acceptable. You can then perform it less frequently. During this phase you should: Report your KPIs each week to upper management to ensure that the stakeholder teams are appropriately prioritizing the work and to show that progress towards the promised business outcomes are being reached. Record and retain your weekly KPIs  over periods of months to years to establish a baseline and to show the rate of improvement. You should keep in mind that this is a continuous improvment process, you will continue to collect and evaluate the KPIs over long periods of time to ensure you are meeting your AQM goals. Value realization Once the AQM process is established, you will see significant reductions in the volume of alerts while reliability and stability remain the same or improve.  In addition, you should see that your alerts have a clear and unambiguous business impact.  Your AQM KPIs will provide quantifiable proof of these improvements. Once you are firmly on the path to AQM's goals, consider moving to other use cases within the Uptime, Performance, and Reliability value stream, such as Service Level Management, or Reliability Engineering.  You can also move to other observability maturity value streams, such as Customer Experience. KPI reference Following are the descriptions of each KPI as well as sample NRQL queries that will extract them from the New Relic platform.  These KPIs are also included in the AQM dashboard that can be downloaded from the New Relic OMA resource center GitHub repo. Incident volume Incident count KPI Incident Count is the number of incidents generated over a period of time. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT count(*) AS 'Incident Count' WHERE current_state='open' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Accumulated incident duration KPI Accumulated incident duration is the total sum of minutes that all the incidents accumulated over a period of time. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT sum(duration)/(1000*60) AS 'Incident Minutes' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Mean time to close (MTTC) KPI Average duration of incidents within the period of time measured. NRQL: FROM nrAQMIncident SELECT average(duration/(1000*60)) AS 'Incident MTTC (minutes)' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Percent under 5 minutes KPI Percentage of incidents where the duration of the incident is under five minutes. This can be an indicator of incident flapping. NRQL: FROM nrAQMIncident SELECT percentage(count(*), WHERE duration <= 5 * 60 * 100) AS '% Under 5min' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Incident engagement Percentage Acknowledged KPI Incidents acknowledged identifies the percentage of incidents that have been engaged with and had their acknowledged property set to true. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT filter(count(*), WHERE current_state='acknowledged')/filter(count(*), WHERE current_state='open')*100 AS '% Investigated' WHERE severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Mean time to investigate (MTTI) KPI Mean time to investigate identifies the average time it takes for an incident to be triaged. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT average(duration/(1000*60)) AS 'Incident MTTI (minutes)' WHERE current_state='acknowledged' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Additional resources Want to get your hands dirty before you start implementing this in your account? Check out the alert quality management lab",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.86598,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Key <em>performance</em> indicators",
        "tags": "<em>Uptime</em>, <em>performance</em>, <em>and</em> <em>reliability</em>",
        "body": ", such as Service Level Management, or <em>Reliability</em> Engineering.  You can also move to other <em>observability</em> <em>maturity</em> value streams, such as <em>Customer</em> <em>Experience</em>. KPI reference Following are the descriptions of each KPI as well as sample NRQL queries that will extract them from the New Relic platform"
      },
      "id": "61372f5964441f181342436d"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/operational-efficiency/sc-implementation-guide": [
    {
      "sections": [
        "Quality foundation implementation guide",
        "Overview",
        "Desired Outcome",
        "Key Performance Indicators",
        "Availability",
        "Largest contentful paint (LCP)",
        "First input delay (FID)",
        "Cumulative layout shift (CLS)",
        "Time to first byte (TTFB)",
        "Ajax response times",
        "HTTP error rate",
        "JavaScript error rate",
        "Prerequisites",
        "Required knowledge",
        "Required Installation and Configuration",
        "Establish current state",
        "Review instrumented pages",
        "Validate Browser URL grouping",
        "Understand how you will segment your data",
        "Import the quality foundation dashboard",
        "Capture current performance for each dashboard page",
        "Improvement Process",
        "Plan your work",
        "Decide which KPIs to improve",
        "Improve targeted KPIs",
        "Improve page load performance",
        "Improve AJAX response times",
        "Improve the AJAX error rate",
        "Improve JavaScript errors",
        "Conclusion"
      ],
      "title": "Quality foundation implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Quality Foundation"
      ],
      "external_id": "91186ed56e33e040c73d1fff940cec0644c199f6",
      "image": "https://docs.newrelic.com/static/9238160720501f4423dff703746fb59d/d9199/cx-what-you-can-measure-nr.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/quality-foundation-implementation-guide/",
      "published_at": "2022-01-12T05:56:50Z",
      "updated_at": "2022-01-12T05:56:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Digital customer experience is your end user’s experience across all your digital touch points. There are four core factors that impact a user’s experience: Availability (Is it reachable?) Performance (Does it perform well enough to be usable?) Content quality (Does it have what users need and can they find it?) Product and content relevance (Does it have what users care about?) Digital customer experience includes web, mobile, and IoT. The first version of this guide is focused on measuring the end user web experience. Quality Foundation is about creating a standard practice to help you understand your digital customer experience in a meaningful way. This implementation guide will help you: Look at customer experience in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about Prioritize what you work on Create a repeatable practice Desired Outcome Improve customer engagement and retention by measuring and improving performance in a way that better aligns to the end user experience. Key Performance Indicators Quality Foundation measures the following KPIs: Availability This KPI measures whether or not your application or its pages can be accessed by your users Goal: Improve uptime and availablity Thresholds: < 99% warning < 95% critical 99% or \"2 9's\" is a good minimum standard of availability, even for employee applications or sub-pages. We configure these default thresholds into the dashboards. You can easily change this to better suit expectations for your application. Largest contentful paint (LCP) Part of Core Web Vitals. Largest Contentful Paint (LCP) measures the time it takes to load the largest image after a user has navigated to a new page. Goal: Reduce LCP to 2.5 seconds or better for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 2.5 seconds Critical: > 4.0 seconds LCP thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. First input delay (FID) Part of Core Web Vitals. Measures the interactivity of a page by tracking the time between user interaction (such as clicking a link or entering text) when the browser begins processing the event. Goal: Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 100 milliseconds Critical: > 300 milliseconds FID thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. Cumulative layout shift (CLS) Part of Core Web Vitals. Measures how much the page layout shifts during render. Goal: Maintain a score of 0.1 or less for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 0.1 score Critical: > 0.25 score CLS thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. Time to first byte (TTFB) This KPI measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. Google considers TTFB secondary to Core Web Vitals. We recommend measuring it for a more complete picture. It can be revealing if you see a change in LCP, because it answers the question as to whether the change occurred server side or client side. Goal: Reduce the time to first byte by improving CDN, network, and service performance. Thresholds: Warning > 0.5 seconds Critical > 1.0 seconds According to Google and Search Engine People, 500 milliseconds is a decent TTFB for pages with dynamic content. You can find mention of these recommendations here. Ajax response times Slow ajax calls can make the user feel as though nothing is happening or the page is broken. If the response time is slow enough, users may even abandon the journey. Goal: Measure and improve ajax response times. Thresholds: Warning > 2 seconds Critical > 2.5 seconds These thresholds come from experience with customers across a variety of industries. HTTP error rate HTTP errors (or HTTP 4xx and 5xx responses) happen when calls to the backend are not successful. Goal: Measure and reduce the HTTP error rate to ensure your customers are able to do what they came to your site to do. Thresholds: Warning < 99% of requests are successful Critical < 97% of requests are successful These thresholds come from experience with customers across a variety of industries. We made the assumption that every ajax request is associated with something the user is trying to achieve and treat it accordingly. Because users will often retry failed actions, we allowed for space between warning and critical thresholds. If the ajax requests being measured are an important part of the user journey, we recommended aiming for higher success rates, such as 99.5% or 99.9%. If the ajax requests are tied to login requests, separate 4xx response codes from 5xx response codes and set a much lower threshold for the 4xx responses. You can look to historical response code rates to determine a reasonable threshold. JavaScript error rate This KPI measures the number of JavaScript errors per page view. Goal: Remove irrelevant JavaScript errors being tracked either by tuning ingest or using filtering. Reduce JavaScript errors that impact customer performance. Thresholds: Warning: > 5% errors per page view Critical: > 10% errors per page view These thresholds come from experience with customers across a variety of industries. For each KPI, we defined thresholds - one for warning, another for critical. You might ask where these values come from or how you can be sure they should apply to your application. Our thresholds are the ones recommended by Google (as with Core Web Vitals) or by us, based on our experience across a large number of customers and applications. If you feel strongly that they should be different, you can adjust them, but you should do this at the organizational level rather than on an application by application basis. Quality Foundation helps you identify where in your application you need to make improvements that will optimize user retention, conversion and satisfaction. It is less about where things are and more about where to get to. It also shows you what you should be measuring going forward. You can use this to define SLOs (in a service level dashboard) and alert on them. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required Installation and Configuration Browser Pro installed in all pages SPA enabled for single page applications Synthetics monitors configured: Ping monitors configured for anonymous users Scripted synthetics check configured for login flow Monitors should be configured to test from all regions applicable to your users Monitors should be configured for each domain and each login flow Data retention for browser events greater than or equal to 2x an average sprint Establish current state Review instrumented pages Validate Browser URL grouping Understand how you will segment your data Import the quality foundation dashboard Capture current performance for each dashboard page Review instrumented pages Review Browser apps and pages to make sure that everything you expect to report back to New Relic is. You can do this by reviewing the Page Views tab in the Browser UI or running the following query: SELECT uniques(pageUrl) from PageView LIMIT MAX Copy You may need to filter out URLs that contain request or customer ID. Validate Browser URL grouping Ensure Browser segments are captured correctly so user experience performance is measurable in both the NewRelic UI as well as at the aggregate level when querying via NRQL. A segment is the text between two / in a URL or between . of a domain name. For example, in the URL website.com/product/widget-name, the segments are: website .com product widget-name When there are a lot of URLs with a lot of segments, URLs can get crushed, so that website.com/product/widget-name becomes website.com/ or website.com/product/. In this example, the first crushed URL is not particularly useful, but the second one may be a useful way of aggregating customer experience data for the product. Not sure whether you need to tune your configuration? Import the Segment Allow List Investigation dashboard in GitHub to help. Once you’ve identified which segments to add, you can add them using Segment allow lists in Browser. Understand how you will segment your data Make Customer Experience data understandable and actionable by breaking it out into different segments. In this case, segments refer to groups of data. It does not refer to sections of URLs, as in segment allow lists. Consider the following statements: Most of our users experience 3 seconds or better to first input delay. On average, we see 2 seconds to the largest contentful paint. Last week, there were 1 million page views. Compared to: Most of the users in the US, Canada, and EMEA experience 2 seconds or better to first input delay. Malaysia and Indonesia users experience 4 seconds; we are looking into this. Customers buying car insurance typically see 1 second to largest contentful paint. For home insurance, it’s 4 seconds. Last week, there were 700,000 page views on mobile browser apps compared to 300,000 on desktop. Let’s make sure we’re optimizing our mobile experience. Typical segmentation involves breaking down user experience into the following categories: Segment Guidance Region/Location Basic: Group by country. Browser events automatically contain the country code of requests, so there is nothing you need to do to break it out further. Advanced: Make regional grouping match regional SLO groups by creating your own region attribute using custom attributes in Browser. Facet by countryCode. Related attributes: regionCode city asnLatitude asnLongitude Device Break out performance and engagement device type so you can understand: Typical breakdown of desktop vs mobile browser users Experience of desktop vs mobile browser users Facet by deviceType. Related attributes: userAgentName userAgentOS userAgentVersion Product/Line of Business In this scenario, a product is a separate line of business or service provided by your organization. Some examples of industries and respective products: An insurance company that sells both car and house insurance A media company that has multiple streaming services or channels A travel company that provides car rental as well as hotel bookings Basic: Break out performance by product by: Faceting on pageUrl: Use this approach when multiple products are grouped into one browser app in New Relic. Faceting by appName: Use this approach when each product is instrumented as a separate web app. Grouping by appName and then facet: Use this approach when there are multiple apps in browser supporting one product. Advanced: Add product offering as a custom attribute to browser pages using custom attributes. Environment During instrumentation or afterwards, follow a naming convention that specifies the environment in Browser. Well named browser apps specify product and/or function as well as environment. Examples: account-management.prod hotels-book.prod car-insurance.uat Using app naming conventions to specify the environment supports filtering data in both the UI and in dashboards. For more information, see the documentation for how to rename Browser apps. Team In some organizations, a single team supports multiple products, while in others, a product is big enough to be supported by multiple teams. Report on team performance against customer experience or engagement by either adding the team name to the Browser app name (for example, account-management.prod.unicorn-squad) or by using custom attributes. Import the quality foundation dashboard This step creates the dashboard that you will use to measure your customer experience and improve it. Clone the GitHub repository. Follow the GitHub repository README instructions to implement the dashboard. Make sure to align the dashboard to lines of business or customer facing offerings rather than teams. This ensures optimization time is spent where it is most impactful. Capture current performance for each dashboard page Follow the GitHub README instructions. Use the dashboard from the previous step to understand the overall performance for each line of business. If relevant, apply filters to see performance across region or device. If values drop below targets and it matters, add it to the sheet as a candidate for improvement. Not worth tracking: A company that sells insurance in the US only notices poor performance in Malaysia. Worth tracking: A company that sells insurance in the US only notices poor performance with respect to mobile users in the US. Improvement Process Plan your work Decide which KPIs to improve Improve targeted KPIs Improve page load performance Improve AJAX response times Improve the AJAX error rate Improve JavaScript errors Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. Decide which KPIs to improve You now know what your user experience looks like across multiple lines of business. Where should you be improving? Start with business priorities. If you have clear business directives or have access to a senior manager above who does, you should focus on what matters most to your organization. For example, let’s say your company has recently launched a new initiative around a line of business but the KPIs associated with the UI are below target. This is where you should focus time initially. Next, focus on KPIs for each line of business. Finally, filter each line of business by device, region, etc., to see if additional focus is needed for specific regions or devices. Improve targeted KPIs To track your progress, create a new dashboard or add a new page to the existing dashboard and name it Quality Foundation KPI Improvement. For more information, see Improve Web Uptime. Improve page load performance Narrow your focus to specific pages that aren’t meeting target KPI values. For each page load KPI result that is out of bounds in the Quality Foundation Dashboard, remove the COMPARE WITH clause and add FACET pageUrl/targetGroupedUrl LIMIT MAX to find which pages are the poor performers. Use targetGroupedUrl when there are many results; for example, when the customer ID is part of the URL. Otherwise, use pageUrl. Original Dashboard query: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' SINCE 1 week AGO COMPARE WITH 1 week AGO Copy New query to identify problem pages: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' FACET targetGroupedUrl LIMIT MAX Copy Once you have identified which pages to improve, improve them following these best practices. Improve AJAX response times Find the slow requests. Go to the Ajax duration widget on the dashboard. View query, then open in query builder. Add facet requestUrl LIMIT MAX to the end of the query. Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - AjaxResponseTimes. Focus improving requests with a timeToSettle > 2.5s. Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve the AJAX error rate Find the failing requests. Go to Dashboards > Query builder. Enter FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND <Ajax Request filter> SINCE 1 week AGO facet pageUrl, appName Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Pages with AjaxErrors. Run the query again for the most problematic pages to find the requests that are failing: FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND pageUrl=<problematic page> AND appName = <corresponding app> <Ajax Request filter> SINCE 1 week AGO facet requestUrl Copy Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve JavaScript errors Find the most common failures. Go to Dashboards > Query builder Enter FROM JavaScriptError SELECT count(errorClass) SINCE 1 week AGO WHERE <PageView filter> FACET transactionName, errorClass, errorMessage, domain Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Javascript Errors. Use this information to figure out which errors need to be addressed Use New Relic’s recommended best practices to resolve errors that need addressing. See JavaScript errors page: Detect and analyze errors. Remove third party errors that do not add value. You may be using a third party JavaScript that is noisy but works as expected. You can take a couple of approaches: Remove the domain name from the JavaScript error/Pageview ratio widget and add it as its own widget so you can see unexpected changes. You can alert on this using Baseline NRQL alerts. Drop the JavaScript error using drop filters. Only use this option if the volume of errors is impacting your data ingest in a significant way. Be as specific as you can in the drop filter. Conclusion Best practices to adopt Revisit performance metrics (shared in this document as Quality Foundation KPIs) at the end of each sprint. Incorporate performance improvements into developer sprints. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Define Customer Experience SLOs. Create alerts for business critical drops in Quality Foundation KPIs. Value Realization At the end of this process you should now: Have an understanding of your end user experience in a way that is tangible, actionable, and easy for engineers as well as the business to understand. Know how releases impact your end customers. Know how your customers are impacted by service, infrastructure, or network level events. See latency issues caused by backend services if they exist. Have created, or be on the path to create, a common language with business owners so you are working together. This can open new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.15405,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Quality foundation <em>implementation</em> <em>guide</em>",
        "sections": "Quality foundation <em>implementation</em> <em>guide</em>",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": " you understand your digital customer experience in a meaningful way. This <em>implementation</em> <em>guide</em> will help you: Look at customer experience in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about Prioritize what"
      },
      "id": "61461531e7b9d25774b6f22d"
    },
    {
      "sections": [
        "Observability implementation guide template",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "KPI1 name",
        "KPI2 name",
        "Prerequisites",
        "Establish the current state",
        "Step 1",
        "Step 2",
        "Step 3",
        "Improvement process",
        "Value realization"
      ],
      "title": "Observability implementation guide template",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Value driver this applies to << change",
        "Use case name << change",
        "Implementation guide"
      ],
      "external_id": "e207c5d5d6379c5a496c46dc890bf51c60274c1c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/om-implementation-guide/",
      "published_at": "2022-01-12T18:22:45Z",
      "updated_at": "2021-12-24T13:23:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is the template for Observability maturity implementation guides. To help you along, refer to: The style guide introduction Other observability maturity implementation guides To get your implementation guide to show up in the left nav as it should, edit ~src/nav/new-relic-solutions.yml. Don't forget to add a link to it to the Observability Maturity introduction page. Overview Put in a brief, executive-level overview of what this guide achieves. Desired outcome What's the benefit of following the steps in this implementation guide? For practitioners? For the business or the organization? Key performance indicators Refer to the KPI section of the service level management (SLM) guide for what this section should look like. KPI1 name Describe the KPI Goal What is your reader trying to do? Best practices Are there any principles your reader should adopt? KPI2 name Describe the KPI Goal What is your reader trying to do? Best practices Are there any principles your reader should adopt? Prerequisites List any of the following that applies: Reading Training Instrumentation Configuration User access needed Stick to what's relevant (don't be exhaustive unless absolutely necessary) and include links wherever possible. Establish the current state Step1 Step2 Step3 If the reader needs to access a JSON file or another file type, make sure those files are available in the oma-resource-center. Step 1 Describe the step. Step 2 Describe the step. Step 3 Describe the step. Improvement process Now that the reader knows where they stand, tell them how to improve what they're trying to improve. Value realization Remind the reader why they did all this work in the first place and what they'll see as a result. Include best practices to adopt going forward so that they can continue to benefit from their hard work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.95029,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Observability</em> <em>implementation</em> <em>guide</em> template",
        "sections": "<em>Observability</em> <em>implementation</em> <em>guide</em> template",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": "This is the template for <em>Observability</em> <em>maturity</em> <em>implementation</em> guides. To help you along, refer to: The style <em>guide</em> introduction Other <em>observability</em> <em>maturity</em> <em>implementation</em> guides To get your <em>implementation</em> <em>guide</em> to show up in the left nav as it should, edit ~src&#x2F;nav&#x2F;new-relic-solutions.yml. Don&#x27;t"
      },
      "id": "61c5c9ec28ccbccadb07ca78"
    },
    {
      "sections": [
        "Service level management use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Service response time",
        "Service quality",
        "Service level objective attainment",
        "Service uptime",
        "Prerequisites",
        "Establish current state",
        "Determine in-scope services",
        "Identify service boundaries",
        "Deploy instrumentation",
        "Perform SLM educational workshops",
        "Analyze KPIs and set baseline SLOs",
        "Establish or optimize alerting",
        "Build problem resolution workflows",
        "Execute continuous improvement review",
        "Next steps",
        "Value realization",
        "Additional resources"
      ],
      "title": "Service level management use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Uptime, performance, and reliability",
        "Service level management",
        "Implementation guide"
      ],
      "external_id": "e3c4da80186b6d33a301db4a15c0b0cff2034131",
      "image": "https://docs.newrelic.com/static/e2478328e46923877c6dd58993aecf5f/d9199/nrSLMServiceMap.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/slm-implementation-guide/",
      "published_at": "2022-01-12T05:57:34Z",
      "updated_at": "2021-11-25T05:19:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview IT Operations is expected to provide services that meet the business’s requirements for performance and reliability. However, many ops teams attempt to measure performance and reliability using legacy methods, like measuring resource consumption. That, in turn, requires that they create complex dashboards of granular metrics which they then try to correlate with application performance and reliability. These complex dashboards require subject matter experts to interpret the results for business stakeholders. Legacy methods create barriers to understanding what a good system state looks like and how bad system states impact the business. Essentially, IT ends up not sharing a common metric vocabulary with the business. This fundamental disconnect will result in the perception that IT is not able to deliver the services that the business requires, with all the implications and impacts that perception carries. Service Level Management (SLM) eliminates that disconnect by better explaining the overall performance of a system in terms that are easily understood by both IT and the business. The intent is to show whether or not the system is meeting its performance and reliability expectations, and if it is trending toward or away from improvement, so proactive steps can be taken. The end goal is that systems are better oriented toward desired business outcomes with IT’s attention focused on issues in areas with the highest business impact. You are a good candidate for SLM if any of the following are true: The business impact of performance and reliability issues are not well understood by all stakeholders. Your MTTx is too high. You are collecting many resource consumption metrics (such as CPU, disk, or memory) or are maintaining many metric correlation rules in order to identify system problems. You can’t see the value of your observability tool(s). Desired outcome Service Level Management’s overall goal is to easily measure and communicate the overall health, performance, and quality of your digital products and services to all stakeholders. By implementing SLM at key output points in your systems, you will have a simpler and more responsive observability practice, tighter alignment with the business, and faster paths to improvement. The SLM process described in this guide will help you to identify the points in your systems where you should measure the key performance metrics of service performance and quality. It will also define and drive a simpler alerting strategy, continuous improvement methodologies, and improved problem resolution workflows. Key performance indicators You will use the SLM process to collect and measure the following KPIs, often referred to as the “Golden Signals”: Service response time Service response time measures the amount of time a service requires to process a transaction. It starts when a transaction request is received by the service and ends when the response is sent. Goal: Reduce transaction response time. Best practices: Measure response time at service boundaries. Use continuous improvement processes to drive down response times. Ensure that non-business transactions (such as health checks) are not included or measured. Map this KPI back to business impact. Report KPIs to all stakeholders. Service quality Service quality is the number of transactions that result in an unhandled error. Typically, these are transactions whose HTTP response code is greater than or equal to 400. Goal: Reduce the number of unhandled errors. Best practices: Measure error rates at service boundaries. Continually identify and remediate sources of high error volumes. Map this KPI back to business impact. Report KPIs to all stakeholders. Service level objective attainment SLO attainment is the percentage of time a business service is meeting its response time and quality goals. Goal: Improve response time and quality to ensure high SLO attainment. Best practices: Use continuous improvement processes to maintain / improve SLO attainment. Map this KPI back to business impact. Report KPIs to all stakeholders. Service uptime Service uptime is the percentage of time a service can be reached by at least one client. Typically this is measured using synthetic transactions from representative remote locations. Goal: Use continuous improvement processes to watch uptime metrics and take appropriate steps to ensure uptime meets business requirements. Best practices: Use continuous improvement processes to maintain / improve SLO attainment. Map this KPI back to business impact Report KPIs to all stakeholders. These KPIs directly measure the most important aspects of an IT service, speed and quality, in a way that is easy and intuitive to understand and communicate to technical and non-technical stakeholders. Prerequisites Before you begin, if you don’t have equivalent experience, you should complete the New Relic University (NRU) Overview Course. You should also have a basic understanding of: New Relic One APM and infrastructure monitoring New Relic One Dashboards and NRQL New Relic One alerting best practices Establish current state As with any continuous improvement process, the first step of SLM is to establish the current state of your KPIs. To do so, you will need to perform the following tasks: Determine in-scope services Identify service boundaries Deploy instrumentation Perform SLM educational workshops Analyze KPIs and set baseline SLOs Establish / optimize Alerting Build problem resolution workflows Execute continuous improvement review To help illustrate this process, we are going to apply it to an example IT service, an ecommerce site for a cellular telephone provider. Determine in-scope services You should first identify the IT services that are going to be in-scope for the initial iteration of the SLM process. These services should be key to ongoing business operations and as close to your customers as possible. Most commonly, you will be applying the SLM process to an application, since that is the service your customers are expecting you to deliver. SLM can be applied to infrastructure-based services; however, it is a more advanced application of SLM which is applicable to a much smaller set of organizations. If you are considering implementing SLM for infrastructure, you should ensure that the service(s) you are instrumenting are actually the closest to your organization’s end-customer. If your infrastructure is hosting a customer-facing app, then the app should be the target of SLM. Absent anything else, a good methodology for identifying in-scope services is to consult your disaster recovery plan. Typically, the most critical business services are prioritized there. Identify service boundaries Next, you should identify each service’s boundary, which is the service component that is closest to the client sending transaction requests. This should be the application receiving the request from the client, browser, or mobile device, and may also be known as the \"external API.\" Reverse proxies, CDNs, and load balancers are not part of the service boundary. Their service level compliance should be measured via the Uptime KPI (external test requests for connectivity). If your services are using APM, you can identify service boundaries using the service map or dependencies features. A service component is on a boundary if it has no inbound connections. In the example below (from a service map), you can see that the WebPortal is on the boundary. An example of using service maps in New Relic One to identify service boundaries. In contrast, the following screenshot (from the dependencies page) shows that the Inventory Service is not on a boundary since it has incoming connections from the WebPortal. Subsequent examples in this guide will build on the WebPortal service boundary. An example of using the dependencies UI in New Relic One to identify service boundaries. You should understand that the SLM process defines a service boundary as being downstream of any dependencies. The service boundary is the point where all the effects and impacts of dependent services are measured as they contribute to the total response time and quality of the service. By measuring service level compliance at the boundary, you will be able to see the impact that all service components upstream of the boundary have on service delivery. This means that your initial steps into SLM can focus on the services that are closest to your users, yet still capture the contribution of more distant services. As your practice matures, you will be able to identify the next round of upstream services that would benefit from direct SLM instrumentation. In our example, the WebService is downstream of the Fulfillment, Plan, Promo, Login, and Inventory services (among others). By applying SLM at the WebService, we will be seeing the impact of the upstream services on the WebService. Any impactful issues with an upstream service will be reflected in the WebService’s service level KPIs. By instrumenting one service, we are capturing the contribution of five additional services. This greatly simplifies our observability practice. In time, problematic upstream services will self-identify themselves as candidates for direct SLM instrumentation. Deploy instrumentation To collect SLM service response time and transaction success KPIs, you need to deploy instrumentation into the components of your production apps on the service boundary. If you don’t have instrumentation that can do this in production already, then you will need to engage the teams and stakeholders that can help you to get this done. For detailed information on deploying the New Relic instrumentation that can gather this information, see our APM install documentation. The uptime KPIs can be collected using synthetic transactions, which don’t require any instrumentation to be added to the service. If needed, you can start your SLM journey there while waiting for the direct instrumentation to be deployed. The uptime tests should perform a basic, yet realistic, check of the service’s functionality. For detailed information on this capability, see our synthetic monitoring documentation. Perform SLM educational workshops You should share the self-paced New Relic Essentials training course with the appropriate stakeholders so they can understand how the New Relic technology platform will aid in the SLM process. Analyze KPIs and set baseline SLOs The SLM process uses speed and quality as its key performance indicators. In technical terms, speed means response time and quality means error rate. At the end of this phase, you will have created baseline service level objectives for each service in the form of a percentage. For example: “98% of service X’s transactions will be error free and occur in less than 500 milliseconds.” For each in-scope service, you should analyze speed and quality at the service boundary. This will give you an overall understanding of how the entire service and all of its dependencies are performing. As you iterate through the SLM process, you can then identify and prioritize the upstream service components that require direct SLM instrumentation. To analyze KPIs, you should do the following for each service: Identify the volume and 95th percentile response time for each of the service’s transactions over a relatively long period of time, typically between seven days and one month. It is important that you use percentile rather than average, so you can see the entire range of response times, including outliers. If you use averages, you will hide outliers. The following is an example of the initial baseline report. Here you can see the volume, p95 response time, and error volume for the WebPortal and a few other services. The WebPortal’s p95 response time is .36 seconds (or 36 milliseconds), so we have decided to set the SLO target to 0.4 seconds. Example of an initial baseline report measuring volume and 95th percentile response time. Next you should review and identify any non-business transactions, since they should not be included in the SLO attainment calculation. For example, you should not include health check / keep alive transactions and you may not want to include administrative transactions. In the example below, we are looking at some of the transactions from the WebPortal service. We have decided that the about.jsp transaction is a non-business transaction that should not be tracked in our SLO attainment calculation. Example showing transaction breakdowns from the initial baseline report to help identify what to track (or not track) for SLO. Finally, import and edit the SLM template dashboard to exclude non-business transactions. Then use the p95 response time as your baseline response time service level objective. For the example chart, we chose 0.4 seconds as our response time threshold and set our service level objective to 95%. This means that we are expecting 95% of the WebPortal’s business transactions to complete in 0.4 seconds or less and without an error. The red line on the chart shows us our 95% service level objective. Example chart now excluding the non-business transactions. As you can see, there are periods of hours where the app is not meeting its SLOs. If we are going to maintain the 95% target, we would need to identify and fix the service components or dependencies that are causing these problems. Establish or optimize alerting After you have set your service level objectives, you will then configure alerts that will inform you when your SLO attainment has dipped below your goal. These alerts will show you when incidents with a high business impact are occurring. When they are triggered, they should be given a high priority and you should engage the proper teams to start the process of diagnosing the source of the problem. A basic starting point is to configure an alert that triggers when your SLO attainment has dipped under your baseline for more than 10 minutes. For more information, see our documentation on configuring alerts. Build problem resolution workflows As we’ve been discussing, the intent of the SLM process is to identify when business impacting issues occur in your IT services. When this occurs, a diagnostic investigation should be launched. The goal of the investigation is to identify what service element is causing the business impacting issue. SLM tells you that there is a problem with business impact, the diagnostic process helps you to find where the problem is. Typically, your high level diagnostic workflow will start at the service boundary and go as follows: Look at the service’s individual transactions and see which one(s) are departing from their performance and/or response time SLOs. Look at each service component responsible for delivering that transaction until you find the component that is failing. Use in-depth diagnostics to identify the root cause of the problem and then resolve it. Execute continuous improvement review This is an ongoing phase of the SLM process where data is reviewed and adjustments are made as required. Your KPIs should be reported to upper management to ensure that stakeholder teams are appropriately prioritizing work and that you are meeting the SLO goals you’ve set. Periodic KPIs should be recorded and retained over periods of months to years to establish a baseline and to show the rate of improvement. In addition, each time you execute the continuous improvement process, you should: Review each service’s architecture to ensure your instrumentation is deployed at the boundary and that there are no observabilty gaps. Review each service’s transactions to confirm that only business transactions are included in your SLO calculations. Review each service’s SLO and determine if it meets the business’s performance and quality requirements. If it does not, then the SLO should be changed and the appropriate stakeholders notified so they can work to improve performance and quality. Review your SLO attainment and determine if any upstream services should be added to the SLM process. Next steps After you’ve established the SLM process, you should identify other services that would benefit from SLM instrumentation. These may be other front-line services or upstream dependencies of services that are covered by SLOs that have shown themselves to be frequent contributors to SLO attainment failures. As you do this, you should start to measure and report your SLM coverage as a percentage of applications covered by SLOs. For example, you may say that 20% of your apps have established SLOs. As SLM expands into your organization and as its value is seen by management and other stakeholders, you may find that you need a dedicated team to manage the SLM process. The SLM process should also become a primary driver to help you prioritize issue resolution activities. SLO attainment failures are a direct indicator that your IT services are having a negative business impact which is visible to your customers as poor performance and/or unhandled errors. Value realization Once the SLM process is established, you will see a reduction in the effort required to identify business impacting issues, a better ability to communicate with your business stakeholders, and an easier time proving the business’ return on investment in IT services. Your SLM KPIs will provide quantifiable proof of these improvements. In addtion, you should be able to simplify your observability strategy by removing or reducing your dependency on legacy consumption metrics and the logic required to correlate them against your true goal of measuring performance and quality. Once you are firmly on the path to SLM's goals, consider moving to other use cases within the Uptime, Performance, and Reliability value stream, such as Service Level Management, or Reliability Engineering. You can also move to other observability maturity value streams, such as Customer Experience. Additional resources Need help getting started? Check out the self-paced service level management training",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.93547,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Service</em> level management use case <em>implementation</em> <em>guide</em>",
        "sections": "<em>Service</em> level management use case <em>implementation</em> <em>guide</em>",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": " on the path to SLM&#x27;s goals, consider moving to other use cases within the Uptime, Performance, and Reliability value stream, such as <em>Service</em> Level Management, or Reliability Engineering. You can also move to other <em>observability</em> <em>maturity</em> value streams, such as Customer Experience. Additional resources Need help getting started? Check out the self-paced <em>service</em> level management training"
      },
      "id": "61403d0464441f0457424337"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/aqm-implementation-guide": [
    {
      "sections": [
        "Service level management use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Service response time",
        "Service quality",
        "Service level objective attainment",
        "Service uptime",
        "Prerequisites",
        "Establish current state",
        "Determine in-scope services",
        "Identify service boundaries",
        "Deploy instrumentation",
        "Perform SLM educational workshops",
        "Analyze KPIs and set baseline SLOs",
        "Establish or optimize alerting",
        "Build problem resolution workflows",
        "Execute continuous improvement review",
        "Next steps",
        "Value realization",
        "Additional resources"
      ],
      "title": "Service level management use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Uptime, performance, and reliability",
        "Service level management",
        "Implementation guide"
      ],
      "external_id": "e3c4da80186b6d33a301db4a15c0b0cff2034131",
      "image": "https://docs.newrelic.com/static/e2478328e46923877c6dd58993aecf5f/d9199/nrSLMServiceMap.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/slm-implementation-guide/",
      "published_at": "2022-01-12T05:57:34Z",
      "updated_at": "2021-11-25T05:19:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview IT Operations is expected to provide services that meet the business’s requirements for performance and reliability. However, many ops teams attempt to measure performance and reliability using legacy methods, like measuring resource consumption. That, in turn, requires that they create complex dashboards of granular metrics which they then try to correlate with application performance and reliability. These complex dashboards require subject matter experts to interpret the results for business stakeholders. Legacy methods create barriers to understanding what a good system state looks like and how bad system states impact the business. Essentially, IT ends up not sharing a common metric vocabulary with the business. This fundamental disconnect will result in the perception that IT is not able to deliver the services that the business requires, with all the implications and impacts that perception carries. Service Level Management (SLM) eliminates that disconnect by better explaining the overall performance of a system in terms that are easily understood by both IT and the business. The intent is to show whether or not the system is meeting its performance and reliability expectations, and if it is trending toward or away from improvement, so proactive steps can be taken. The end goal is that systems are better oriented toward desired business outcomes with IT’s attention focused on issues in areas with the highest business impact. You are a good candidate for SLM if any of the following are true: The business impact of performance and reliability issues are not well understood by all stakeholders. Your MTTx is too high. You are collecting many resource consumption metrics (such as CPU, disk, or memory) or are maintaining many metric correlation rules in order to identify system problems. You can’t see the value of your observability tool(s). Desired outcome Service Level Management’s overall goal is to easily measure and communicate the overall health, performance, and quality of your digital products and services to all stakeholders. By implementing SLM at key output points in your systems, you will have a simpler and more responsive observability practice, tighter alignment with the business, and faster paths to improvement. The SLM process described in this guide will help you to identify the points in your systems where you should measure the key performance metrics of service performance and quality. It will also define and drive a simpler alerting strategy, continuous improvement methodologies, and improved problem resolution workflows. Key performance indicators You will use the SLM process to collect and measure the following KPIs, often referred to as the “Golden Signals”: Service response time Service response time measures the amount of time a service requires to process a transaction. It starts when a transaction request is received by the service and ends when the response is sent. Goal: Reduce transaction response time. Best practices: Measure response time at service boundaries. Use continuous improvement processes to drive down response times. Ensure that non-business transactions (such as health checks) are not included or measured. Map this KPI back to business impact. Report KPIs to all stakeholders. Service quality Service quality is the number of transactions that result in an unhandled error. Typically, these are transactions whose HTTP response code is greater than or equal to 400. Goal: Reduce the number of unhandled errors. Best practices: Measure error rates at service boundaries. Continually identify and remediate sources of high error volumes. Map this KPI back to business impact. Report KPIs to all stakeholders. Service level objective attainment SLO attainment is the percentage of time a business service is meeting its response time and quality goals. Goal: Improve response time and quality to ensure high SLO attainment. Best practices: Use continuous improvement processes to maintain / improve SLO attainment. Map this KPI back to business impact. Report KPIs to all stakeholders. Service uptime Service uptime is the percentage of time a service can be reached by at least one client. Typically this is measured using synthetic transactions from representative remote locations. Goal: Use continuous improvement processes to watch uptime metrics and take appropriate steps to ensure uptime meets business requirements. Best practices: Use continuous improvement processes to maintain / improve SLO attainment. Map this KPI back to business impact Report KPIs to all stakeholders. These KPIs directly measure the most important aspects of an IT service, speed and quality, in a way that is easy and intuitive to understand and communicate to technical and non-technical stakeholders. Prerequisites Before you begin, if you don’t have equivalent experience, you should complete the New Relic University (NRU) Overview Course. You should also have a basic understanding of: New Relic One APM and infrastructure monitoring New Relic One Dashboards and NRQL New Relic One alerting best practices Establish current state As with any continuous improvement process, the first step of SLM is to establish the current state of your KPIs. To do so, you will need to perform the following tasks: Determine in-scope services Identify service boundaries Deploy instrumentation Perform SLM educational workshops Analyze KPIs and set baseline SLOs Establish / optimize Alerting Build problem resolution workflows Execute continuous improvement review To help illustrate this process, we are going to apply it to an example IT service, an ecommerce site for a cellular telephone provider. Determine in-scope services You should first identify the IT services that are going to be in-scope for the initial iteration of the SLM process. These services should be key to ongoing business operations and as close to your customers as possible. Most commonly, you will be applying the SLM process to an application, since that is the service your customers are expecting you to deliver. SLM can be applied to infrastructure-based services; however, it is a more advanced application of SLM which is applicable to a much smaller set of organizations. If you are considering implementing SLM for infrastructure, you should ensure that the service(s) you are instrumenting are actually the closest to your organization’s end-customer. If your infrastructure is hosting a customer-facing app, then the app should be the target of SLM. Absent anything else, a good methodology for identifying in-scope services is to consult your disaster recovery plan. Typically, the most critical business services are prioritized there. Identify service boundaries Next, you should identify each service’s boundary, which is the service component that is closest to the client sending transaction requests. This should be the application receiving the request from the client, browser, or mobile device, and may also be known as the \"external API.\" Reverse proxies, CDNs, and load balancers are not part of the service boundary. Their service level compliance should be measured via the Uptime KPI (external test requests for connectivity). If your services are using APM, you can identify service boundaries using the service map or dependencies features. A service component is on a boundary if it has no inbound connections. In the example below (from a service map), you can see that the WebPortal is on the boundary. An example of using service maps in New Relic One to identify service boundaries. In contrast, the following screenshot (from the dependencies page) shows that the Inventory Service is not on a boundary since it has incoming connections from the WebPortal. Subsequent examples in this guide will build on the WebPortal service boundary. An example of using the dependencies UI in New Relic One to identify service boundaries. You should understand that the SLM process defines a service boundary as being downstream of any dependencies. The service boundary is the point where all the effects and impacts of dependent services are measured as they contribute to the total response time and quality of the service. By measuring service level compliance at the boundary, you will be able to see the impact that all service components upstream of the boundary have on service delivery. This means that your initial steps into SLM can focus on the services that are closest to your users, yet still capture the contribution of more distant services. As your practice matures, you will be able to identify the next round of upstream services that would benefit from direct SLM instrumentation. In our example, the WebService is downstream of the Fulfillment, Plan, Promo, Login, and Inventory services (among others). By applying SLM at the WebService, we will be seeing the impact of the upstream services on the WebService. Any impactful issues with an upstream service will be reflected in the WebService’s service level KPIs. By instrumenting one service, we are capturing the contribution of five additional services. This greatly simplifies our observability practice. In time, problematic upstream services will self-identify themselves as candidates for direct SLM instrumentation. Deploy instrumentation To collect SLM service response time and transaction success KPIs, you need to deploy instrumentation into the components of your production apps on the service boundary. If you don’t have instrumentation that can do this in production already, then you will need to engage the teams and stakeholders that can help you to get this done. For detailed information on deploying the New Relic instrumentation that can gather this information, see our APM install documentation. The uptime KPIs can be collected using synthetic transactions, which don’t require any instrumentation to be added to the service. If needed, you can start your SLM journey there while waiting for the direct instrumentation to be deployed. The uptime tests should perform a basic, yet realistic, check of the service’s functionality. For detailed information on this capability, see our synthetic monitoring documentation. Perform SLM educational workshops You should share the self-paced New Relic Essentials training course with the appropriate stakeholders so they can understand how the New Relic technology platform will aid in the SLM process. Analyze KPIs and set baseline SLOs The SLM process uses speed and quality as its key performance indicators. In technical terms, speed means response time and quality means error rate. At the end of this phase, you will have created baseline service level objectives for each service in the form of a percentage. For example: “98% of service X’s transactions will be error free and occur in less than 500 milliseconds.” For each in-scope service, you should analyze speed and quality at the service boundary. This will give you an overall understanding of how the entire service and all of its dependencies are performing. As you iterate through the SLM process, you can then identify and prioritize the upstream service components that require direct SLM instrumentation. To analyze KPIs, you should do the following for each service: Identify the volume and 95th percentile response time for each of the service’s transactions over a relatively long period of time, typically between seven days and one month. It is important that you use percentile rather than average, so you can see the entire range of response times, including outliers. If you use averages, you will hide outliers. The following is an example of the initial baseline report. Here you can see the volume, p95 response time, and error volume for the WebPortal and a few other services. The WebPortal’s p95 response time is .36 seconds (or 36 milliseconds), so we have decided to set the SLO target to 0.4 seconds. Example of an initial baseline report measuring volume and 95th percentile response time. Next you should review and identify any non-business transactions, since they should not be included in the SLO attainment calculation. For example, you should not include health check / keep alive transactions and you may not want to include administrative transactions. In the example below, we are looking at some of the transactions from the WebPortal service. We have decided that the about.jsp transaction is a non-business transaction that should not be tracked in our SLO attainment calculation. Example showing transaction breakdowns from the initial baseline report to help identify what to track (or not track) for SLO. Finally, import and edit the SLM template dashboard to exclude non-business transactions. Then use the p95 response time as your baseline response time service level objective. For the example chart, we chose 0.4 seconds as our response time threshold and set our service level objective to 95%. This means that we are expecting 95% of the WebPortal’s business transactions to complete in 0.4 seconds or less and without an error. The red line on the chart shows us our 95% service level objective. Example chart now excluding the non-business transactions. As you can see, there are periods of hours where the app is not meeting its SLOs. If we are going to maintain the 95% target, we would need to identify and fix the service components or dependencies that are causing these problems. Establish or optimize alerting After you have set your service level objectives, you will then configure alerts that will inform you when your SLO attainment has dipped below your goal. These alerts will show you when incidents with a high business impact are occurring. When they are triggered, they should be given a high priority and you should engage the proper teams to start the process of diagnosing the source of the problem. A basic starting point is to configure an alert that triggers when your SLO attainment has dipped under your baseline for more than 10 minutes. For more information, see our documentation on configuring alerts. Build problem resolution workflows As we’ve been discussing, the intent of the SLM process is to identify when business impacting issues occur in your IT services. When this occurs, a diagnostic investigation should be launched. The goal of the investigation is to identify what service element is causing the business impacting issue. SLM tells you that there is a problem with business impact, the diagnostic process helps you to find where the problem is. Typically, your high level diagnostic workflow will start at the service boundary and go as follows: Look at the service’s individual transactions and see which one(s) are departing from their performance and/or response time SLOs. Look at each service component responsible for delivering that transaction until you find the component that is failing. Use in-depth diagnostics to identify the root cause of the problem and then resolve it. Execute continuous improvement review This is an ongoing phase of the SLM process where data is reviewed and adjustments are made as required. Your KPIs should be reported to upper management to ensure that stakeholder teams are appropriately prioritizing work and that you are meeting the SLO goals you’ve set. Periodic KPIs should be recorded and retained over periods of months to years to establish a baseline and to show the rate of improvement. In addition, each time you execute the continuous improvement process, you should: Review each service’s architecture to ensure your instrumentation is deployed at the boundary and that there are no observabilty gaps. Review each service’s transactions to confirm that only business transactions are included in your SLO calculations. Review each service’s SLO and determine if it meets the business’s performance and quality requirements. If it does not, then the SLO should be changed and the appropriate stakeholders notified so they can work to improve performance and quality. Review your SLO attainment and determine if any upstream services should be added to the SLM process. Next steps After you’ve established the SLM process, you should identify other services that would benefit from SLM instrumentation. These may be other front-line services or upstream dependencies of services that are covered by SLOs that have shown themselves to be frequent contributors to SLO attainment failures. As you do this, you should start to measure and report your SLM coverage as a percentage of applications covered by SLOs. For example, you may say that 20% of your apps have established SLOs. As SLM expands into your organization and as its value is seen by management and other stakeholders, you may find that you need a dedicated team to manage the SLM process. The SLM process should also become a primary driver to help you prioritize issue resolution activities. SLO attainment failures are a direct indicator that your IT services are having a negative business impact which is visible to your customers as poor performance and/or unhandled errors. Value realization Once the SLM process is established, you will see a reduction in the effort required to identify business impacting issues, a better ability to communicate with your business stakeholders, and an easier time proving the business’ return on investment in IT services. Your SLM KPIs will provide quantifiable proof of these improvements. In addtion, you should be able to simplify your observability strategy by removing or reducing your dependency on legacy consumption metrics and the logic required to correlate them against your true goal of measuring performance and quality. Once you are firmly on the path to SLM's goals, consider moving to other use cases within the Uptime, Performance, and Reliability value stream, such as Service Level Management, or Reliability Engineering. You can also move to other observability maturity value streams, such as Customer Experience. Additional resources Need help getting started? Check out the self-paced service level management training",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.34317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Service level <em>management</em> use case <em>implementation</em> <em>guide</em>",
        "sections": "Service level <em>management</em> use case <em>implementation</em> <em>guide</em>",
        "tags": "<em>Uptime</em>, <em>performance</em>, <em>and</em> <em>reliability</em>",
        "body": " on the path to SLM&#x27;s goals, consider moving to other use cases within the <em>Uptime</em>, <em>Performance</em>, and <em>Reliability</em> value stream, such as Service Level <em>Management</em>, or <em>Reliability</em> Engineering. You can also move to other <em>observability</em> <em>maturity</em> value streams, such as Customer Experience. Additional resources Need help getting started? Check out the self-paced service level <em>management</em> training"
      },
      "id": "61403d0464441f0457424337"
    },
    {
      "sections": [
        "Quality foundation implementation guide",
        "Overview",
        "Desired Outcome",
        "Key Performance Indicators",
        "Availability",
        "Largest contentful paint (LCP)",
        "First input delay (FID)",
        "Cumulative layout shift (CLS)",
        "Time to first byte (TTFB)",
        "Ajax response times",
        "HTTP error rate",
        "JavaScript error rate",
        "Prerequisites",
        "Required knowledge",
        "Required Installation and Configuration",
        "Establish current state",
        "Review instrumented pages",
        "Validate Browser URL grouping",
        "Understand how you will segment your data",
        "Import the quality foundation dashboard",
        "Capture current performance for each dashboard page",
        "Improvement Process",
        "Plan your work",
        "Decide which KPIs to improve",
        "Improve targeted KPIs",
        "Improve page load performance",
        "Improve AJAX response times",
        "Improve the AJAX error rate",
        "Improve JavaScript errors",
        "Conclusion"
      ],
      "title": "Quality foundation implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Customer experience",
        "Digital customer experience",
        "Implementation guide",
        "Quality Foundation"
      ],
      "external_id": "91186ed56e33e040c73d1fff940cec0644c199f6",
      "image": "https://docs.newrelic.com/static/9238160720501f4423dff703746fb59d/d9199/cx-what-you-can-measure-nr.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/customer-experience/quality-foundation-implementation-guide/",
      "published_at": "2022-01-12T05:56:50Z",
      "updated_at": "2022-01-12T05:56:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Digital customer experience is your end user’s experience across all your digital touch points. There are four core factors that impact a user’s experience: Availability (Is it reachable?) Performance (Does it perform well enough to be usable?) Content quality (Does it have what users need and can they find it?) Product and content relevance (Does it have what users care about?) Digital customer experience includes web, mobile, and IoT. The first version of this guide is focused on measuring the end user web experience. Quality Foundation is about creating a standard practice to help you understand your digital customer experience in a meaningful way. This implementation guide will help you: Look at customer experience in relation to: Global functions, such as search and login Lines of business Regions Report back to business stakeholders on what they care about Prioritize what you work on Create a repeatable practice Desired Outcome Improve customer engagement and retention by measuring and improving performance in a way that better aligns to the end user experience. Key Performance Indicators Quality Foundation measures the following KPIs: Availability This KPI measures whether or not your application or its pages can be accessed by your users Goal: Improve uptime and availablity Thresholds: < 99% warning < 95% critical 99% or \"2 9's\" is a good minimum standard of availability, even for employee applications or sub-pages. We configure these default thresholds into the dashboards. You can easily change this to better suit expectations for your application. Largest contentful paint (LCP) Part of Core Web Vitals. Largest Contentful Paint (LCP) measures the time it takes to load the largest image after a user has navigated to a new page. Goal: Reduce LCP to 2.5 seconds or better for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 2.5 seconds Critical: > 4.0 seconds LCP thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. First input delay (FID) Part of Core Web Vitals. Measures the interactivity of a page by tracking the time between user interaction (such as clicking a link or entering text) when the browser begins processing the event. Goal: Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 100 milliseconds Critical: > 300 milliseconds FID thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. Cumulative layout shift (CLS) Part of Core Web Vitals. Measures how much the page layout shifts during render. Goal: Maintain a score of 0.1 or less for the 75% percentile for all pages or at least the most critical pages. Thresholds: Warning: > 0.1 score Critical: > 0.25 score CLS thresholds are defined by the team at Google. The thresholds and the supporting logic behind them can be found here. Time to first byte (TTFB) This KPI measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server. Google considers TTFB secondary to Core Web Vitals. We recommend measuring it for a more complete picture. It can be revealing if you see a change in LCP, because it answers the question as to whether the change occurred server side or client side. Goal: Reduce the time to first byte by improving CDN, network, and service performance. Thresholds: Warning > 0.5 seconds Critical > 1.0 seconds According to Google and Search Engine People, 500 milliseconds is a decent TTFB for pages with dynamic content. You can find mention of these recommendations here. Ajax response times Slow ajax calls can make the user feel as though nothing is happening or the page is broken. If the response time is slow enough, users may even abandon the journey. Goal: Measure and improve ajax response times. Thresholds: Warning > 2 seconds Critical > 2.5 seconds These thresholds come from experience with customers across a variety of industries. HTTP error rate HTTP errors (or HTTP 4xx and 5xx responses) happen when calls to the backend are not successful. Goal: Measure and reduce the HTTP error rate to ensure your customers are able to do what they came to your site to do. Thresholds: Warning < 99% of requests are successful Critical < 97% of requests are successful These thresholds come from experience with customers across a variety of industries. We made the assumption that every ajax request is associated with something the user is trying to achieve and treat it accordingly. Because users will often retry failed actions, we allowed for space between warning and critical thresholds. If the ajax requests being measured are an important part of the user journey, we recommended aiming for higher success rates, such as 99.5% or 99.9%. If the ajax requests are tied to login requests, separate 4xx response codes from 5xx response codes and set a much lower threshold for the 4xx responses. You can look to historical response code rates to determine a reasonable threshold. JavaScript error rate This KPI measures the number of JavaScript errors per page view. Goal: Remove irrelevant JavaScript errors being tracked either by tuning ingest or using filtering. Reduce JavaScript errors that impact customer performance. Thresholds: Warning: > 5% errors per page view Critical: > 10% errors per page view These thresholds come from experience with customers across a variety of industries. For each KPI, we defined thresholds - one for warning, another for critical. You might ask where these values come from or how you can be sure they should apply to your application. Our thresholds are the ones recommended by Google (as with Core Web Vitals) or by us, based on our experience across a large number of customers and applications. If you feel strongly that they should be different, you can adjust them, but you should do this at the organizational level rather than on an application by application basis. Quality Foundation helps you identify where in your application you need to make improvements that will optimize user retention, conversion and satisfaction. It is less about where things are and more about where to get to. It also shows you what you should be measuring going forward. You can use this to define SLOs (in a service level dashboard) and alert on them. Prerequisites Required knowledge Familiarity with synthetic monitoring Familiarity with browser monitoring Familiarity with basic Browser UI views Familiarity with SPA data in Browser UI Required Installation and Configuration Browser Pro installed in all pages SPA enabled for single page applications Synthetics monitors configured: Ping monitors configured for anonymous users Scripted synthetics check configured for login flow Monitors should be configured to test from all regions applicable to your users Monitors should be configured for each domain and each login flow Data retention for browser events greater than or equal to 2x an average sprint Establish current state Review instrumented pages Validate Browser URL grouping Understand how you will segment your data Import the quality foundation dashboard Capture current performance for each dashboard page Review instrumented pages Review Browser apps and pages to make sure that everything you expect to report back to New Relic is. You can do this by reviewing the Page Views tab in the Browser UI or running the following query: SELECT uniques(pageUrl) from PageView LIMIT MAX Copy You may need to filter out URLs that contain request or customer ID. Validate Browser URL grouping Ensure Browser segments are captured correctly so user experience performance is measurable in both the NewRelic UI as well as at the aggregate level when querying via NRQL. A segment is the text between two / in a URL or between . of a domain name. For example, in the URL website.com/product/widget-name, the segments are: website .com product widget-name When there are a lot of URLs with a lot of segments, URLs can get crushed, so that website.com/product/widget-name becomes website.com/ or website.com/product/. In this example, the first crushed URL is not particularly useful, but the second one may be a useful way of aggregating customer experience data for the product. Not sure whether you need to tune your configuration? Import the Segment Allow List Investigation dashboard in GitHub to help. Once you’ve identified which segments to add, you can add them using Segment allow lists in Browser. Understand how you will segment your data Make Customer Experience data understandable and actionable by breaking it out into different segments. In this case, segments refer to groups of data. It does not refer to sections of URLs, as in segment allow lists. Consider the following statements: Most of our users experience 3 seconds or better to first input delay. On average, we see 2 seconds to the largest contentful paint. Last week, there were 1 million page views. Compared to: Most of the users in the US, Canada, and EMEA experience 2 seconds or better to first input delay. Malaysia and Indonesia users experience 4 seconds; we are looking into this. Customers buying car insurance typically see 1 second to largest contentful paint. For home insurance, it’s 4 seconds. Last week, there were 700,000 page views on mobile browser apps compared to 300,000 on desktop. Let’s make sure we’re optimizing our mobile experience. Typical segmentation involves breaking down user experience into the following categories: Segment Guidance Region/Location Basic: Group by country. Browser events automatically contain the country code of requests, so there is nothing you need to do to break it out further. Advanced: Make regional grouping match regional SLO groups by creating your own region attribute using custom attributes in Browser. Facet by countryCode. Related attributes: regionCode city asnLatitude asnLongitude Device Break out performance and engagement device type so you can understand: Typical breakdown of desktop vs mobile browser users Experience of desktop vs mobile browser users Facet by deviceType. Related attributes: userAgentName userAgentOS userAgentVersion Product/Line of Business In this scenario, a product is a separate line of business or service provided by your organization. Some examples of industries and respective products: An insurance company that sells both car and house insurance A media company that has multiple streaming services or channels A travel company that provides car rental as well as hotel bookings Basic: Break out performance by product by: Faceting on pageUrl: Use this approach when multiple products are grouped into one browser app in New Relic. Faceting by appName: Use this approach when each product is instrumented as a separate web app. Grouping by appName and then facet: Use this approach when there are multiple apps in browser supporting one product. Advanced: Add product offering as a custom attribute to browser pages using custom attributes. Environment During instrumentation or afterwards, follow a naming convention that specifies the environment in Browser. Well named browser apps specify product and/or function as well as environment. Examples: account-management.prod hotels-book.prod car-insurance.uat Using app naming conventions to specify the environment supports filtering data in both the UI and in dashboards. For more information, see the documentation for how to rename Browser apps. Team In some organizations, a single team supports multiple products, while in others, a product is big enough to be supported by multiple teams. Report on team performance against customer experience or engagement by either adding the team name to the Browser app name (for example, account-management.prod.unicorn-squad) or by using custom attributes. Import the quality foundation dashboard This step creates the dashboard that you will use to measure your customer experience and improve it. Clone the GitHub repository. Follow the GitHub repository README instructions to implement the dashboard. Make sure to align the dashboard to lines of business or customer facing offerings rather than teams. This ensures optimization time is spent where it is most impactful. Capture current performance for each dashboard page Follow the GitHub README instructions. Use the dashboard from the previous step to understand the overall performance for each line of business. If relevant, apply filters to see performance across region or device. If values drop below targets and it matters, add it to the sheet as a candidate for improvement. Not worth tracking: A company that sells insurance in the US only notices poor performance in Malaysia. Worth tracking: A company that sells insurance in the US only notices poor performance with respect to mobile users in the US. Improvement Process Plan your work Decide which KPIs to improve Improve targeted KPIs Improve page load performance Improve AJAX response times Improve the AJAX error rate Improve JavaScript errors Plan your work Whether you have a dedicated initiative to improve performance or classifying as ongoing maintenance, you need to track your progress at the end of every sprint. Decide which KPIs to improve You now know what your user experience looks like across multiple lines of business. Where should you be improving? Start with business priorities. If you have clear business directives or have access to a senior manager above who does, you should focus on what matters most to your organization. For example, let’s say your company has recently launched a new initiative around a line of business but the KPIs associated with the UI are below target. This is where you should focus time initially. Next, focus on KPIs for each line of business. Finally, filter each line of business by device, region, etc., to see if additional focus is needed for specific regions or devices. Improve targeted KPIs To track your progress, create a new dashboard or add a new page to the existing dashboard and name it Quality Foundation KPI Improvement. For more information, see Improve Web Uptime. Improve page load performance Narrow your focus to specific pages that aren’t meeting target KPI values. For each page load KPI result that is out of bounds in the Quality Foundation Dashboard, remove the COMPARE WITH clause and add FACET pageUrl/targetGroupedUrl LIMIT MAX to find which pages are the poor performers. Use targetGroupedUrl when there are many results; for example, when the customer ID is part of the URL. Otherwise, use pageUrl. Original Dashboard query: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' SINCE 1 week AGO COMPARE WITH 1 week AGO Copy New query to identify problem pages: FROM PageViewTiming SELECT percentile(largestContentfulPaint, 75) WHERE appName ='WebPortal' AND pageUrl LIKE '%phone%' FACET targetGroupedUrl LIMIT MAX Copy Once you have identified which pages to improve, improve them following these best practices. Improve AJAX response times Find the slow requests. Go to the Ajax duration widget on the dashboard. View query, then open in query builder. Add facet requestUrl LIMIT MAX to the end of the query. Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - AjaxResponseTimes. Focus improving requests with a timeToSettle > 2.5s. Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve the AJAX error rate Find the failing requests. Go to Dashboards > Query builder. Enter FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND <Ajax Request filter> SINCE 1 week AGO facet pageUrl, appName Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Pages with AjaxErrors. Run the query again for the most problematic pages to find the requests that are failing: FROM AjaxRequest SELECT percentage(count(*), WHERE httpResponseCode >= 400) WHERE httpResponseCode >= 200 AND pageUrl=<problematic page> AND appName = <corresponding app> <Ajax Request filter> SINCE 1 week AGO facet requestUrl Copy Use New Relic’s recommended best practices to improve response times. See AJAX troubleshooting tips. Improve JavaScript errors Find the most common failures. Go to Dashboards > Query builder Enter FROM JavaScriptError SELECT count(errorClass) SINCE 1 week AGO WHERE <PageView filter> FACET transactionName, errorClass, errorMessage, domain Copy Run the query. View the results as a table and save to your KPI Improvement dashboard as LOB - Javascript Errors. Use this information to figure out which errors need to be addressed Use New Relic’s recommended best practices to resolve errors that need addressing. See JavaScript errors page: Detect and analyze errors. Remove third party errors that do not add value. You may be using a third party JavaScript that is noisy but works as expected. You can take a couple of approaches: Remove the domain name from the JavaScript error/Pageview ratio widget and add it as its own widget so you can see unexpected changes. You can alert on this using Baseline NRQL alerts. Drop the JavaScript error using drop filters. Only use this option if the volume of errors is impacting your data ingest in a significant way. Be as specific as you can in the drop filter. Conclusion Best practices to adopt Revisit performance metrics (shared in this document as Quality Foundation KPIs) at the end of each sprint. Incorporate performance improvements into developer sprints. Openly share metrics with the lines of the business you support as well as other internal stakeholders. Define Customer Experience SLOs. Create alerts for business critical drops in Quality Foundation KPIs. Value Realization At the end of this process you should now: Have an understanding of your end user experience in a way that is tangible, actionable, and easy for engineers as well as the business to understand. Know how releases impact your end customers. Know how your customers are impacted by service, infrastructure, or network level events. See latency issues caused by backend services if they exist. Have created, or be on the path to create, a common language with business owners so you are working together. This can open new avenues for recognition and sponsorship for new projects.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.1539,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Quality</em> foundation <em>implementation</em> <em>guide</em>",
        "sections": "<em>Quality</em> foundation <em>implementation</em> <em>guide</em>",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": "Overview Digital customer experience is your end user’s experience across all your digital touch points. There are four core factors that impact a user’s experience: Availability (Is it reachable?) <em>Performance</em> (Does it <em>perform</em> well enough to be usable?) Content <em>quality</em> (Does it have what users need"
      },
      "id": "61461531e7b9d25774b6f22d"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/writer-workflow/github-troubleshooting/",
      "sections": [
        "GitHub troubleshooting",
        "GitHub authentication fails",
        "My build is failing mysteriously",
        "Diagnose markdown errors with yarn-verify",
        "Example: Troubleshoot with yarn-verify",
        "Issues with the local site",
        "Stop and restart yarn",
        "Ensure the problem isn't with your branch",
        "Clean your local cache",
        "Remove corrupted cache files",
        "Start a build from start",
        "Important",
        "Run your local build in private mode",
        "My redirect throws a 404 error when testing it locally",
        "A check fails in the PR",
        "Reset the 'build the docs site' build check",
        "Caution",
        "Troubleshoot merging conflicts",
        "What’s new related merge conflicts"
      ],
      "published_at": "2022-01-12T18:25:36Z",
      "title": "GitHub troubleshooting",
      "updated_at": "2021-12-04T10:44:53Z",
      "type": "docs",
      "external_id": "8ac23cfb3c3f1453d33e2082e46967a6f29cd508",
      "document_type": "page",
      "popularity": 1,
      "body": "Are you having problems working on a doc in GitHub? Check out the following common issues. GitHub authentication fails If you suddenly find that you can no longer push to your remote branch in GitHub Desktop, you may have developed a problem with SSH. If logging out of GitHub Desktop via Preferences doesn’t seem to help, you can confirm if you have an SSH issue by switching to the command line and trying to push manually. For example: git push --set-upstream origin second-kafka-pr-for-issue-1123 If this command prompts you for a passphrase, your SSH was somehow confused. By entering your passphrase, you should be back in business. If you can’t remember your passphrase, check out this article. My build is failing mysteriously Here’s a few things you can check if your build is failing: Indenting in the nav files Front matter If there's apostrophes and colons in frontmatter fields, surround them with quotes to avoid problems. Missing closed brackets or tags Poorly formatted image links Be careful when renaming images and their filename paths. A mismatch can cause the entire local build to fail. Be especially careful when dealing with image files that are imported. Image filenames Image filenames are case-sensitive. Using the wrong capitalization results in a missing image in the doc. Images with encoded values (like %) in the filename can be especially tricky, try to avoid them. Diagnose markdown errors with yarn-verify If you know which file is causing an error, you can further troubleshoot with the yarn verify-mdx path/to/file.mdx command. This command returns more information about the error than the normal Gatsby output. This includes things such as the specific character and line number causing the error. Example: Troubleshoot with yarn-verify Let's pretend I've made a changes to multiple docs in my branch. When I try to either run the site locally or access the Gatsby Cloud build, I get the following error: Unexpected character = (U+003D) before name, expected a character that can start a name, such as a letter, $, or _/usr/src/app/www/src/content/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/aqm-implementation-guide.mdx: Unexpected character = (U+003D) before name, expected a character that can start a name, such as a letter, $, or _ Copy The error does tell me that the doc with an error is /docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/aqm-implementation-guide.mdx. Other than that, all I know is that there is a = character messing things up somewhere. Cool, but this is a NRQL doc, there are a dozens of = characters. So, I run yarn verify-mdx src/content/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/aqm-implementation-guide.mdx. This returns the following: reading src/content/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/aqm-implementation-guide.mdx { \"message\": \"Unexpected character `=` (U+003D) before name, expected a character that can start a name, such as a letter, `$`, or `_`\", \"name\": \"284:227\", \"reason\": \"Unexpected character `=` (U+003D) before name, expected a character that can start a name, such as a letter, `$`, or `_`\", \"line\": 284, \"column\": 227, \"location\": { \"start\": { \"line\": 284, \"column\": 227, \"offset\": 19129, \"index\": 1 }, \"end\": { \"line\": null, \"column\": null } }, \"source\": \"remark-mdx\", \"ruleId\": \"unexpected-character\", \"fatal\": true } [ Copy In this case, the relvant info is: \"line\": 284, \"column\": 227, Copy and \"source\": \"remark-mdx\", \"ruleId\": \"unexpected-character\", \"fatal\": true Copy This tells me that there is an unexpected character in line 284, column 227. Then I can go to that section of the doc and further troubleshoot, knowing exactly where the error comes from. In this case, I likely just need to wrap a NRQL example in quotes. Issues with the local site If you're running with issues with your local build, try these options: Stop and restart yarn In the terminal, ensure you're in the /docs-website directory. Hit CONTROL+C to interrupt the yarn process, if necessary. Run yarn && yarn start. Ensure the problem isn't with your branch In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. In GitHub Desktop, commit any changes needed on your branch, and then switch to the Develop branch. Back in the terminal, run yarn && yarn start. If the site now builds correctly, the issue is with the changes in your branch. Stop Yarn again, go back to your branch, and troubleshoot. Clean your local cache Run yarn clean to blow away your local cache. This will make your next build slower, so make sure you have time! In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. Begin a new build by running yarn clean && yarn && yarn start. Remove corrupted cache files There may be times when your .cache directory has been corrupted. This directory is ignored by Git, which means that it travels with you from branch to branch. This might be the problem if your local builds are failing regardless of which branch you’re on. To solve this from your /docs-website directory, run rm -rf .cache. Start a build from start Blow away all your node modules, hidden .cache folder, and local cache and start a build from scratch. This takes a long time to run, around 10–20 minutes. In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. Blow away modules and cache and start from scratch by running the kknuke Keyboard Maestro command, or run yarn reboot in your terminal. Important If you use the kknuke Keyboard Maestro command, when everything completes, start the site by running yarn start. Run your local build in private mode Sometimes the local site builds, but pages within the site don't. Running the local build in a private/incognito session may to fix this issue. You can also try clearing out your browser's cache. My redirect throws a 404 error when testing it locally Redirects are a bit strange on local builds. To test them, navigate to the page that is being redirected, wait until it throws a 404, and then wait ~1-2 minutes. It should redirect you after a while. If it doesn’t, ensure you set up the redirect correctly. You can also test the redirects out in the Gatsby build. A check fails in the PR Important The only checks needed to merge a PR are the checks marked as required on the PR. These are run linter, run tests, license/cla, and unpaired translations removed for merges to develop, and build the docs site for merges to main. If a required check fails, the failure must be addressed in order for the PR to be merged. If an optional check fails, reach out in the help channel so that the hero can look into the failure, but feel free to merge the PR since optional checks don't block releases. Rarely, a build or check will fail due to some internal error. You can re-run the check by going to the PR, clicking Details, and then clicking Re-run jobs. If that doesn't fix it, you probably have genuine build errors. Pull down locally and troubleshoot. Reset the 'build the docs site' build check Caution This adds a LOT of time to the build check. There are times when this check fails. If this happens after your local builds have built successfully, you may need to force a rebuild of the cache. In your local repo, find the file gatsby-config.js (use CMD-P to jump to it fast in VSCode). Swap the first and second line of code. It doesn’t matter what order these lines are in, except to make the Gatsby Build check rebuild the cache. const fs = require('fs'); const parse = require('rehype-parse'); Save the file and commit the change to your PR. Re-run the build checks. Wait a LOOOOONG time. Troubleshoot merging conflicts Merge conflicts can seem pretty scary, but it’s ultimately just deciding between two different versions of a doc. Here are some tips on how to get through it. Fix your merge conflict as soon as possible. Especially if you’re working on taxonomy changes. If your branch lingers for a while it can get outdated from develop pretty fast and that can cause some unexpected issues. Check your fix locally to make sure that it looks good there. Ask your PR approver to review your PR after you fix the merge conflict. Here are two options to resolve conflicts: When you see the conflicts in GitHub desktop, click the option to resolve these in VS Code. Use the GitHub website editor (click the Resolve conflict button) to fix these. What’s new related merge conflicts Merge conflicts pop up pretty often with what’s new posts because the whats-new-ids.json file that’s automatically updated when the site builds can get out-of-date pretty fast. If you see changes to this file show up in GitHub Desktop, make sure to discard them, rather than push them up to your branch. This will make it less likely that other people will have to deal with merge conflicts related to this file. Caution Never merge a PR that changes whats-new-ids.json.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.56332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Stop <em>and</em> restart yarn",
        "body": "-relic-solutions&#x2F;<em>observability</em>-<em>maturity</em>&#x2F;<em>uptime</em>-<em>performance</em>-<em>reliability</em>&#x2F;aqm-<em>implementation</em>-<em>guide</em>.mdx: Unexpected character = (U+003D) before name, expected a character that can start a name, such as a letter, $, or _ Copy The error does tell me that the doc with an error is &#x2F;docs&#x2F;new-relic-solutions"
      },
      "id": "61a9ebd264441f22bd9286ae"
    }
  ],
  "/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/slm-implementation-guide": [
    {
      "sections": [
        "Alert quality management use case implementation guide",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "Incident volume",
        "Incident count KPI",
        "Accumulated incident duration KPI",
        "Mean time to close (MTTC) KPI",
        "Percent under 5 minutes KPI",
        "User engagement",
        "Percentage Acknowledged KPI",
        "Mean time to investigate (MTTI) KPI",
        "Prerequisites",
        "Establish current state",
        "Install and configure the incident event webhook",
        "Install the AQM dashboard",
        "Perform initial AQM orientation and enablement",
        "Accumulate AQM data",
        "Perform second enablement session",
        "Improvement process",
        "Value realization",
        "KPI reference",
        "Incident engagement",
        "Additional resources"
      ],
      "title": "Alert quality management use case implementation guide",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Uptime, performance, and reliability",
        "Alert quality management",
        "Implementation guide"
      ],
      "external_id": "b69abb6b9b6c1257482958e12952dc189aecec2a",
      "image": "https://docs.newrelic.com/static/2be50db00a885e2d8ada51aa391f60d1/748b0/nrAQMIncidentFlow.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/aqm-implementation-guide/",
      "published_at": "2022-01-12T05:57:34Z",
      "updated_at": "2021-11-25T05:13:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Overview Teams suffer from alert fatigue when they experience high alert volumes and alerts that are not aligned to business impact. As they start to believe that most alerts are false, they may prioritize easy to resolve alerts over others.  Also, they may close unresolved incidents so they can stay within their SLA targets. The result will be slower incident responses, magnified issue scope, and increased severity when true business impacting issues occur. Alert Quality Management (AQM) focuses on reducing the number of nuisance incidents so that you focus only on alerts with true business impact.  This reduces alert fatigue and ensures that you and your team focus your attention on the right places at the right times. You are a good candidate for AQM if: You have too many alerts. You have alerts that stay open for long time periods. Your alerts are not relevant. Your customers discover your issues before your monitoring tools do. You can't see the value of your observability tool(s). Desired outcome An alert strategy based on measuring business impact will result in faster response times and greater proactive awareness of critical events.  An improved alert signal to noise ratio reduces confusion and improves rapid identification and problem isolation. AQM's overall goal is to ensure that fewer, more valuable, incidents are created, resulting in: Increased uptime and availability Reduced MTTR Decreased alert volume The ability to easily identify alerts that are not valuable, so you can either make them valuable or remove them. The AQM process described in this guide generates the key performance indicators and metrics that you will use to measure progress towards these goals.  The metrics are measured in real time, published in a dashboard, and are used to drive a continuous improvement process that identifies and reduces nuisance alerts and increases user engagement in incident investigation. AQM does not encompass anomaly detection or AIOps, which are designed to detect unknown or unexpected modes of failure.  The two practices (AQM and ML/AI) work hand in hand, they are not mutually exclusive. Key performance indicators You will use the AQM process to collect and measure the following KPIs: Incident volume Incident Count Accumulated incident time Mean Time to Close (MTTC) Percent Under 5 Minutes User Engagement Mean Time to Investigate  (MTTI) % of Incidents Investigated These KPIs will help you to find the noisiest and least valuable alerts so you can improve their value or eliminate them.  You will then use the long term metric trends to show real business impact to management and stakeholders.  Detailed information on each metric follows. Incident volume You should treat incidents (with or without alerts) like a queue of tasks.  Just like a queue, the number of alerts should spend time near zero. Each incident should be a trigger for action to resolve the condition.  If an alert does not result in action, then you should question the value of the alert condition. If you see a constant rate of incidents or specific incidents that are \"always-on\", then you should question why. Are you in a constant state of business impact, or do you simply have a large volume of noise? The alert volume KPIs help you to answer those questions and to measure progress towards a healthy state of high quality alerting. Incident count KPI Incident Count is the number of incidents generated over a period of time. Typically you should compare the current and previous weeks. Goal: Reduce the number of low value / nuisance incidents. Best practices: Ensure condition settings are intended to detect real business impact. Ensure condition settings are detecting abnormal behavior. Communicate that the incident details \"Acknowledge\" feature helps measure meaningful and actionable alerts. See Percentage Incident Acknowledge KPI. Report AQM KPIs to all stakeholders. Accumulated incident duration KPI Accumulated incident duration is the total sum of minutes that all the incidents accumulated over a period of time. Typically you should compare the current and previous weeks. Goal: Reduce the total accumulated minutes of incidents. Best practices: Do not manually close incidents. Manual closure will skew the real duration of incident length. Eliminate alerts that do not result in any remediation actions from the recipients. Improve percent investigated and mean-time-to-investigate KPIs by communicating their importance in improving detection and response times. Report AQM KPIs to all Stakeholders. Mean time to close (MTTC) KPI Average duration of incidents within the period of time measured. Goal: Reduce MTTC Best practices: Do not manually close incidents. Manual closure will skew the real duration of incident length. Improve Reliability Engineering skills. Report AQM KPIs to all stakeholders. Percent under 5 minutes KPI Percentage of incidents where the duration of the incident is under five minutes. This can be an indicator of incident flapping. Goal: Minimize percentage of incidents with short durations Best practices: Ensure that conditions are detecting legitimate deviations from expected behavior. See Baselining and Service Level Management. Ensure that conditions are detecting legitimate deviations that correlate to business impact or impending business impact. User engagement You should measure the value of an incident by the amount of attention it receives.  Engagement in this context is measured by whether or not an incident has been acknowledged. The amount of engagement an individual alert receives is a direct measurement of its value.  More engagement implies a valuable alert, less (or zero) engagement implies a nuisance alert that should be modified or disabled. There is a significant difference between measuring the moment of incident awareness vs. acknowledging the moment resolution activity begins. If you are using an integration with New Relic Alerting, be sure that the \"acknowledge\" event that is sent to New Relic is triggered when resolution activity begins, not when the incident is sent to the external incident management tool.  For more information regarding the standard Incident Management process, see \"Incident Management Process: 5 Steps to Effective Resolution Posted on August 31, 2020 by OnPage Corporation. -- in reference to ITIL4\" Percentage Acknowledged KPI Incidents acknowledged identifies the percentage of incidents that have been engaged with and had their acknowledged property set to true. Typically you should compare the current and previous weeks. Goal: Increase the percentage of incident engagement. Best practices: Educate the DevOps team on when it is appropriate to acknowledge an incident alert. Gamify alert acknowledgement to drive usage. Discourage mass acknowledgement exercises. Mean time to investigate (MTTI) KPI Mean time to investigate identifies the average time it takes for an incident to be triaged. Typically you should compare the current and previous weeks. Goal: Reduce the mean time to investigate Best practices: Work at building incident responder's confidence in alerts. Ensure that valuable alerts are acknowledged. Incentivize response teams to respond quickly to alerts. Prerequisites Before you begin, if you don't have equivalent experience, complete the New Relic University (NRU) Overview Course. Also, make sure you have a basic understanding of: NR1 Alert policy and conditions configuration NR1 incident notification channel webhook configuration NR1 NRQL NR1 alerting best practices NR1 APM & Infrastructure How to baseline data in order to determine anomalies vs. normal behavior. Establish current state As with any continuous improvement process, the first step of AQM is to establish the current state of your KPIs. To do so, perform the following tasks: Install and configure the incident event webhook Install the AQM Dashboard Perform initial AQM orientation and enablement Accumulate AQM data Perform second enablement session Install and configure the incident event webhook The webhook will create New Relic events for each incident as it proceeds through its lifecycle (open, acknowledge, close). To ensure that the AQM process generates accurate and valuable findings, this webhook must be added as a notification channel to every alert policy. The AQM process requires incident, not violation data. This is why you will not be using the default NrAiIncident event, which provides violation data only.  Instead, you will use this webhook to send the required incident data to New Relic. To use the webhook, do the following: Identify your primary production account and each of your accounts that you will be analyzing with the AQM process. Install the incident event webhook into each account that will participate in the AQM process and configure the webhook to report nrAQMIncident events to your primary production account. Assign the webhook as a notification channel to every alert policy in each account. This example shows a webhook notification channel assigned to each alert policy for a New Relic account with multiple sub-accounts. The webhook, AQM dashboard, and detailed installation instructions can be found in the New Relic OMA resource center on GitHub. Install the AQM dashboard The AQM dashboard is the primary asset that drives the AQM process.  You need to install the AQM dashboard into the primary production account you identified in the \"Install and configure incident event webhook\" step you previously performed by doing the following: Download the dashboard definition JSON file from the New Relic OMA resource center GitHub repo. Import the definition into your primary production account. For more details on importing dashboards, see the New Relic Introduction to dashboards documentation Perform initial AQM orientation and enablement During this phase, your incident management team(s) and other stakeholders will learn the goals of the AQM process and the scope of their involvement in it. The most critical portion of this task is educating your team on the importance of acknowledging incident alerts, since that's how the alert's value is determined.  In general, instruct them to follow these guidelines: If you look at an alert and decide to take any sort of further investigative action, acknowledge the alert. If you typically close an alert without doing anything else, do not acknowledge the alert. If the incident alert is always on, do not close or acknowledge it. For further details, see Second Enablement Session. You can use the first session template presentation to communicate this material to your stakeholders. Accumulate AQM data The overall process requires at least two weeks of data before it can proceed.  During this time, you should periodically check the following items: Confirm that incident alert event data is accumulating. Confirm that the webhook is attached to every alert policy. Ensure that incident responders are following the alert acknowledgement guidelines. Perform second enablement session During this phase, you will introduce incident management teams and other stakeholders to the initial AQM data and the ongoing continuous  improvement process you'll be following. The process consists of four activities: Review AQM Dashboard and KPI Trending: Here you and the stakeholders will look at the AQM KPIs and identify their week over week trends.  The team should identify areas where KPIs are not improving and develop strategies to drive improvement. Identify Achievements, Challenges, and Opportunities: Here you and the stakeholders will map the current state of alert quality to business impact, identifying areas where improvement has resulted in better business outcomes and areas where problems are impacting business outcomes. Incident Policy Review: Using the AQM dashboard, you and the stakeholders will identify the noisiest incident policies.  Once identified, those policies should be evaluated as detailed in step 4 below. Alert Policy Recommendations: In this step, you and the stakeholders will review the noisiest policies using the following criteria: Do the alerts have any business impact? Are the policies properly configured? Are they telling us something about the resource that needs to be fixed? Are the policies necessary? Do they have business impact? Are the thresholds set properly? Technical recommendations: Here, you and the stakeholders will review any technical recommendations, including: Are there application / system problems for engineering to review? Are there poorly constructed policies that need to be fixed? Are there instrumentation gaps? You can use the second session template presentation to keep this part of the AQM process organized. Improvement process This is the ongoing phase of the continuous improvement process where you periodically review your accumulated AQM data and make adjustments as needed to alert policies. You should perform this step once a week until your alert volume is acceptable. You can then perform it less frequently. During this phase you should: Report your KPIs each week to upper management to ensure that the stakeholder teams are appropriately prioritizing the work and to show that progress towards the promised business outcomes are being reached. Record and retain your weekly KPIs  over periods of months to years to establish a baseline and to show the rate of improvement. You should keep in mind that this is a continuous improvment process, you will continue to collect and evaluate the KPIs over long periods of time to ensure you are meeting your AQM goals. Value realization Once the AQM process is established, you will see significant reductions in the volume of alerts while reliability and stability remain the same or improve.  In addition, you should see that your alerts have a clear and unambiguous business impact.  Your AQM KPIs will provide quantifiable proof of these improvements. Once you are firmly on the path to AQM's goals, consider moving to other use cases within the Uptime, Performance, and Reliability value stream, such as Service Level Management, or Reliability Engineering.  You can also move to other observability maturity value streams, such as Customer Experience. KPI reference Following are the descriptions of each KPI as well as sample NRQL queries that will extract them from the New Relic platform.  These KPIs are also included in the AQM dashboard that can be downloaded from the New Relic OMA resource center GitHub repo. Incident volume Incident count KPI Incident Count is the number of incidents generated over a period of time. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT count(*) AS 'Incident Count' WHERE current_state='open' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Accumulated incident duration KPI Accumulated incident duration is the total sum of minutes that all the incidents accumulated over a period of time. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT sum(duration)/(1000*60) AS 'Incident Minutes' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Mean time to close (MTTC) KPI Average duration of incidents within the period of time measured. NRQL: FROM nrAQMIncident SELECT average(duration/(1000*60)) AS 'Incident MTTC (minutes)' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Percent under 5 minutes KPI Percentage of incidents where the duration of the incident is under five minutes. This can be an indicator of incident flapping. NRQL: FROM nrAQMIncident SELECT percentage(count(*), WHERE duration <= 5 * 60 * 100) AS '% Under 5min' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Incident engagement Percentage Acknowledged KPI Incidents acknowledged identifies the percentage of incidents that have been engaged with and had their acknowledged property set to true. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT filter(count(*), WHERE current_state='acknowledged')/filter(count(*), WHERE current_state='open')*100 AS '% Investigated' WHERE severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Mean time to investigate (MTTI) KPI Mean time to investigate identifies the average time it takes for an incident to be triaged. Typically you should compare the current and previous weeks. NRQL: FROM nrAQMIncident SELECT average(duration/(1000*60)) AS 'Incident MTTI (minutes)' WHERE current_state='acknowledged' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Additional resources Want to get your hands dirty before you start implementing this in your account? Check out the alert quality management lab",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 290.20462,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alert quality <em>management</em> use case <em>implementation</em> <em>guide</em>",
        "sections": "Alert quality <em>management</em> use case <em>implementation</em> <em>guide</em>",
        "tags": "<em>Uptime</em>, <em>performance</em>, <em>and</em> <em>reliability</em>",
        "body": ", such as <em>Service</em> <em>Level</em> <em>Management</em>, or <em>Reliability</em> Engineering.  You can also move to other <em>observability</em> <em>maturity</em> value streams, such as Customer Experience. KPI reference Following are the descriptions of each KPI as well as sample NRQL queries that will extract them from the New Relic platform"
      },
      "id": "61372f5964441f181342436d"
    },
    {
      "sections": [
        "Observability implementation guide template",
        "Overview",
        "Desired outcome",
        "Key performance indicators",
        "KPI1 name",
        "KPI2 name",
        "Prerequisites",
        "Establish the current state",
        "Step 1",
        "Step 2",
        "Step 3",
        "Improvement process",
        "Value realization"
      ],
      "title": "Observability implementation guide template",
      "type": "docs",
      "tags": [
        "Observability maturity",
        "Value driver this applies to << change",
        "Use case name << change",
        "Implementation guide"
      ],
      "external_id": "e207c5d5d6379c5a496c46dc890bf51c60274c1c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-docs/article-templates/om-implementation-guide/",
      "published_at": "2022-01-12T18:22:45Z",
      "updated_at": "2021-12-24T13:23:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is the template for Observability maturity implementation guides. To help you along, refer to: The style guide introduction Other observability maturity implementation guides To get your implementation guide to show up in the left nav as it should, edit ~src/nav/new-relic-solutions.yml. Don't forget to add a link to it to the Observability Maturity introduction page. Overview Put in a brief, executive-level overview of what this guide achieves. Desired outcome What's the benefit of following the steps in this implementation guide? For practitioners? For the business or the organization? Key performance indicators Refer to the KPI section of the service level management (SLM) guide for what this section should look like. KPI1 name Describe the KPI Goal What is your reader trying to do? Best practices Are there any principles your reader should adopt? KPI2 name Describe the KPI Goal What is your reader trying to do? Best practices Are there any principles your reader should adopt? Prerequisites List any of the following that applies: Reading Training Instrumentation Configuration User access needed Stick to what's relevant (don't be exhaustive unless absolutely necessary) and include links wherever possible. Establish the current state Step1 Step2 Step3 If the reader needs to access a JSON file or another file type, make sure those files are available in the oma-resource-center. Step 1 Describe the step. Step 2 Describe the step. Step 3 Describe the step. Improvement process Now that the reader knows where they stand, tell them how to improve what they're trying to improve. Value realization Remind the reader why they did all this work in the first place and what they'll see as a result. Include best practices to adopt going forward so that they can continue to benefit from their hard work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.66348,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Observability</em> <em>implementation</em> <em>guide</em> template",
        "sections": "<em>Observability</em> <em>implementation</em> <em>guide</em> template",
        "tags": "<em>Observability</em> <em>maturity</em>",
        "body": " forget to add a link to it to the <em>Observability</em> <em>Maturity</em> introduction page. Overview Put in a brief, executive-<em>level</em> overview of what this <em>guide</em> achieves. Desired outcome What&#x27;s the benefit of following the steps in this <em>implementation</em> <em>guide</em>? For practitioners? For the business or the organization"
      },
      "id": "61c5c9ec28ccbccadb07ca78"
    },
    {
      "sections": [
        "Get started with New Relic's service level management",
        "BETA FEATURE",
        "What are SLIs and SLOs?",
        "Service levels and APM SLA reports",
        "What's next?"
      ],
      "title": "Get started with New Relic's service level management",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started",
        "Service levels management"
      ],
      "external_id": "c3da65667ad9557562bd537c738309d80d3f31ee",
      "image": "https://docs.newrelic.com/static/a0a3554edde9777dc70c4ee8281fddd6/01e7c/slm1_1.png",
      "url": "https://docs.newrelic.com/docs/service-level-management/intro-slm/",
      "published_at": "2022-01-12T07:44:40Z",
      "updated_at": "2022-01-08T01:45:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With New Relic you can define and consume service level indicators and service level objectives for your applications. What are SLIs and SLOs? Service levels are used to measure the performance of a service from the end user (or client application) point of view. For instance, a Service Level can represent whether a video loaded quickly enough, or whether a directions service returned at least one possible route between two points. Service level indicators (SLIs) are accurate quantitative measures of the user experience as described by a service level. They represent a proportion of successful outputs, and therefore they’re expressed as a percentage (%). For example, an SLI can measure the proportion of requests that were faster than some threshold, or the proportion of records coming into a pipeline that resulted in the correct value coming out. And while users understand that a video might take a few additional seconds to load, or that an application might return an error from time to time, this shouldn’t happen often if you don’t want to lose their trust. Therefore, once you’ve defined SLIs for the performance aspects that are most relevant for the end users of your services, you need to set SLOs to track that the service is meeting their expectations. Service level objectives (SLOs) are defined as a target value that an SLI must meet over a period of time. For example, videos must start playing in less than 2 seconds 99% of the time over a week period. Please refer to the Service level management use case implementation guide to learn more about identifying service boundaries and deploying the instrumentation that your service levels will be based on. Service levels and APM SLA reports New Relic has provided automatic SLA Reports for APM Services for a long time. The Apdex-based reports, which you can get on your email inbox on Mondays, are automatically generated for services that produce web transactions, and are useful to see trends over time. On top of the SLAs, our new SLM level capability is better aligned with modern service level best practices, such as those promoted by the Google SRE Handbook, and provides new, improved functionality: SLIs can be defined on any NRDB event that is reported to New Relic, not just APM transactions. Therefore you can also base SLIs on your own custom events. You can decide which service boundaries and which metrics are relevant for your service levels, and you can set your own objectives. You can view SLO results across your accounts, and within your workloads. What's next? Ready to get started? If you don't already have one, sign up for a free New Relic account. You can find service levels in several places in New Relic One: At the top nav bar, under the More menu (which you can customize). At the previews of those entities that have an SLI defined. In APM services, at the reports section. Within a workload, at the service levels tab. Carry on and read our docs on how to create and consume SLIs and SLOs. You can also check out how to manage SLMs with our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.46822,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with New Relic&#x27;s <em>service</em> <em>level</em> <em>management</em>",
        "sections": "Get started with New Relic&#x27;s <em>service</em> <em>level</em> <em>management</em>",
        "tags": "<em>Service</em> <em>levels</em> <em>management</em>",
        "body": "% of the time over a week period. Please refer to the <em>Service</em> <em>level</em> <em>management</em> use case <em>implementation</em> <em>guide</em> to learn more about identifying <em>service</em> boundaries and deploying the instrumentation that your <em>service</em> levels will be based on. <em>Service</em> levels and APM SLA reports New Relic has provided automatic"
      },
      "id": "61a824fe28ccbcc5e3c22dc5"
    }
  ],
  "/docs/new-relic-solutions/overview": [
    {
      "sections": [
        "Establish objectives and baselines: define team SLOs",
        "Service level components",
        "Resources",
        "1. Build an inventory of services requiring SLOs",
        "2. Research customer expectations for SLOs",
        "3. Define SLOs",
        "4. Determine what can be instrumented",
        "New Relic products",
        "APM installation",
        "Infrastructure installation",
        "Infrastructure on-host integrations",
        "Synthetics",
        "Browser monitoring",
        "Mobile monitoring",
        "5. Review the default metrics",
        "6. Set up custom instrumentation",
        "7. Create dashboards to track SLIs"
      ],
      "title": "Establish objectives and baselines: define team SLOs",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "6bfd37ee90b6890a53bfcf5ca688bbf72d551b70",
      "image": "https://docs.newrelic.com/static/5a07ed4ece7f7732b279460ca80f946d/c1b63/new-relic-logs-alerts.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/establish-objectives-baselines-define-team-slos/",
      "published_at": "2022-01-12T01:49:03Z",
      "updated_at": "2022-01-08T01:56:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A DevOps transformation requires a cultural shift so that teams can build new skills and motivations for the type of cross-team work required in a true DevOps practice. The transformation can be difficult when the people involved do not see the benefits of change as a clear objective. Service level objectives (SLOs) provide a powerful mechanism to codify the goals of a DevOps team in a way that can be measured and shared. They also provide clear boundaries on service expectations that help teams achieve greater velocity and freedom in experimenting with new approaches. This tutorial defines SLOs for successful service delivery objectives and utilize New Relic instrumentation to surface the current performance metrics relative to those objectives. Measurable SLOs and visibility into your current progress against those SLOs ensure that you will be able to properly assess future optimization efforts. See also our service level management feature. Service level components An SLO is an agreed upon means of measuring the performance of your service. The SLO defines a target value of a specified quantitative measure, which is called a service level indicator (SLI); for example: Average response time Response time percentile Application availability SLOs clarify a target value for SLIs; for example: Average response time should be less than 200 ms 95% of requests should be completed within 250 ms Availability of the service should be 99.99% Logically group SLOs together to provide an overall boolean indicator of whether or not the service is meeting expectations. For example, a helpful SLO for alerting purposes could be: 95% of requests completed within 250 ms AND availability is 99.99% Copy Service level components Example values SLI (Indicator) HTTP status codes SLO (Objective) < 1% HTTP 500s over 30 days SLA (Agreement) For every additional .1% of HTTP 500s, 5% refund of total contract Resources Value stream mapping can be a useful exercise to work through before setting SLOs. Work with your teams to clarify key components of your service and the appropriate metrics. Use these inputs as starting points for this tutorial. In addition: Learn about SLOs, SLIs, and SLAs from the Google Cloud Platform blog. Learn how New Relic has applied SLOs and SLIs into its reliability practices form this SREcon18 Americas presentation (approximately 21 minutes). 1. Build an inventory of services requiring SLOs Start defining SLOs for your application by first taking an inventory of the services that your application provides to both your internal and external customers. Draft a list of services. Make the scope of services you consider as comprehensive as possible. Engage your team members and other stakeholders to validate the list for completeness. Segment your application stack to understand the potential components that might require SLOs. For example, most applications can be segmented as: Application (backend/microservices) Dependency services (such as the message queue) Database Website Underlying servers This example lists components that would benefit from SLOs: Customer type Component name Owner Language stack Operating system External Service 1 John D. Java RHEL 6 Internal Service 2 Jane A. .NET Win2003 R2 Internal ActiveMQ John D. Java AIX External Website Jane A. Classic ASP Win2000 Internal MS SQL Dave Z. n/a Win2003 R2 Building a definitive list of services that require an SLO can be challenging, because an application often consists of many endpoints with complex interdependencies. Begin your SLO journey with pragmatism. Start by defining a broader, simpler set of SLOs that are driven by what your customers care about most and what your team can control. As your teams better align around SLOs, you can then begin to fine-tune and add more complexity. 2. Research customer expectations for SLOs Once you have an inventory of services, begin to gather the information you need to define the SLOs for those services. Interviews with customers that depend on your services are often valuable for understanding service expectations. For example, to define SLOs for internal teams, New Relic, ask questions such as: If possible, can you broadly categorize the types of requests we can expect from you and your service? To what extent do you or your service depend on timely responses to requests? Are there requests for which response time is not critical? How does your service handle unavailable dependencies or data? What is the maximum amount of unavailable data that your service can handle? At what threshold does your service fail if a request takes too long? What are acceptable rates of errors? What would a SLA look like between our product and yours? Existing usage data can also be a helpful research input. 3. Define SLOs Using the research on customer expectations that you gathered, draft a focused set of SLOs. New Relic recommends setting SLOs against one or more of the following SLIs: Application availability percentage Average response time Response percentile Error rate Apdex value Also, consider instrumenting and tracking the following SLIs: Throughput (peak and trough) Database call count and duration DNS and SSL timing DOM processing and page rendering Mean-time-to-detection (MTTD) For a more comprehensive list of potential areas to measure, see Measuring DevOps. Recommendation: To determine if your application is performing to customer expectations: Consider combining multiple SLIs (for example, availability and response time) into one SLO. Aim to define a consistent set of conditions across all of the services in your list. Consult your team and stakeholders to validate that the SLOs you set are reasonable, consistently attainable (even if you are not currently meeting them), and aligned to customer expectations. After you finish this step, you should have a set of well-defined SLOs and SLIs. 4. Determine what can be instrumented Now you're ready to deploy agents or monitors to establish a performance baseline for the SLIs you created. With proper instrumentation in place, you'll have visibility into the performance indicators that matter for your team and your customers. In addition, you'll also have a clear understanding of how to meet your SLOs. Identify the service components your team will optimize. Verify which application tiers meet New Relic monitoring requirements. To ensure you have robust baselines from which to work, determine the level of instrumentation that is possible (or allowed) within your organization. It's best practice to instrument everything you can, but there may be situations where instrumentation isn't viable. In that case, you should determine what other data is available or can be created. For example, you can gather logs to query them for SLO data and set alerts for them. one.newrelic.com > Logs: Use the New Relic log management UI to leverage your logs. If the application has a web front end in these situations, use New Relic synthetic monitors. Our synthetic monitors offer non-agent monitoring while still providing the ability to establish a baseline. To instrument the example applications and components in this tutorial, use these New Relic features: New Relic products Customer type Component name Tier owner Language stack Server OS New Relic products External Service 1 John D. Java RHEL 6 APM, infrastructure monitoring, synthetic monitors Internal Service 2 Jane A. .Net Win2003 R2 APM, infrastructure monitoring Internal ActiveMQ John D. Java AIX APM External Website Jane A. Classic ASP Win2000 Synthetic monitors Internal MS SQL Dave Z. NA Win2003 R2 Infrastructure monitoring, on-host integrations APM installation After reviewing the compatibility and requirements for APM, install an APM agent on your application stack. Steps for installing APM agents vary based on language agent type. Follow the install procedures for a specific APM agents. Infrastructure installation After reviewing the requirements for New Relic infrastructure monitoring, follow the install procedures to install the infrastructure agent on instances that host your applications. The infrastructure agent requires the following host permissions: Linux: To install and run the agent, you must have root privileges. Windows: To install and run the agent, you must have Administrator privileges. Infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations based on their availability. New Relic supports several commonly used application components, including MySQL, Apache, NGINX, and more. For more information, see our on-host integration docs. Synthetics New Relic synthetic monitoring gives you a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. Follow the procedures to create a simple browser check. Be sure to verify that your website URL is accessible from the Synthetics public network locations. Browser monitoring New Relic browser monitoring provides deep insights into how your users are interacting with your application or website. Browser monitoring complements synthetic monitors with data based on actual user experiences, which is useful in discerning how DevOps efforts are ultimately improving the experience for the customer. For more information, see the compatibility and requirements, then install the New Relic browser agent. Mobile monitoring The growing role of mobile apps in customer experience often spurs new performance data needs. Installation of New Relic mobile monitoring lets DevOps teams instrument iOS and Android applications to gain a fuller understanding of service delivery quality. 5. Review the default metrics After you deploy the agents and monitors, use service maps to review the default metrics that New Relic captures. For example, a typical service map show many of the common SLIs that application teams rely on, including response time, Apdex, throughput, and error rate metrics from APM. It also shows page load time, Ajax response, throughput, and error rate from browser monitoring. 6. Set up custom instrumentation To close any remaining gaps in visibility for your SLIs, use custom instrumentation. New Relic provides several avenues for adding custom instrumentation, including: Making API calls to agents from inside your source code Packaging XML-based custom instrumentation modules with deployed applications Adding UI-based instrumentation without a code deploy In addition, you can add custom attributes to each transaction event that match application performance factors to critical business information. Then you can track those attributes in Insights dashboards. For more information, see the custom instrumentation documentation for your application: APM Browser Infrastructure Mobile Synthetics 7. Create dashboards to track SLIs Once you implement the appropriate instrumentation, it's easy to visualize your service level indicators with New Relic dashboards, which provide a single location to query and view all the data that New Relic tools gather. To learn more about how to run queries to produce charts and dashboards, see Introduction to query builder. For more about the data you can query, see New Relic data types. The metrics you capture will become your application's baseline. Share dashboards with your application team and stakeholders to provide visibility into what is happening with your application and to monitor future performance.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1385.8523,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>New</em> <em>Relic</em> products",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " SLOs for successful service delivery objectives and utilize <em>New</em> <em>Relic</em> instrumentation to surface the current performance metrics relative to those objectives. Measurable SLOs and visibility into your current progress against those SLOs ensure that you will be able to properly assess future"
      },
      "id": "6044151ee7b9d259ef5799ea"
    },
    {
      "sections": [
        "Create application baselines",
        "1. Identify components",
        "Tip",
        "Example: List of components",
        "2. Determine compatibility",
        "Example: Components matched to New Relic products",
        "3. Deploy monitoring",
        "Deploy APM",
        "Deploy infrastructure",
        "Deploy infrastructure on-host integrations",
        "Create synthetic monitors",
        "4. Gather metrics",
        "5. Set up dashboards",
        "Example: Component performance compared against baselines",
        "Expert tips"
      ],
      "title": "Create application baselines",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Cloud adoption"
      ],
      "external_id": "9ddad276285ff4458594478dfd25b2b09aa6a5d2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/create-application-baselines/",
      "published_at": "2022-01-12T07:54:58Z",
      "updated_at": "2022-01-04T01:54:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Cloud migrations can take many forms. Some companies choose to port their applications directly from their data center to the cloud (a “Lift and Shift” migration) while others focus on completely re-architecting their applications to take advantage of benefits available only in the cloud. No matter your approach, there are three primary questions you want to answer after your migration: Has my application gotten slower? Is my application less stable than before? Am I losing customers due to either of the previous questions? To answer these questions, start by performing some basic testing to establish a baseline for the performance and availability of your systems. A baseline is a measurement of the current performance and availability of your application, which you then use as a comparison after your migration to validate your business case. In some cases, you may change a baseline when you perform migration acceptance testing. You can also use a baseline as a comparison point during your migration to make sure that you are on track. 1. Identify components Before you begin a cloud migration, identify all the tiers of your entire application stack. List all of the components (applications, services, etc.) that you want to migrate. Segment the application stack as follows: Application (backend/microservices/cron jobs) Dependency services, such as the message queue Database Website Underlying server and infrastructure Tip Make sure that you have access to applications and instances before you start creating application baselines. Engage your application owners, DevOps engineers, and product managers for access. Example: List of components Here is an example of the list of components in an application stack: Component Name Owner Language Stack Accessibility (Internet, Intranet) Operating System Service 1 John Doe Java Internet RHEL 6 Service 2 Maya Wiz .NET Intranet Win2003 R2 RabbitMQ John Doe Java Intranet AIX Website Maya Wiz Classic ASP Internet Win2000 MS SQL Dave Z NA Intranet Win2003 R2 2. Determine compatibility Once you identify the applications that you want to migrate, it is time to verify which application tiers to monitor with the New Relic platform. Work with stakeholders in your organization to determine the amount of instrumentation that is possible–or allowed–within your organization. This is an important step and one that will pay off, as the more you can instrument, the better your baselines. Here are the New Relic products to use for baselining, depending on the components that you identified: APM: Monitor your web apps with APM. See Compatibility and requirements for New Relic agents and products to learn precise compatibility details for each supported language. Infrastructure: Monitor your hosts with infrastructure. See Compatibility and requirements for infrastructure for supported operating systems and environments. You can also instrument other products and services with on-host integrations. Synthetics: Monitor web frontends and APIs with synthetics. Sometimes, you may not be able to instrument your on-premise environment with APM or infrastructure. For example, maybe your organization's policy forbids installing an agent behind a firewall. In these cases, if the application has a web frontend, use Synthetics, as it offers non-agent monitoring while still providing the ability to establish a baseline. Example: Components matched to New Relic products Match the components that you identified with their corresponding products: Component Name Tier Owner Language Stack Accessibility (Internet/ Intranet) Operating System New Relic products Service 1 John Doe Java Internet RHEL 6 APM, Infrastructure, Synthetics Service 2 Maya Wiz .NET Intranet Win2003 R2 APM, Infrastructure ActiveMQ John Doe Java Intranet AIX APM Website Maya Wiz Classic ASP Internet Win2000 Synthetics MS SQL Dave Z n/a Intranet Win2003 R2 Infrastructure, On-host Integration 3. Deploy monitoring Based on the component-product matches you made, deploy agents or monitors across your architecture: Deploy APM Install the APM agent on your application stack. The steps to install the APM agent are different based on language. Deploy infrastructure After reviewing the requirements for infrastructure, follow the instructions to install the infrastructure agent on your hosts: Install for Linux Install for Windows Server Install on AWS Elastic Beanstalk Install with a configuration management tool Deploy infrastructure on-host integrations To gain extended visibility into applications that your code depends on, deploy on-host integrations. Available integrations include Apache, MySQL, NGINX, and others. Create synthetic monitors Synthetics is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. To get started add a monitor. Tip Make sure to verify that your website URL is accessible from the public network. You may also need to add New Relic IPs to your allow list. 4. Gather metrics After you deploy the agents and monitors, identify which metrics are the most important to your business and use these metrics to define your KPIs. Some recommendations include: Response time: Time taken to respond to a request. Throughput: Number of requests that came in through the application. Requesting queuing (Apache, IIS, NGINX): Duration of time taken for a request to reach your application. Database call duration: Duration of time taken to complete a database call. DB call counts: Number of calls made by application code to the database. Error rate: Percent of errors reported. Apdex score: An industry standard to measure user satisfaction with the response time of web applications and services. DNS setup timing: The time it takes to connect and receive data from DNS. SSL setup timing: The time it takes to establish an SSL connection. You can find some of these metrics in service maps, as well as on APM, and [browser] (/docs/ /new-relic-browser/getting-started/browser-overview-page-website-performance-summary) overview pages. For more detailed information about navigating, interpreting, and using APM, check out these New Relic University's tutorials: Overview dashboard tour Transactions dashboard Understanding Apdex 5. Set up dashboards After you define your KPIs, it's easy to visualize them in dashboards. Dashboards provide a single location to view all the data that New Relic products gather. Dashboards data consists of events, and each event has an event type, a timestamp, and key-value attributes. For more information about events, see Data collection and Default events for New Relic products. You can locate your KPIs and business metrics data in New Relic using the data explorer and the NRQL query language. You can also build dashboards to track the performance of those KPIs: Example: Component performance compared against baselines Continuing the examples in this document, the following table illustrates the maturity of your application performance over a period of time based on deployment milestones. Each milestone will serve as a new baseline for your applications: Component Milestone 1 Milestone 2 Milestone N Environment Component Name Response Time SLA Apdex Response Time SLA Apdex Response On-Prem Service 1 1.5 secs 80% 70% 1.5 secs 68% 0.65 1.4 secs Cloud Service 1 0.9 secs 96.8% 95% 0.9 secs 98% 0.99 0.7 secs On-Prem Service 2 0.7 secs 73% 68% 0.7 secs 80% 0.78 0.85 secs Cloud Service 2 0.6 secs 90% 92% 0.6 secs 89% 0.90 0.5 secs After your migration, compare these baselines against your migration acceptance testing baselines. Expert tips If you find that you need data that is not captured by default instrumentation, we make it easy for you to capture custom data: APM custom instrumentation Browser custom data Infrastructure custom attributes Custom event data Mobile custom data Synthetics custom attributes You can also learn more about APM custom instrumentation with the New Relic University Custom data tutorial series.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1224.5706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Example: Components matched to <em>New</em> <em>Relic</em> products",
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": " want to migrate, it is time to verify which application tiers to monitor with the <em>New</em> <em>Relic</em> platform. Work with stakeholders in your organization to determine the amount of instrumentation that is possible–or allowed–within your organization. This is an important step and one that will pay off"
      },
      "id": "6044605c64441f1d15378edf"
    },
    {
      "sections": [
        "Iterate and measure impact: track metrics before and after deployments",
        "Prerequisite",
        "1. Integrate measurements into your development process",
        "2. Add automated deployment markers",
        "Tip",
        "3. Test your pipeline with infrastructure"
      ],
      "title": "Iterate and measure impact: track metrics before and after deployments",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "New Relic solutions",
        "Measure DevOps success"
      ],
      "external_id": "06e2013529667ec66bde080abc3623ac6b6a6695",
      "image": "https://docs.newrelic.com/static/886d79f19e7b5576a06f8cc6016d053d/c1b63/apm-deployments.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/new-relic-solutions/iterate-measure-impact-track-metrics-after-deployments/",
      "published_at": "2022-01-12T07:55:33Z",
      "updated_at": "2022-01-03T18:36:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A properly instrumented system gives teams full visibility into the impact of the changes they make. Capturing tangible, measurable metrics from before and after each change allows teams to optimize changes in isolation, and reduce the impact to other ongoing changes. Prerequisite Before starting this tutorial, be sure to complete the Establish objectives and baselines tutorial and set the appropriate KPI targets for your applications. 1. Integrate measurements into your development process With appropriate measurements incorporated into all phases of your development cycle, you can surface errors and performance issues before your customers uncover them. As your application teams plan their work, use your KPI dashboards in daily stand-ups and other planning meetings to analyze necessary debugging work, assess whether recent deployments were successful, and to prioritize other work efforts. When development and operations teams use dashboards during planning and discussions, they ensure that they’re consistently incorporating feedback about customer experiences and reliability risks into their development efforts. For proper testing, ensure that instrumentation in your pre-production environments is in parity with your production environments. Use dashboards to compare the environments and verify that the code and infrastructure changes you make are correct across them, and eliminate any anomalies before pushing code to production. 2. Add automated deployment markers It’s important to track deployments and how the impact of the code and infrastructure changes you make affect customer experience. APM’s deployment markers feature allows you to record deployments for each application. A deployment marker is an event indicating that a deployment happened, and it's paired with metadata available from your SCM system (such metadata typically includes the user, revision, change-log, etc.). APM displays a vertical line, or “marker”, on charts and graphs at the deployment event’s timestamp. When you hover over the line, APM displays the associated metadata for that deployment. one.newrelic.com > APM > (select an app) > Monitoring > Overview APM also provides a chronological list of deployments of your application, and additional metrics, such as error rate and Apdex from the time of the deployment, are available as well. one.newrelic.com > APM > (select an app) > Events > Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip New Relic recommends that you make POST requests to the New Relic REST API as the final step of a successful CI/CD deployment as described in the API documentation. The following tools have integrations or plugins available to help automate this: Chef (see newrelic_depoyment) Jenkins Ansible 3. Test your pipeline with infrastructure An important part of a successful DevOps transformation is a cultural shift toward smaller, more frequent changes to your code and infrastructure. After you complete the first two steps of this tutorial, begin to test and gather appropriate performance insights about your deployment pipeline to more clearly understand the impact of the changes you make. Code changes should be as small as possible in terms of the number of lines of code and source files you change. Changes should also involve as few team members as possible. This makes it much easier to identify issue owners and determine root causes if errors occur. Similarly, infrastructure changes should also have as small a footprint as possible to minimize the number of applications affected by each change. Our infrastructure agent helps you see when an infrastructure change has caused a spike in issues, as shown in the following example: one.newrelic.com > Infrastructure > Hosts For cloud infrastructure changes or larger code changes, consider using a blue/green deployment strategy. APM supports multiple app names which fits this model quite nicely. To implement this strategy: Deploy a version of your application to existing infrastructure using a rollup app name that signifies it as the “blue” version (or control version). Deploy a new version of your application to a subset of the infrastructure (or an alternate set of infrastructure) with a rollup name that signifies this as the “green” version (or experimental version). Ensure that traffic is routed appropriately between both versions. Compare established KPI dashboards of both versions against one another. Optimize the new version accordingly to meet your KPI targets. When you're satisfied with the application's performance, deploy the new version across your infrastructure using the original app name, and consider this the new baseline for any future changes you'll make to the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1215.4974,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>solutions</em>",
        "body": ") &gt; Events &gt; Deployments Tracking deployments is an invaluable way to determine the root cause of immediate, long-term, or gradual degradations in your application. Tip <em>New</em> <em>Relic</em> recommends that you make POST requests to the <em>New</em> <em>Relic</em> REST API as the final step of a successful CI&#x2F;CD deployment"
      },
      "id": "60450efc64441fb48e378eee"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/diagnostics-cli-licensing-security": [
    {
      "sections": [
        "Run the Diagnostics CLI (nrdiag)",
        "Platform-specific procedures",
        "Linux",
        "macOS",
        "Windows",
        "Browser monitoring",
        "Docker container",
        "Suites flag (highly recommended CLI option)",
        "Upload results to a New Relic account",
        "Important",
        "Automatic Account upload",
        "Manual upload"
      ],
      "title": "Run the Diagnostics CLI (nrdiag)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "61cb738c86d3a012865b754bdf0c219319f6a8ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/run-diagnostics-cli-nrdiag/",
      "published_at": "2022-01-12T03:28:52Z",
      "updated_at": "2021-12-14T04:15:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download latest version To use the Diagnostics CLI: Review the release notes, to make sure you have the latest version. Download the latest version, which contains executable files for Linux, macOS, and Windows. Move the executable for your platform into the location of your application's root directory. Temporarily raise the logging level for the New Relic agent for more accurate troubleshooting. After you change the logging level, restart your application. Run the executable. Recommendation: To scope your troubleshooting more easily, run nrdiag with a task suite (CLI option). The Diagnostics CLI automatically searches its root directory and subdirectories for agent configuration files and other relevant data. Platform-specific procedures To run the Diagnostics CLI, follow the procedures for your platform: Linux Ensure you have the Diagnostics CLI: From the command line, change the directory to your application's root directory and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/linux directory, move nrdiag into the application's root directory. Run nrdiag (along with any CLI options ./nrdiag CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to your New Relic account if you include an attachment flag. macOS Ensure you have the Diagnostics CLI: From the command line, change directory to the application's root directory and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/mac directory, move nrdiag into the application's root directory. Run nrdiag (along with any CLI options ./nrdiag CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to your New Relic account if you include an attachment flag. Windows Ensure you have the Diagnostics CLI: From the command line, change directory to the application's root directory, and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/win directory, move nrdiag.exe or nrdiag_x64.exe into the application's root directory. For troubleshooting web applications, ensure you are running the executable from your project's parent directory, or specify your config file location with the -c option. Run the executable (along with any CLI options from the directory you placed the binary. Since some checks require elevated permissions, for best results run from an admin shell. Run via PowerShell if you add any CLI_OPTIONS: ./nrdiag.exe CLI_OPTIONS Copy OR, for x64 systems: ./nrdiag_x64.exe CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to New Relic account if you include an attachment flag. Browser monitoring Ensure you have the latest version of the Diagnostics CLI. If necessary, manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/OS directory, run nrdiag (along with any CLI options: ./nrdiag -browser-url WEBSITE_URL CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers and uploads relevant files to your New Relic account if you include an attachment flag. Docker container To troubleshoot your New Relic-instrumented application running in a Docker container, use the docker exec command: Download and unzip the nrdiag_latest.zip file. Copy the binary to the container. Replace IMAGE_NAME with the name of your docker container: docker cp nrdiag/linux/nrdiag IMAGE_NAME:/bin Copy Run the nrdiag command in the docker container. Replace IMAGE_NAME as above, and replace APPLICATION_ROOT with the root directory of your application, where you installed the New Relic agent: docker exec -it -w APPLICATION_ROOT IMAGE_NAME nrdiag Copy (Optional) Remove the nrdiag binary when finished: docker exec IMAGE_NAME rm /bin/nrdiag Copy Suites flag (highly recommended CLI option) A suite is a collection of health checks that target specific products or issues. Using a suite can help narrow the scope of troubleshooting and reduce the occurrence of false positives. To review a list of available suites, run the Diagnostics CLI with the -help suites option: ./nrdiag --help suites Copy To run suites with nrdiag, provide the -suites flag and one or more suite names (for example, java) to run as arguments. Linux, macOS: For 32-bit systems: ./nrdiag --suites SUITE NAMES Copy For 64-bit systems: ./nrdiag_x64 --suites SUITE NAMES Copy Windows: To run from PowerShell, add ./ to the start of cmd. For 32-bit systems: nrdiag.exe --suites SUITE NAMES Copy For 64-bit systems: nrdiag_x64.exe --suites SUITE NAMES Copy Upload results to a New Relic account Important If your system is configured to not connect to external IP addresses, this method will not work. Instead, attach the output files in an email to New Relic Support. If there is an issue with your license key you will need to manually upload results to your account. Automatic Account upload To upload your results automatically to a New Relic account when the Diagnostics CLI is executed, use the -attach or -a command line flag. This will validate any New Relic License Keys found in your environment for upload. Uploading your results to an account will automatically upload the contents of the nrdiag-output.json and nrdiag-output.zip. If you want to inspect or modify the file's contents before upload, follow the manual upload procedures. Linux, macOS, synthetic private minion: ./nrdiag -attach Copy Windows: To run from PowerShell, add ./ to the start of cmd. For 32-bit systems: nrdiag.exe -attach Copy For 64-bit systems: nrdiag_x64.exe -attach Copy Manual upload If you have a support ticket, use the permalink functionality to share your results. This will help improve troubleshooting speed. The New Relic diagnostics app has the drag and drop functionality if your results are unable to be automatically uploaded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.46298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Run the <em>Diagnostics</em> <em>CLI</em> (<em>nrdiag</em>)",
        "sections": "Run the <em>Diagnostics</em> <em>CLI</em> (<em>nrdiag</em>)",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": " automatically to a <em>New</em> <em>Relic</em> account when the <em>Diagnostics</em> <em>CLI</em> is executed, <em>use</em> the -attach or -a command line flag. This will validate any <em>New</em> <em>Relic</em> License Keys found in your environment for upload. Uploading your results to an account will automatically upload the contents of the <em>nrdiag</em>"
      },
      "id": "61bfb6ef196a67ea13ef04f5"
    },
    {
      "sections": [
        "Pass command line options for nrdiag"
      ],
      "title": "Pass command line options for nrdiag",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "8f44035147a6f69c41f002c68bc09e1e4a334959",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/pass-command-line-options-nrdiag/",
      "published_at": "2022-01-12T03:28:53Z",
      "updated_at": "2021-12-14T04:14:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To use the following command line options with the Diagnostics CLI: Option Usage -attachment-endpoint STRING Attachment endpoint to include with the support ticket. -a -attach Attach for automatic upload to a New Relic account. This uses a validated license key from your environment. DEPRECATED -ak STRING -attachment-key STRING Attachment key for automatic upload to a support ticket. This gets the attachment key from an existing ticket. (Note: this functionality will be removed soon. Please use the automatic upload option above) -browser-url STRING Diagnostics CLI version 1.1.9 or higher When invoked, this will only run diagnostics checks related to browser monitoring. This command checks that New Relic's browser monitoring agent is present and returns the agent version, the injection method (via APM or via copy/paste), and the loader type (Pro, Lite, SPA). To be used to provide detail to New Relic Support when troubleshooting intranet sites. -c STRING -config-file STRING Override default agent configuration file location. Can be used to specify either a folder to search in addition to the default folders, or a path to a specific configuration file. --filter STRING Filter task results by result status. Accepts a comma separated list. Accepts Success, Warning, Failure, Error, None, or Info. Example syntax: \\\"Success,Warning,Failure\" Copy -h --help Display complete list of command line options. To list all tasks to be run, use -h tasks. Type: bool -inNewRelicCLI Type: bool -interactive Type: bool -output-path STRING Specifies a different output directory to write the results for nrdiag-output.zip, nrdiag-output.json, and nrdiag-filelist.txt. Default location is ./. -o --override STRING Pass in arguments to override when requested by New Relic Support. Format: identifier.property=value. Example syntax: --override Java/Config/Agent.Status=Success Copy -o Base/Config/Validate.agentlanguage=PHP Copy -p STRING --proxy STRING Provide proxy to be used in HTTP connection tasks. Can be HTTP or HTTPS. Proxy should be in the format http(s)://proxyIp:proxy. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. In most cases port is not needed. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -proxy-pw STRING Proxy password, if necessary. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -proxy-user STRING Proxy username, if necessary. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -q --quiet Quiet output only prints the high-level results and not the explanatory output. Suppresses file addition warnings if -y is also used. Does not contradict -v. Inclusion filters are ignored. Type: bool -qq --VeryQuiet Very quiet output only prints a single summary line for output (implies q). Suppresses file addition warnings if -y is also used. Does not contradict -v. Inclusion filters are ignored. Type: bool --SkipVersionCheck Skip the automatic check for a newer version of the application. Type: bool --ShowOverrideHelp Type: bool -s STRING --suites STRING Run a suite, a collection of tasks that target specific products or issues. To specify multiple suites, separate them with commas. To get a list of all suites, run: ./nrdiag -h suites Copy -t STRING --tasks STRING Run only a subset of tasks, either by agent or by task type. To specify multiple tasks, separate them with commas and/or with a wildcard *. For a list of all tasks, run: ./nrdiag -h tasks Copy -usage-opt-out Decline to send anonymous Diagnostics CLI tool usage data to New Relic for this run. Type: bool -v --verbose Display verbose logging during check execution. Disabled by default. Type: bool --version Displays current Diagnostics CLI version. This also prompts to check for a newer version and prompts to download if a newer version is available. Takes precedence over no-version-check. Type: bool -y --yes --YesToAll Respond yes to any prompt that comes up while running. Disabled by default. Type: bool",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.46204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Pass command line options for <em>nrdiag</em>",
        "sections": "Pass command line options for <em>nrdiag</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "To <em>use</em> the following command line options with the <em>Diagnostics</em> <em>CLI</em>: Option Usage -attachment-endpoint STRING Attachment endpoint to include with the support ticket. -a -attach Attach for automatic upload to a <em>New</em> <em>Relic</em> account. This uses a validated license key from your environment. DEPRECATED -ak"
      },
      "id": "61bfb6c0196a67a82aef062e"
    },
    {
      "sections": [
        "Validate config file settings with nrdiag",
        "Deployment example"
      ],
      "title": "Validate config file settings with nrdiag",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "a2c402d34a11749a86bd5f0620066305785cd0e1",
      "image": "https://docs.newrelic.com/static/cdfee4566aed5bcc19663854a0b4c8bc/8c557/agent_enabled.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/validate-config-file-settings-nrdiag/",
      "published_at": "2022-01-12T03:29:30Z",
      "updated_at": "2021-12-14T04:13:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Diagnostics CLI includes detailed configuration setting validation for the Java agent's newrelic.yml file. To request support for other New Relic agents, use our GitHub template. If you run nrdiag in the usual manner (on the system running your application with the New Relic agent already installed), the new validation is applied automatically, and any warnings also automatically appear. Deployment example You can also use this feature as a linter to validate a config file before deployment. To do this, run the appropriate task and provide the path to your config file. For example, if your newrelic.yml and nrdiag are both in the current directory, run the following command to lint the config file: ./nrdiag -t Java/Config/ValidateSettings -c newrelic.yml Copy Here is an example of the output for an incorrect setting. The agent_enabled setting in this case has a value of yes, but the Java agent only accepts the values true or false. This misconfiguration will prevent the agent from running. If you enable your Java agent incorrectly, the Diagnostics CLI returns a message like this, describing what setting needs to be updated and how it needs to be changed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.4609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Validate config file settings with <em>nrdiag</em>",
        "sections": "Validate config file settings with <em>nrdiag</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "The <em>Diagnostics</em> <em>CLI</em> includes detailed configuration setting validation for the Java agent&#x27;s newrelic.yml file. To request support for other <em>New</em> <em>Relic</em> agents, <em>use</em> our GitHub template. If you run <em>nrdiag</em> in the usual manner (on the system running your application with the <em>New</em> <em>Relic</em> agent already"
      },
      "id": "61bfb6c064441f121e99f98c"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/diagnostics-cli-nrdiag": [
    {
      "sections": [
        "Run the Diagnostics CLI (nrdiag)",
        "Platform-specific procedures",
        "Linux",
        "macOS",
        "Windows",
        "Browser monitoring",
        "Docker container",
        "Suites flag (highly recommended CLI option)",
        "Upload results to a New Relic account",
        "Important",
        "Automatic Account upload",
        "Manual upload"
      ],
      "title": "Run the Diagnostics CLI (nrdiag)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "61cb738c86d3a012865b754bdf0c219319f6a8ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/run-diagnostics-cli-nrdiag/",
      "published_at": "2022-01-12T03:28:52Z",
      "updated_at": "2021-12-14T04:15:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download latest version To use the Diagnostics CLI: Review the release notes, to make sure you have the latest version. Download the latest version, which contains executable files for Linux, macOS, and Windows. Move the executable for your platform into the location of your application's root directory. Temporarily raise the logging level for the New Relic agent for more accurate troubleshooting. After you change the logging level, restart your application. Run the executable. Recommendation: To scope your troubleshooting more easily, run nrdiag with a task suite (CLI option). The Diagnostics CLI automatically searches its root directory and subdirectories for agent configuration files and other relevant data. Platform-specific procedures To run the Diagnostics CLI, follow the procedures for your platform: Linux Ensure you have the Diagnostics CLI: From the command line, change the directory to your application's root directory and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/linux directory, move nrdiag into the application's root directory. Run nrdiag (along with any CLI options ./nrdiag CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to your New Relic account if you include an attachment flag. macOS Ensure you have the Diagnostics CLI: From the command line, change directory to the application's root directory and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/mac directory, move nrdiag into the application's root directory. Run nrdiag (along with any CLI options ./nrdiag CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to your New Relic account if you include an attachment flag. Windows Ensure you have the Diagnostics CLI: From the command line, change directory to the application's root directory, and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/win directory, move nrdiag.exe or nrdiag_x64.exe into the application's root directory. For troubleshooting web applications, ensure you are running the executable from your project's parent directory, or specify your config file location with the -c option. Run the executable (along with any CLI options from the directory you placed the binary. Since some checks require elevated permissions, for best results run from an admin shell. Run via PowerShell if you add any CLI_OPTIONS: ./nrdiag.exe CLI_OPTIONS Copy OR, for x64 systems: ./nrdiag_x64.exe CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to New Relic account if you include an attachment flag. Browser monitoring Ensure you have the latest version of the Diagnostics CLI. If necessary, manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/OS directory, run nrdiag (along with any CLI options: ./nrdiag -browser-url WEBSITE_URL CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers and uploads relevant files to your New Relic account if you include an attachment flag. Docker container To troubleshoot your New Relic-instrumented application running in a Docker container, use the docker exec command: Download and unzip the nrdiag_latest.zip file. Copy the binary to the container. Replace IMAGE_NAME with the name of your docker container: docker cp nrdiag/linux/nrdiag IMAGE_NAME:/bin Copy Run the nrdiag command in the docker container. Replace IMAGE_NAME as above, and replace APPLICATION_ROOT with the root directory of your application, where you installed the New Relic agent: docker exec -it -w APPLICATION_ROOT IMAGE_NAME nrdiag Copy (Optional) Remove the nrdiag binary when finished: docker exec IMAGE_NAME rm /bin/nrdiag Copy Suites flag (highly recommended CLI option) A suite is a collection of health checks that target specific products or issues. Using a suite can help narrow the scope of troubleshooting and reduce the occurrence of false positives. To review a list of available suites, run the Diagnostics CLI with the -help suites option: ./nrdiag --help suites Copy To run suites with nrdiag, provide the -suites flag and one or more suite names (for example, java) to run as arguments. Linux, macOS: For 32-bit systems: ./nrdiag --suites SUITE NAMES Copy For 64-bit systems: ./nrdiag_x64 --suites SUITE NAMES Copy Windows: To run from PowerShell, add ./ to the start of cmd. For 32-bit systems: nrdiag.exe --suites SUITE NAMES Copy For 64-bit systems: nrdiag_x64.exe --suites SUITE NAMES Copy Upload results to a New Relic account Important If your system is configured to not connect to external IP addresses, this method will not work. Instead, attach the output files in an email to New Relic Support. If there is an issue with your license key you will need to manually upload results to your account. Automatic Account upload To upload your results automatically to a New Relic account when the Diagnostics CLI is executed, use the -attach or -a command line flag. This will validate any New Relic License Keys found in your environment for upload. Uploading your results to an account will automatically upload the contents of the nrdiag-output.json and nrdiag-output.zip. If you want to inspect or modify the file's contents before upload, follow the manual upload procedures. Linux, macOS, synthetic private minion: ./nrdiag -attach Copy Windows: To run from PowerShell, add ./ to the start of cmd. For 32-bit systems: nrdiag.exe -attach Copy For 64-bit systems: nrdiag_x64.exe -attach Copy Manual upload If you have a support ticket, use the permalink functionality to share your results. This will help improve troubleshooting speed. The New Relic diagnostics app has the drag and drop functionality if your results are unable to be automatically uploaded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.46295,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Run the <em>Diagnostics</em> <em>CLI</em> (<em>nrdiag</em>)",
        "sections": "Run the <em>Diagnostics</em> <em>CLI</em> (<em>nrdiag</em>)",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": " automatically to a <em>New</em> <em>Relic</em> account when the <em>Diagnostics</em> <em>CLI</em> is executed, <em>use</em> the -attach or -a command line flag. This will validate any <em>New</em> <em>Relic</em> License Keys found in your environment for upload. Uploading your results to an account will automatically upload the contents of the <em>nrdiag</em>"
      },
      "id": "61bfb6ef196a67ea13ef04f5"
    },
    {
      "sections": [
        "Pass command line options for nrdiag"
      ],
      "title": "Pass command line options for nrdiag",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "8f44035147a6f69c41f002c68bc09e1e4a334959",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/pass-command-line-options-nrdiag/",
      "published_at": "2022-01-12T03:28:53Z",
      "updated_at": "2021-12-14T04:14:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To use the following command line options with the Diagnostics CLI: Option Usage -attachment-endpoint STRING Attachment endpoint to include with the support ticket. -a -attach Attach for automatic upload to a New Relic account. This uses a validated license key from your environment. DEPRECATED -ak STRING -attachment-key STRING Attachment key for automatic upload to a support ticket. This gets the attachment key from an existing ticket. (Note: this functionality will be removed soon. Please use the automatic upload option above) -browser-url STRING Diagnostics CLI version 1.1.9 or higher When invoked, this will only run diagnostics checks related to browser monitoring. This command checks that New Relic's browser monitoring agent is present and returns the agent version, the injection method (via APM or via copy/paste), and the loader type (Pro, Lite, SPA). To be used to provide detail to New Relic Support when troubleshooting intranet sites. -c STRING -config-file STRING Override default agent configuration file location. Can be used to specify either a folder to search in addition to the default folders, or a path to a specific configuration file. --filter STRING Filter task results by result status. Accepts a comma separated list. Accepts Success, Warning, Failure, Error, None, or Info. Example syntax: \\\"Success,Warning,Failure\" Copy -h --help Display complete list of command line options. To list all tasks to be run, use -h tasks. Type: bool -inNewRelicCLI Type: bool -interactive Type: bool -output-path STRING Specifies a different output directory to write the results for nrdiag-output.zip, nrdiag-output.json, and nrdiag-filelist.txt. Default location is ./. -o --override STRING Pass in arguments to override when requested by New Relic Support. Format: identifier.property=value. Example syntax: --override Java/Config/Agent.Status=Success Copy -o Base/Config/Validate.agentlanguage=PHP Copy -p STRING --proxy STRING Provide proxy to be used in HTTP connection tasks. Can be HTTP or HTTPS. Proxy should be in the format http(s)://proxyIp:proxy. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. In most cases port is not needed. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -proxy-pw STRING Proxy password, if necessary. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -proxy-user STRING Proxy username, if necessary. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -q --quiet Quiet output only prints the high-level results and not the explanatory output. Suppresses file addition warnings if -y is also used. Does not contradict -v. Inclusion filters are ignored. Type: bool -qq --VeryQuiet Very quiet output only prints a single summary line for output (implies q). Suppresses file addition warnings if -y is also used. Does not contradict -v. Inclusion filters are ignored. Type: bool --SkipVersionCheck Skip the automatic check for a newer version of the application. Type: bool --ShowOverrideHelp Type: bool -s STRING --suites STRING Run a suite, a collection of tasks that target specific products or issues. To specify multiple suites, separate them with commas. To get a list of all suites, run: ./nrdiag -h suites Copy -t STRING --tasks STRING Run only a subset of tasks, either by agent or by task type. To specify multiple tasks, separate them with commas and/or with a wildcard *. For a list of all tasks, run: ./nrdiag -h tasks Copy -usage-opt-out Decline to send anonymous Diagnostics CLI tool usage data to New Relic for this run. Type: bool -v --verbose Display verbose logging during check execution. Disabled by default. Type: bool --version Displays current Diagnostics CLI version. This also prompts to check for a newer version and prompts to download if a newer version is available. Takes precedence over no-version-check. Type: bool -y --yes --YesToAll Respond yes to any prompt that comes up while running. Disabled by default. Type: bool",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.462,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Pass command line options for <em>nrdiag</em>",
        "sections": "Pass command line options for <em>nrdiag</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "To <em>use</em> the following command line options with the <em>Diagnostics</em> <em>CLI</em>: Option Usage -attachment-endpoint STRING Attachment endpoint to include with the support ticket. -a -attach Attach for automatic upload to a <em>New</em> <em>Relic</em> account. This uses a validated license key from your environment. DEPRECATED -ak"
      },
      "id": "61bfb6c0196a67a82aef062e"
    },
    {
      "sections": [
        "Diagnostics CLI licensing and security",
        "License agreements",
        "Data uploaded to account",
        "Data storage",
        "Environment variables"
      ],
      "title": "Diagnostics CLI licensing and security",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "b85d0e253bc6caefd68ff15d535f1c67fb8b5c42",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/diagnostics-cli-licensing-security/",
      "published_at": "2022-01-12T05:58:19Z",
      "updated_at": "2021-12-14T04:14:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Like any other New Relic tool, the Diagnostics CLI service is designed to protect you and your customers' data privacy. The Diagnostics CLI inspects system information and New Relic product artifacts (logs and config files) that are relevant for performing diagnostic checks that assess New Relic product configuration and operability. By default, this data is not transmitted to New Relic. You do have the option to upload this information to a support ticket over HTTPS. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. License agreements The use of the Diagnostics CLI is subject to this license agreement, as well as licensing agreements for open-source software used by the Diagnostics CLI. Data uploaded to account The Diagnostics CLI allows uploading of this information to a support ticket over HTTPS if you use a specific command-line argument. You will be prompted before the collection of any files that we expect to have sensitive information. Before the collected files contained within nrdiag-output.zip and nrdiag-output.json are uploaded to New Relic, you will also be prompted. This allows you to review and edit any information that you do not want to provide. (For example, the nrdiag-output.zip will include your user name.) You also have the option to cancel the upload altogether. Data storage Any support ticket attachments made using nrdiag or containing nrdiag data that are less than or equal to 20MB are stored by Zendesk. All of these attachments are stored by New Relic. For more information, see Zendesk's privacy and data protection policies. Environment variables The Diagnostics CLI examines the following environment variables to perform diagnostic checks. The values of these variables are recorded locally in the nrdiag-output.json file. These include: Any environment variable containing NEWRELIC or NEW_RELIC Any environment variable beginning with NRIA A-C: APP_ENV APPDATA COR_ENABLE_PROFILER COR_PROFILER COR_PROFILER_PATH CORECLR_ENABLE_PROFILING CORECLR_PROFILER CORECLR_PROFILER_PATH D-I: DEFAULT_LOCALE_CFG_FILE DOCKER_API_VERSION DOCKER_HOST DOTNET_INSTALL_PATH DOTNET_SDK_VERSION GLIBC_REPO GLIBC_VERSION HOME J-L: JAVA_HOME JAVA_JCE JAVA_PACKAGE JAVA_VERSION_BUILD JAVA_VERSION_MAJOR JAVA_VERSION_MINOR JBOSS_HOME LANG LOCALAPPDATA M: MINION_API_ENDPOINT MINION_API_PROXY MINION_API_PROXY_SELF_SIGNED_CERT MINION_CHECK_TIMEOUT MINION_DOCKER_API_VERSION MINION_DOCKER_HOST MINION_DOCKER_RUNNER_APPARMOR MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT MINION_GROUP MINION_JAR MINION_JVM_MB MINION_JVM_OPTS MINION_LOG_LEVEL MINION_PROVIDER MINION_USER N-Z: PATH ProgramFiles ProgramData RACK_ENV RAILS_ENV RUBY_ENV WORKDIR",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.46194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Diagnostics</em> <em>CLI</em> licensing and security",
        "sections": "<em>Diagnostics</em> <em>CLI</em> licensing and security",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Like any other <em>New</em> <em>Relic</em> tool, the <em>Diagnostics</em> <em>CLI</em> service is designed to protect you and your customers&#x27; data privacy. The <em>Diagnostics</em> <em>CLI</em> inspects system information and <em>New</em> <em>Relic</em> <em>product</em> artifacts (logs and config files) that are relevant for performing diagnostic checks that assess <em>New</em> <em>Relic</em>"
      },
      "id": "61bfb6c064441f89fe99f183"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/interpret-nrdiag-output": [
    {
      "sections": [
        "Run the Diagnostics CLI (nrdiag)",
        "Platform-specific procedures",
        "Linux",
        "macOS",
        "Windows",
        "Browser monitoring",
        "Docker container",
        "Suites flag (highly recommended CLI option)",
        "Upload results to a New Relic account",
        "Important",
        "Automatic Account upload",
        "Manual upload"
      ],
      "title": "Run the Diagnostics CLI (nrdiag)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "61cb738c86d3a012865b754bdf0c219319f6a8ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/run-diagnostics-cli-nrdiag/",
      "published_at": "2022-01-12T03:28:52Z",
      "updated_at": "2021-12-14T04:15:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download latest version To use the Diagnostics CLI: Review the release notes, to make sure you have the latest version. Download the latest version, which contains executable files for Linux, macOS, and Windows. Move the executable for your platform into the location of your application's root directory. Temporarily raise the logging level for the New Relic agent for more accurate troubleshooting. After you change the logging level, restart your application. Run the executable. Recommendation: To scope your troubleshooting more easily, run nrdiag with a task suite (CLI option). The Diagnostics CLI automatically searches its root directory and subdirectories for agent configuration files and other relevant data. Platform-specific procedures To run the Diagnostics CLI, follow the procedures for your platform: Linux Ensure you have the Diagnostics CLI: From the command line, change the directory to your application's root directory and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/linux directory, move nrdiag into the application's root directory. Run nrdiag (along with any CLI options ./nrdiag CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to your New Relic account if you include an attachment flag. macOS Ensure you have the Diagnostics CLI: From the command line, change directory to the application's root directory and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/mac directory, move nrdiag into the application's root directory. Run nrdiag (along with any CLI options ./nrdiag CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to your New Relic account if you include an attachment flag. Windows Ensure you have the Diagnostics CLI: From the command line, change directory to the application's root directory, and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/win directory, move nrdiag.exe or nrdiag_x64.exe into the application's root directory. For troubleshooting web applications, ensure you are running the executable from your project's parent directory, or specify your config file location with the -c option. Run the executable (along with any CLI options from the directory you placed the binary. Since some checks require elevated permissions, for best results run from an admin shell. Run via PowerShell if you add any CLI_OPTIONS: ./nrdiag.exe CLI_OPTIONS Copy OR, for x64 systems: ./nrdiag_x64.exe CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to New Relic account if you include an attachment flag. Browser monitoring Ensure you have the latest version of the Diagnostics CLI. If necessary, manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/OS directory, run nrdiag (along with any CLI options: ./nrdiag -browser-url WEBSITE_URL CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers and uploads relevant files to your New Relic account if you include an attachment flag. Docker container To troubleshoot your New Relic-instrumented application running in a Docker container, use the docker exec command: Download and unzip the nrdiag_latest.zip file. Copy the binary to the container. Replace IMAGE_NAME with the name of your docker container: docker cp nrdiag/linux/nrdiag IMAGE_NAME:/bin Copy Run the nrdiag command in the docker container. Replace IMAGE_NAME as above, and replace APPLICATION_ROOT with the root directory of your application, where you installed the New Relic agent: docker exec -it -w APPLICATION_ROOT IMAGE_NAME nrdiag Copy (Optional) Remove the nrdiag binary when finished: docker exec IMAGE_NAME rm /bin/nrdiag Copy Suites flag (highly recommended CLI option) A suite is a collection of health checks that target specific products or issues. Using a suite can help narrow the scope of troubleshooting and reduce the occurrence of false positives. To review a list of available suites, run the Diagnostics CLI with the -help suites option: ./nrdiag --help suites Copy To run suites with nrdiag, provide the -suites flag and one or more suite names (for example, java) to run as arguments. Linux, macOS: For 32-bit systems: ./nrdiag --suites SUITE NAMES Copy For 64-bit systems: ./nrdiag_x64 --suites SUITE NAMES Copy Windows: To run from PowerShell, add ./ to the start of cmd. For 32-bit systems: nrdiag.exe --suites SUITE NAMES Copy For 64-bit systems: nrdiag_x64.exe --suites SUITE NAMES Copy Upload results to a New Relic account Important If your system is configured to not connect to external IP addresses, this method will not work. Instead, attach the output files in an email to New Relic Support. If there is an issue with your license key you will need to manually upload results to your account. Automatic Account upload To upload your results automatically to a New Relic account when the Diagnostics CLI is executed, use the -attach or -a command line flag. This will validate any New Relic License Keys found in your environment for upload. Uploading your results to an account will automatically upload the contents of the nrdiag-output.json and nrdiag-output.zip. If you want to inspect or modify the file's contents before upload, follow the manual upload procedures. Linux, macOS, synthetic private minion: ./nrdiag -attach Copy Windows: To run from PowerShell, add ./ to the start of cmd. For 32-bit systems: nrdiag.exe -attach Copy For 64-bit systems: nrdiag_x64.exe -attach Copy Manual upload If you have a support ticket, use the permalink functionality to share your results. This will help improve troubleshooting speed. The New Relic diagnostics app has the drag and drop functionality if your results are unable to be automatically uploaded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.46295,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Run the <em>Diagnostics</em> <em>CLI</em> (<em>nrdiag</em>)",
        "sections": "Run the <em>Diagnostics</em> <em>CLI</em> (<em>nrdiag</em>)",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": " automatically to a <em>New</em> <em>Relic</em> account when the <em>Diagnostics</em> <em>CLI</em> is executed, <em>use</em> the -attach or -a command line flag. This will validate any <em>New</em> <em>Relic</em> License Keys found in your environment for upload. Uploading your results to an account will automatically upload the contents of the <em>nrdiag</em>"
      },
      "id": "61bfb6ef196a67ea13ef04f5"
    },
    {
      "sections": [
        "Pass command line options for nrdiag"
      ],
      "title": "Pass command line options for nrdiag",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "8f44035147a6f69c41f002c68bc09e1e4a334959",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/pass-command-line-options-nrdiag/",
      "published_at": "2022-01-12T03:28:53Z",
      "updated_at": "2021-12-14T04:14:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To use the following command line options with the Diagnostics CLI: Option Usage -attachment-endpoint STRING Attachment endpoint to include with the support ticket. -a -attach Attach for automatic upload to a New Relic account. This uses a validated license key from your environment. DEPRECATED -ak STRING -attachment-key STRING Attachment key for automatic upload to a support ticket. This gets the attachment key from an existing ticket. (Note: this functionality will be removed soon. Please use the automatic upload option above) -browser-url STRING Diagnostics CLI version 1.1.9 or higher When invoked, this will only run diagnostics checks related to browser monitoring. This command checks that New Relic's browser monitoring agent is present and returns the agent version, the injection method (via APM or via copy/paste), and the loader type (Pro, Lite, SPA). To be used to provide detail to New Relic Support when troubleshooting intranet sites. -c STRING -config-file STRING Override default agent configuration file location. Can be used to specify either a folder to search in addition to the default folders, or a path to a specific configuration file. --filter STRING Filter task results by result status. Accepts a comma separated list. Accepts Success, Warning, Failure, Error, None, or Info. Example syntax: \\\"Success,Warning,Failure\" Copy -h --help Display complete list of command line options. To list all tasks to be run, use -h tasks. Type: bool -inNewRelicCLI Type: bool -interactive Type: bool -output-path STRING Specifies a different output directory to write the results for nrdiag-output.zip, nrdiag-output.json, and nrdiag-filelist.txt. Default location is ./. -o --override STRING Pass in arguments to override when requested by New Relic Support. Format: identifier.property=value. Example syntax: --override Java/Config/Agent.Status=Success Copy -o Base/Config/Validate.agentlanguage=PHP Copy -p STRING --proxy STRING Provide proxy to be used in HTTP connection tasks. Can be HTTP or HTTPS. Proxy should be in the format http(s)://proxyIp:proxy. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. In most cases port is not needed. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -proxy-pw STRING Proxy password, if necessary. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -proxy-user STRING Proxy username, if necessary. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -q --quiet Quiet output only prints the high-level results and not the explanatory output. Suppresses file addition warnings if -y is also used. Does not contradict -v. Inclusion filters are ignored. Type: bool -qq --VeryQuiet Very quiet output only prints a single summary line for output (implies q). Suppresses file addition warnings if -y is also used. Does not contradict -v. Inclusion filters are ignored. Type: bool --SkipVersionCheck Skip the automatic check for a newer version of the application. Type: bool --ShowOverrideHelp Type: bool -s STRING --suites STRING Run a suite, a collection of tasks that target specific products or issues. To specify multiple suites, separate them with commas. To get a list of all suites, run: ./nrdiag -h suites Copy -t STRING --tasks STRING Run only a subset of tasks, either by agent or by task type. To specify multiple tasks, separate them with commas and/or with a wildcard *. For a list of all tasks, run: ./nrdiag -h tasks Copy -usage-opt-out Decline to send anonymous Diagnostics CLI tool usage data to New Relic for this run. Type: bool -v --verbose Display verbose logging during check execution. Disabled by default. Type: bool --version Displays current Diagnostics CLI version. This also prompts to check for a newer version and prompts to download if a newer version is available. Takes precedence over no-version-check. Type: bool -y --yes --YesToAll Respond yes to any prompt that comes up while running. Disabled by default. Type: bool",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.462,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Pass command line options for <em>nrdiag</em>",
        "sections": "Pass command line options for <em>nrdiag</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "To <em>use</em> the following command line options with the <em>Diagnostics</em> <em>CLI</em>: Option Usage -attachment-endpoint STRING Attachment endpoint to include with the support ticket. -a -attach Attach for automatic upload to a <em>New</em> <em>Relic</em> account. This uses a validated license key from your environment. DEPRECATED -ak"
      },
      "id": "61bfb6c0196a67a82aef062e"
    },
    {
      "sections": [
        "Diagnostics CLI licensing and security",
        "License agreements",
        "Data uploaded to account",
        "Data storage",
        "Environment variables"
      ],
      "title": "Diagnostics CLI licensing and security",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "b85d0e253bc6caefd68ff15d535f1c67fb8b5c42",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/diagnostics-cli-licensing-security/",
      "published_at": "2022-01-12T05:58:19Z",
      "updated_at": "2021-12-14T04:14:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Like any other New Relic tool, the Diagnostics CLI service is designed to protect you and your customers' data privacy. The Diagnostics CLI inspects system information and New Relic product artifacts (logs and config files) that are relevant for performing diagnostic checks that assess New Relic product configuration and operability. By default, this data is not transmitted to New Relic. You do have the option to upload this information to a support ticket over HTTPS. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. License agreements The use of the Diagnostics CLI is subject to this license agreement, as well as licensing agreements for open-source software used by the Diagnostics CLI. Data uploaded to account The Diagnostics CLI allows uploading of this information to a support ticket over HTTPS if you use a specific command-line argument. You will be prompted before the collection of any files that we expect to have sensitive information. Before the collected files contained within nrdiag-output.zip and nrdiag-output.json are uploaded to New Relic, you will also be prompted. This allows you to review and edit any information that you do not want to provide. (For example, the nrdiag-output.zip will include your user name.) You also have the option to cancel the upload altogether. Data storage Any support ticket attachments made using nrdiag or containing nrdiag data that are less than or equal to 20MB are stored by Zendesk. All of these attachments are stored by New Relic. For more information, see Zendesk's privacy and data protection policies. Environment variables The Diagnostics CLI examines the following environment variables to perform diagnostic checks. The values of these variables are recorded locally in the nrdiag-output.json file. These include: Any environment variable containing NEWRELIC or NEW_RELIC Any environment variable beginning with NRIA A-C: APP_ENV APPDATA COR_ENABLE_PROFILER COR_PROFILER COR_PROFILER_PATH CORECLR_ENABLE_PROFILING CORECLR_PROFILER CORECLR_PROFILER_PATH D-I: DEFAULT_LOCALE_CFG_FILE DOCKER_API_VERSION DOCKER_HOST DOTNET_INSTALL_PATH DOTNET_SDK_VERSION GLIBC_REPO GLIBC_VERSION HOME J-L: JAVA_HOME JAVA_JCE JAVA_PACKAGE JAVA_VERSION_BUILD JAVA_VERSION_MAJOR JAVA_VERSION_MINOR JBOSS_HOME LANG LOCALAPPDATA M: MINION_API_ENDPOINT MINION_API_PROXY MINION_API_PROXY_SELF_SIGNED_CERT MINION_CHECK_TIMEOUT MINION_DOCKER_API_VERSION MINION_DOCKER_HOST MINION_DOCKER_RUNNER_APPARMOR MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT MINION_GROUP MINION_JAR MINION_JVM_MB MINION_JVM_OPTS MINION_LOG_LEVEL MINION_PROVIDER MINION_USER N-Z: PATH ProgramFiles ProgramData RACK_ENV RAILS_ENV RUBY_ENV WORKDIR",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.46194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Diagnostics</em> <em>CLI</em> licensing and security",
        "sections": "<em>Diagnostics</em> <em>CLI</em> licensing and security",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Like any other <em>New</em> <em>Relic</em> tool, the <em>Diagnostics</em> <em>CLI</em> service is designed to protect you and your customers&#x27; data privacy. The <em>Diagnostics</em> <em>CLI</em> inspects system information and <em>New</em> <em>Relic</em> <em>product</em> artifacts (logs and config files) that are relevant for performing diagnostic checks that assess <em>New</em> <em>Relic</em>"
      },
      "id": "61bfb6c064441f89fe99f183"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/pass-command-line-options-nrdiag": [
    {
      "sections": [
        "Run the Diagnostics CLI (nrdiag)",
        "Platform-specific procedures",
        "Linux",
        "macOS",
        "Windows",
        "Browser monitoring",
        "Docker container",
        "Suites flag (highly recommended CLI option)",
        "Upload results to a New Relic account",
        "Important",
        "Automatic Account upload",
        "Manual upload"
      ],
      "title": "Run the Diagnostics CLI (nrdiag)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "61cb738c86d3a012865b754bdf0c219319f6a8ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/run-diagnostics-cli-nrdiag/",
      "published_at": "2022-01-12T03:28:52Z",
      "updated_at": "2021-12-14T04:15:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download latest version To use the Diagnostics CLI: Review the release notes, to make sure you have the latest version. Download the latest version, which contains executable files for Linux, macOS, and Windows. Move the executable for your platform into the location of your application's root directory. Temporarily raise the logging level for the New Relic agent for more accurate troubleshooting. After you change the logging level, restart your application. Run the executable. Recommendation: To scope your troubleshooting more easily, run nrdiag with a task suite (CLI option). The Diagnostics CLI automatically searches its root directory and subdirectories for agent configuration files and other relevant data. Platform-specific procedures To run the Diagnostics CLI, follow the procedures for your platform: Linux Ensure you have the Diagnostics CLI: From the command line, change the directory to your application's root directory and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/linux directory, move nrdiag into the application's root directory. Run nrdiag (along with any CLI options ./nrdiag CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to your New Relic account if you include an attachment flag. macOS Ensure you have the Diagnostics CLI: From the command line, change directory to the application's root directory and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/mac directory, move nrdiag into the application's root directory. Run nrdiag (along with any CLI options ./nrdiag CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to your New Relic account if you include an attachment flag. Windows Ensure you have the Diagnostics CLI: From the command line, change directory to the application's root directory, and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/win directory, move nrdiag.exe or nrdiag_x64.exe into the application's root directory. For troubleshooting web applications, ensure you are running the executable from your project's parent directory, or specify your config file location with the -c option. Run the executable (along with any CLI options from the directory you placed the binary. Since some checks require elevated permissions, for best results run from an admin shell. Run via PowerShell if you add any CLI_OPTIONS: ./nrdiag.exe CLI_OPTIONS Copy OR, for x64 systems: ./nrdiag_x64.exe CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to New Relic account if you include an attachment flag. Browser monitoring Ensure you have the latest version of the Diagnostics CLI. If necessary, manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/OS directory, run nrdiag (along with any CLI options: ./nrdiag -browser-url WEBSITE_URL CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers and uploads relevant files to your New Relic account if you include an attachment flag. Docker container To troubleshoot your New Relic-instrumented application running in a Docker container, use the docker exec command: Download and unzip the nrdiag_latest.zip file. Copy the binary to the container. Replace IMAGE_NAME with the name of your docker container: docker cp nrdiag/linux/nrdiag IMAGE_NAME:/bin Copy Run the nrdiag command in the docker container. Replace IMAGE_NAME as above, and replace APPLICATION_ROOT with the root directory of your application, where you installed the New Relic agent: docker exec -it -w APPLICATION_ROOT IMAGE_NAME nrdiag Copy (Optional) Remove the nrdiag binary when finished: docker exec IMAGE_NAME rm /bin/nrdiag Copy Suites flag (highly recommended CLI option) A suite is a collection of health checks that target specific products or issues. Using a suite can help narrow the scope of troubleshooting and reduce the occurrence of false positives. To review a list of available suites, run the Diagnostics CLI with the -help suites option: ./nrdiag --help suites Copy To run suites with nrdiag, provide the -suites flag and one or more suite names (for example, java) to run as arguments. Linux, macOS: For 32-bit systems: ./nrdiag --suites SUITE NAMES Copy For 64-bit systems: ./nrdiag_x64 --suites SUITE NAMES Copy Windows: To run from PowerShell, add ./ to the start of cmd. For 32-bit systems: nrdiag.exe --suites SUITE NAMES Copy For 64-bit systems: nrdiag_x64.exe --suites SUITE NAMES Copy Upload results to a New Relic account Important If your system is configured to not connect to external IP addresses, this method will not work. Instead, attach the output files in an email to New Relic Support. If there is an issue with your license key you will need to manually upload results to your account. Automatic Account upload To upload your results automatically to a New Relic account when the Diagnostics CLI is executed, use the -attach or -a command line flag. This will validate any New Relic License Keys found in your environment for upload. Uploading your results to an account will automatically upload the contents of the nrdiag-output.json and nrdiag-output.zip. If you want to inspect or modify the file's contents before upload, follow the manual upload procedures. Linux, macOS, synthetic private minion: ./nrdiag -attach Copy Windows: To run from PowerShell, add ./ to the start of cmd. For 32-bit systems: nrdiag.exe -attach Copy For 64-bit systems: nrdiag_x64.exe -attach Copy Manual upload If you have a support ticket, use the permalink functionality to share your results. This will help improve troubleshooting speed. The New Relic diagnostics app has the drag and drop functionality if your results are unable to be automatically uploaded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.46295,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Run the <em>Diagnostics</em> <em>CLI</em> (<em>nrdiag</em>)",
        "sections": "Run the <em>Diagnostics</em> <em>CLI</em> (<em>nrdiag</em>)",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": " automatically to a <em>New</em> <em>Relic</em> account when the <em>Diagnostics</em> <em>CLI</em> is executed, <em>use</em> the -attach or -a command line flag. This will validate any <em>New</em> <em>Relic</em> License Keys found in your environment for upload. Uploading your results to an account will automatically upload the contents of the <em>nrdiag</em>"
      },
      "id": "61bfb6ef196a67ea13ef04f5"
    },
    {
      "sections": [
        "Diagnostics CLI licensing and security",
        "License agreements",
        "Data uploaded to account",
        "Data storage",
        "Environment variables"
      ],
      "title": "Diagnostics CLI licensing and security",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "b85d0e253bc6caefd68ff15d535f1c67fb8b5c42",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/diagnostics-cli-licensing-security/",
      "published_at": "2022-01-12T05:58:19Z",
      "updated_at": "2021-12-14T04:14:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Like any other New Relic tool, the Diagnostics CLI service is designed to protect you and your customers' data privacy. The Diagnostics CLI inspects system information and New Relic product artifacts (logs and config files) that are relevant for performing diagnostic checks that assess New Relic product configuration and operability. By default, this data is not transmitted to New Relic. You do have the option to upload this information to a support ticket over HTTPS. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. License agreements The use of the Diagnostics CLI is subject to this license agreement, as well as licensing agreements for open-source software used by the Diagnostics CLI. Data uploaded to account The Diagnostics CLI allows uploading of this information to a support ticket over HTTPS if you use a specific command-line argument. You will be prompted before the collection of any files that we expect to have sensitive information. Before the collected files contained within nrdiag-output.zip and nrdiag-output.json are uploaded to New Relic, you will also be prompted. This allows you to review and edit any information that you do not want to provide. (For example, the nrdiag-output.zip will include your user name.) You also have the option to cancel the upload altogether. Data storage Any support ticket attachments made using nrdiag or containing nrdiag data that are less than or equal to 20MB are stored by Zendesk. All of these attachments are stored by New Relic. For more information, see Zendesk's privacy and data protection policies. Environment variables The Diagnostics CLI examines the following environment variables to perform diagnostic checks. The values of these variables are recorded locally in the nrdiag-output.json file. These include: Any environment variable containing NEWRELIC or NEW_RELIC Any environment variable beginning with NRIA A-C: APP_ENV APPDATA COR_ENABLE_PROFILER COR_PROFILER COR_PROFILER_PATH CORECLR_ENABLE_PROFILING CORECLR_PROFILER CORECLR_PROFILER_PATH D-I: DEFAULT_LOCALE_CFG_FILE DOCKER_API_VERSION DOCKER_HOST DOTNET_INSTALL_PATH DOTNET_SDK_VERSION GLIBC_REPO GLIBC_VERSION HOME J-L: JAVA_HOME JAVA_JCE JAVA_PACKAGE JAVA_VERSION_BUILD JAVA_VERSION_MAJOR JAVA_VERSION_MINOR JBOSS_HOME LANG LOCALAPPDATA M: MINION_API_ENDPOINT MINION_API_PROXY MINION_API_PROXY_SELF_SIGNED_CERT MINION_CHECK_TIMEOUT MINION_DOCKER_API_VERSION MINION_DOCKER_HOST MINION_DOCKER_RUNNER_APPARMOR MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT MINION_GROUP MINION_JAR MINION_JVM_MB MINION_JVM_OPTS MINION_LOG_LEVEL MINION_PROVIDER MINION_USER N-Z: PATH ProgramFiles ProgramData RACK_ENV RAILS_ENV RUBY_ENV WORKDIR",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.46194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Diagnostics</em> <em>CLI</em> licensing and security",
        "sections": "<em>Diagnostics</em> <em>CLI</em> licensing and security",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Like any other <em>New</em> <em>Relic</em> tool, the <em>Diagnostics</em> <em>CLI</em> service is designed to protect you and your customers&#x27; data privacy. The <em>Diagnostics</em> <em>CLI</em> inspects system information and <em>New</em> <em>Relic</em> <em>product</em> artifacts (logs and config files) that are relevant for performing diagnostic checks that assess <em>New</em> <em>Relic</em>"
      },
      "id": "61bfb6c064441f89fe99f183"
    },
    {
      "sections": [
        "Validate config file settings with nrdiag",
        "Deployment example"
      ],
      "title": "Validate config file settings with nrdiag",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "a2c402d34a11749a86bd5f0620066305785cd0e1",
      "image": "https://docs.newrelic.com/static/cdfee4566aed5bcc19663854a0b4c8bc/8c557/agent_enabled.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/validate-config-file-settings-nrdiag/",
      "published_at": "2022-01-12T03:29:30Z",
      "updated_at": "2021-12-14T04:13:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Diagnostics CLI includes detailed configuration setting validation for the Java agent's newrelic.yml file. To request support for other New Relic agents, use our GitHub template. If you run nrdiag in the usual manner (on the system running your application with the New Relic agent already installed), the new validation is applied automatically, and any warnings also automatically appear. Deployment example You can also use this feature as a linter to validate a config file before deployment. To do this, run the appropriate task and provide the path to your config file. For example, if your newrelic.yml and nrdiag are both in the current directory, run the following command to lint the config file: ./nrdiag -t Java/Config/ValidateSettings -c newrelic.yml Copy Here is an example of the output for an incorrect setting. The agent_enabled setting in this case has a value of yes, but the Java agent only accepts the values true or false. This misconfiguration will prevent the agent from running. If you enable your Java agent incorrectly, the Diagnostics CLI returns a message like this, describing what setting needs to be updated and how it needs to be changed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.46088,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Validate config file settings with <em>nrdiag</em>",
        "sections": "Validate config file settings with <em>nrdiag</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "The <em>Diagnostics</em> <em>CLI</em> includes detailed configuration setting validation for the Java agent&#x27;s newrelic.yml file. To request support for other <em>New</em> <em>Relic</em> agents, <em>use</em> our GitHub template. If you run <em>nrdiag</em> in the usual manner (on the system running your application with the <em>New</em> <em>Relic</em> agent already"
      },
      "id": "61bfb6c064441f121e99f98c"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/run-diagnostics-cli-nrdiag": [
    {
      "sections": [
        "Pass command line options for nrdiag"
      ],
      "title": "Pass command line options for nrdiag",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "8f44035147a6f69c41f002c68bc09e1e4a334959",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/pass-command-line-options-nrdiag/",
      "published_at": "2022-01-12T03:28:53Z",
      "updated_at": "2021-12-14T04:14:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To use the following command line options with the Diagnostics CLI: Option Usage -attachment-endpoint STRING Attachment endpoint to include with the support ticket. -a -attach Attach for automatic upload to a New Relic account. This uses a validated license key from your environment. DEPRECATED -ak STRING -attachment-key STRING Attachment key for automatic upload to a support ticket. This gets the attachment key from an existing ticket. (Note: this functionality will be removed soon. Please use the automatic upload option above) -browser-url STRING Diagnostics CLI version 1.1.9 or higher When invoked, this will only run diagnostics checks related to browser monitoring. This command checks that New Relic's browser monitoring agent is present and returns the agent version, the injection method (via APM or via copy/paste), and the loader type (Pro, Lite, SPA). To be used to provide detail to New Relic Support when troubleshooting intranet sites. -c STRING -config-file STRING Override default agent configuration file location. Can be used to specify either a folder to search in addition to the default folders, or a path to a specific configuration file. --filter STRING Filter task results by result status. Accepts a comma separated list. Accepts Success, Warning, Failure, Error, None, or Info. Example syntax: \\\"Success,Warning,Failure\" Copy -h --help Display complete list of command line options. To list all tasks to be run, use -h tasks. Type: bool -inNewRelicCLI Type: bool -interactive Type: bool -output-path STRING Specifies a different output directory to write the results for nrdiag-output.zip, nrdiag-output.json, and nrdiag-filelist.txt. Default location is ./. -o --override STRING Pass in arguments to override when requested by New Relic Support. Format: identifier.property=value. Example syntax: --override Java/Config/Agent.Status=Success Copy -o Base/Config/Validate.agentlanguage=PHP Copy -p STRING --proxy STRING Provide proxy to be used in HTTP connection tasks. Can be HTTP or HTTPS. Proxy should be in the format http(s)://proxyIp:proxy. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. In most cases port is not needed. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -proxy-pw STRING Proxy password, if necessary. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -proxy-user STRING Proxy username, if necessary. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -q --quiet Quiet output only prints the high-level results and not the explanatory output. Suppresses file addition warnings if -y is also used. Does not contradict -v. Inclusion filters are ignored. Type: bool -qq --VeryQuiet Very quiet output only prints a single summary line for output (implies q). Suppresses file addition warnings if -y is also used. Does not contradict -v. Inclusion filters are ignored. Type: bool --SkipVersionCheck Skip the automatic check for a newer version of the application. Type: bool --ShowOverrideHelp Type: bool -s STRING --suites STRING Run a suite, a collection of tasks that target specific products or issues. To specify multiple suites, separate them with commas. To get a list of all suites, run: ./nrdiag -h suites Copy -t STRING --tasks STRING Run only a subset of tasks, either by agent or by task type. To specify multiple tasks, separate them with commas and/or with a wildcard *. For a list of all tasks, run: ./nrdiag -h tasks Copy -usage-opt-out Decline to send anonymous Diagnostics CLI tool usage data to New Relic for this run. Type: bool -v --verbose Display verbose logging during check execution. Disabled by default. Type: bool --version Displays current Diagnostics CLI version. This also prompts to check for a newer version and prompts to download if a newer version is available. Takes precedence over no-version-check. Type: bool -y --yes --YesToAll Respond yes to any prompt that comes up while running. Disabled by default. Type: bool",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.462,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Pass command line options for <em>nrdiag</em>",
        "sections": "Pass command line options for <em>nrdiag</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "To <em>use</em> the following command line options with the <em>Diagnostics</em> <em>CLI</em>: Option Usage -attachment-endpoint STRING Attachment endpoint to include with the support ticket. -a -attach Attach for automatic upload to a <em>New</em> <em>Relic</em> account. This uses a validated license key from your environment. DEPRECATED -ak"
      },
      "id": "61bfb6c0196a67a82aef062e"
    },
    {
      "sections": [
        "Diagnostics CLI licensing and security",
        "License agreements",
        "Data uploaded to account",
        "Data storage",
        "Environment variables"
      ],
      "title": "Diagnostics CLI licensing and security",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "b85d0e253bc6caefd68ff15d535f1c67fb8b5c42",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/diagnostics-cli-licensing-security/",
      "published_at": "2022-01-12T05:58:19Z",
      "updated_at": "2021-12-14T04:14:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Like any other New Relic tool, the Diagnostics CLI service is designed to protect you and your customers' data privacy. The Diagnostics CLI inspects system information and New Relic product artifacts (logs and config files) that are relevant for performing diagnostic checks that assess New Relic product configuration and operability. By default, this data is not transmitted to New Relic. You do have the option to upload this information to a support ticket over HTTPS. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. License agreements The use of the Diagnostics CLI is subject to this license agreement, as well as licensing agreements for open-source software used by the Diagnostics CLI. Data uploaded to account The Diagnostics CLI allows uploading of this information to a support ticket over HTTPS if you use a specific command-line argument. You will be prompted before the collection of any files that we expect to have sensitive information. Before the collected files contained within nrdiag-output.zip and nrdiag-output.json are uploaded to New Relic, you will also be prompted. This allows you to review and edit any information that you do not want to provide. (For example, the nrdiag-output.zip will include your user name.) You also have the option to cancel the upload altogether. Data storage Any support ticket attachments made using nrdiag or containing nrdiag data that are less than or equal to 20MB are stored by Zendesk. All of these attachments are stored by New Relic. For more information, see Zendesk's privacy and data protection policies. Environment variables The Diagnostics CLI examines the following environment variables to perform diagnostic checks. The values of these variables are recorded locally in the nrdiag-output.json file. These include: Any environment variable containing NEWRELIC or NEW_RELIC Any environment variable beginning with NRIA A-C: APP_ENV APPDATA COR_ENABLE_PROFILER COR_PROFILER COR_PROFILER_PATH CORECLR_ENABLE_PROFILING CORECLR_PROFILER CORECLR_PROFILER_PATH D-I: DEFAULT_LOCALE_CFG_FILE DOCKER_API_VERSION DOCKER_HOST DOTNET_INSTALL_PATH DOTNET_SDK_VERSION GLIBC_REPO GLIBC_VERSION HOME J-L: JAVA_HOME JAVA_JCE JAVA_PACKAGE JAVA_VERSION_BUILD JAVA_VERSION_MAJOR JAVA_VERSION_MINOR JBOSS_HOME LANG LOCALAPPDATA M: MINION_API_ENDPOINT MINION_API_PROXY MINION_API_PROXY_SELF_SIGNED_CERT MINION_CHECK_TIMEOUT MINION_DOCKER_API_VERSION MINION_DOCKER_HOST MINION_DOCKER_RUNNER_APPARMOR MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT MINION_GROUP MINION_JAR MINION_JVM_MB MINION_JVM_OPTS MINION_LOG_LEVEL MINION_PROVIDER MINION_USER N-Z: PATH ProgramFiles ProgramData RACK_ENV RAILS_ENV RUBY_ENV WORKDIR",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.46194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Diagnostics</em> <em>CLI</em> licensing and security",
        "sections": "<em>Diagnostics</em> <em>CLI</em> licensing and security",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Like any other <em>New</em> <em>Relic</em> tool, the <em>Diagnostics</em> <em>CLI</em> service is designed to protect you and your customers&#x27; data privacy. The <em>Diagnostics</em> <em>CLI</em> inspects system information and <em>New</em> <em>Relic</em> <em>product</em> artifacts (logs and config files) that are relevant for performing diagnostic checks that assess <em>New</em> <em>Relic</em>"
      },
      "id": "61bfb6c064441f89fe99f183"
    },
    {
      "sections": [
        "Validate config file settings with nrdiag",
        "Deployment example"
      ],
      "title": "Validate config file settings with nrdiag",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "a2c402d34a11749a86bd5f0620066305785cd0e1",
      "image": "https://docs.newrelic.com/static/cdfee4566aed5bcc19663854a0b4c8bc/8c557/agent_enabled.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/validate-config-file-settings-nrdiag/",
      "published_at": "2022-01-12T03:29:30Z",
      "updated_at": "2021-12-14T04:13:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Diagnostics CLI includes detailed configuration setting validation for the Java agent's newrelic.yml file. To request support for other New Relic agents, use our GitHub template. If you run nrdiag in the usual manner (on the system running your application with the New Relic agent already installed), the new validation is applied automatically, and any warnings also automatically appear. Deployment example You can also use this feature as a linter to validate a config file before deployment. To do this, run the appropriate task and provide the path to your config file. For example, if your newrelic.yml and nrdiag are both in the current directory, run the following command to lint the config file: ./nrdiag -t Java/Config/ValidateSettings -c newrelic.yml Copy Here is an example of the output for an incorrect setting. The agent_enabled setting in this case has a value of yes, but the Java agent only accepts the values true or false. This misconfiguration will prevent the agent from running. If you enable your Java agent incorrectly, the Diagnostics CLI returns a message like this, describing what setting needs to be updated and how it needs to be changed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.46088,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Validate config file settings with <em>nrdiag</em>",
        "sections": "Validate config file settings with <em>nrdiag</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "The <em>Diagnostics</em> <em>CLI</em> includes detailed configuration setting validation for the Java agent&#x27;s newrelic.yml file. To request support for other <em>New</em> <em>Relic</em> agents, <em>use</em> our GitHub template. If you run <em>nrdiag</em> in the usual manner (on the system running your application with the <em>New</em> <em>Relic</em> agent already"
      },
      "id": "61bfb6c064441f121e99f98c"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/validate-config-file-settings-nrdiag": [
    {
      "sections": [
        "Run the Diagnostics CLI (nrdiag)",
        "Platform-specific procedures",
        "Linux",
        "macOS",
        "Windows",
        "Browser monitoring",
        "Docker container",
        "Suites flag (highly recommended CLI option)",
        "Upload results to a New Relic account",
        "Important",
        "Automatic Account upload",
        "Manual upload"
      ],
      "title": "Run the Diagnostics CLI (nrdiag)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "61cb738c86d3a012865b754bdf0c219319f6a8ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/run-diagnostics-cli-nrdiag/",
      "published_at": "2022-01-12T03:28:52Z",
      "updated_at": "2021-12-14T04:15:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download latest version To use the Diagnostics CLI: Review the release notes, to make sure you have the latest version. Download the latest version, which contains executable files for Linux, macOS, and Windows. Move the executable for your platform into the location of your application's root directory. Temporarily raise the logging level for the New Relic agent for more accurate troubleshooting. After you change the logging level, restart your application. Run the executable. Recommendation: To scope your troubleshooting more easily, run nrdiag with a task suite (CLI option). The Diagnostics CLI automatically searches its root directory and subdirectories for agent configuration files and other relevant data. Platform-specific procedures To run the Diagnostics CLI, follow the procedures for your platform: Linux Ensure you have the Diagnostics CLI: From the command line, change the directory to your application's root directory and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/linux directory, move nrdiag into the application's root directory. Run nrdiag (along with any CLI options ./nrdiag CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to your New Relic account if you include an attachment flag. macOS Ensure you have the Diagnostics CLI: From the command line, change directory to the application's root directory and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/mac directory, move nrdiag into the application's root directory. Run nrdiag (along with any CLI options ./nrdiag CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to your New Relic account if you include an attachment flag. Windows Ensure you have the Diagnostics CLI: From the command line, change directory to the application's root directory, and ensure that the nrdiag.zip file is present. OR Manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/win directory, move nrdiag.exe or nrdiag_x64.exe into the application's root directory. For troubleshooting web applications, ensure you are running the executable from your project's parent directory, or specify your config file location with the -c option. Run the executable (along with any CLI options from the directory you placed the binary. Since some checks require elevated permissions, for best results run from an admin shell. Run via PowerShell if you add any CLI_OPTIONS: ./nrdiag.exe CLI_OPTIONS Copy OR, for x64 systems: ./nrdiag_x64.exe CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers, and uploads relevant files to New Relic account if you include an attachment flag. Browser monitoring Ensure you have the latest version of the Diagnostics CLI. If necessary, manually download the latest version. Unzip nrdiag.zip if necessary. From the nrdiag_1.2.3/OS directory, run nrdiag (along with any CLI options: ./nrdiag -browser-url WEBSITE_URL CLI_OPTIONS Copy The Diagnostics CLI outputs any issues it discovers and uploads relevant files to your New Relic account if you include an attachment flag. Docker container To troubleshoot your New Relic-instrumented application running in a Docker container, use the docker exec command: Download and unzip the nrdiag_latest.zip file. Copy the binary to the container. Replace IMAGE_NAME with the name of your docker container: docker cp nrdiag/linux/nrdiag IMAGE_NAME:/bin Copy Run the nrdiag command in the docker container. Replace IMAGE_NAME as above, and replace APPLICATION_ROOT with the root directory of your application, where you installed the New Relic agent: docker exec -it -w APPLICATION_ROOT IMAGE_NAME nrdiag Copy (Optional) Remove the nrdiag binary when finished: docker exec IMAGE_NAME rm /bin/nrdiag Copy Suites flag (highly recommended CLI option) A suite is a collection of health checks that target specific products or issues. Using a suite can help narrow the scope of troubleshooting and reduce the occurrence of false positives. To review a list of available suites, run the Diagnostics CLI with the -help suites option: ./nrdiag --help suites Copy To run suites with nrdiag, provide the -suites flag and one or more suite names (for example, java) to run as arguments. Linux, macOS: For 32-bit systems: ./nrdiag --suites SUITE NAMES Copy For 64-bit systems: ./nrdiag_x64 --suites SUITE NAMES Copy Windows: To run from PowerShell, add ./ to the start of cmd. For 32-bit systems: nrdiag.exe --suites SUITE NAMES Copy For 64-bit systems: nrdiag_x64.exe --suites SUITE NAMES Copy Upload results to a New Relic account Important If your system is configured to not connect to external IP addresses, this method will not work. Instead, attach the output files in an email to New Relic Support. If there is an issue with your license key you will need to manually upload results to your account. Automatic Account upload To upload your results automatically to a New Relic account when the Diagnostics CLI is executed, use the -attach or -a command line flag. This will validate any New Relic License Keys found in your environment for upload. Uploading your results to an account will automatically upload the contents of the nrdiag-output.json and nrdiag-output.zip. If you want to inspect or modify the file's contents before upload, follow the manual upload procedures. Linux, macOS, synthetic private minion: ./nrdiag -attach Copy Windows: To run from PowerShell, add ./ to the start of cmd. For 32-bit systems: nrdiag.exe -attach Copy For 64-bit systems: nrdiag_x64.exe -attach Copy Manual upload If you have a support ticket, use the permalink functionality to share your results. This will help improve troubleshooting speed. The New Relic diagnostics app has the drag and drop functionality if your results are unable to be automatically uploaded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.46292,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Run the <em>Diagnostics</em> <em>CLI</em> (<em>nrdiag</em>)",
        "sections": "Run the <em>Diagnostics</em> <em>CLI</em> (<em>nrdiag</em>)",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": " automatically to a <em>New</em> <em>Relic</em> account when the <em>Diagnostics</em> <em>CLI</em> is executed, <em>use</em> the -attach or -a command line flag. This will validate any <em>New</em> <em>Relic</em> License Keys found in your environment for upload. Uploading your results to an account will automatically upload the contents of the <em>nrdiag</em>"
      },
      "id": "61bfb6ef196a67ea13ef04f5"
    },
    {
      "sections": [
        "Pass command line options for nrdiag"
      ],
      "title": "Pass command line options for nrdiag",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "8f44035147a6f69c41f002c68bc09e1e4a334959",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/pass-command-line-options-nrdiag/",
      "published_at": "2022-01-12T03:28:53Z",
      "updated_at": "2021-12-14T04:14:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To use the following command line options with the Diagnostics CLI: Option Usage -attachment-endpoint STRING Attachment endpoint to include with the support ticket. -a -attach Attach for automatic upload to a New Relic account. This uses a validated license key from your environment. DEPRECATED -ak STRING -attachment-key STRING Attachment key for automatic upload to a support ticket. This gets the attachment key from an existing ticket. (Note: this functionality will be removed soon. Please use the automatic upload option above) -browser-url STRING Diagnostics CLI version 1.1.9 or higher When invoked, this will only run diagnostics checks related to browser monitoring. This command checks that New Relic's browser monitoring agent is present and returns the agent version, the injection method (via APM or via copy/paste), and the loader type (Pro, Lite, SPA). To be used to provide detail to New Relic Support when troubleshooting intranet sites. -c STRING -config-file STRING Override default agent configuration file location. Can be used to specify either a folder to search in addition to the default folders, or a path to a specific configuration file. --filter STRING Filter task results by result status. Accepts a comma separated list. Accepts Success, Warning, Failure, Error, None, or Info. Example syntax: \\\"Success,Warning,Failure\" Copy -h --help Display complete list of command line options. To list all tasks to be run, use -h tasks. Type: bool -inNewRelicCLI Type: bool -interactive Type: bool -output-path STRING Specifies a different output directory to write the results for nrdiag-output.zip, nrdiag-output.json, and nrdiag-filelist.txt. Default location is ./. -o --override STRING Pass in arguments to override when requested by New Relic Support. Format: identifier.property=value. Example syntax: --override Java/Config/Agent.Status=Success Copy -o Base/Config/Validate.agentlanguage=PHP Copy -p STRING --proxy STRING Provide proxy to be used in HTTP connection tasks. Can be HTTP or HTTPS. Proxy should be in the format http(s)://proxyIp:proxy. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. In most cases port is not needed. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -proxy-pw STRING Proxy password, if necessary. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -proxy-user STRING Proxy username, if necessary. If the Diagnostics CLI finds a proxy in the agent config file, it will use that proxy by default. -q --quiet Quiet output only prints the high-level results and not the explanatory output. Suppresses file addition warnings if -y is also used. Does not contradict -v. Inclusion filters are ignored. Type: bool -qq --VeryQuiet Very quiet output only prints a single summary line for output (implies q). Suppresses file addition warnings if -y is also used. Does not contradict -v. Inclusion filters are ignored. Type: bool --SkipVersionCheck Skip the automatic check for a newer version of the application. Type: bool --ShowOverrideHelp Type: bool -s STRING --suites STRING Run a suite, a collection of tasks that target specific products or issues. To specify multiple suites, separate them with commas. To get a list of all suites, run: ./nrdiag -h suites Copy -t STRING --tasks STRING Run only a subset of tasks, either by agent or by task type. To specify multiple tasks, separate them with commas and/or with a wildcard *. For a list of all tasks, run: ./nrdiag -h tasks Copy -usage-opt-out Decline to send anonymous Diagnostics CLI tool usage data to New Relic for this run. Type: bool -v --verbose Display verbose logging during check execution. Disabled by default. Type: bool --version Displays current Diagnostics CLI version. This also prompts to check for a newer version and prompts to download if a newer version is available. Takes precedence over no-version-check. Type: bool -y --yes --YesToAll Respond yes to any prompt that comes up while running. Disabled by default. Type: bool",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.46198,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Pass command line options for <em>nrdiag</em>",
        "sections": "Pass command line options for <em>nrdiag</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "To <em>use</em> the following command line options with the <em>Diagnostics</em> <em>CLI</em>: Option Usage -attachment-endpoint STRING Attachment endpoint to include with the support ticket. -a -attach Attach for automatic upload to a <em>New</em> <em>Relic</em> account. This uses a validated license key from your environment. DEPRECATED -ak"
      },
      "id": "61bfb6c0196a67a82aef062e"
    },
    {
      "sections": [
        "Diagnostics CLI licensing and security",
        "License agreements",
        "Data uploaded to account",
        "Data storage",
        "Environment variables"
      ],
      "title": "Diagnostics CLI licensing and security",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "b85d0e253bc6caefd68ff15d535f1c67fb8b5c42",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/diagnostics-cli-nrdiag/diagnostics-cli-licensing-security/",
      "published_at": "2022-01-12T05:58:19Z",
      "updated_at": "2021-12-14T04:14:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Like any other New Relic tool, the Diagnostics CLI service is designed to protect you and your customers' data privacy. The Diagnostics CLI inspects system information and New Relic product artifacts (logs and config files) that are relevant for performing diagnostic checks that assess New Relic product configuration and operability. By default, this data is not transmitted to New Relic. You do have the option to upload this information to a support ticket over HTTPS. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. License agreements The use of the Diagnostics CLI is subject to this license agreement, as well as licensing agreements for open-source software used by the Diagnostics CLI. Data uploaded to account The Diagnostics CLI allows uploading of this information to a support ticket over HTTPS if you use a specific command-line argument. You will be prompted before the collection of any files that we expect to have sensitive information. Before the collected files contained within nrdiag-output.zip and nrdiag-output.json are uploaded to New Relic, you will also be prompted. This allows you to review and edit any information that you do not want to provide. (For example, the nrdiag-output.zip will include your user name.) You also have the option to cancel the upload altogether. Data storage Any support ticket attachments made using nrdiag or containing nrdiag data that are less than or equal to 20MB are stored by Zendesk. All of these attachments are stored by New Relic. For more information, see Zendesk's privacy and data protection policies. Environment variables The Diagnostics CLI examines the following environment variables to perform diagnostic checks. The values of these variables are recorded locally in the nrdiag-output.json file. These include: Any environment variable containing NEWRELIC or NEW_RELIC Any environment variable beginning with NRIA A-C: APP_ENV APPDATA COR_ENABLE_PROFILER COR_PROFILER COR_PROFILER_PATH CORECLR_ENABLE_PROFILING CORECLR_PROFILER CORECLR_PROFILER_PATH D-I: DEFAULT_LOCALE_CFG_FILE DOCKER_API_VERSION DOCKER_HOST DOTNET_INSTALL_PATH DOTNET_SDK_VERSION GLIBC_REPO GLIBC_VERSION HOME J-L: JAVA_HOME JAVA_JCE JAVA_PACKAGE JAVA_VERSION_BUILD JAVA_VERSION_MAJOR JAVA_VERSION_MINOR JBOSS_HOME LANG LOCALAPPDATA M: MINION_API_ENDPOINT MINION_API_PROXY MINION_API_PROXY_SELF_SIGNED_CERT MINION_CHECK_TIMEOUT MINION_DOCKER_API_VERSION MINION_DOCKER_HOST MINION_DOCKER_RUNNER_APPARMOR MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT MINION_GROUP MINION_JAR MINION_JVM_MB MINION_JVM_OPTS MINION_LOG_LEVEL MINION_PROVIDER MINION_USER N-Z: PATH ProgramFiles ProgramData RACK_ENV RAILS_ENV RUBY_ENV WORKDIR",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.4619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Diagnostics</em> <em>CLI</em> licensing and security",
        "sections": "<em>Diagnostics</em> <em>CLI</em> licensing and security",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Like any other <em>New</em> <em>Relic</em> tool, the <em>Diagnostics</em> <em>CLI</em> service is designed to protect you and your customers&#x27; data privacy. The <em>Diagnostics</em> <em>CLI</em> inspects system information and <em>New</em> <em>Relic</em> <em>product</em> artifacts (logs and config files) that are relevant for performing diagnostic checks that assess <em>New</em> <em>Relic</em>"
      },
      "id": "61bfb6c064441f89fe99f183"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/find-help-use-support-portal": [
    {
      "sections": [
        "Introduction to New Relic",
        "Get started with New Relic",
        "All the answers in one place",
        "Bring all your data together",
        "Analyze your data",
        "Respond to incidents faster",
        "Troubleshoot from anywhere in your stack"
      ],
      "title": "Introduction to New Relic",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "f47a40a9afd699e69c351f5e87f64ed5dadd7e43",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/intro-new-relic/",
      "published_at": "2022-01-12T18:27:10Z",
      "updated_at": "2022-01-12T18:27:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic is an observability platform that helps you build better software. You can bring in data from any digital source so that you can fully understand your system and how to improve it. This short video shows twenty of the most common ways to get your data into New Relic (approx. 5:22 minutes): With New Relic, you can: Bring all your data together: Instrument everything and import data from across your technology stack using our agents, integrations, and APIs, and access it from a single UI. Analyze your data: Get all your data at your fingertips to find the root causes of problems and optimize your systems. Build dashboards and charts or use our powerful query language. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. Get started with New Relic Here's how you can quickly get started capturing and analyzing your data: If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever! Follow the steps in our Add your data UI page to get data flowing in. For your first install, we recommend the Guided install option, which will set up many integrations with a single command. Once you have data coming into New Relic, learn more about the New Relic UI or set up Alerts. All the answers in one place New Relic is built for full stack observability. It links all relevant data so that you get the whole picture of everything that enables your systems to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Monitoring vs. observability: New Relic provides answers to essential questions in one place. As just one example of what you can do with New Relic, imagine you are a Kubernetes administrator overseeing many clusters and pods of software containers. Where do you start troubleshooting? This short video shows how you can locate a problem cluster and use distributed tracing to find relevant logs: Bring all your data together Capture, organize, and make sense of your data in New Relic One, no matter where it comes from. Use our agents and integrations to automatically collect data from common frameworks and tools, or use our APIs for data that’s more specific to your business or technology. If you don't see your technologies or tasks listed here, see a larger list at New Relic Instant Observability. There you will find integrations bundled into quickstarts, providing you instant access to pre-built dashboards and alerts specific to your technology. If you want to... New Relic can help you... Instrument your application Instrument your code: Use our APM agents to automatically instrument your applications in C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Track transactions: Gather distributed tracing details as your transactions cross boundaries between apps and services. Instrument your environment Instrument your infrastructure: Observe your entire environment (including Linux, Windows, AWS, Azure, Google Cloud Platform, Kubernetes, Docker, and more). Collect and centralize logs: See your log data in context with your other application and infrastructure data. Save time switching between tools and reach solutions more quickly. Instrument your digital experiences Enhance browser performance: Decrease page load times, as well as triage and eliminate errors. Monitor mobile apps: Troubleshoot crashes and check the health of your Android and iOS apps with our mobile agents. Simulate user activity: Ensure you’re meeting customer expectations by running automated checks to monitor key user flows and experiences. Send data via APIs or build your own solution Collect data without an agent: Call our APIs directly if you prefer to use OpenTelemetry or other agents. Build your own integration: You can use our Flex tool, or one of language-specific SDKs for creating your own exporters to send data to New Relic. New Relic One gives you access to a wide range of observability tools, including: Application monitoring Browser monitoring Mobile monitoring Synthetic monitoring Serverless monitoring Infrastructure monitoring Log management You can start anywhere, but you'll never get lost. True observability across your entire stack means that you're in control. Analyze your data With your data secure at New Relic, our platform can alert you to problems and help you organize, process, and understand your data, whether it's metrics, events, logs, or traces: Explore your data visually: Jump into our data explorer to navigate all your data and make connections between your entities without any knowledge of query languages. Query and visualize your data: Use our curated dashboard visualizations or create your own. Use NRQL (New Relic Query Language) to slice and dice your data and dig deeper into questions. Query your data programmatically: Access your data through our NerdGraph GraphQL API. Easily prototype queries in our GraphiQL editor. Respond to incidents faster DevOps, site-reliability, and network operation teams need reliable, real-time alerts and anomaly detection to ensure their systems are always up and running efficiently. Let Applied Intelligence, our hybrid machine learning engine, automatically detect anomalies, reduce alert noise, and enrich incidents with context so that you can respond faster to incidents. Proactive detection: Be notified of unusual app behavior and get an analysis of this unusual behavior sent to Slack. Not using Slack? Set up a webhook to deliver messages when you need them. Get notifications: Set up alerts across your data sources and get notified when systems need your attention. Preserve your attention and control how many threshold violations should fire before you're notified. Troubleshoot from anywhere in your stack Being fully connected, the New Relic UI allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but they can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 357.68344,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction <em>to</em> <em>New</em> <em>Relic</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " and optimize your systems. Build dashboards and charts or <em>use</em> our powerful query language. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. <em>Get</em> <em>started</em> with <em>New</em> <em>Relic</em> Here&#x27;s how you can quickly <em>get</em> <em>started</em>"
      },
      "id": "619d5b3e196a6705bda0837d"
    },
    {
      "sections": [
        "Glossary of New Relic terms",
        "account dropdown",
        "account switcher",
        "administrator",
        "agent",
        "agent API",
        "aggregated metrics",
        "aggregation delay",
        "aggregation function",
        "aggregation method",
        "aggregation timer",
        "aggregation window",
        "alert",
        "alert condition",
        "alert evaluation",
        "alert policy",
        "apdex",
        "apdex_f",
        "apdex_t",
        "API (application programming interface)",
        "APM",
        "application",
        "application ID",
        "application name",
        "Applied Intelligence (AI)",
        "attribute",
        "availability monitoring",
        "browser",
        "Browser monitoring",
        "background external",
        "child account",
        "cloud-based integration",
        "collector",
        "Command line interface (CLI)",
        "compute unit (CU)",
        "condition_id",
        "CPM (calls per minute)",
        "CPU burn",
        "custom attribute",
        "custom dashboard",
        "custom event",
        "custom instrumentation",
        "custom metric",
        "data collector",
        "data explorer",
        "degradation period",
        "dimensional metric",
        "Docker",
        "downtime",
        "entity",
        "event",
        "expected error",
        "exporter",
        "Flex",
        "framework",
        "harvest cycle",
        "health status indicator",
        "host",
        "host ID",
        "ignored error",
        "incident",
        "Infrastructure monitoring",
        "Insights",
        "instance ID",
        "instrumentation",
        "integration",
        "interaction",
        "interaction trace",
        "inventory data",
        "key transaction",
        "launcher",
        "log",
        "Log monitoring",
        "Logs",
        "Logs in context",
        "master account",
        "metric",
        "metric timeslice",
        "metric grouping issue",
        "minion",
        "Mobile monitoring",
        "monitor",
        "NerdGraph",
        "Nerdlet",
        "Nerdpack",
        "New Relic Edge with Infinite Tracing",
        "New Relic One",
        "New Relic One catalog",
        "NRQL (New Relic query language)",
        "non-web transaction",
        "notification",
        "notification channel",
        "on-host integration",
        "owner",
        "page load timing",
        "parameter",
        "parent account",
        "permalink",
        "pinger",
        "polling interval (AWS)",
        "PPM (pages per minute)",
        "private location",
        "recovery period",
        "response time",
        "restricted user",
        "rollup",
        "root span",
        "RPM",
        "RUM (real user monitoring)",
        "runbook",
        "SAML (Security Assertion Markup Language)",
        "Selenium",
        "service",
        "signal",
        "signal filter",
        "span",
        "SSL certificate",
        "SSO (single sign on)",
        "streaming algorithm",
        "sub-accounts",
        "Synthetic monitoring",
        "target",
        "tag",
        "thresholds",
        "throughput",
        "tier",
        "time picker",
        "time range",
        "timeslice data",
        "trace",
        "traffic light",
        "transaction",
        "transaction trace",
        "UI",
        "user",
        "UTC",
        "value function (metrics)",
        "violation",
        "web external",
        "web transaction",
        "WebDriverJS",
        "workload"
      ],
      "title": "Glossary of New Relic terms",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "8f8fc1ec9f41e6a4d6b4e986e9b0589bc2ca1f86",
      "image": "https://docs.newrelic.com/static/44172b3e07c1f24191825360676b9d99/c1b63/account-dropdown.png",
      "url": "https://docs.newrelic.com/docs/glossary/glossary/",
      "published_at": "2022-01-12T11:32:36Z",
      "updated_at": "2022-01-08T01:45:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you're considering New Relic One or you're already using our capabilities, this glossary of common terminology can help. And if you don't already have a New Relic account, don't hesitate to sign up at newrelic.com/signup. It's free, forever! account dropdown In the upper right of the New Relic UI, the account dropdown gives you access to your account settings. If you're trying to switch between accounts, use the account switcher. account switcher If you have access to more than one account in a multi-account organization, you can use the account switcher to switch between accounts. This is located in the top right of most New Relic UI pages. For more on factors that affect access to accounts, see Factors affecting access. To find account settings, use the account dropdown. administrator A type of user role on a New Relic account. For more information, see Users. agent At New Relic, an agent is a piece of monitoring software that provides integrations with various technologies (for example, web frameworks, host operating systems, or database types). The agents send that data to New Relic, usually on a specific cadence. For more information, see: New Relic Instant Observability Install agents agent API Some New Relic agents have agent APIs that allow you to extend the functionality of an agent. You can use the API to control, customize and extend the functionality of the agent. Here are some agent API docs: APM agents: C SDK API Go agent API Java agent API .NET agent API Node.js agent API PHP agent API Ruby agent API Python agent API Browser agent: Browser agent API Mobile agents: iOS SDK API Android SDK API aggregated metrics Aggregated metric data summarizes calls to specific methods in your application, including how many times each one was called and response times. In the New Relic UI, you see the class and method names along with their aggregate numbers. Metric data aggregation depends on the New Relic tool and your subscription level. For more information, see the documentation about data retention. aggregation delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. aggregation function You can use NRQL query functions, such as sum(), average(), or latest() to choose how the data points in an aggregation window should be processed into a single data point. The single aggregated data point is what's passed through the alert evaluation process. aggregation method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics) CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer setting. The Timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. aggregation timer The length of time in seconds to wait after each data point received, to ensure the entire batch is processed. Required when using EVENT_TIMER aggregation_method type. aggregation window Streaming alerts gathers data together into specific amounts of time. These windows of time are customizable. Data points are collected together based their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. alert An alert communicates an event or incident that designated personnel can track through Alerts. For an explanation of how basic alerts concepts are related, see Concepts and workflow. alert condition An alert condition (or condition), identified by its unique numeric condition_id, contains the criteria for creating a violation. The condition includes the threshold that is set for a metric timeslice or a custom metric over time on a chosen target. For an explanation of how a condition relates to other basic alerts concepts, see Concepts and workflow. alert evaluation Streaming data is assessed on a set of aggregation windows to determine if an alert condition is violating or recovering. The aggregation window time is how long we'll collect data before running the NRQL query condition. The offset evaluation time is how long you want us to wait for late data before assessing it. If a window doesn't have any data points, it's treated as a gap for loss of signal. alert policy A collection of one or more conditions, one or more notification channels, and an Incident preference setting. If a condition contained within the policy opens a violation, an incident may be opened depending on the Incident preference setting. Notifications will then be sent to all channels attached to the policy. For an explanation of how a policy relates to other basic alerts concepts, see Concepts and workflow. apdex Apdex is an industry-standard way to measure users' satisfaction with the response time of an application or service. New Relic rates each response as Satisfied, Tolerated, or Frustrated, and uses these ratings to calculate an overall user satisfaction score. For more information, see Apdex: Measure user satisfaction. apdex_f The response time above which a transaction are rated frustrating. Defaults to four times apdex_t. Requests that complete in less than apdex_t are rated satisfied. Requests that take longer than apdex_t, but less than four times apdex_t (apdex_f), are tolerated. Any requests that take longer than apdex_f are rated frustrating. For more information, see Apdex: Measure user satisfaction. apdex_t The response time above which a transaction is considered tolerable. The default value is 0.5 seconds, but you can change this in your Apdex settings. Requests that complete in less than apdex_t are rated satisfied. Requests that take more than apdex_t, but less than apdex_f, are tolerated. Any requests that take longer than apdex_f are rated frustrating. For more information, see Apdex: Measure user satisfaction. API (application programming interface) New Relic offers a variety of APIs and SDKs. For more information, see the introduction to New Relic's APIs. APM New Relic's APM (application performance monitoring) provides monitoring of your web or non-web application's performance. APM supports apps using several programming languages. application For New Relic purposes, any program instrumented by New Relic. application ID Some New Relic solutions assign a monitored application a unique application ID, often shortened to app ID. When present, this ID is available in the UI. It is also reported as an attribute and can be queried. For how to determine this, see Find app ID. application name The name that New Relic combines with your license key to uniquely identify a particular app. For more information, see Name your application. Applied Intelligence (AI) Applied Intelligence (AI) helps you find, troubleshoot, and resolve problems more quickly. Specifically, it’s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. Applied Intelligence includes Alerts, Incident Intelligence, and Proactive Detection. attribute Attributes are key-value pairs attached to data objects reported to New Relic. Attributes add detail, and they're similar to tags or labels in other SaaS software. You can explore this data by querying or searching via the UI or by using the data dictionary. Examples: APM reports a Transaction event. This includes timing data for the transaction in a duration attribute, which might have a value of .002. Our Infrastructure Monitoring reports a ProcessSample event. This includes a variety of CPU usage attributes, including a cpuSystemPercent attribute, which might have a value of .01. Our Telemetry SDK reports a Metric data type for storing metrics, with attached attributes like metricName and newrelic.source. Some New Relic tools allow you to report custom attributes to enhance your monitoring. For more information about attributes in APM, see Agent attributes. availability monitoring See Types of Synthetics monitors. browser The New Relic UI supports most browsers. For more information, see Supported browsers. For our end-user browser monitoring tool, see Browser Monitoring. Browser monitoring A Real User Monitoring (RUM) solution that measures the speed and performance of your end users as they navigate to your site from different web browsers, devices, operating systems, and networks. background external See web external. child account See parent account. cloud-based integration New Relic offers cloud-based integrations with providers such as Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. collector The component that collects data from New Relic agents running on an app server, mobile device, or end-user browser. While the agent is installed on a user's app server, the collectors are centrally located in New Relic's data center. In order to contact the collector, the agent must be able to reach New Relic's domains and IP addresses. (The exact domain or IP depends on the New Relic monitoring tool.) The collector receives and interprets this data, and stores it in a database. The data is then retrieved and presented in the New Relic UI and by our various REST APIs. Command line interface (CLI) Our command line interface (CLI) is a tool you can use to build a New Relic application. This is the same tool our own engineers use. Go here for quick start instructions. Go to our Developer site for sample apps and guides. compute unit (CU) A unit of measurement that determines your pricing for some New Relic products governed by our original product-based pricing model. For more information, see Compute unit pricing. condition_id See alert condition. CPM (calls per minute) The number of calls your application receives each minute. This usually corresponds to the number of page views or external connections, and is usually the same as RPM (requests per minute). CPU burn The time consumed by code minus the wait time for a transaction. This is the time actually spent processing the transaction. It appears in the New Relic UI at the top of the transaction view for the agents that provide it (Ruby and PHP only). custom attribute A key-value pair added to a transaction or event in order to gain additional information about it. For more information, see custom attributes. custom dashboard A customizable dashboard with charts and tables that includes data from multiple New Relic data sources. For more information, see dashboards. custom event An event, in New Relic terms, is a data object with attached attributes. New Relic reports default event types, like Transaction and TransactionError. You can also create your own events. Events can be queried, and are used in some other features. You can generate custom events with APM agents, the browser monitoring agent, the mobile monitoring agents, and via the Event API. Alternatively, you can add custom attributes to some existing default New Relic events. custom instrumentation Custom instrumentation allows you to extend New Relic's monitoring to instrument code elements New Relic doesn't automatically instrument. Custom instrumentation is useful when your framework is not supported by New Relic, or when New Relic fails to pick up some element of your program. You can also use custom instrumentation to block a transaction from being reported entirely. For more information, see Custom instrumentation. custom metric Metric timeslice data that is manually recorded via an API call. Custom metrics allow you to record arbitrary metrics; for example, timing or computer resource data. All custom metric names must be prefixed with Custom/. For more information, see Custom metrics. Not to be confused with custom instrumentation data. data collector See collector. data explorer Use the data explorer to access, query and customize your data, create visualizations, and make connections between your services in a consistent and curated experience. For more on using the data explorer, see Introduction to the data explorer. degradation period When a data source enters a violating state, a degradation period of time begins. The degradation period is set in the condition's threshold. A violation will open if the source stays in a violating state for the entire degradation period. In addition: If the data source enters a non-violating state before the entire time has elapsed, the degradation period countdown is reset, and a violation does not open. If your alert condition threshold is configured as at least once in, the degradation period always lasts a single minute. dimensional metric A dimensional metric is a metric that has multiple attributes, also known as dimensions. At New Relic, we report dimensional metrics using the Metric data type. For more on other metric data types, see Metric data. Docker An open platform for distributed applications, which allows you to assemble multi-container portable apps. Infrastructure Monitoring includes integrated Docker monitoring. For more information about Docker, see the Docker website. downtime The period of time when customers cannot access your site and your app is not reporting to New Relic. For more information, see Synthetic Monitoring and Types of synthetic monitors. entity In New Relic, an entity is anything we can identify that has data you can monitor. An entity can be something you monitor directly, like applications and microservices, or indirectly, like data centers. You can identify one or more entities to be targets for alert conditions. In the Alerts API, the entity being monitored is identified with an entity_id. For more on this, see What are entities? event The word event is a general term that can have many meanings. At New Relic, event can have several meanings: At New Relic, event data is one of our core data types. Event data represents a record of a single event at a particular moment in time. Events can vary by type (for example, Transaction or Mobile, and will have associated attributes (for example, timestamp or transactionName). For more details, see Event data. For our infrastructure monitoring, the word event can be used to refer to important system and host activity. For example, a configuration change for a monitored host would be registered on Infrastructure's Events UI page. For alerts, the Events UI page displays a list of alerts-related incidents for your monitored entities. Events are reported for a violation opening and for closing. In some contexts, event can refer to any NRQL-queryable data type. For example, when you run a NRQL query, you will see a count of inspected events: this refers to a count of all data types queried. expected error An expected error is a common error that you don't want to affect your Apdex score or error rate. For more information, see Manage errors in APM. exporter At New Relic, an exporter is a type of integration that reports telemetry data to New Relic from a third-party (non-New Relic) telemetry tool. For examples, see Exporters, or search our integration quickstarts in New Relic I/O. Flex New Relic Flex is an application-agnostic, all-in-one infrastructure integration. With it, you can build your own integration that collects metric data from a wide variety of services, and that can instrument any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format (for example, JSON or plain text) to the terminal. It's a recommended way to create a custom integration, because it doesn't require coding skills. framework A framework is a structured collection of pre-defined functions, into which an application builder inserts their own code to build their application. A framework is not the same as a library. While a library is a collection of functions you can call as needed, a framework is a skeleton for your application. The functions in that framework then call your functions. For more about the distinction between a framework and a library, see What is the difference between a framework and a library?. New Relic automatically instruments many common frameworks. For more about the frameworks New Relic supports, see the agent-specific documentation: C SDK supported frameworks Go supported frameworks Java supported frameworks .NET supported frameworks Node.js supported frameworks PHP supported frameworks Python supported frameworks Ruby supported frameworks harvest cycle The period of time between each connection from a New Relic agent to the collector. Between harvest cycles, an agent collects and caches data. At the end of the cycle an agent reports those data to the collector, then begins a new harvest cycle. health status indicator Some New Relic UI pages have a health status indicator appearing next to an index of monitored entities. This is a colored bar (generally green, yellow, red, or gray) indicating the status of your app or other entity monitored by New Relic. It also indicates whether the entity has any alert policies assigned to it and whether there are any policy violations. In general, the colored bar will be green, yellow, red, or gray to indicate the health status. Exceptions: Our REST API (v2) uses orange instead of yellow for the application's health and reporting status. Service maps use different criteria for reporting the health of a connection between an app and an external service not monitored by New Relic (for example, a third party API). host At New Relic, a host means one of the following: A physical machine is a hardware-based device with dedicated physical resources, including memory, processing, and storage. Each machine has its own OS which applications run on. A virtual machine (VM) is the software implementation of a physical machine that executes programs like a physical machine. One or more virtual machines can run on a physical machine. Each virtual machine has its own OS and allocated virtual machine resources such as RAM and CPU. A cloud instance is a type of virtual machine that is run in the public cloud. In this context, virtual machines and cloud instances are different from Java Virtual Machines (JVMs) and containers. host ID Each host identified by APM is assigned a host ID. This ID is used to uniquely identify it, and to retrieve data about that host via the REST API. For more information, see List host ID. ignored error An error that you have told the APM agent not to report to the collector. For more information, see Manage errors in APM. incident An incident is a collection of one or more violations of the conditions defined in an alert policy. An incident record includes all of the open and close time stamps for each violation, as well as chart snapshots of the data being evaluated around the time of each violation. You can view detailed information from the Incidents pages in the user interface. You can also select your preference for how we roll up violations into the incident. For an explanation of how an incident relates to other basic alerts concepts, see Concepts and workflow. Infrastructure monitoring By connecting changes in host performance to changes in your configuration, infrastructure monitoring provides real-time metrics and powerful analytics that reduce your mean-time-to-resolution (MTTR). Infrastructure is specifically designed for complex environments that need flexible, dynamic server monitoring, from a physical datacenter to thousands of Amazon Elastic Compute Cloud (Amazon EC2) instances and other types of integrations. Insights Insights was the name for the New Relic product that previously governed the reporting of custom events, and the ability to query and chart your New Relic data. These features are now a fundamental part of the New Relic One platform and are no longer governed by the Insights product or name. To learn more about these features: Event API for reporting custom events Query and chart data For historical reasons, the word \"Insights\" is still used in some places. For example: For New Relic organizations on our original pricing model, Insights Pro is still the product name governing custom event data ingest and retention. Some APM agents still have Insights language in their codebase. For example, the Java agent custom_insights_events configuration. There is an API key called the Insights insert key. instance ID Each instance identified by New Relic is assigned a unique instance ID. Instance IDs are most commonly found for JVMs (Java Virtual Machines), but can exist for each agent. This ID is used to uniquely identify it, and to retrieve data about that instance via the REST API. For more information, see List instance IDs. instrumentation The collection of data from an application or host. When New Relic instruments a framework, it detects the methods and calls used by that framework, and intelligently groups them together. integration At New Relic, an integration refers to a solution that integrates with a specific technology (like a web framework or a type of database). All our integrations can be found as quickstarts in New Relic Instant Observability. interaction In our mobile monitoring, an interaction is a specific code path initiated by a user interaction (usually a button press). An interaction is the mobile equivalent of a transaction, and like a transaction an interaction can be traced and monitored. You can see much of the data included in an interaction in the BrowserInteraction event. interaction trace An interaction trace is a complete picture of a single interaction. With interaction traces, New Relic gives you much deeper visibility into a single slow interaction, which can help you understand a broader problem. Interaction traces are the mobile equivalent of a transaction trace. For more information, see Creating interactions (iOS) and Creating interactions (Android). inventory data Inventory data is information about the status or configuration of a service or host. Examples of inventory data include: Configuration settings Name of the host the service is on Amazon AWS region Port being used For more information, see Understand and use data. key transaction A web transaction that the user has marked as particularly important; for example, key business events (such as signups or purchase confirmations), or transactions with a high performance impact (such as searches). Key transactions have their own pages in the UI and other customized values. For more information, see Key transactions. launcher A launcher is a specific piece of code you can include when you create a New Relic One app. It creates the tile on the homepage that you click to launch the app. For more information, see the documentation about core UI components. log A log is a message about a system used to understand the activity of the system and to diagnose problems. For more information on how we use log data, see Log management. Log monitoring Our log management and monitoring features give you the tools to collect, process, explore, visualize, and alert on your log data using your existing log forwarder. With all of your log data in one place, you'll be able to make better decisions, detect and resolve problems more quickly, and see your logs in context to troubleshoot faster. Logs Our Logs feature is a scalable log management platform that allows you to connect your log data with the rest of your telemetry data. Pre-built plugins with some of the most common open-source logging tools make it simple to send your data from anywhere to New Relic. Logs in context Logs in context makes it easy to link to your log data with related data across the rest of our platform. Bringing all of this data together in a single tool allows you to quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. master account See parent account. metric A metric is a numeric measurement. Metric data is a broad category because there are several ways to make and report measurements. For more about how metrics are reported at New Relic, see New Relic data types. metric timeslice New Relic reports metrics in several ways. One variety of metric data is called metric timeslice data; this is the type of data used to generate many of the charts in APM, mobile monitoring, and browser monitoring (for more details, see metric timeslice data). Over time, metric timeslice data is aggregated into longer timeslice data records for more efficient storage. For more about how we aggregate this type of data, see Data aggregation. For how to query this type of data, see Query metric timeslice data. metric grouping issue A metric grouping issue occurs when an account sends too many differently named metric timeslice data points to New Relic, and those individual web transactions are not properly aggregated. For example, rather than a single /user/controlpanel/ metric name, you might see /user/controlpanel/alice, /user/controlpanel/bob, and /user/controlpanel/carol. For more information, see Metric grouping issues. minion The software that accepts monitor jobs from a private location. A minion is a packaged virtual appliance that runs in your hypervisor. For more information, see Private locations overview and install and configure private minions. Mobile monitoring Mobile monitoring allows you to monitor and manage the performance of your mobile apps on Android, iOS, tvOS, and other systems. Mobile monitoring provides end-to-end details, including crashes, throughput, HTTP requests, error traces, and more. Not to be confused with New Relic's own mobile apps for Android, iPhone, and iPad. monitor For our Synthetic Monitoring, a monitor ensures your website or API endpoint is available. For more information, see Adding and editing monitors. NerdGraph NerdGraph is our GraphQL API, an efficient and flexible query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph calls get all the data you need in a single request. NerdGraph also makes it easier to evolve APIs over time and enables powerful developer tools. You can use our NerdGraph GraphiQL explorer to explore the schema and find definitions. With valid New Relic API key, you can try it out yourself at api.newrelic.com/graphiql. Nerdlet A Nerdlet is a component of a New Relic One application. It's a specific UI view, represented by a React JavaScript package. For more information, see Nerdpack file structure. Nerdpack A Nerdpack is a component of a New Relic One application. It's the package containing all the files needed by that application. For more information, see Nerdpack file structure. New Relic Edge with Infinite Tracing New Relic Edge with Infinite Tracing is a fully managed, distributed tracing service that observes 100% of your application traces, then provides actionable data so you can solve issues faster. For more information, see /docs/understand-dependencies/distributed-tracing/get-started/how-new-relic-distributed-tracing-works. New Relic One For more information, see Introduction to New Relic One. New Relic One catalog Our catalog is a collection of applications built on the New Relic One platform. The catalog includes custom apps we've built, public open source apps, and any apps that you buid. You can browse the catalog on New Relic One. NRQL (New Relic query language) NRQL is a query language, similar in form to SQL, that allows you to query the data stored in your New Relic account. non-web transaction APM identifies transactions as either web or non-web. When New Relic does not detect a transaction was initiated by a web request, this is called a non-web transaction. For more information, see Background processes and other non-web transactions. notification The message sent when an incident opens, is acknowledged, or closes. The type of notification is defined by the alert policy's notification channel. For an explanation of how notifications relate to other basic alerts concepts, see Concepts and workflow. notification channel Where we send a notification when an incident opens, is acknowledged, or closes. Available channels include email, mobile push notifications, webhooks, and more. on-host integration On-host integrations refer to integrations that reside on your own servers or hosts and that communicate with our infrastructure agent. For more information, see Introduction to on-host integrations. owner For accounts on our original pricing model, this is a type of user role: the user who initially created the account. For more information, see Users. page load timing With page load timing, New Relic monitors the full load time for end-user browsers. New Relic's application agents dynamically inject JavaScript into the page, then capture the following key load points: Navigation start: The user initiates the transaction. First byte: The browser receives the requested page. DOM ready: The browser has finished parsing DOM. Page ready: Page loading is complete. Page load timing is sometimes referred to as RUM, or real user monitoring. Unlike standard RUM, page load timing also captures JavaScript errors and AJAX requests. For more information, see Page load timing process. parameter Deprecated term; see attribute. parent account New Relic organizations can have a parent/child account structure. This structure was much more important for organizations on our original user model, but is still used for some features for organizations on the New Relic One user model. Learn more about account structure. Parent accounts were previously referred to as \"master accounts\", and child accounts were previously referred to as \"sub-accounts\". permalink A unique URL that links to a view of your application at a specific point in time. Permalinks are useful for troubleshooting and for sharing interesting time windows with colleagues. pinger The component of New Relic that connects to your website to verify your website is accessible. New Relic has pingers in Europe, Asia, and the United States. Each pinger attempts to contact your website at least once every two minutes. If enough pingers are unable to reach your website, your application will be considered down. For in-depth scriptable testing, including real browser tests and tests of API endpoints, see Synthetic Monitoring. Synthetic Monitoring includes free ping monitoring, which allows you to monitor your website from locations around the world. For more information, see Types of Synthetic monitors. polling interval (AWS) Our Amazon integrations query your AWS services according to a polling interval, which varies depending on the integration. Each polling interval occurs for every AWS entity. For example, if you have thirteen Elastic Load Balancers (ELB), each one will be polled every five minutes. Depending on the AWS integration, there may be delays in the timing between the API request and the metric data returned. If you notice unusual delays, follow the integration troubleshooting procedures. PPM (pages per minute) The number of pages per minute your application serves. private location A Synthetic monitor feature that allows you to run Synthetic monitors from within your own systems by creating private minions. Private locations allow you to extend your Synthetic coverage to new geographical locations, and to monitor websites behind your firewall such as an intranet site. For more information, see Private locations overview. recovery period A recovery period of time begins when a data source enters a non-violating state after being in a violating state. The recovery period is set in the condition's threshold. A violation will close when a source remains in a non-violating state and the recovery period time has elapsed. If the data source enters a violating state before the time has elapsed, the recovery period clock will reset and the violation won't close. response time The duration of time between a request for service and a response. For more information, see Response time. restricted user A type of user role on a New Relic account. For more information, see Users. rollup Using the same application name for multiple applications. This allows you to combine data in APM, either from multiple applications, or from multiple instances of an application. For more information, see Rolling up app data. root span For distributed tracing, the root span is the first span in a trace. In many cases, the root span duration will represent the duration of the entire trace, or be very close to it. However, for more complex, modern systems that use a lot of asynchronous, non-blocking processes, this will not be true. For those systems, the root span’s duration may be significantly less than the duration of the trace. RPM The term RPM usually refers to the number of requests per minute your application receives from users. This is usually the same as CPM (calls per minute). Historically, some New Relic monitoring solutions, like APM and Browser Monitoring, used to contain RPM in the URL; for example, https://rpm.newrelic.com. This language use originally referred to Rails performance management because the first iteration of our product monitored Ruby on Rails applications. We monitor many more languages and systems than Ruby now. RUM (real user monitoring) See page load timing. runbook A runbook contains standard procedures and operations typically used by system administrators, network operations staff, and other personnel to handle outages, alert incidents, and other situations. If your organization stores runbook instructions as URLs, you can link this information to an alerts policy so your personnel has easy access to this information when an incident violates the defined policy thresholds. SAML (Security Assertion Markup Language) SAML is an XML-based data format for sharing authentication data between two parties. New Relic accounts must obtain a SAML certificate in order to enable Single Sign On for their users. For more information, see SAML service providers. Selenium Selenium is an open-source browser testing suite. Synthetics uses Selenium to test monitored websites with real browsers. For more information, see monitor types. service A service is a cluster of runtime server processes that accomplish a particular task, usually service requests. Unlike an application, a service is not usually invoked by a human. New Relic offers a variety of integrations that allow you to report data from your services. signal The stream of telemetry data that's watched and alerted on. You use NRQL queries to define a signal. signal filter When we receive data and it's routed to the streaming alerts platform, your NRQL WHERE clause will filter the data coming in. The filtered streaming data is what's evaluated for loss of signal violations, for example. span In a distributed trace, a span is a \"named, timed operation representing a contiguous segment of work in that trace\" (from OpenTracing.io definition). For distributed tracing, spans are displayed in the distributed tracing UI, and the data type Span is available to be queried. See also root span. SSL certificate SSL certificates encrypt data that is being transmitted. While New Relic refers to security certificates as SSL because it is a more commonly used term, all certificates adhere to industry standards for secure encryption in transit. SSO (single sign on) SSO (single sign on) allows you to manage user authentication in New Relic using an external SSO provider. For more information, see Setting up SSO. streaming algorithm This is what determines when the data in an aggregation window is processed. The streaming algorithm uses your server's clock time and the aggregation window size to trigger the alert evaluation process. sub-accounts See master account. Synthetic monitoring Synthetic monitoring allows you to monitor your website or API endpoint via automated, scriptable tools. Use free ping monitor to ensure your website is accessible, or expand your monitoring with browser monitors, which test your website with real browsers. Go further with scripting, to script browsers or API monitors for sophisticated testing. target A target is a resource or component monitored by a New Relic monitoring tool that has been identified in an alert condition. When the data source for that target crosses the defined critical threshold, we will open a violation. Depending on your policy's Incident preference setting, Alerts may create an incident record and send notifications through the defined channels. See also entity. tag Tags are key:value metadata added to monitored apps, hosts, dashboards, and other entities to help you organize your data at a high level. For details, see Tags. thresholds Thresholds are alert condition settings that define a violation. Threshold values include the value a data source must pass to trigger a violation and the time-related settings that define a violation; for example: Passing a certain value for at least x minutes Passing a certain value only once in x minutes While the data source passes a certain value, a degradation period starts. Likewise, when that data source stops passing a certain value, a recovery period starts. The durations of these two time periods are defined in the alert condition threshold settings. Thresholds have a required critical (red) threshold and an optional warning (yellow) threshold. In the UI, the entity's health status indicator will change to yellow or red when a threshold has been crossed and a violation will open. For more information, see Define thresholds. For an explanation of how thresholds relate to other basic Alerts concepts, see Concepts and workflow. throughput Throughput is a measurement of user activity for a monitored application. APM throughput and Browser Monitoring throughput are measured in different ways: APM: requests per minute (RPM) Browser: page views per minute (PPM) tier A tier can refer to how New Relic categorizes or visualizes the various agent language ecosystems that we support. For example: In APM, the color-coded categories that appear on your app's main Overview chart show response time spent in various functions, processes, or agents as tiers; for example, request queuing, garbage collection, Middleware, JVMs, etc. In New Relic labels, TIER can be used to define or classify the client-server architecture; for example, front-end and back-end tiers. \"Tier\" may sometimes be used to refer to our pricing editions. time picker By default the New Relic UI shows data for the past 30 minutes, ending now. To change the time window, use the time picker. time range A time range can refer to a length of time selected in the New Relic UI. New Relic displays a time range depending on the range you select using the time picker. timeslice data See metric timeslice data. trace A trace is a description of how a request travels through a system. Trace data helps you understand the performance of your system and diagnose problems. For more information on how we use trace data, see New Relic data types. traffic light See health status. transaction A transaction is defined as one logical unit of work in an application. This term primarily refers to server-side transactions monitored by APM. For more information, see documentation about web transactions and non-web transactions. The term transaction is also sometimes used in Browser Monitoring. In that case, it primarily refers to activity beginning with a browser-side web request and ending with a complete page load. transaction trace A transaction trace is a complete picture of a single transaction, down to the database queries and exact invocation patterns. With transaction traces, New Relic gives you much deeper visibility into a single slow transaction, which can help you understand a broader problem. For more information, see Transaction traces. UI The New Relic user interface. For more information, see Standard page functions. user A user can refer to a specific user role in a New Relic account. For more information, see Users. UTC Universal Time Coordinated (UTC), or Coordinated Universal Time, is a standard timestamp for synchronizing time around the world. value function (metrics) The numeric value obtained from metric timeslice data; for example, an average, minimum, maximum, total, sample size, etc. violation A violation occurs when the entity monitored by an alert condition reports a value that crosses the thresholds defined in that condition. For an explanation of how violations relate to other basic alerts concepts, see Concepts and workflow. You can view a summary of the violations for a selected incident's page. You can also view the violations for a specific entity from the product's UI. web external Web external is the term applied to the portion of time spent in transactions to external applications from within the code of the application you are monitoring. That time can be a call to a third party company (a payment provider, for example) or it could be a call to another microservice within your own company. Web external demonstrates how performance is impacted by your code executing outside the application you are measuring. web transaction A transaction is defined as one logical unit of work in an application. This term primarily refers to server-side transactions monitored by APM. Web transactions are initiated with an HTTP request. For most organizations, these represent customer-centric interactions and thus are the most important transactions to monitor. For more information, see Web transactions and Non-web transactions. WebDriverJS WebDriver is a Selenium component, used to control Synthetics scripted browsers. Specifically, Synthetics uses WebDriverJS, a Node.js-based flavor of Selenium. For more information, see Writing scripted browsers and Scripted browser examples. workload A workload represents a group of entities that work together to provide a digital service. For more information, see Workloads.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.56403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Glossary of <em>New</em> <em>Relic</em> terms",
        "sections": "Glossary of <em>New</em> <em>Relic</em> terms",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " line interface (CLI) is a tool you can <em>use</em> to build a <em>New</em> <em>Relic</em> application. This is the same tool our own engineers <em>use</em>. Go here for quick <em>start</em> instructions. Go to our Developer site for sample apps and guides. compute unit (CU) A unit of measurement that determines your pricing for some <em>New</em> <em>Relic</em>"
      },
      "id": "61b40189196a672dd0a5aa8c"
    },
    {
      "sections": [
        "Choose your data center (US or EU)",
        "Requirements",
        "Regions and availability",
        "Regions and account hierarchy",
        "Hierarchy example for partnership accounts",
        "Create an EU region account",
        "API endpoints for EU region accounts",
        "Access New Relic One",
        "Billing and pricing",
        "Operational access and processing",
        "Verify your account is based in EU region"
      ],
      "title": "Choose your data center (US or EU)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "58aede83cf1625a8a52aaeed540cebfbaa024d61",
      "image": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-setup/choose-your-data-center/images/Eu_account_hierarchy.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-setup/choose-your-data-center/",
      "published_at": "2022-01-12T08:14:28Z",
      "updated_at": "2021-12-14T04:22:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's global data hosting structure consists of two regions: the European Union (EU) region and the United States (US) region. Selecting your preferred region during the account setup process allows you to specify the region where your performance monitoring data will be hosted. You can also create accounts in each region. Requirements Access to the New Relic EU region requires the latest agent version. For new customers: Install the most recent agent version. For existing customers: Update to the most recent agent version. Minimum agent version required: C SDK 1.0.0 or higher Go 2.0.0 or higher Java 4.0.0 or higher .NET 8.0.0 or higher Node.js 3.0.0 or higher PHP 8.0.0.204 or higher Python 3.0.0.89 or higher Ruby 5.0.0.342 or higher Regions and availability Your choice of data center is not limited by your geographic location. You can choose to create an account with data hosted in either the EU or US region, regardless of where you or your systems reside. You can also create accounts in each region. New Relic offers almost all the same active products, features, support offerings, and performance levels in the EU region as what is offered in the US region. Exceptions: The following are not supported with an EU region account: Infinite Tracing is not available. APM's weekly performance reports are not available. Errors inbox is not available. Log patterns Deprecated products and features are not available. New Relic's Incident Intelligence service operates solely in the US whether you store your data in New Relic’s US region data center or New Relic’s EU region data center, by using New Relic Incident Intelligence, you consent that New Relic may move and store your data in the US region. New Relic CodeStream operates solely in the US. Whether you have selected New Relic's US or EU region data center during setup of your New Relic account, when using New Relic CodeStream, you consent that your New Relic CodeStream data will get stored in the US. Regions and account hierarchy You can create accounts in each region. If your data is currently being hosted in the US region, you must create a new account to store data in the EU region. You cannot view EU data from a US account, or US data from an EU account. The data collected remains separate. The data cannot be aggregated or migrated between accounts. For organizations that have a parent/child account structure, you can only have one parent account. For more, see Manage apps or users with child accounts. For partnership accounts, no changes to the partnership owner account are required. However, data cannot be shared across regions, so a partnership requires a parent account for each region. Hierarchy example for partnership accounts With partnership accounts, a new parent account must be created for any data to be host in the EU region. This hierarchy illustrates how global accounts are structured with partnership owner accounts. Data is not aggregated beyond the parent account. Example hierarchy for partnership organizations. Because data cannot be shared across regions, a partnership will require a parent account for each region. Create an EU region account To create a New Relic account in the EU region: Go to the New Relic signup page. OR If you have a specific offer from a New Relic partner, follow that link directly. Follow the online steps to create your account. From the Select your region dropdown, select European Union. Agree to the Terms of Service. When you receive an email confirmation message, select the link to confirm your account and sign in to New Relic. Then install or update to the most recent agent version. API endpoints for EU region accounts If you have an EU region account, use the appropriate endpoints to access the following New Relic APIs: API EU endpoint Browser source maps API sourcemaps.service. eu .newrelic.com Copy Infrastructure Alert API infra-api. eu .newrelic.com Copy Dashboard API rpm. eu .newrelic.com/api/explore/dashboards/list Copy Insert API insights-collector. eu01 .nr-data.net Copy Insights Query API insights-api. eu .newrelic.com Copy Mobile apps rpm. eu .newrelic.com/mobile Copy NerdGraph GraphiQL API api. eu .newrelic.com/graphiql Copy Partner API The partner API is a global API with no regional data differences. Use this endpoint for both EU and US accounts: rpm.newrelic.com/api/v2/partners/ Copy REST API api. eu .newrelic.com Copy Synthetics API synthetics. eu .newrelic.com/synthetics/api Copy Trace API trace-api. eu .newrelic.com/trace/v1 Copy Metric API metric-api. eu .newrelic.com/metric/v1 Copy Log API log-api. eu .newrelic.com/log/v1 Copy Access New Relic One If your accounts report data to the EU data center, use the following link to go to New Relic One: one.eu.newrelic.com. Billing and pricing New Relic's account billing process and pricing options are the same for both the EU and US regions. Operational access and processing Customer Data is hosted in the region selected during account creation. Systems Operations Data is stored in the US region. All other information, including account information (such as license subscription information, billing, and internal monitoring) is hosted in the US region and replicated in the EU region. New Relic may access and process Customer Data in the United States and such other jurisdictions where New Relic has affiliates and subsidiaries, including as may be necessary to maintain, secure, or perform the services, to provide technical support, or as necessary to comply with law or a binding order of a government body. Customer Data from existing New Relic accounts cannot be transferred or shared across regions, and new data generated cannot be shared with existing accounts, even in partnership accounts. Verify your account is based in EU region Use either of these options to verify whether your account data is hosted in the EU region's data center: In APM, mouse over the application name to view the URL. If it begins with rpm.eu.newrelic.com/, it is an EU-based account. Check your New Relic license key. If it begins with EU, it is an EU-based account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.99373,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Access <em>New</em> <em>Relic</em> One",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " <em>New</em> <em>Relic</em>&#x27;s US or EU region data center during setup of your <em>New</em> <em>Relic</em> account, when <em>using</em> <em>New</em> <em>Relic</em> CodeStream, you consent that your <em>New</em> <em>Relic</em> CodeStream data will <em>get</em> stored in the US. Regions and account hierarchy You can create accounts in each region. If your data is currently being hosted"
      },
      "id": "61b81bf6e7b9d2a96fef4e3a"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/troubleshooting/find-agent-root-directory": [
    {
      "sections": [
        "Networks",
        "Tip",
        "TLS encryption",
        "User-facing domains",
        "APM agents",
        "Port 443 recommended",
        "Agent downloads",
        "Infrastructure agents",
        "Browser domains",
        "Mobile domains",
        "Synthetic monitor public locations",
        "Synthetic monitor private locations",
        "Alerts webhooks, api.newrelic.com, cloud integrations, and ticketing integrations",
        "Pixie integration",
        "OpenTelemetry"
      ],
      "title": "Networks",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "9f7555daaafae1753bf1e741a5d607e7f0f87b7c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/networks/",
      "published_at": "2022-01-12T18:27:20Z",
      "updated_at": "2022-01-08T17:44:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Networks, IPs, domains, ports, and endpoints last updated January 6, 2022. This is a list of the networks, IP addresses, domains, ports, and endpoints used by API clients or agents to communicate with New Relic. TLS is required for all domains. For information on our FedRAMP endpoints, see our FedRAMP endpoints documentation. Tip This doc describes how to ensure our agents and integrations can access New Relic's domains. To monitor the performance of your network, see Get started with Network Performance Monitoring. TLS encryption To ensure data security for our customers and to be in compliance with FedRAMP and other standards for data encryption, Transport Layer Security (TLS) is required for all domains. Our preferred protocol for all domains is TLS 1.2. For more information, see New Relic's Explorers Hub post about TLS 1.2. In addition, TLS 1.2 is required for most domains, except: APM agent connections Browser agent connections Event API For future updates to required and supported protocol versions, follow the Security Notifications tag in New Relic's Explorers Hub. User-facing domains Your browser must be able to communicate with a number of domains for New Relic One to work properly. Update your allow list to ensure New Relic can communicate with a number of integral domains that are listed in this section. Blocking domains can cause issues with individual product features or prevent pages from loading altogether. This list doesn't cover domains that New Relic connects to that can be blocked without affecting your usage of the product. It also doesn't cover Nerdpacks or other features that communicate with external services that have additional domain requirements. If your organization uses a firewall that restricts outbound traffic, follow the specific procedures for the operating system and the firewall you use to add the following domains to the allow list. Domain Description *.newrelic.com New Relic One and supporting services *.nr-assets.net Static New Relic assets *.nr-ext.net New Relic One Nerdpacks and assets *.amazonaws.com New Relic One catalog assets behind AWS S3 *.cloudfront.net Static New Relic assets behind AWS CloudFront CDN secure.gravatar.com Support for Gravatar avatars fonts.googleapis.com Support for Google Fonts fonts.gstatic.com Support for Google Fonts www.google.com Support for reCAPTCHA www.gstatic.com Support for reCAPTCHA *.nr-data.net OpenTelemetry and Pixie onenr.io New Relic One sharing permalinks APM agents To enhance network performance and data security, New Relic uses a CDN and DDoS prevention service with a large IP range. New Relic agents require your firewall to allow outgoing connections to the following networks and ports. To add the following IP connections to the allow list, follow the specific procedures for the operating system and the firewall you use. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections APM data Networks US region accounts: 162.247.240.0/22 EU region accounts: 185.221.84.0/22 Ports US region accounts: Default: TCP 443 (recommended) TCP 80 EU region accounts: Default: TCP 443 (recommended) TCP 80 Endpoints US region accounts: collector*.newrelic.com EU region accounts: collector*.eu01.nr-data.net:443 (recommended) Port 443 recommended Recommendation: Use port 443, a secured channel for encrypted HTTPS traffic. Some New Relic agents also offer port 80, an unsecured channel open to all HTTP traffic. While some agents can be configured to use both port 80 and port 443, we recommend that you choose the port 443 (default). If you have an existing configuration that uses port 80, you can update it to use port 443, the default New Relic connection. Agent downloads TLS is required for all domains. Service for download.newrelic.com is provided through Fastly and is subject to change without warning. For the most current list of public IP addresses for New Relic agent downloads, see api.fastly.com/public-ip-list. Infrastructure agents In order to report data to New Relic, our infrastructure monitoring needs outbound access to these domains, networks, and ports. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections Infrastructure data Domains infra-api.newrelic.com: Required to submit events, metrics, and inventory data. identity-api.newrelic.com: Required for entity registration (for example, a host entity). infrastructure-command-api.newrelic.com: Required to determine feature flags. Also used for gradual rollout of new capabilities. log-api.newrelic.com: Required to submit logs to a US datacenter. log-api.eu.newrelic.com: Required to submit logs to an EU datacenter. metric-api.newrelic.com: Required to submit dimensional metrics. Networks For US region accounts: 162.247.240.0/22 For EU region accounts: 185.221.84.0/22 Port 443 Domains + Port For US region accounts: infra-api.newrelic.com:443 identity-api.newrelic.com:443 infrastructure-command-api.newrelic.com:443 log-api.newrelic.com:443 metric-api.newrelic.com:443 For EU region accounts: infra-api.eu.newrelic.com:443 identity-api.eu.newrelic.com:443 infrastructure-command-api.eu.newrelic.com:443 log-api.eu.newrelic.com:443 metric-api.eu.newrelic.com:443 Proxy If your system needs a proxy to connect to this domain, use the Infrastructure proxy setting. Browser domains In addition to the IP addresses for APM agents, applications monitored by our browser agents use outgoing connections to the following domains. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: For US region accounts: bam.nr-data.net js-agent.newrelic.com For EU region accounts: eu01.nr-data.net bam.eu01.nr-data.net For more information about CDN access for the js-agent.newrelic.com file to the domain bam.nr-data.net or to one of the New Relic beacons, see Security for browser monitoring. Mobile domains In addition to the IP addresses for APM agents, applications monitored by our mobile agents use outgoing connections to the following domains. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: For US region accounts: mobile-collector.newrelic.com mobile-crash.newrelic.com mobile-symbol-upload.newrelic.com For EU region accounts: mobile-collector.eu01.nr-data.net mobile-crash.eu01.nr-data.net mobile-symbol-upload.eu01.nr-data.net Synthetic monitor public locations To configure your firewall to allow synthetic monitors to access your monitored URL, use Synthetic public minion IPs. TLS is required for all domains. Synthetic monitor private locations Synthetic private minions report to a specific endpoint based on region. To allow the private minion to access the endpoint or the static IP addresses associated with the endpoint, follow the specific procedures for the operating system and the firewall you use. These IP addresses may change in the future. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections Synthetics private location data Endpoint For US region accounts: https://synthetics-horde.nr-data.net/ For EU region accounts: https://synthetics-horde.eu01.nr-data.net/ IP addresses For US region accounts: 13.248.153.51 76.223.21.185 For EU region accounts: 185.221.86.57 185.221.86.25 Alerts webhooks, api.newrelic.com, cloud integrations, and ticketing integrations Endpoints that use api.newrelic.com (such as our GraphQL API for NerdGraph) and our New Relic-generated webhooks for alert policies use an IP address from designated network blocks for the US or European Union region. TLS is required for all addresses in these blocks. Network blocks for US region accounts: 162.247.240.0/22 Network blocks for EU region accounts: 158.177.65.64/29 159.122.103.184/29 161.156.125.32/28 These network blocks also apply to third-party ticketing integrations and New Relic cloud integrations. Pixie integration The Pixie integration runs in your Kubernetes cluster and pulls a set of curated observability data from Pixie to send it to New Relic using the OpenTelemetry line protocol. The Pixie integration requires outbound network access to the following: work.withpixie.ai:443 otlp.nr-data.net:4317 (US region accounts) otlp.eu01.nr-data.net:4317 (EU region accounts) OpenTelemetry New Relic supports the native OpenTelemetry Protocol (OTLP) for exporting telemetry data. This allows you to use the vendor neutral components developed by the OpenTelemetry community to export your data to New Relic. To export OTLP data to New Relic, configure the OTLP exporter to add a header ( api-key ) whose value is your account license key. And, based on your region, configure the endpoint where the exporter sends data to New Relic. See the OpenTelemetry quick start for more information. otlp.nr-data.net:4317 (US region accounts) otlp.eu01.nr-data.net:4317 (EU region accounts) Network blocks for US region accounts: 162.247.240.0/22 Network blocks for EU region accounts: 185.221.84.0/22",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.77429,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>User</em>-facing domains",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": " for <em>New</em> <em>Relic</em> One to work properly. Update your allow list to ensure <em>New</em> <em>Relic</em> can communicate with a number of integral domains that are listed in this section. Blocking domains can cause issues with individual <em>product</em> features or prevent pages from loading altogether. This list doesn&#x27;t cover domains"
      },
      "id": "603eb81364441f64a24e88b6"
    },
    {
      "sections": [
        "Not seeing data",
        "Problem",
        "Solution",
        "APM agents",
        "Deleted or renamed applications in APM",
        "No connection to collector",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Other factors affecting access"
      ],
      "title": "Not seeing data",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "1351bcdb406ddc130d9e2388806e5c2c28e22f75",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/not-seeing-data/",
      "published_at": "2022-01-12T05:59:00Z",
      "updated_at": "2021-12-14T04:17:40Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You do not see data in the UI after installing a New Relic agent. Solution You should start seeing data within a few minutes after installing a New Relic agent and generating traffic for your app. If you don't see data, you can use the New Relic Diagnostics utility to automatically identify common issues. For additional troubleshooting tips, see the agent-specific docs.  APM agents Follow the troubleshooting procedures for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby In addition, you can try these troubleshooting steps that apply to all APM agents: Deleted or renamed applications in APM An app needs to stop reporting data for at least an hour before you can reuse that name. It also needs to reconnect with the New Relic collector (be restarted) before new data will be accepted. The app remains in the collector's cache for an hour before it is flushed. During that time it is marked as \"deleted,\" so no new data is accepted. Also, the data is associated with an executing app that has been deleted until the agent is restarted. For more information, see: Name your application Use multiple names for an app No connection to collector Your app will not be affected if the New Relic agent cannot connect to the collector. Data continues to be collected, and it is uploaded as soon as the connection is restored. While the network is down or the collector unavailable, you may see gaps where data is missing in the APM CPU and memory charts. The agent will continue attempting to reconnect, and when it succeeds, you will again see data appearing in the UI. During the time the agent is unable to communicate with the collector, it is still collecting data. Once it is able to connect again, it will upload the data and fill in the missing segment so there will not be any confusion about whether your application was down or just not reporting data. To save memory, the data will be aggregated and averaged over the period, so you will see flat bars and charts over the period when it was unable to communicate with the collector. Browser monitoring See Troubleshooting browser monitoring installation. Infrastructure monitoring Follow the troubleshooting procedures for your infrastructure agent: Linux Windows AWS integrations On-host integrations Mobile monitoring Follow the troubleshooting procedures for your mobile app: iOS Android Other factors affecting access For more on factors that can affect your ability to access New Relic features, see Factors affecting access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.13982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Problem You do not see data in the UI after installing a <em>New</em> <em>Relic</em> agent. Solution You should start seeing data within a few minutes after installing a <em>New</em> <em>Relic</em> agent and generating traffic for your app. If you don&#x27;t see data, you can <em>use</em> the <em>New</em> <em>Relic</em> Diagnostics utility to automatically identify"
      },
      "id": "603e8f2928ccbccc87eba750"
    },
    {
      "sections": [
        "Generate New Relic agent logs for troubleshooting",
        "APM agent logging",
        "Infrastructure agent logging",
        "Mobile agent logging",
        "Logging for other New Relic tools"
      ],
      "title": "Generate New Relic agent logs for troubleshooting",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "cc4e412038d0e125474a7ead0440a3cad51554dc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/generate-new-relic-agent-logs-troubleshooting/",
      "published_at": "2022-01-12T03:18:47Z",
      "updated_at": "2021-12-14T04:16:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some New Relic solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for troubleshooting, auditing, and diagnostics. Related docs: For general agent troubleshooting, see Not seeing data. Learn about New Relic Diagnostics: a utility that automatically detects common problems. APM agent logging C SDK logs Go agent logs Java logs .NET logs Node.js logs PHP logs Python logs Ruby logs Infrastructure agent logging See Infrastructure agent logs. Mobile agent logging Android log settings iOS log settings Logging for other New Relic tools For log generation and troubleshooting instructions for tools not listed here, see the docs for a specific solution in New Relic Instant Observability.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.54419,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "sections": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Some <em>New</em> <em>Relic</em> solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for <em>troubleshooting</em>, auditing, and diagnostics. Related docs: For general agent <em>troubleshooting</em>, see Not seeing data. Learn about <em>New</em> <em>Relic</em> Diagnostics: a utility"
      },
      "id": "61bfb6ef196a67b63eef0936"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/troubleshooting/generate-new-relic-agent-logs-troubleshooting": [
    {
      "sections": [
        "Networks",
        "Tip",
        "TLS encryption",
        "User-facing domains",
        "APM agents",
        "Port 443 recommended",
        "Agent downloads",
        "Infrastructure agents",
        "Browser domains",
        "Mobile domains",
        "Synthetic monitor public locations",
        "Synthetic monitor private locations",
        "Alerts webhooks, api.newrelic.com, cloud integrations, and ticketing integrations",
        "Pixie integration",
        "OpenTelemetry"
      ],
      "title": "Networks",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "9f7555daaafae1753bf1e741a5d607e7f0f87b7c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/networks/",
      "published_at": "2022-01-12T18:27:20Z",
      "updated_at": "2022-01-08T17:44:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Networks, IPs, domains, ports, and endpoints last updated January 6, 2022. This is a list of the networks, IP addresses, domains, ports, and endpoints used by API clients or agents to communicate with New Relic. TLS is required for all domains. For information on our FedRAMP endpoints, see our FedRAMP endpoints documentation. Tip This doc describes how to ensure our agents and integrations can access New Relic's domains. To monitor the performance of your network, see Get started with Network Performance Monitoring. TLS encryption To ensure data security for our customers and to be in compliance with FedRAMP and other standards for data encryption, Transport Layer Security (TLS) is required for all domains. Our preferred protocol for all domains is TLS 1.2. For more information, see New Relic's Explorers Hub post about TLS 1.2. In addition, TLS 1.2 is required for most domains, except: APM agent connections Browser agent connections Event API For future updates to required and supported protocol versions, follow the Security Notifications tag in New Relic's Explorers Hub. User-facing domains Your browser must be able to communicate with a number of domains for New Relic One to work properly. Update your allow list to ensure New Relic can communicate with a number of integral domains that are listed in this section. Blocking domains can cause issues with individual product features or prevent pages from loading altogether. This list doesn't cover domains that New Relic connects to that can be blocked without affecting your usage of the product. It also doesn't cover Nerdpacks or other features that communicate with external services that have additional domain requirements. If your organization uses a firewall that restricts outbound traffic, follow the specific procedures for the operating system and the firewall you use to add the following domains to the allow list. Domain Description *.newrelic.com New Relic One and supporting services *.nr-assets.net Static New Relic assets *.nr-ext.net New Relic One Nerdpacks and assets *.amazonaws.com New Relic One catalog assets behind AWS S3 *.cloudfront.net Static New Relic assets behind AWS CloudFront CDN secure.gravatar.com Support for Gravatar avatars fonts.googleapis.com Support for Google Fonts fonts.gstatic.com Support for Google Fonts www.google.com Support for reCAPTCHA www.gstatic.com Support for reCAPTCHA *.nr-data.net OpenTelemetry and Pixie onenr.io New Relic One sharing permalinks APM agents To enhance network performance and data security, New Relic uses a CDN and DDoS prevention service with a large IP range. New Relic agents require your firewall to allow outgoing connections to the following networks and ports. To add the following IP connections to the allow list, follow the specific procedures for the operating system and the firewall you use. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections APM data Networks US region accounts: 162.247.240.0/22 EU region accounts: 185.221.84.0/22 Ports US region accounts: Default: TCP 443 (recommended) TCP 80 EU region accounts: Default: TCP 443 (recommended) TCP 80 Endpoints US region accounts: collector*.newrelic.com EU region accounts: collector*.eu01.nr-data.net:443 (recommended) Port 443 recommended Recommendation: Use port 443, a secured channel for encrypted HTTPS traffic. Some New Relic agents also offer port 80, an unsecured channel open to all HTTP traffic. While some agents can be configured to use both port 80 and port 443, we recommend that you choose the port 443 (default). If you have an existing configuration that uses port 80, you can update it to use port 443, the default New Relic connection. Agent downloads TLS is required for all domains. Service for download.newrelic.com is provided through Fastly and is subject to change without warning. For the most current list of public IP addresses for New Relic agent downloads, see api.fastly.com/public-ip-list. Infrastructure agents In order to report data to New Relic, our infrastructure monitoring needs outbound access to these domains, networks, and ports. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections Infrastructure data Domains infra-api.newrelic.com: Required to submit events, metrics, and inventory data. identity-api.newrelic.com: Required for entity registration (for example, a host entity). infrastructure-command-api.newrelic.com: Required to determine feature flags. Also used for gradual rollout of new capabilities. log-api.newrelic.com: Required to submit logs to a US datacenter. log-api.eu.newrelic.com: Required to submit logs to an EU datacenter. metric-api.newrelic.com: Required to submit dimensional metrics. Networks For US region accounts: 162.247.240.0/22 For EU region accounts: 185.221.84.0/22 Port 443 Domains + Port For US region accounts: infra-api.newrelic.com:443 identity-api.newrelic.com:443 infrastructure-command-api.newrelic.com:443 log-api.newrelic.com:443 metric-api.newrelic.com:443 For EU region accounts: infra-api.eu.newrelic.com:443 identity-api.eu.newrelic.com:443 infrastructure-command-api.eu.newrelic.com:443 log-api.eu.newrelic.com:443 metric-api.eu.newrelic.com:443 Proxy If your system needs a proxy to connect to this domain, use the Infrastructure proxy setting. Browser domains In addition to the IP addresses for APM agents, applications monitored by our browser agents use outgoing connections to the following domains. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: For US region accounts: bam.nr-data.net js-agent.newrelic.com For EU region accounts: eu01.nr-data.net bam.eu01.nr-data.net For more information about CDN access for the js-agent.newrelic.com file to the domain bam.nr-data.net or to one of the New Relic beacons, see Security for browser monitoring. Mobile domains In addition to the IP addresses for APM agents, applications monitored by our mobile agents use outgoing connections to the following domains. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: For US region accounts: mobile-collector.newrelic.com mobile-crash.newrelic.com mobile-symbol-upload.newrelic.com For EU region accounts: mobile-collector.eu01.nr-data.net mobile-crash.eu01.nr-data.net mobile-symbol-upload.eu01.nr-data.net Synthetic monitor public locations To configure your firewall to allow synthetic monitors to access your monitored URL, use Synthetic public minion IPs. TLS is required for all domains. Synthetic monitor private locations Synthetic private minions report to a specific endpoint based on region. To allow the private minion to access the endpoint or the static IP addresses associated with the endpoint, follow the specific procedures for the operating system and the firewall you use. These IP addresses may change in the future. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections Synthetics private location data Endpoint For US region accounts: https://synthetics-horde.nr-data.net/ For EU region accounts: https://synthetics-horde.eu01.nr-data.net/ IP addresses For US region accounts: 13.248.153.51 76.223.21.185 For EU region accounts: 185.221.86.57 185.221.86.25 Alerts webhooks, api.newrelic.com, cloud integrations, and ticketing integrations Endpoints that use api.newrelic.com (such as our GraphQL API for NerdGraph) and our New Relic-generated webhooks for alert policies use an IP address from designated network blocks for the US or European Union region. TLS is required for all addresses in these blocks. Network blocks for US region accounts: 162.247.240.0/22 Network blocks for EU region accounts: 158.177.65.64/29 159.122.103.184/29 161.156.125.32/28 These network blocks also apply to third-party ticketing integrations and New Relic cloud integrations. Pixie integration The Pixie integration runs in your Kubernetes cluster and pulls a set of curated observability data from Pixie to send it to New Relic using the OpenTelemetry line protocol. The Pixie integration requires outbound network access to the following: work.withpixie.ai:443 otlp.nr-data.net:4317 (US region accounts) otlp.eu01.nr-data.net:4317 (EU region accounts) OpenTelemetry New Relic supports the native OpenTelemetry Protocol (OTLP) for exporting telemetry data. This allows you to use the vendor neutral components developed by the OpenTelemetry community to export your data to New Relic. To export OTLP data to New Relic, configure the OTLP exporter to add a header ( api-key ) whose value is your account license key. And, based on your region, configure the endpoint where the exporter sends data to New Relic. See the OpenTelemetry quick start for more information. otlp.nr-data.net:4317 (US region accounts) otlp.eu01.nr-data.net:4317 (EU region accounts) Network blocks for US region accounts: 162.247.240.0/22 Network blocks for EU region accounts: 185.221.84.0/22",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.77429,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>User</em>-facing domains",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": " for <em>New</em> <em>Relic</em> One to work properly. Update your allow list to ensure <em>New</em> <em>Relic</em> can communicate with a number of integral domains that are listed in this section. Blocking domains can cause issues with individual <em>product</em> features or prevent pages from loading altogether. This list doesn&#x27;t cover domains"
      },
      "id": "603eb81364441f64a24e88b6"
    },
    {
      "sections": [
        "Not seeing data",
        "Problem",
        "Solution",
        "APM agents",
        "Deleted or renamed applications in APM",
        "No connection to collector",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Other factors affecting access"
      ],
      "title": "Not seeing data",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "1351bcdb406ddc130d9e2388806e5c2c28e22f75",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/not-seeing-data/",
      "published_at": "2022-01-12T05:59:00Z",
      "updated_at": "2021-12-14T04:17:40Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You do not see data in the UI after installing a New Relic agent. Solution You should start seeing data within a few minutes after installing a New Relic agent and generating traffic for your app. If you don't see data, you can use the New Relic Diagnostics utility to automatically identify common issues. For additional troubleshooting tips, see the agent-specific docs.  APM agents Follow the troubleshooting procedures for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby In addition, you can try these troubleshooting steps that apply to all APM agents: Deleted or renamed applications in APM An app needs to stop reporting data for at least an hour before you can reuse that name. It also needs to reconnect with the New Relic collector (be restarted) before new data will be accepted. The app remains in the collector's cache for an hour before it is flushed. During that time it is marked as \"deleted,\" so no new data is accepted. Also, the data is associated with an executing app that has been deleted until the agent is restarted. For more information, see: Name your application Use multiple names for an app No connection to collector Your app will not be affected if the New Relic agent cannot connect to the collector. Data continues to be collected, and it is uploaded as soon as the connection is restored. While the network is down or the collector unavailable, you may see gaps where data is missing in the APM CPU and memory charts. The agent will continue attempting to reconnect, and when it succeeds, you will again see data appearing in the UI. During the time the agent is unable to communicate with the collector, it is still collecting data. Once it is able to connect again, it will upload the data and fill in the missing segment so there will not be any confusion about whether your application was down or just not reporting data. To save memory, the data will be aggregated and averaged over the period, so you will see flat bars and charts over the period when it was unable to communicate with the collector. Browser monitoring See Troubleshooting browser monitoring installation. Infrastructure monitoring Follow the troubleshooting procedures for your infrastructure agent: Linux Windows AWS integrations On-host integrations Mobile monitoring Follow the troubleshooting procedures for your mobile app: iOS Android Other factors affecting access For more on factors that can affect your ability to access New Relic features, see Factors affecting access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.13982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Problem You do not see data in the UI after installing a <em>New</em> <em>Relic</em> agent. Solution You should start seeing data within a few minutes after installing a <em>New</em> <em>Relic</em> agent and generating traffic for your app. If you don&#x27;t see data, you can <em>use</em> the <em>New</em> <em>Relic</em> Diagnostics utility to automatically identify"
      },
      "id": "603e8f2928ccbccc87eba750"
    },
    {
      "sections": [
        "Install New Relic",
        "Install APM",
        "Install browser monitoring",
        "Install infrastructure monitoring",
        "Install mobile monitoring",
        "Install synthetic monitors",
        "Troubleshooting"
      ],
      "title": "Install New Relic ",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "819ccfd8df22ff322271245ca0831bf53609b91f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/cross-product-functions/install-configure/install-new-relic/",
      "published_at": "2022-01-12T11:30:53Z",
      "updated_at": "2021-12-30T20:03:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you sign up for a New Relic account (it's free, forever!) and install any of our monitoring services, you can start working with your data. Get started quickly with our New Relic Instant Observability quickstarts. Alternatively, use our guided install. Here are links to instructions on how to install New Relic monitoring services: APM Browser Infrastructure Mobile Synthetic monitors Integrations for third-party telemetry services Data ingest APIs (metrics, events, logs, traces) Install APM C Go Java .NET For Windows .NET applications on IIS, use our guided install in New Relic One to get started with APM. If you're on an EU server, use our launcher for EU accounts instead. Node.js PHP Python Ruby Install browser monitoring See browser monitoring install. Install infrastructure monitoring Linux guided install for infrastructure monitoring Linux procedures for infrastructure monitoring Windows Kubernetes Prometheus On-host integrations (for services like NGINX, StatsD, MySQL, etc.) AWS cloud integrations Azure cloud integrations Google Cloud Platform Install mobile monitoring Android iOS Install synthetic monitors Synthetic monitoring doesn't require installation, except for its private minions feature. Troubleshooting You should start seeing your data in the New Relic UI after installing the agent, generating some traffic, and waiting a few minutes. If no data appears, follow our troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.51015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>New</em> <em>Relic</em> ",
        "sections": "Install <em>New</em> <em>Relic</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "After you sign up for a <em>New</em> <em>Relic</em> account (it&#x27;s free, forever!) and install any of our monitoring services, you can start working with your data. Get started quickly with our <em>New</em> <em>Relic</em> Instant Observability quickstarts. Alternatively, <em>use</em> our guided install. Here are links to instructions on how"
      },
      "id": "61b8148ce7b9d22373ef3a8b"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/troubleshooting/log-audit-all-data-your-new-relic-agent-transmits": [
    {
      "sections": [
        "Networks",
        "Tip",
        "TLS encryption",
        "User-facing domains",
        "APM agents",
        "Port 443 recommended",
        "Agent downloads",
        "Infrastructure agents",
        "Browser domains",
        "Mobile domains",
        "Synthetic monitor public locations",
        "Synthetic monitor private locations",
        "Alerts webhooks, api.newrelic.com, cloud integrations, and ticketing integrations",
        "Pixie integration",
        "OpenTelemetry"
      ],
      "title": "Networks",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "9f7555daaafae1753bf1e741a5d607e7f0f87b7c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/networks/",
      "published_at": "2022-01-12T18:27:20Z",
      "updated_at": "2022-01-08T17:44:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Networks, IPs, domains, ports, and endpoints last updated January 6, 2022. This is a list of the networks, IP addresses, domains, ports, and endpoints used by API clients or agents to communicate with New Relic. TLS is required for all domains. For information on our FedRAMP endpoints, see our FedRAMP endpoints documentation. Tip This doc describes how to ensure our agents and integrations can access New Relic's domains. To monitor the performance of your network, see Get started with Network Performance Monitoring. TLS encryption To ensure data security for our customers and to be in compliance with FedRAMP and other standards for data encryption, Transport Layer Security (TLS) is required for all domains. Our preferred protocol for all domains is TLS 1.2. For more information, see New Relic's Explorers Hub post about TLS 1.2. In addition, TLS 1.2 is required for most domains, except: APM agent connections Browser agent connections Event API For future updates to required and supported protocol versions, follow the Security Notifications tag in New Relic's Explorers Hub. User-facing domains Your browser must be able to communicate with a number of domains for New Relic One to work properly. Update your allow list to ensure New Relic can communicate with a number of integral domains that are listed in this section. Blocking domains can cause issues with individual product features or prevent pages from loading altogether. This list doesn't cover domains that New Relic connects to that can be blocked without affecting your usage of the product. It also doesn't cover Nerdpacks or other features that communicate with external services that have additional domain requirements. If your organization uses a firewall that restricts outbound traffic, follow the specific procedures for the operating system and the firewall you use to add the following domains to the allow list. Domain Description *.newrelic.com New Relic One and supporting services *.nr-assets.net Static New Relic assets *.nr-ext.net New Relic One Nerdpacks and assets *.amazonaws.com New Relic One catalog assets behind AWS S3 *.cloudfront.net Static New Relic assets behind AWS CloudFront CDN secure.gravatar.com Support for Gravatar avatars fonts.googleapis.com Support for Google Fonts fonts.gstatic.com Support for Google Fonts www.google.com Support for reCAPTCHA www.gstatic.com Support for reCAPTCHA *.nr-data.net OpenTelemetry and Pixie onenr.io New Relic One sharing permalinks APM agents To enhance network performance and data security, New Relic uses a CDN and DDoS prevention service with a large IP range. New Relic agents require your firewall to allow outgoing connections to the following networks and ports. To add the following IP connections to the allow list, follow the specific procedures for the operating system and the firewall you use. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections APM data Networks US region accounts: 162.247.240.0/22 EU region accounts: 185.221.84.0/22 Ports US region accounts: Default: TCP 443 (recommended) TCP 80 EU region accounts: Default: TCP 443 (recommended) TCP 80 Endpoints US region accounts: collector*.newrelic.com EU region accounts: collector*.eu01.nr-data.net:443 (recommended) Port 443 recommended Recommendation: Use port 443, a secured channel for encrypted HTTPS traffic. Some New Relic agents also offer port 80, an unsecured channel open to all HTTP traffic. While some agents can be configured to use both port 80 and port 443, we recommend that you choose the port 443 (default). If you have an existing configuration that uses port 80, you can update it to use port 443, the default New Relic connection. Agent downloads TLS is required for all domains. Service for download.newrelic.com is provided through Fastly and is subject to change without warning. For the most current list of public IP addresses for New Relic agent downloads, see api.fastly.com/public-ip-list. Infrastructure agents In order to report data to New Relic, our infrastructure monitoring needs outbound access to these domains, networks, and ports. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections Infrastructure data Domains infra-api.newrelic.com: Required to submit events, metrics, and inventory data. identity-api.newrelic.com: Required for entity registration (for example, a host entity). infrastructure-command-api.newrelic.com: Required to determine feature flags. Also used for gradual rollout of new capabilities. log-api.newrelic.com: Required to submit logs to a US datacenter. log-api.eu.newrelic.com: Required to submit logs to an EU datacenter. metric-api.newrelic.com: Required to submit dimensional metrics. Networks For US region accounts: 162.247.240.0/22 For EU region accounts: 185.221.84.0/22 Port 443 Domains + Port For US region accounts: infra-api.newrelic.com:443 identity-api.newrelic.com:443 infrastructure-command-api.newrelic.com:443 log-api.newrelic.com:443 metric-api.newrelic.com:443 For EU region accounts: infra-api.eu.newrelic.com:443 identity-api.eu.newrelic.com:443 infrastructure-command-api.eu.newrelic.com:443 log-api.eu.newrelic.com:443 metric-api.eu.newrelic.com:443 Proxy If your system needs a proxy to connect to this domain, use the Infrastructure proxy setting. Browser domains In addition to the IP addresses for APM agents, applications monitored by our browser agents use outgoing connections to the following domains. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: For US region accounts: bam.nr-data.net js-agent.newrelic.com For EU region accounts: eu01.nr-data.net bam.eu01.nr-data.net For more information about CDN access for the js-agent.newrelic.com file to the domain bam.nr-data.net or to one of the New Relic beacons, see Security for browser monitoring. Mobile domains In addition to the IP addresses for APM agents, applications monitored by our mobile agents use outgoing connections to the following domains. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: For US region accounts: mobile-collector.newrelic.com mobile-crash.newrelic.com mobile-symbol-upload.newrelic.com For EU region accounts: mobile-collector.eu01.nr-data.net mobile-crash.eu01.nr-data.net mobile-symbol-upload.eu01.nr-data.net Synthetic monitor public locations To configure your firewall to allow synthetic monitors to access your monitored URL, use Synthetic public minion IPs. TLS is required for all domains. Synthetic monitor private locations Synthetic private minions report to a specific endpoint based on region. To allow the private minion to access the endpoint or the static IP addresses associated with the endpoint, follow the specific procedures for the operating system and the firewall you use. These IP addresses may change in the future. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections Synthetics private location data Endpoint For US region accounts: https://synthetics-horde.nr-data.net/ For EU region accounts: https://synthetics-horde.eu01.nr-data.net/ IP addresses For US region accounts: 13.248.153.51 76.223.21.185 For EU region accounts: 185.221.86.57 185.221.86.25 Alerts webhooks, api.newrelic.com, cloud integrations, and ticketing integrations Endpoints that use api.newrelic.com (such as our GraphQL API for NerdGraph) and our New Relic-generated webhooks for alert policies use an IP address from designated network blocks for the US or European Union region. TLS is required for all addresses in these blocks. Network blocks for US region accounts: 162.247.240.0/22 Network blocks for EU region accounts: 158.177.65.64/29 159.122.103.184/29 161.156.125.32/28 These network blocks also apply to third-party ticketing integrations and New Relic cloud integrations. Pixie integration The Pixie integration runs in your Kubernetes cluster and pulls a set of curated observability data from Pixie to send it to New Relic using the OpenTelemetry line protocol. The Pixie integration requires outbound network access to the following: work.withpixie.ai:443 otlp.nr-data.net:4317 (US region accounts) otlp.eu01.nr-data.net:4317 (EU region accounts) OpenTelemetry New Relic supports the native OpenTelemetry Protocol (OTLP) for exporting telemetry data. This allows you to use the vendor neutral components developed by the OpenTelemetry community to export your data to New Relic. To export OTLP data to New Relic, configure the OTLP exporter to add a header ( api-key ) whose value is your account license key. And, based on your region, configure the endpoint where the exporter sends data to New Relic. See the OpenTelemetry quick start for more information. otlp.nr-data.net:4317 (US region accounts) otlp.eu01.nr-data.net:4317 (EU region accounts) Network blocks for US region accounts: 162.247.240.0/22 Network blocks for EU region accounts: 185.221.84.0/22",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.77429,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>User</em>-facing domains",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": " for <em>New</em> <em>Relic</em> One to work properly. Update your allow list to ensure <em>New</em> <em>Relic</em> can communicate with a number of integral domains that are listed in this section. Blocking domains can cause issues with individual <em>product</em> features or prevent pages from loading altogether. This list doesn&#x27;t cover domains"
      },
      "id": "603eb81364441f64a24e88b6"
    },
    {
      "sections": [
        "Not seeing data",
        "Problem",
        "Solution",
        "APM agents",
        "Deleted or renamed applications in APM",
        "No connection to collector",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Other factors affecting access"
      ],
      "title": "Not seeing data",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "1351bcdb406ddc130d9e2388806e5c2c28e22f75",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/not-seeing-data/",
      "published_at": "2022-01-12T05:59:00Z",
      "updated_at": "2021-12-14T04:17:40Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You do not see data in the UI after installing a New Relic agent. Solution You should start seeing data within a few minutes after installing a New Relic agent and generating traffic for your app. If you don't see data, you can use the New Relic Diagnostics utility to automatically identify common issues. For additional troubleshooting tips, see the agent-specific docs.  APM agents Follow the troubleshooting procedures for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby In addition, you can try these troubleshooting steps that apply to all APM agents: Deleted or renamed applications in APM An app needs to stop reporting data for at least an hour before you can reuse that name. It also needs to reconnect with the New Relic collector (be restarted) before new data will be accepted. The app remains in the collector's cache for an hour before it is flushed. During that time it is marked as \"deleted,\" so no new data is accepted. Also, the data is associated with an executing app that has been deleted until the agent is restarted. For more information, see: Name your application Use multiple names for an app No connection to collector Your app will not be affected if the New Relic agent cannot connect to the collector. Data continues to be collected, and it is uploaded as soon as the connection is restored. While the network is down or the collector unavailable, you may see gaps where data is missing in the APM CPU and memory charts. The agent will continue attempting to reconnect, and when it succeeds, you will again see data appearing in the UI. During the time the agent is unable to communicate with the collector, it is still collecting data. Once it is able to connect again, it will upload the data and fill in the missing segment so there will not be any confusion about whether your application was down or just not reporting data. To save memory, the data will be aggregated and averaged over the period, so you will see flat bars and charts over the period when it was unable to communicate with the collector. Browser monitoring See Troubleshooting browser monitoring installation. Infrastructure monitoring Follow the troubleshooting procedures for your infrastructure agent: Linux Windows AWS integrations On-host integrations Mobile monitoring Follow the troubleshooting procedures for your mobile app: iOS Android Other factors affecting access For more on factors that can affect your ability to access New Relic features, see Factors affecting access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.13982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Problem You do not see data in the UI after installing a <em>New</em> <em>Relic</em> agent. Solution You should start seeing data within a few minutes after installing a <em>New</em> <em>Relic</em> agent and generating traffic for your app. If you don&#x27;t see data, you can <em>use</em> the <em>New</em> <em>Relic</em> Diagnostics utility to automatically identify"
      },
      "id": "603e8f2928ccbccc87eba750"
    },
    {
      "sections": [
        "Generate New Relic agent logs for troubleshooting",
        "APM agent logging",
        "Infrastructure agent logging",
        "Mobile agent logging",
        "Logging for other New Relic tools"
      ],
      "title": "Generate New Relic agent logs for troubleshooting",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "cc4e412038d0e125474a7ead0440a3cad51554dc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/generate-new-relic-agent-logs-troubleshooting/",
      "published_at": "2022-01-12T03:18:47Z",
      "updated_at": "2021-12-14T04:16:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some New Relic solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for troubleshooting, auditing, and diagnostics. Related docs: For general agent troubleshooting, see Not seeing data. Learn about New Relic Diagnostics: a utility that automatically detects common problems. APM agent logging C SDK logs Go agent logs Java logs .NET logs Node.js logs PHP logs Python logs Ruby logs Infrastructure agent logging See Infrastructure agent logs. Mobile agent logging Android log settings iOS log settings Logging for other New Relic tools For log generation and troubleshooting instructions for tools not listed here, see the docs for a specific solution in New Relic Instant Observability.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.54419,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "sections": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Some <em>New</em> <em>Relic</em> solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for <em>troubleshooting</em>, auditing, and diagnostics. Related docs: For general agent <em>troubleshooting</em>, see Not seeing data. Learn about <em>New</em> <em>Relic</em> Diagnostics: a utility"
      },
      "id": "61bfb6ef196a67b63eef0936"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/troubleshooting/metric-grouping-issues": [
    {
      "sections": [
        "Networks",
        "Tip",
        "TLS encryption",
        "User-facing domains",
        "APM agents",
        "Port 443 recommended",
        "Agent downloads",
        "Infrastructure agents",
        "Browser domains",
        "Mobile domains",
        "Synthetic monitor public locations",
        "Synthetic monitor private locations",
        "Alerts webhooks, api.newrelic.com, cloud integrations, and ticketing integrations",
        "Pixie integration",
        "OpenTelemetry"
      ],
      "title": "Networks",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "9f7555daaafae1753bf1e741a5d607e7f0f87b7c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/networks/",
      "published_at": "2022-01-12T18:27:20Z",
      "updated_at": "2022-01-08T17:44:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Networks, IPs, domains, ports, and endpoints last updated January 6, 2022. This is a list of the networks, IP addresses, domains, ports, and endpoints used by API clients or agents to communicate with New Relic. TLS is required for all domains. For information on our FedRAMP endpoints, see our FedRAMP endpoints documentation. Tip This doc describes how to ensure our agents and integrations can access New Relic's domains. To monitor the performance of your network, see Get started with Network Performance Monitoring. TLS encryption To ensure data security for our customers and to be in compliance with FedRAMP and other standards for data encryption, Transport Layer Security (TLS) is required for all domains. Our preferred protocol for all domains is TLS 1.2. For more information, see New Relic's Explorers Hub post about TLS 1.2. In addition, TLS 1.2 is required for most domains, except: APM agent connections Browser agent connections Event API For future updates to required and supported protocol versions, follow the Security Notifications tag in New Relic's Explorers Hub. User-facing domains Your browser must be able to communicate with a number of domains for New Relic One to work properly. Update your allow list to ensure New Relic can communicate with a number of integral domains that are listed in this section. Blocking domains can cause issues with individual product features or prevent pages from loading altogether. This list doesn't cover domains that New Relic connects to that can be blocked without affecting your usage of the product. It also doesn't cover Nerdpacks or other features that communicate with external services that have additional domain requirements. If your organization uses a firewall that restricts outbound traffic, follow the specific procedures for the operating system and the firewall you use to add the following domains to the allow list. Domain Description *.newrelic.com New Relic One and supporting services *.nr-assets.net Static New Relic assets *.nr-ext.net New Relic One Nerdpacks and assets *.amazonaws.com New Relic One catalog assets behind AWS S3 *.cloudfront.net Static New Relic assets behind AWS CloudFront CDN secure.gravatar.com Support for Gravatar avatars fonts.googleapis.com Support for Google Fonts fonts.gstatic.com Support for Google Fonts www.google.com Support for reCAPTCHA www.gstatic.com Support for reCAPTCHA *.nr-data.net OpenTelemetry and Pixie onenr.io New Relic One sharing permalinks APM agents To enhance network performance and data security, New Relic uses a CDN and DDoS prevention service with a large IP range. New Relic agents require your firewall to allow outgoing connections to the following networks and ports. To add the following IP connections to the allow list, follow the specific procedures for the operating system and the firewall you use. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections APM data Networks US region accounts: 162.247.240.0/22 EU region accounts: 185.221.84.0/22 Ports US region accounts: Default: TCP 443 (recommended) TCP 80 EU region accounts: Default: TCP 443 (recommended) TCP 80 Endpoints US region accounts: collector*.newrelic.com EU region accounts: collector*.eu01.nr-data.net:443 (recommended) Port 443 recommended Recommendation: Use port 443, a secured channel for encrypted HTTPS traffic. Some New Relic agents also offer port 80, an unsecured channel open to all HTTP traffic. While some agents can be configured to use both port 80 and port 443, we recommend that you choose the port 443 (default). If you have an existing configuration that uses port 80, you can update it to use port 443, the default New Relic connection. Agent downloads TLS is required for all domains. Service for download.newrelic.com is provided through Fastly and is subject to change without warning. For the most current list of public IP addresses for New Relic agent downloads, see api.fastly.com/public-ip-list. Infrastructure agents In order to report data to New Relic, our infrastructure monitoring needs outbound access to these domains, networks, and ports. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections Infrastructure data Domains infra-api.newrelic.com: Required to submit events, metrics, and inventory data. identity-api.newrelic.com: Required for entity registration (for example, a host entity). infrastructure-command-api.newrelic.com: Required to determine feature flags. Also used for gradual rollout of new capabilities. log-api.newrelic.com: Required to submit logs to a US datacenter. log-api.eu.newrelic.com: Required to submit logs to an EU datacenter. metric-api.newrelic.com: Required to submit dimensional metrics. Networks For US region accounts: 162.247.240.0/22 For EU region accounts: 185.221.84.0/22 Port 443 Domains + Port For US region accounts: infra-api.newrelic.com:443 identity-api.newrelic.com:443 infrastructure-command-api.newrelic.com:443 log-api.newrelic.com:443 metric-api.newrelic.com:443 For EU region accounts: infra-api.eu.newrelic.com:443 identity-api.eu.newrelic.com:443 infrastructure-command-api.eu.newrelic.com:443 log-api.eu.newrelic.com:443 metric-api.eu.newrelic.com:443 Proxy If your system needs a proxy to connect to this domain, use the Infrastructure proxy setting. Browser domains In addition to the IP addresses for APM agents, applications monitored by our browser agents use outgoing connections to the following domains. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: For US region accounts: bam.nr-data.net js-agent.newrelic.com For EU region accounts: eu01.nr-data.net bam.eu01.nr-data.net For more information about CDN access for the js-agent.newrelic.com file to the domain bam.nr-data.net or to one of the New Relic beacons, see Security for browser monitoring. Mobile domains In addition to the IP addresses for APM agents, applications monitored by our mobile agents use outgoing connections to the following domains. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: For US region accounts: mobile-collector.newrelic.com mobile-crash.newrelic.com mobile-symbol-upload.newrelic.com For EU region accounts: mobile-collector.eu01.nr-data.net mobile-crash.eu01.nr-data.net mobile-symbol-upload.eu01.nr-data.net Synthetic monitor public locations To configure your firewall to allow synthetic monitors to access your monitored URL, use Synthetic public minion IPs. TLS is required for all domains. Synthetic monitor private locations Synthetic private minions report to a specific endpoint based on region. To allow the private minion to access the endpoint or the static IP addresses associated with the endpoint, follow the specific procedures for the operating system and the firewall you use. These IP addresses may change in the future. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections Synthetics private location data Endpoint For US region accounts: https://synthetics-horde.nr-data.net/ For EU region accounts: https://synthetics-horde.eu01.nr-data.net/ IP addresses For US region accounts: 13.248.153.51 76.223.21.185 For EU region accounts: 185.221.86.57 185.221.86.25 Alerts webhooks, api.newrelic.com, cloud integrations, and ticketing integrations Endpoints that use api.newrelic.com (such as our GraphQL API for NerdGraph) and our New Relic-generated webhooks for alert policies use an IP address from designated network blocks for the US or European Union region. TLS is required for all addresses in these blocks. Network blocks for US region accounts: 162.247.240.0/22 Network blocks for EU region accounts: 158.177.65.64/29 159.122.103.184/29 161.156.125.32/28 These network blocks also apply to third-party ticketing integrations and New Relic cloud integrations. Pixie integration The Pixie integration runs in your Kubernetes cluster and pulls a set of curated observability data from Pixie to send it to New Relic using the OpenTelemetry line protocol. The Pixie integration requires outbound network access to the following: work.withpixie.ai:443 otlp.nr-data.net:4317 (US region accounts) otlp.eu01.nr-data.net:4317 (EU region accounts) OpenTelemetry New Relic supports the native OpenTelemetry Protocol (OTLP) for exporting telemetry data. This allows you to use the vendor neutral components developed by the OpenTelemetry community to export your data to New Relic. To export OTLP data to New Relic, configure the OTLP exporter to add a header ( api-key ) whose value is your account license key. And, based on your region, configure the endpoint where the exporter sends data to New Relic. See the OpenTelemetry quick start for more information. otlp.nr-data.net:4317 (US region accounts) otlp.eu01.nr-data.net:4317 (EU region accounts) Network blocks for US region accounts: 162.247.240.0/22 Network blocks for EU region accounts: 185.221.84.0/22",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.7742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>User</em>-facing domains",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": " for <em>New</em> <em>Relic</em> One to work properly. Update your allow list to ensure <em>New</em> <em>Relic</em> can communicate with a number of integral domains that are listed in this section. Blocking domains can cause issues with individual <em>product</em> features or prevent pages from loading altogether. This list doesn&#x27;t cover domains"
      },
      "id": "603eb81364441f64a24e88b6"
    },
    {
      "sections": [
        "Not seeing data",
        "Problem",
        "Solution",
        "APM agents",
        "Deleted or renamed applications in APM",
        "No connection to collector",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Other factors affecting access"
      ],
      "title": "Not seeing data",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "1351bcdb406ddc130d9e2388806e5c2c28e22f75",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/not-seeing-data/",
      "published_at": "2022-01-12T05:59:00Z",
      "updated_at": "2021-12-14T04:17:40Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You do not see data in the UI after installing a New Relic agent. Solution You should start seeing data within a few minutes after installing a New Relic agent and generating traffic for your app. If you don't see data, you can use the New Relic Diagnostics utility to automatically identify common issues. For additional troubleshooting tips, see the agent-specific docs.  APM agents Follow the troubleshooting procedures for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby In addition, you can try these troubleshooting steps that apply to all APM agents: Deleted or renamed applications in APM An app needs to stop reporting data for at least an hour before you can reuse that name. It also needs to reconnect with the New Relic collector (be restarted) before new data will be accepted. The app remains in the collector's cache for an hour before it is flushed. During that time it is marked as \"deleted,\" so no new data is accepted. Also, the data is associated with an executing app that has been deleted until the agent is restarted. For more information, see: Name your application Use multiple names for an app No connection to collector Your app will not be affected if the New Relic agent cannot connect to the collector. Data continues to be collected, and it is uploaded as soon as the connection is restored. While the network is down or the collector unavailable, you may see gaps where data is missing in the APM CPU and memory charts. The agent will continue attempting to reconnect, and when it succeeds, you will again see data appearing in the UI. During the time the agent is unable to communicate with the collector, it is still collecting data. Once it is able to connect again, it will upload the data and fill in the missing segment so there will not be any confusion about whether your application was down or just not reporting data. To save memory, the data will be aggregated and averaged over the period, so you will see flat bars and charts over the period when it was unable to communicate with the collector. Browser monitoring See Troubleshooting browser monitoring installation. Infrastructure monitoring Follow the troubleshooting procedures for your infrastructure agent: Linux Windows AWS integrations On-host integrations Mobile monitoring Follow the troubleshooting procedures for your mobile app: iOS Android Other factors affecting access For more on factors that can affect your ability to access New Relic features, see Factors affecting access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.1398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Problem You do not see data in the UI after installing a <em>New</em> <em>Relic</em> agent. Solution You should start seeing data within a few minutes after installing a <em>New</em> <em>Relic</em> agent and generating traffic for your app. If you don&#x27;t see data, you can <em>use</em> the <em>New</em> <em>Relic</em> Diagnostics utility to automatically identify"
      },
      "id": "603e8f2928ccbccc87eba750"
    },
    {
      "sections": [
        "Generate New Relic agent logs for troubleshooting",
        "APM agent logging",
        "Infrastructure agent logging",
        "Mobile agent logging",
        "Logging for other New Relic tools"
      ],
      "title": "Generate New Relic agent logs for troubleshooting",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "cc4e412038d0e125474a7ead0440a3cad51554dc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/generate-new-relic-agent-logs-troubleshooting/",
      "published_at": "2022-01-12T03:18:47Z",
      "updated_at": "2021-12-14T04:16:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some New Relic solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for troubleshooting, auditing, and diagnostics. Related docs: For general agent troubleshooting, see Not seeing data. Learn about New Relic Diagnostics: a utility that automatically detects common problems. APM agent logging C SDK logs Go agent logs Java logs .NET logs Node.js logs PHP logs Python logs Ruby logs Infrastructure agent logging See Infrastructure agent logs. Mobile agent logging Android log settings iOS log settings Logging for other New Relic tools For log generation and troubleshooting instructions for tools not listed here, see the docs for a specific solution in New Relic Instant Observability.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.54417,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "sections": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Some <em>New</em> <em>Relic</em> solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for <em>troubleshooting</em>, auditing, and diagnostics. Related docs: For general agent <em>troubleshooting</em>, see Not seeing data. Learn about <em>New</em> <em>Relic</em> Diagnostics: a utility"
      },
      "id": "61bfb6ef196a67b63eef0936"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/troubleshooting/not-seeing-data": [
    {
      "sections": [
        "Networks",
        "Tip",
        "TLS encryption",
        "User-facing domains",
        "APM agents",
        "Port 443 recommended",
        "Agent downloads",
        "Infrastructure agents",
        "Browser domains",
        "Mobile domains",
        "Synthetic monitor public locations",
        "Synthetic monitor private locations",
        "Alerts webhooks, api.newrelic.com, cloud integrations, and ticketing integrations",
        "Pixie integration",
        "OpenTelemetry"
      ],
      "title": "Networks",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "9f7555daaafae1753bf1e741a5d607e7f0f87b7c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/networks/",
      "published_at": "2022-01-12T18:27:20Z",
      "updated_at": "2022-01-08T17:44:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Networks, IPs, domains, ports, and endpoints last updated January 6, 2022. This is a list of the networks, IP addresses, domains, ports, and endpoints used by API clients or agents to communicate with New Relic. TLS is required for all domains. For information on our FedRAMP endpoints, see our FedRAMP endpoints documentation. Tip This doc describes how to ensure our agents and integrations can access New Relic's domains. To monitor the performance of your network, see Get started with Network Performance Monitoring. TLS encryption To ensure data security for our customers and to be in compliance with FedRAMP and other standards for data encryption, Transport Layer Security (TLS) is required for all domains. Our preferred protocol for all domains is TLS 1.2. For more information, see New Relic's Explorers Hub post about TLS 1.2. In addition, TLS 1.2 is required for most domains, except: APM agent connections Browser agent connections Event API For future updates to required and supported protocol versions, follow the Security Notifications tag in New Relic's Explorers Hub. User-facing domains Your browser must be able to communicate with a number of domains for New Relic One to work properly. Update your allow list to ensure New Relic can communicate with a number of integral domains that are listed in this section. Blocking domains can cause issues with individual product features or prevent pages from loading altogether. This list doesn't cover domains that New Relic connects to that can be blocked without affecting your usage of the product. It also doesn't cover Nerdpacks or other features that communicate with external services that have additional domain requirements. If your organization uses a firewall that restricts outbound traffic, follow the specific procedures for the operating system and the firewall you use to add the following domains to the allow list. Domain Description *.newrelic.com New Relic One and supporting services *.nr-assets.net Static New Relic assets *.nr-ext.net New Relic One Nerdpacks and assets *.amazonaws.com New Relic One catalog assets behind AWS S3 *.cloudfront.net Static New Relic assets behind AWS CloudFront CDN secure.gravatar.com Support for Gravatar avatars fonts.googleapis.com Support for Google Fonts fonts.gstatic.com Support for Google Fonts www.google.com Support for reCAPTCHA www.gstatic.com Support for reCAPTCHA *.nr-data.net OpenTelemetry and Pixie onenr.io New Relic One sharing permalinks APM agents To enhance network performance and data security, New Relic uses a CDN and DDoS prevention service with a large IP range. New Relic agents require your firewall to allow outgoing connections to the following networks and ports. To add the following IP connections to the allow list, follow the specific procedures for the operating system and the firewall you use. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections APM data Networks US region accounts: 162.247.240.0/22 EU region accounts: 185.221.84.0/22 Ports US region accounts: Default: TCP 443 (recommended) TCP 80 EU region accounts: Default: TCP 443 (recommended) TCP 80 Endpoints US region accounts: collector*.newrelic.com EU region accounts: collector*.eu01.nr-data.net:443 (recommended) Port 443 recommended Recommendation: Use port 443, a secured channel for encrypted HTTPS traffic. Some New Relic agents also offer port 80, an unsecured channel open to all HTTP traffic. While some agents can be configured to use both port 80 and port 443, we recommend that you choose the port 443 (default). If you have an existing configuration that uses port 80, you can update it to use port 443, the default New Relic connection. Agent downloads TLS is required for all domains. Service for download.newrelic.com is provided through Fastly and is subject to change without warning. For the most current list of public IP addresses for New Relic agent downloads, see api.fastly.com/public-ip-list. Infrastructure agents In order to report data to New Relic, our infrastructure monitoring needs outbound access to these domains, networks, and ports. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections Infrastructure data Domains infra-api.newrelic.com: Required to submit events, metrics, and inventory data. identity-api.newrelic.com: Required for entity registration (for example, a host entity). infrastructure-command-api.newrelic.com: Required to determine feature flags. Also used for gradual rollout of new capabilities. log-api.newrelic.com: Required to submit logs to a US datacenter. log-api.eu.newrelic.com: Required to submit logs to an EU datacenter. metric-api.newrelic.com: Required to submit dimensional metrics. Networks For US region accounts: 162.247.240.0/22 For EU region accounts: 185.221.84.0/22 Port 443 Domains + Port For US region accounts: infra-api.newrelic.com:443 identity-api.newrelic.com:443 infrastructure-command-api.newrelic.com:443 log-api.newrelic.com:443 metric-api.newrelic.com:443 For EU region accounts: infra-api.eu.newrelic.com:443 identity-api.eu.newrelic.com:443 infrastructure-command-api.eu.newrelic.com:443 log-api.eu.newrelic.com:443 metric-api.eu.newrelic.com:443 Proxy If your system needs a proxy to connect to this domain, use the Infrastructure proxy setting. Browser domains In addition to the IP addresses for APM agents, applications monitored by our browser agents use outgoing connections to the following domains. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: For US region accounts: bam.nr-data.net js-agent.newrelic.com For EU region accounts: eu01.nr-data.net bam.eu01.nr-data.net For more information about CDN access for the js-agent.newrelic.com file to the domain bam.nr-data.net or to one of the New Relic beacons, see Security for browser monitoring. Mobile domains In addition to the IP addresses for APM agents, applications monitored by our mobile agents use outgoing connections to the following domains. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: For US region accounts: mobile-collector.newrelic.com mobile-crash.newrelic.com mobile-symbol-upload.newrelic.com For EU region accounts: mobile-collector.eu01.nr-data.net mobile-crash.eu01.nr-data.net mobile-symbol-upload.eu01.nr-data.net Synthetic monitor public locations To configure your firewall to allow synthetic monitors to access your monitored URL, use Synthetic public minion IPs. TLS is required for all domains. Synthetic monitor private locations Synthetic private minions report to a specific endpoint based on region. To allow the private minion to access the endpoint or the static IP addresses associated with the endpoint, follow the specific procedures for the operating system and the firewall you use. These IP addresses may change in the future. TLS is required for all domains. Use the IP connections for account data in the US or European Union region as appropriate: IP connections Synthetics private location data Endpoint For US region accounts: https://synthetics-horde.nr-data.net/ For EU region accounts: https://synthetics-horde.eu01.nr-data.net/ IP addresses For US region accounts: 13.248.153.51 76.223.21.185 For EU region accounts: 185.221.86.57 185.221.86.25 Alerts webhooks, api.newrelic.com, cloud integrations, and ticketing integrations Endpoints that use api.newrelic.com (such as our GraphQL API for NerdGraph) and our New Relic-generated webhooks for alert policies use an IP address from designated network blocks for the US or European Union region. TLS is required for all addresses in these blocks. Network blocks for US region accounts: 162.247.240.0/22 Network blocks for EU region accounts: 158.177.65.64/29 159.122.103.184/29 161.156.125.32/28 These network blocks also apply to third-party ticketing integrations and New Relic cloud integrations. Pixie integration The Pixie integration runs in your Kubernetes cluster and pulls a set of curated observability data from Pixie to send it to New Relic using the OpenTelemetry line protocol. The Pixie integration requires outbound network access to the following: work.withpixie.ai:443 otlp.nr-data.net:4317 (US region accounts) otlp.eu01.nr-data.net:4317 (EU region accounts) OpenTelemetry New Relic supports the native OpenTelemetry Protocol (OTLP) for exporting telemetry data. This allows you to use the vendor neutral components developed by the OpenTelemetry community to export your data to New Relic. To export OTLP data to New Relic, configure the OTLP exporter to add a header ( api-key ) whose value is your account license key. And, based on your region, configure the endpoint where the exporter sends data to New Relic. See the OpenTelemetry quick start for more information. otlp.nr-data.net:4317 (US region accounts) otlp.eu01.nr-data.net:4317 (EU region accounts) Network blocks for US region accounts: 162.247.240.0/22 Network blocks for EU region accounts: 185.221.84.0/22",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.7742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>User</em>-facing domains",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": " for <em>New</em> <em>Relic</em> One to work properly. Update your allow list to ensure <em>New</em> <em>Relic</em> can communicate with a number of integral domains that are listed in this section. Blocking domains can cause issues with individual <em>product</em> features or prevent pages from loading altogether. This list doesn&#x27;t cover domains"
      },
      "id": "603eb81364441f64a24e88b6"
    },
    {
      "sections": [
        "Generate New Relic agent logs for troubleshooting",
        "APM agent logging",
        "Infrastructure agent logging",
        "Mobile agent logging",
        "Logging for other New Relic tools"
      ],
      "title": "Generate New Relic agent logs for troubleshooting",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "cc4e412038d0e125474a7ead0440a3cad51554dc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/generate-new-relic-agent-logs-troubleshooting/",
      "published_at": "2022-01-12T03:18:47Z",
      "updated_at": "2021-12-14T04:16:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some New Relic solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for troubleshooting, auditing, and diagnostics. Related docs: For general agent troubleshooting, see Not seeing data. Learn about New Relic Diagnostics: a utility that automatically detects common problems. APM agent logging C SDK logs Go agent logs Java logs .NET logs Node.js logs PHP logs Python logs Ruby logs Infrastructure agent logging See Infrastructure agent logs. Mobile agent logging Android log settings iOS log settings Logging for other New Relic tools For log generation and troubleshooting instructions for tools not listed here, see the docs for a specific solution in New Relic Instant Observability.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.54417,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "sections": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Some <em>New</em> <em>Relic</em> solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for <em>troubleshooting</em>, auditing, and diagnostics. Related docs: For general agent <em>troubleshooting</em>, see Not seeing data. Learn about <em>New</em> <em>Relic</em> Diagnostics: a utility"
      },
      "id": "61bfb6ef196a67b63eef0936"
    },
    {
      "sections": [
        "Install New Relic",
        "Install APM",
        "Install browser monitoring",
        "Install infrastructure monitoring",
        "Install mobile monitoring",
        "Install synthetic monitors",
        "Troubleshooting"
      ],
      "title": "Install New Relic ",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Install and configure"
      ],
      "external_id": "819ccfd8df22ff322271245ca0831bf53609b91f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/cross-product-functions/install-configure/install-new-relic/",
      "published_at": "2022-01-12T11:30:53Z",
      "updated_at": "2021-12-30T20:03:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you sign up for a New Relic account (it's free, forever!) and install any of our monitoring services, you can start working with your data. Get started quickly with our New Relic Instant Observability quickstarts. Alternatively, use our guided install. Here are links to instructions on how to install New Relic monitoring services: APM Browser Infrastructure Mobile Synthetic monitors Integrations for third-party telemetry services Data ingest APIs (metrics, events, logs, traces) Install APM C Go Java .NET For Windows .NET applications on IIS, use our guided install in New Relic One to get started with APM. If you're on an EU server, use our launcher for EU accounts instead. Node.js PHP Python Ruby Install browser monitoring See browser monitoring install. Install infrastructure monitoring Linux guided install for infrastructure monitoring Linux procedures for infrastructure monitoring Windows Kubernetes Prometheus On-host integrations (for services like NGINX, StatsD, MySQL, etc.) AWS cloud integrations Azure cloud integrations Google Cloud Platform Install mobile monitoring Android iOS Install synthetic monitors Synthetic monitoring doesn't require installation, except for its private minions feature. Troubleshooting You should start seeing your data in the New Relic UI after installing the agent, generating some traffic, and waiting a few minutes. If no data appears, follow our troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.5101,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>New</em> <em>Relic</em> ",
        "sections": "Install <em>New</em> <em>Relic</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "After you sign up for a <em>New</em> <em>Relic</em> account (it&#x27;s free, forever!) and install any of our monitoring services, you can start working with your data. Get started quickly with our <em>New</em> <em>Relic</em> Instant Observability quickstarts. Alternatively, <em>use</em> our guided install. Here are links to instructions on how"
      },
      "id": "61b8148ce7b9d22373ef3a8b"
    }
  ],
  "/docs/query-your-data/explore-query-data/browse-data/introduction-data-explorer": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.8161,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " can use the search feature at any time to search <em>data</em> across New Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> builder features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Use your charts",
        "Use open-source charting library",
        "Change the appearance of your chart",
        "Customize your charts",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2022-01-12T10:19:26Z",
      "updated_at": "2021-12-30T20:51:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Use open-source charting library You can use Nerdpacks to create your own custom visualizations. We have also teamed up with Formidable so you can use an open-source charting library, and quickly add unique \"victory charts\" to your New Relic One dashboards. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. Depending on the chart type, additional customization options are available. Format date and time Tables and billboards. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Line charts and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Line charts, area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Bar charts, pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.77899,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  <em>your</em> charts ",
        "sections": "Use <em>your</em> charts",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " in advanced (NRQL) mode or view <em>your</em> chart while using the <em>data</em> explorer to specify <em>data</em>, the <em>query</em> builder analyzes <em>your</em> <em>data</em> and applies a chart type that fits <em>your</em> <em>data</em>. For some queries, you&#x27;ll have several options of chart types to choose from. To change chart type, use the Chart type menu"
      },
      "id": "603ec29a196a67ef5da83d82"
    },
    {
      "sections": [
        "Use advanced (NRQL) mode to query data",
        "Compare advanced (NRQL) mode query with basic mode specification",
        "Important",
        "Notes about advanced (NRQL) mode"
      ],
      "title": "Use advanced (NRQL) mode to query data",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "9abf8d760b8e1dacd1a1b2b0556f8fa7f92080f5",
      "image": "https://docs.newrelic.com/static/7db331ae854429d71dc7112a168594a2/69538/inline-advanced-nrql_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/use-advanced-nrql-mode-query-data/",
      "published_at": "2022-01-12T05:02:46Z",
      "updated_at": "2021-12-30T20:50:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "While basic mode is an excellent choice for creating charts without needing to know how to write queries, working in advanced (NRQL) mode offers more power and additional features. Any data specified in basic mode can be written as an NRQL query in advanced (NRQL) mode. To see what your basic mode data specification looks like as an NRQL query, click the Advanced (NRQL) link from the basic page. Example of an advanced (NRQL) query. Compare advanced (NRQL) mode query with basic mode specification When you switch from basic mode to advanced (NRQL) mode, the query you see produces the exact same chart as the basic data specification. Important If your query was started using basic mode and if you make changes to that query using advanced (NRQL) mode, you cannot return to basic mode to edit that query. Any additional changes may only be made in advanced (NRQL) mode. Use this table to understand how basic mode specifications correspond to the equivalent NRQL query. To set this In basic mode, you enter ... In advanced (NRQL) mode, you write ... The event type, attribute, and function on that attribute View a chart with Transaction : Name : unique_count SELECT uniqueCount(name) FROM Transaction Narrowing your results to show only those transactions with a 404 page not found error Narrow results to httpResponseCode='404' WHERE httpResponseCode = '404' Enable a preliminary timeline view not needed in basic mode TIMESERIES — enables line chart type (required for initial chart view) To see a separate value for each application with a 404 error Facet by appName FACET `appName` To view the five applications with the most 404 errors Limit 5 — default value is 10 LIMIT 5 To view errors over the last three hours Select Last 3 hrs — converted to seconds in NRQL query SINCE 10800 seconds ago To enhance the results of sampling transaction data This feature is run automatically in basic mode EXTRAPOLATE Notes about advanced (NRQL) mode Queries written directly in NRQL can be more complex than queries written in basic mode. For example, to learn how to create widgets with multiple NRQL queries, watch this short video (3:40 minutes). The NRQL documentation contains both reference information and query examples. This table identifies some additional items to keep in mind. Item Description Prompts For each statement or function in your query, you can view a list of valid options, with tooltips. Example of a prompt in advanced (NRQL) mode. Events You can use multiple event types in an NRQL query. Attributes You can use multiple attributes per event type in an NRQL query. View previous queries Once you run an NRQL query, use the My recent queries dropdown to view up the last 1,000 queries that you ran. The dropdown has a search box to help you find your query. Working with basic mode and NRQL If you start creating a chart using basic mode and then switch to advanced (NRQL), be aware that if you make any changes to the NRQL query, you will lose those changes in basic mode. Autocompleter The query builder’s autocompleter will display events and attributes reported within the last 60 minutes. An example of this is a process that runs once a day, such as a standard system health check that kicks off every morning at 6:00am. If you attempt to query the event at 7:05am, the event and subsequent attributes will not be visible in the autocomplete dropdown. These events and attributes are still queryable by typing the exact string. Multi query When using the TIMESERIES clause you can run and compare up to 10 queries from different accounts. To use multi query, enter your first query with TIMESERIES and run it. Once the results are rendered, the Add another query button is activated and you can add another query.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.77457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use advanced (NRQL) mode to <em>query</em> <em>data</em>",
        "sections": "Use advanced (NRQL) mode to <em>query</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "While basic mode is an excellent choice for creating charts without needing to know how to write queries, working in advanced (NRQL) mode offers more power and additional features. Any <em>data</em> specified in basic mode can be written as an NRQL <em>query</em> in advanced (NRQL) mode. To see what <em>your</em> basic mode"
      },
      "id": "603ea876196a67cc1fa83dd5"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.4871,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> <em>dashboard</em>",
        "sections": "Organize <em>your</em> <em>dashboards</em> with pages",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One <em>dashboards</em> to create or manage <em>your</em> charts directly from the chart menu, customize <em>your</em> <em>dashboard</em>&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> <em>dashboard</em> and built <em>your</em> charts, use our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2022-01-12T05:59:40Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.91708,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Filter New Relic One <em>dashboards</em> by facets",
        "sections": "Filter New Relic One <em>dashboards</em> by facets",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " attributes to filter the current <em>dashboard</em> or a related, linked <em>dashboard</em>. By letting you quickly filter <em>your</em> <em>dashboards</em>, and link to pre-filtered <em>dashboards</em>, <em>your</em> <em>dashboards</em> are more interactive and easy to use. This feature is available when adding a new chart to a <em>dashboard</em> or when editing a chart"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Use your charts",
        "Use open-source charting library",
        "Change the appearance of your chart",
        "Customize your charts",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2022-01-12T10:19:26Z",
      "updated_at": "2021-12-30T20:51:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Use open-source charting library You can use Nerdpacks to create your own custom visualizations. We have also teamed up with Formidable so you can use an open-source charting library, and quickly add unique \"victory charts\" to your New Relic One dashboards. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. Depending on the chart type, additional customization options are available. Format date and time Tables and billboards. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Line charts and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Line charts, area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Bar charts, pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.77428,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  <em>your</em> charts ",
        "sections": "Use <em>your</em> charts",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Once you&#x27;ve created a chart, you can customize the appearance of it to best present the <em>data</em>. You can share a chart in different formats and add a chart to a new or existing <em>dashboard</em>. Use open-source charting library You can use Nerdpacks to create <em>your</em> own custom visualizations. We have also"
      },
      "id": "603ec29a196a67ef5da83d82"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/dashboards-api": [
    {
      "sections": [
        "Dashboard API migration: from Insights API to NerdGraph",
        "Why a new dashboards API?",
        "Get started with NerdGraph",
        "Operations mapping table",
        "Dashboard properties mapping table",
        "Widget properties mapping table",
        "Tip",
        "Visualizations mapping table",
        "Examples: from REST endpoints to GraphQL queries/mutations",
        "List (GET) -> entitySearch query",
        "List all dashboard entities you have access to",
        "List all dashboards by name",
        "List all dashboards by creator’s email",
        "List all dashboards by creator’s user id",
        "Show (GET) -> entity query",
        "Get dashboard info given its entity guid",
        "Create (POST) -> dashboardCreate mutation",
        "Create dashboard with two pages and two widgets per page",
        "Update (PUT) -> dashboardUpdate mutation",
        "Update previously created dashboard to 1 page and 1 widget per page",
        "Delete (DELETE) -> dashboardDelete mutation",
        "Delete previously created dashboard"
      ],
      "title": "Dashboard API migration: from Insights API to NerdGraph",
      "type": "docs",
      "tags": [
        "NerdGraph",
        "Dashboards",
        "Dashboards API"
      ],
      "external_id": "7a1a086f45b7aefccb5d2cd5f42b3a0f0dd526c2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/dashboards-api-migration-insights-api-nerdgraph/",
      "published_at": "2022-01-12T03:05:28Z",
      "updated_at": "2021-10-13T02:05:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Insights Dashboard API is deprecated, but you can use NerdGraph (our GraphQL API) to create and configure dashboards. If you're not migrating from the old Insights API, you can skip this doc and go to the new Dashboards API. Why a new dashboards API? Our Insights product, which was a way to query data and create charts and dashboards, has been deprecated and its set of features moved over to be a core part of the New Relic One platform. To learn more about this transition and new features, see the Insights to New Relic One migration guide. The Insights Dashboard API will be deprecated in July of 2021. Until then, if you're using the Insights Dashboard API, you should attempt to switch over to using NerdGraph. (The Insights query API will not be deprecated but NerdGraph is preferred.) Keep reading to learn how to get started with NerdGraph and learn about equivalent operations. Get started with NerdGraph NerdGraph is the preferred API for making NRQL queries of your New Relic data. Every user who uses NerdGraph needs their own user key. When using NerdGraph, it helps to understand that our dashboards are entities that report data from other entities, such as monitored apps, hosts and services. If you're new to NerdGraph and GraphQL, you may want to first read our Introduction to NerdGraph and some of Create dashboards with NerdGraph. The NerdGraph API explorer is located at api.newrelic.com/graphiql. Operations mapping table The table below maps every Insights API operation to the new dashboards API. Insights API operation NerdGraph API query/mutation Notes List (GET) entitySearch() View a paginated list of dashboards that match the filter. Show (GET) entity() View an existing dashboard given its entity guid. Create (POST) dashboardCreate() Create a new dashboard. Update (PUT) dashboardUpdate() Update an existing dashboard given its entity guid. Delete (DELETE) dashboardDelete() Delete an existing dashboard given its entity guid. Dashboard properties mapping table For more information about all the fields in the new dashboards GraphQL schema, have a look at NerdGraph's GraphiQL explorer. The table below maps dashboard properties from the Insights API to the new dashboards API. Insights API dashboard property NerdGraph API dashboard property Notes id guid ID of the New Relic entity the dashboard now represents createdAt createdAt updatedAt updatedAt title name editable permissions editable and visibility merged in the same concept visibility permissions editable and visibility merged in the same concept description description metadata - No need of versioning in GraphQL APIs icon - Not translated to New Relic One grid_column_count - 12 column dashboards by default in New Relic One filter - Not translated to New Relic One yet Widget properties mapping table For more information about all the fields in the new dashboards GraphQL schema, have a look at NerdGraph's GraphiQL explorer. The table below maps widget properties from the Insights API to the new dashboards API. Insights API dashboard property NerdGraph API dashboard property Notes id id account_id - Translated into widget configuration for those that require one visualization visualization presentation.title title presentation.drilldown_dashboard_id linkedEntities Used to link a widget to a dashboard for the facet linking feature presentation.notes - Not translated to New Relic One yet layout layout data configuration + rawConfiguration Tip To learn how to build every type of widget, see Create dashboard widgets. Visualizations mapping table We have simplified our widget visualizations by grouping the ones that were in fact the same but obtained through different types of queries. For instance, a line widget is plotted the same way regardless of the type of query: old line_chart vs. comparison_line_chart in Insights. Insights API visualization NerdGraph API visualization uniques_list viz.table single_event viz.table facet_table viz.table event_table viz.table faceted_area_chart viz.area predefined_metric_chart.application_breakdown viz.area predefined_metric_chart.scope_breakdown viz.area predefined_metric_chart.browser_breakdown viz.area predefined_metric_chart.background_breakdown viz.area predefined_metric_chart.solr_breakdown viz.area predefined_metric_chart.gc_runs_breakdown viz.area facet_bar_chart viz.bar billboard viz.billboard attribute_sheet viz.billboard billboard_comparison viz.billboard gauge viz.bullet event_feed viz.event-feed funnel viz.funnel heatmap viz.heatmap histogram viz.histogram inventory infra.inventory raw_json viz.json line_chart viz.line comparison_line_chart viz.line faceted_line_chart viz.line metric_line_chart viz.line markdown viz.markdown facet_pie_chart viz.pie Examples: from REST endpoints to GraphQL queries/mutations One of the main benefits of NerdGraph being a GraphQL-format API is that it provides a complete and understandable description of the APIs' data. By using the NerdGraph API explorer, you can discover GraphQL types and fields, along with a brief explanation. We want to facilitate your migration from the Insights API to the new New Relic One dashboards API. Find below some examples that illustrate how the old REST endpoints map to the new GraphQL queries or mutations. List (GET) -> entitySearch query Dashboards in New Relic One embrace the concept of entity. They are now another entity in New Relic’s entity ecosystem. Try it out using the NerdGraph GraphiQL explorer. List all dashboard entities you have access to { actor { entitySearch(queryBuilder: {type: DASHBOARD}) { results { entities { ... on DashboardEntityOutline { guid name accountId } } } } } } Copy List all dashboards by name { actor { entitySearch(queryBuilder: {name: \"My dashboard\"}) { results { entities { ... on DashboardEntityOutline { guid name accountId } } } } } } Copy List all dashboards by creator’s email { actor { entitySearch(queryBuilder: {type: DASHBOARD, tags: {key: \"createdBy\", value: \"email@domain.com\"}}) { results { entities { ... on DashboardEntityOutline { guid name accountId } } } } } } Copy List all dashboards by creator’s user id { actor { entitySearch(query: \"type ='DASHBOARD' and ownerId = '2357322'\") { results { entities { ... on DashboardEntityOutline { guid name accountId } } } } } } Copy Show (GET) -> entity query In order to get information on a dashboard, all you need is to provide its unique entity identifier or entity guid. Then you can access all the dashboard properties that you are interested in by adding them in the GraphQL query. Try it out using the NerdGraph GraphiQL explorer. Get dashboard info given its entity guid { actor { entity(guid: \"MY_DASHBOARD_GUID\") { ... on DashboardEntity { guid accountId name createdAt updatedAt permissions description owner { email userId } pages { guid name createdAt updatedAt description owner { email userId } widgets { id visualization { id } title layout { row column height width } rawConfiguration linkedEntities { guid } } } } } } } Copy Create (POST) -> dashboardCreate mutation Operations that mutate the state of the system are mutations in GraphQL APIs. You can create a dashboard by providing the required input for the dashboardCreate mutation. Although GraphQL APIs aim to be self-explanatory, Nerdgraph docs can help you with some information about the fields, like the doc about how to build dashboard widgets. Try it out using the NerdGraph GraphiQL explorer. Create dashboard with two pages and two widgets per page mutation { dashboardCreate(accountId: 1, dashboard: { name: \"My awesome dashboard\", permissions: PUBLIC_READ_WRITE, pages: [{ name: \"My first page\", widgets: [{ visualization: { id: \"viz.markdown\" }, title: \"My markdown widget\", layout: { row: 1, column: 1, width: 4, height: 3 }, rawConfiguration: { text: \"#My markdown\" } }, { visualization: { id: \"viz.line\" }, title: \"My line widget\", layout: { row: 1, column: 5, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ accountId: 1, query: \"SELECT count(*) FROM Transaction FACET appName TIMESERIES\" }] } }] }, { name: \"My second page\", widgets: [{ visualization: { id: \"viz.billboard\" }, title: \"My billboard widget with thresholds\", layout: { row: 1, column: 1, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ accountId: 1, query: \"SELECT count(*) FROM Transaction\" }], thresholds: [{ alertSeverity: WARNING, value: 650 }, { alertSeverity: CRITICAL, value: 1500 }] } }, { visualization: { id: \"viz.table\" }, title: \"My table widget\", layout: { row: 1, column: 5, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ query: \"SELECT * FROM Transaction\", accountId: 1 }] } }] }] }) { errors { description type } entityResult { guid accountId name createdAt updatedAt permissions description owner { email userId } pages { guid name createdAt updatedAt description owner { email userId } widgets { id visualization { id } title layout { row column height width } rawConfiguration linkedEntities { guid } } } } } } Copy Update (PUT) -> dashboardUpdate mutation The dashboardUpdate mutation allows you to update an existing dashboard by providing the existing dashboard guid and the new configuration. Similarly to creating a dashboard, the mutation tries to be self-explanatory, but you can look up the doc about how to build dashboard widgets. Try it out using the NerdGraph GraphiQL explorer. Update previously created dashboard to 1 page and 1 widget per page mutation { dashboardUpdate(guid: \"MY_DASHBOARD_GUID\" dashboard: { name: \"My awesome dashboard\", permissions: PUBLIC_READ_WRITE, pages: [{ name: \"My first page\", widgets: [{ visualization: { id: \"viz.line\" }, title: \"My line widget\", layout: { row: 1, column: 1, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ accountId: 1, query: \"SELECT count(*) FROM Transaction FACET appName TIMESERIES\" }] } }] }, { name: \"My second page\", widgets: [{ visualization: { id: \"viz.table\" }, title: \"My table widget\", layout: { row: 1, column: 1, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ query: \"SELECT * FROM Transaction\", accountId: 1 }] } }] }] }) { errors { description type } entityResult { guid accountId name createdAt updatedAt permissions description owner { email userId } pages { guid name createdAt updatedAt description owner { email userId } widgets { id visualization { id } title layout { row column height width } rawConfiguration linkedEntities { guid } } } } } } Copy Delete (DELETE) -> dashboardDelete mutation The dashboardDelete mutation allows you to delete an existing dashboard by providing its entity guid. Try it out using the NerdGraph GraphiQL explorer. Delete previously created dashboard mutation { dashboardDelete(guid:\"MY_DASHBOARD_GUID\") { status errors { type description } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.02286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Dashboard</em> <em>API</em> migration: from Insights <em>API</em> to NerdGraph",
        "sections": "<em>Dashboard</em> <em>API</em> migration: from Insights <em>API</em> to NerdGraph",
        "tags": "<em>Dashboards</em> <em>API</em>",
        "body": "The Insights <em>Dashboard</em> <em>API</em> is deprecated, but you can use NerdGraph (our GraphQL <em>API</em>) to create and configure <em>dashboards</em>. If you&#x27;re not migrating from the old Insights <em>API</em>, you can skip this doc and go to the new <em>Dashboards</em> <em>API</em>. Why a new <em>dashboards</em> <em>API</em>? Our Insights product, which was a way"
      },
      "id": "60441442e7b9d2020b5799b9"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 53.98854,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage your <em>dashboard</em>",
        "sections": "Organize your <em>dashboards</em> with pages",
        "tags": "<em>Dashboards</em>",
        "body": "Access any of your New Relic One <em>dashboards</em> to create or manage your charts directly from the chart menu, customize your <em>dashboard</em>&#x27;s layout, adjust display modes, or export your data. Once you have customized your <em>dashboard</em> and built your charts, use our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Insights Dashboard API",
        "End of life notice",
        "Requirements",
        "Overview",
        "Example use cases",
        "Account and data security",
        "Use the API Explorer",
        "View Dashboard API video",
        "Use API endpoints",
        "Dashboard API schema",
        "Important",
        "Caution",
        "Example dashboard schema",
        "Dashboard data definitions",
        "Widget data definitions",
        "Supported visualizations"
      ],
      "title": "Insights Dashboard API",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Insights API"
      ],
      "external_id": "71a0104d88a3a8859513802e853850d8b0456606",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/insights-apis/insights-dashboard-api/",
      "published_at": "2022-01-12T05:38:28Z",
      "updated_at": "2021-08-02T03:52:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Do not use the Insights Dashboards API. Instead, use the New Relic One Dashboards API with NerdGraph, our GraphQL API. End of life notice The Insights Dashboard API reaches end of life in 2021. As of July 28, 2021, the CREATE and UPDATE endpoints are not available. As of August 30, 2021, the GET and DELETE endpoints are not available. To make the transition from the Insights Dashboard API to the New Relic One Dashboards API, see our migration guide. For more information, see the NerdGraph dashboards tutorial and Explorers Hub post. Requirements If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Overview The Insights Dashboard API allows you to list, create, read, update, and delete new or existing dashboards. New Relic's API Explorer includes the cURL request format, available parameters, response status codes, and JSON response structure for available API calls. Example use cases The Insights Dashboard API is a flexible solution for many different use cases. Here are a few examples of how you can leverage the Dashboard API to solve problems: Automatically create dashboards for new teams or services pre-populated with standard organization metrics and charts. Use the API to view dashboard schemas, and save them in a central repository for source control and backups. Create widget and dashboard templates to allow teams to self-service. Account and data security The Dashboard API includes safeguards to help ensure account and data security. Requirements Comments User key and permissions Required: This API requires a user key. You cannot use your account-level REST API key to manage dashboards. Cross-account widgets You can view cross-account widgets on a dashboard by using the Insights or New Relic One dashboards UI. However, the ability to view cross-account widgets when using the Dashboard API has these restrictions: To view the list of widgets on a specific dashboard with the Dashboard API, you must use the SHOW endpoint. To view a widget in the API payload, the widget's account ID must be the same as the account ID for the payload. If the account ID is not the same, the widget's details will not be listed. Instead, the widget's payload will show: \"visualization\": \"inaccessible\" Copy Use the API Explorer To view the Dashboard API options in the API Explorer: Log in to your New Relic account. Go to rpm.newrelic.com/api/explore. From the API Explorer's Select an account and key dropdown, select a user key. Select Dashboards, then select the API function. To use API functions with existing dashboards, include the dashboard id. To find the dashboard id, select the LIST endpoint, and apply filtering options. View Dashboard API video Follow along with this step-by-step tutorial to learn how to find your API keys, create new dashboards, view and update existing dashboards via the REST API. For a step-by-step guide to using the New Relic API Explorer to manage Insights dashboards, watch this video (approximately 6 minutes). Or, go directly to the full online course about New Relic APIs. Use API endpoints The API supports the following functions for Insights dashboards only. The API does not support these functions for data apps (collections of linked dashboards). API endpoints Comments CREATE POST /v2/dashboards Create a new dashboard. The API permits a maximum of 300 widgets when creating or updating a dashboard. Attempting to POST more than 300 widgets will produce an error. To add more widgets to the dashboard, use the Insights UI. UPDATE PUT /v2/dashboards/:id: Update an existing dashboard for the dashboard id. The API permits a maximum of 300 widgets when creating or updating a dashboard. Attempting to PUT more than 300 widgets will produce an error. To add more or edit existing widgets on the dashboard, use the Insights UI. SHOW GET /v2/dashboards/:id: View an existing dashboard and all accessible widgets for the dashboard id. To help ensure data security, the SHOW function returns only the dashboard widgets that the user has permission to view. If a dashboard includes widgets that the user is not authorized to view, the API will provide a placeholder with the visualization field set to inaccessible. LIST GET /v2/dashboards?page=:page:&per_page=:count: View a paginated list of dashboards. The list shows filterable dashboard metadata only; no widgets will appear in the list. Search options include: filter[title] as substring search filter[category] (all / favorites / mine} filter[created_after] as ISO date filter[created_before] as ISO date filter[updated_after] as ISO date filter[updated_before] as ISO date Sort options include: name recently_viewed last_edited If no sort option is provided, results will be ordered by id. Pagination options include the page and per_page fields. The per_page field controls the number of results per page with a default and maximum of 100 results. The response will include a pagination Link header, which provides next page and last page links. DELETE DELETE /v2/dashboards/:id: Delete an existing dashboard indicated by the dashboard id. Dashboard API schema JSON is the only supported format. When using API functions, be sure to add .json to the end of the request URL, as shown in the API Explorer. Important Widgets have a size limit of 3x3 (height and width may not exceed 3). Caution The Dashboard API 3-column restriction also applies to the dashboards you upload to New Relic One dashboards. If you update a dashboard with a different layout using the API, the uploaded dashboard will revert to the 3-column configuration. Example dashboard schema { \"dashboard\": { \"metadata\": { \"version\": 1 }, \"title\": \"API Widget Sample\", \"icon\":\"none|archive|bar-chart|line-chart|bullseye|user|usd|money|thumbs-up|thumbs-down|cloud|bell|bullhorn|comments-o|envelope|globe|shopping-cart|sitemap|clock-o|crosshairs|rocket|users|mobile|tablet|adjust|dashboard|flag|flask|road|bolt|cog|leaf|magic|puzzle-piece|bug|fire|legal|trophy|pie-chart|sliders|paper-plane|life-ring|heart\", \"grid_column_count\": 3|12, \"visibility\": \"owner|all\", \"editable\": \"read_only|editable_by_owner|editable_by_all\", \"filter\": { \"event_types\": [ \"Transaction\" ], \"attributes\": [ \"appName\" ] }, \"widgets\": [ { \"visualization\": \"billboard|gauge|billboard_comparison\", \"account_id\": 12345, \"data\": [ { \"nrql\": \"SELECT count(*) from Transaction since 5 minutes ago\" } ], \"presentation\": { \"title\": \"Threshold Event Chart\", \"notes\": null, \"threshold\": { \"red\": 18000000, \"yellow\": 8000000 } }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 1, \"column\": 1 } }, { \"visualization\": \"facet_bar_chart|faceted_line_chart|facet_pie_chart|facet_table|faceted_area_chart|heatmap\", \"account_id\": 12345, \"data\": [ { \"nrql\": \"SELECT count(*) from Transaction since 5 minutes ago facet appName\" } ], \"presentation\": { \"title\": \"Facet Chart\", \"notes\": null, \"drilldown_dashboard_id\": 64 }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 1, \"column\": 2 } }, { \"visualization\": \"attribute_sheet|single_event|histogram|funnel|raw_json|event_feed|event_table|uniques_list|line_chart|comparison_line_chart\", \"account_id\": 12345, \"data\": [ { \"nrql\": \"SELECT latest(appName), latest(duration) from Transaction since 5 minutes ago\" } ], \"presentation\": { \"title\": \"Simple Event Chart\", \"notes\": null }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 1, \"column\": 3 } }, { \"visualization\": \"markdown\", \"account_id\": 12345, \"data\": [ { \"source\": \"# Dashboard Note\\n\\n[link goes here](https://www.newrelic.com)\" } ], \"presentation\": { \"title\": \"\", \"notes\": null }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 2, \"column\": 1 } }, { \"visualization\": \"metric_line_chart\", \"account_id\": 12345, \"data\": [ { \"duration\": 1800000, \"end_time\": null, \"entity_ids\": [ 238575 ], \"metrics\": [ { \"name\": \"Apdex\", \"units\": null, \"scope\": \"\", \"values\": [ \"score\" ] } ], \"order_by\": \"score\", \"limit\": 10 } ], \"presentation\": { \"title\": \"Metric Line Chart\", \"notes\": null }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 2, \"column\": 2 } }, ] } } Copy Dashboard data definitions For examples of these data elements being used in a JSON call, see the Dashboard API schema. Dashboard data element Description metadata Object Specifies the version of the dashboard schema. The version must be 1. icon String Name of an icon from the Insights icon library. grid_column_count Integer Specifies the number of columns in the grid layout. title String User-supplied title of the dashboard. filter Object Specifies configuration of the smart filter on the dashboard. visibility String Specifies who can view the dashboard in the Insights UI and the API. editable String Specifies who can edit the dashboard in the Insights UI and the API. widgets Array Array of widget data element objects. Widget data definitions For examples of these data elements being used in a JSON call, see the Dashboard API schema. Widget data element Description visualization String What sort of visualization to place in the widget; for example, billboard, line_chart, area chart, etc. data Array Array of objects with chart-specific information needed to query necessary data. Currently only one data object is supported. account_id Long Source account to fetch data from, if not the current account. presentation Object Object with chart title and notes, plus chart-specific customization. layout Object Object with column, row, width, and height to determine chart layout in the dashboard. Supported visualizations The Dashboard API supports: event_table line_chart facet_table facet_bar_chart facet_pie_chart billboard faceted_area_chart faceted_line_chart event_table comparison_line_chart heatmap histogram billboard_comparison attribute_sheet funnel gauge json list Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 50.763393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Insights <em>Dashboard</em> <em>API</em>",
        "sections": "Insights <em>Dashboard</em> <em>API</em>",
        "tags": "Insights <em>API</em>",
        "body": "Do not use the Insights <em>Dashboards</em> <em>API</em>. Instead, use the New Relic One <em>Dashboards</em> <em>API</em> with NerdGraph, our GraphQL <em>API</em>. End of life notice The Insights <em>Dashboard</em> <em>API</em> reaches end of life in 2021. As of July 28, 2021, the CREATE and UPDATE endpoints are not available. As of August 30, 2021, the GET"
      },
      "id": "609f9c8664441fc63fd2a1f9"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/dashboards-charts-import-export-data": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.3093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> <em>dashboard</em>",
        "sections": "Manage <em>your</em> <em>charts</em> <em>and</em> markdown content",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One <em>dashboards</em> to create or manage <em>your</em> <em>charts</em> directly from the <em>chart</em> menu, customize <em>your</em> <em>dashboard</em>&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> <em>dashboard</em> and built <em>your</em> <em>charts</em>, use our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Use your charts",
        "Use open-source charting library",
        "Change the appearance of your chart",
        "Customize your charts",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2022-01-12T10:19:26Z",
      "updated_at": "2021-12-30T20:51:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Use open-source charting library You can use Nerdpacks to create your own custom visualizations. We have also teamed up with Formidable so you can use an open-source charting library, and quickly add unique \"victory charts\" to your New Relic One dashboards. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. Depending on the chart type, additional customization options are available. Format date and time Tables and billboards. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Line charts and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Line charts, area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Bar charts, pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 290.72394,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  <em>your</em> <em>charts</em> ",
        "sections": "Use <em>your</em> <em>charts</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " teamed up with Formidable so you can use an open-source charting library, and quickly add unique &quot;victory <em>charts</em>&quot; to <em>your</em> New Relic One <em>dashboards</em>. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of <em>your</em> <em>chart</em> When you run <em>your</em> <em>query</em>"
      },
      "id": "603ec29a196a67ef5da83d82"
    },
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2022-01-12T05:59:40Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.06058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Filter New Relic One <em>dashboards</em> by facets",
        "sections": "Filter New Relic One <em>dashboards</em> by facets",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " on an existing <em>dashboard</em>. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One <em>dashboards</em>. Will not work on a standalone <em>chart</em> in the <em>query</em> builder. NRQL <em>query</em> must contain a FACET clause. Available only for bar <em>charts</em>, heat maps"
      },
      "id": "60445d1e28ccbc23082c60af"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/explore-public-api-performance-dashboard": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.487,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> <em>dashboard</em>",
        "sections": "Organize <em>your</em> <em>dashboards</em> with pages",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One <em>dashboards</em> to create or manage <em>your</em> charts directly from the chart menu, customize <em>your</em> <em>dashboard</em>&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> <em>dashboard</em> and built <em>your</em> charts, use our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2022-01-12T05:59:40Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.91705,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Filter New Relic One <em>dashboards</em> by facets",
        "sections": "Filter New Relic One <em>dashboards</em> by facets",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " attributes to filter the current <em>dashboard</em> or a related, linked <em>dashboard</em>. By letting you quickly filter <em>your</em> <em>dashboards</em>, and link to pre-filtered <em>dashboards</em>, <em>your</em> <em>dashboards</em> are more interactive and easy to use. This feature is available when adding a new chart to a <em>dashboard</em> or when editing a chart"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Use your charts",
        "Use open-source charting library",
        "Change the appearance of your chart",
        "Customize your charts",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2022-01-12T10:19:26Z",
      "updated_at": "2021-12-30T20:51:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Use open-source charting library You can use Nerdpacks to create your own custom visualizations. We have also teamed up with Formidable so you can use an open-source charting library, and quickly add unique \"victory charts\" to your New Relic One dashboards. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. Depending on the chart type, additional customization options are available. Format date and time Tables and billboards. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Line charts and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Line charts, area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Bar charts, pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.77419,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  <em>your</em> charts ",
        "sections": "Use <em>your</em> charts",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Once you&#x27;ve created a chart, you can customize the appearance of it to best present the <em>data</em>. You can share a chart in different formats and add a chart to a new or existing <em>dashboard</em>. Use open-source charting library You can use Nerdpacks to create <em>your</em> own custom visualizations. We have also"
      },
      "id": "603ec29a196a67ef5da83d82"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.487,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> <em>dashboard</em>",
        "sections": "Organize <em>your</em> <em>dashboards</em> with pages",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One <em>dashboards</em> to create or manage <em>your</em> charts directly from the chart menu, customize <em>your</em> <em>dashboard</em>&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> <em>dashboard</em> and built <em>your</em> charts, use our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Use your charts",
        "Use open-source charting library",
        "Change the appearance of your chart",
        "Customize your charts",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2022-01-12T10:19:26Z",
      "updated_at": "2021-12-30T20:51:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Use open-source charting library You can use Nerdpacks to create your own custom visualizations. We have also teamed up with Formidable so you can use an open-source charting library, and quickly add unique \"victory charts\" to your New Relic One dashboards. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. Depending on the chart type, additional customization options are available. Format date and time Tables and billboards. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Line charts and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Line charts, area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Bar charts, pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.77419,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  <em>your</em> charts ",
        "sections": "Use <em>your</em> charts",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Once you&#x27;ve created a chart, you can customize the appearance of it to best present the <em>data</em>. You can share a chart in different formats and add a chart to a new or existing <em>dashboard</em>. Use open-source charting library You can use Nerdpacks to create <em>your</em> own custom visualizations. We have also"
      },
      "id": "603ec29a196a67ef5da83d82"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2022-01-12T10:11:09Z",
      "updated_at": "2021-11-25T05:12:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full platform user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Delete. Editing: To edit a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Edit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.57812,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "sections": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a <em>dashboard</em>. This gives you great flexibility around what you display on <em>dashboards</em>, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.48694,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> <em>dashboard</em>",
        "sections": "Organize <em>your</em> <em>dashboards</em> with pages",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One <em>dashboards</em> to create or manage <em>your</em> charts directly from the chart menu, customize <em>your</em> <em>dashboard</em>&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> <em>dashboard</em> and built <em>your</em> charts, use our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2022-01-12T05:59:40Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.91705,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Filter New Relic One <em>dashboards</em> by facets",
        "sections": "Filter New Relic One <em>dashboards</em> by facets",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " attributes to filter the current <em>dashboard</em> or a related, linked <em>dashboard</em>. By letting you quickly filter <em>your</em> <em>dashboards</em>, and link to pre-filtered <em>dashboards</em>, <em>your</em> <em>dashboards</em> are more interactive and easy to use. This feature is available when adding a new chart to a <em>dashboard</em> or when editing a chart"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Use your charts",
        "Use open-source charting library",
        "Change the appearance of your chart",
        "Customize your charts",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2022-01-12T10:19:26Z",
      "updated_at": "2021-12-30T20:51:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Use open-source charting library You can use Nerdpacks to create your own custom visualizations. We have also teamed up with Formidable so you can use an open-source charting library, and quickly add unique \"victory charts\" to your New Relic One dashboards. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. Depending on the chart type, additional customization options are available. Format date and time Tables and billboards. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Line charts and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Line charts, area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Bar charts, pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.77414,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  <em>your</em> charts ",
        "sections": "Use <em>your</em> charts",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Once you&#x27;ve created a chart, you can customize the appearance of it to best present the <em>data</em>. You can share a chart in different formats and add a chart to a new or existing <em>dashboard</em>. Use open-source charting library You can use Nerdpacks to create <em>your</em> own custom visualizations. We have also"
      },
      "id": "603ec29a196a67ef5da83d82"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard": [
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2022-01-12T05:59:40Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.91705,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Filter New Relic One <em>dashboards</em> by facets",
        "sections": "Filter New Relic One <em>dashboards</em> by facets",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " attributes to filter the current <em>dashboard</em> or a related, linked <em>dashboard</em>. By letting you quickly filter <em>your</em> <em>dashboards</em>, and link to pre-filtered <em>dashboards</em>, <em>your</em> <em>dashboards</em> are more interactive and easy to use. This feature is available when adding a new chart to a <em>dashboard</em> or when editing a chart"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Use your charts",
        "Use open-source charting library",
        "Change the appearance of your chart",
        "Customize your charts",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2022-01-12T10:19:26Z",
      "updated_at": "2021-12-30T20:51:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Use open-source charting library You can use Nerdpacks to create your own custom visualizations. We have also teamed up with Formidable so you can use an open-source charting library, and quickly add unique \"victory charts\" to your New Relic One dashboards. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. Depending on the chart type, additional customization options are available. Format date and time Tables and billboards. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Line charts and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Line charts, area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Bar charts, pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.77414,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  <em>your</em> charts ",
        "sections": "Use <em>your</em> charts",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Once you&#x27;ve created a chart, you can customize the appearance of it to best present the <em>data</em>. You can share a chart in different formats and add a chart to a new or existing <em>dashboard</em>. Use open-source charting library You can use Nerdpacks to create <em>your</em> own custom visualizations. We have also"
      },
      "id": "603ec29a196a67ef5da83d82"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2022-01-12T10:11:09Z",
      "updated_at": "2021-11-25T05:12:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full platform user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Delete. Editing: To edit a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Edit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.57812,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "sections": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a <em>dashboard</em>. This gives you great flexibility around what you display on <em>dashboards</em>, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/new-relic-global-performance-data-sets": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.48688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> <em>dashboard</em>",
        "sections": "Organize <em>your</em> <em>dashboards</em> with pages",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One <em>dashboards</em> to create or manage <em>your</em> charts directly from the chart menu, customize <em>your</em> <em>dashboard</em>&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> <em>dashboard</em> and built <em>your</em> charts, use our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2022-01-12T05:59:40Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.91704,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Filter New Relic One <em>dashboards</em> by facets",
        "sections": "Filter New Relic One <em>dashboards</em> by facets",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " attributes to filter the current <em>dashboard</em> or a related, linked <em>dashboard</em>. By letting you quickly filter <em>your</em> <em>dashboards</em>, and link to pre-filtered <em>dashboards</em>, <em>your</em> <em>dashboards</em> are more interactive and easy to use. This feature is available when adding a new chart to a <em>dashboard</em> or when editing a chart"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Use your charts",
        "Use open-source charting library",
        "Change the appearance of your chart",
        "Customize your charts",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2022-01-12T10:19:26Z",
      "updated_at": "2021-12-30T20:51:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Use open-source charting library You can use Nerdpacks to create your own custom visualizations. We have also teamed up with Formidable so you can use an open-source charting library, and quickly add unique \"victory charts\" to your New Relic One dashboards. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. Depending on the chart type, additional customization options are available. Format date and time Tables and billboards. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Line charts and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Line charts, area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Bar charts, pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.7741,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  <em>your</em> charts ",
        "sections": "Use <em>your</em> charts",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Once you&#x27;ve created a chart, you can customize the appearance of it to best present the <em>data</em>. You can share a chart in different formats and add a chart to a new or existing <em>dashboard</em>. Use open-source charting library You can use Nerdpacks to create <em>your</em> own custom visualizations. We have also"
      },
      "id": "603ec29a196a67ef5da83d82"
    }
  ],
  "/docs/query-your-data/explore-query-data/get-started/introduction-querying-new-relic-data": [
    {
      "sections": [
        "Understand and manage data ingest",
        "Data ingestion UI",
        "Data ingestion sources",
        "Understand where data is coming from",
        "How ingested data is broken down",
        "Set alerts for data use",
        "Adjust your data ingest",
        "Drop unwanted data",
        "Disable agents and integrations",
        "Adjust APM data ingest",
        "Adjust infrastructure data ingest",
        "Adjust log data ingest"
      ],
      "title": "Understand and manage data ingest",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f1c46558041c874a2076f781fa975a21105f60e4",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/manage-data-coming-new-relic/",
      "published_at": "2022-01-12T06:18:34Z",
      "updated_at": "2022-01-08T03:50:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you report data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing model, you're charged for the number of bytes written to our database that are above and beyond the free per-month amount. If you're trying to estimate the cost of your data ingest, see Calculate data ingest. Data ingestion UI To learn how to easily analyze the data your account is ingesting, watch this short video (3:18 minutes). The Data ingestion tab is located in the Data management UI. The Data ingestion UI shows your ingest rates for the time period specified by the time picker in the upper right. The page shows your daily average GBs, and the total GBs for that time range. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively manage your data ingest in various ways. To see the underlying NRQL query that is used to generate the chart, click View query. From the account dropdown, select Manage your data, and then select Data ingestion. For how to get more details about ingested data, see Get ingest details. Data ingestion sources The data ingestion UI chart shows you a high level breakdown of your billable data usage. The table below explains those sources. In this table, \"usage metric group\" refers to the value of that source's usageMetric attribute value on the NrConsumption event. Data sources Description Metrics In the data ingestion chart, Metrics is a combination of two types of metrics: metric timeslice data and dimensional metrics. Usage metric group: MetricsBytes. Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM This includes APM events, like Transaction and TransactionError. Usage metric group: ApmEventsBytes. Infrastructure Includes several categories of infrastructure monitoring events, described below. Infrastructure host data. Usage metric group:InfraHostBytes. Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data. Infrastructure process data stored in ProcessSample. Usage metric group: InfraProcessBytes. Data related to each process running on the hosts running the infrastructure agent. This feature is turned off by default. For more information, see Process metrics. Infrastructure integrations. Usage metric group: InfraIntegrationBytes. Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created. Usage metric group: LoggingBytes. Log records are stored on the Log data type by default. Additional custom data partitions will create new data types, which are always prefixed with Log_ and are counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our log blobs docs. Default Custom events. Usage metric group: CustomEventsBytes Mobile events Mobile events, including the general Mobile event, MobileRequestError, MobileBreadcrumb, MobileSession, MobileHandledException, MobileCrash. Usage metric group: MobileEventsBytes. Tracing Usage metric group: TracingBytes. This includes the Span data type and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser events Browser events, including the namespaces of Browser, Browser:EventLog, Browser:JSErrors, and PcvPerf (PageView timing). Usage metric group: BrowserEventsBytes. Lambda AWS Lambda events. Usage metric group: ServerlessBytes. Understand where data is coming from You can inspect your data ingest to gain more information about your ingest health. From the data ingestion UI page, you can analyze your usage in more detail. Spending some time understanding your ingested data and where it comes from and how it changes over time can be valuable. You'll know your ingest baselines, and you'll be able to more easily spot anomalies, like ingest spikes, and understand their source. On the data ingestion chart, time is on the X axis and the bands representing data sources are located along the Y axis. Click on a data source band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the data source band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the time range. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. For more about creating more detailed queries: Learn some NRQL basics. See some example usage-related queries. How ingested data is broken down Some of the usage data in this UI can vary depending on your account. This information is intended to help you understand how we're working with your ingest data: The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a one hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use For how to set alerts that will notify you when you're reaching data ingest levels you don't want to cross, see Query and alert on usage data. For example, you might set an alert on logs, which can accumulate quickly in an active system. Adjust your data ingest Here are some ideas for managing your data: Drop unwanted data On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. For how to drop log data, see Drop log data. Disable agents and integrations If you have agents or integrations that you don't need at all, you can uninstall/delete those tools. For instructions, see the specific docs for that tool. Adjust APM data ingest Options for adjusting APM data include: Configure the sampling rate for transaction events. Set appropriate Apdex scores, for example, for frequency of traces. Optimize custom instrumentation and/or custom metrics. Adjust infrastructure data ingest Options for adjusting infrastructure data include: Adjust sampling rate for network, storage, and system events. Disable process metrics. Adjust polling intervals: Polling for cloud integrations. For on-host integrations: edit the configuration file for a specific integration. Control the reporting of specific attributes. Manage Kubernetes events integration. Adjust log data ingest Options for adjusting log data ingest include: Use the log forwarder to filter log events on the sending side. Drop log data, either via the UI or with NerdGraph.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.69815,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> <em>manage</em> <em>data</em> <em>ingest</em>",
        "sections": "<em>Understand</em> <em>and</em> <em>manage</em> <em>data</em> <em>ingest</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively <em>manage</em> your <em>data</em> <em>ingest</em> in various ways. To see the underlying NRQL query that is used to generate"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Report metrics via the Metric API",
        "Quick start: Send metric data",
        "Endpoint URL",
        "Tip",
        "HTTP request headers",
        "HTTP request body",
        "Structure",
        "JSON payload creating two metrics",
        "Required key-value pairs",
        "JSON payload with three metric types",
        "Share attributes across metrics with common",
        "Example of common attributes",
        "Response validation and status codes",
        "Missing data with 202 response",
        "Status codes"
      ],
      "title": "Report metrics via the Metric API",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "ad2f24e880ef009b256115c0db440b4bb4de9c7c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/report-metrics-metric-api/",
      "published_at": "2022-01-12T02:25:45Z",
      "updated_at": "2022-01-08T12:41:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Metric API to send custom metrics to the New Relic platform. This document includes a quick start to send your first custom metric, plus detailed information on how to format and send your metric data. Quick start: Send metric data We report the metric types count, gauge, and summary. For more information on metrics see our documentation. Metric data is submitted to New Relic through an HTTP POST request. Each request is composed of one or more metric data points, which consist of a metric name, a timestamp, and a value. Follow this example to send your first metric data points to New Relic: Get the license key for the account you want to report data to. Insert the license key into the following JSON, and then send the JSON to our endpoint. Update the timestamp with a valid epoch timestamp. fix(Metric API): Remove unnecessary indentation This example creates a single metric data point for a metric named memory.heap, but you can create additional attributes or data points by specifying metric types or adding optional common blocks. curl -vvv -k -H \"Content-Type: application/json\" \\ -H \"Api-Key: NEW_RELIC_LICENSE_KEY\" \\ -X POST https://metric-api.newrelic.com/metric/v1 \\ --data '[{ \"metrics\":[{ \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":2.3, \"timestamp\":CURRENT_TIME, \"attributes\":{\"host.name\":\"dev.server.com\"} }] }]' Copy The metric should be available in New Relic in a few seconds. You can query the data from any NRQL interface using this query: FROM Metric SELECT max(memory.heap) TIMESERIES Copy For more on where data shows up, see Find Metric API data. Endpoint URL Use an HTTP POST when sending metric data to the metric API endpoint: https://metric-api.newrelic.com/metric/v1 Copy Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. HTTP request headers Include the following HTTP request headers with the POST request. You can send some parameters as query parameters instead of request headers. Header Send as a query parameter? Details Content-Type No Required. Must be application/json. Content-Length No Required (usually set automatically by the HTTP client). The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes Required. A license key for the account you want to report data to. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if GZIP. The value must be GZIP or Identity. If no value is present, then Identity is assumed. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. HTTP request body The body of the HTTP POST request must be in JSON format. The following describes the requirements and recommendations for the JSON payload. The payload must be encoded as UTF-8. Structure The JSON payload uses this structure: The JSON payload is an array of maps. Each map must contain a metrics key whose value is an array containing one or more metric data points. A metric data point is identified by a name, value, and timestamp along with an optional set of attributes. JSON payload creating two metrics This example payload creates two metrics. service.errors.all is a count metric with three attributes and service.memory is a gauge metric with two attributes. [ { \"metrics\": [ { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 15, \"timestamp\": [CURRENT_TIME](#optional-map-attributes), \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"host.name\": \"dev.server.com\", \"service.name\": \"foo\" } }, { \"name\": \"service.memory\", \"type\": \"gauge\", \"value\": 2.7, \"timestamp\": CURRENT_TIME, \"attributes\": { \"host.name\": \"dev.server.com\", \"app.name\": \"foo\" } } ] } ] Copy Required key-value pairs Each metric data point map in the metrics array uses the following key-value structure: Key Description name string Required. The name of the metric. The value must be less than 255 characters. value number or map Required. The value varies depending on the metric type. For gauge and count the value should be a single number. For summary, the value should be a map with key-value pairs specifying the count, sum, min, and max. timestamp long Required. The metric's start time in Unix time. Defaults to the current time in UTC timezone. This field also support seconds, microseconds, and nanoseconds. However, the data will be converted to milliseconds for storage and query. Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. interval.ms positive long Required for count and summary metric types. The length of the time window. type Recommended. This should be one of the supported metric types. If you do not specify a type, then this will default to a gauge. attributes strings, JSON numbers, or booleans Recommended. A map of key value pairs associated with this specific metric. Values can be strings, JSON numbers, or booleans. Keys are case-sensitive and must be less than 255 characters. JSON payload with three metric types Here's an example payload containing one metric data point for each metric type: [ { \"metrics\": [ { \"name\": \"cache.misses\", \"type\": \"count\", \"value\": 15, \"timestamp\": [CURRENT_TIME](#optional-map-attributes), \"interval.ms\": 10000, \"attributes\": { \"cache.name\": \"myCache\", \"host.name\": \"dev.server.com\" } }, { \"name\": \"temperature\", \"type\": \"gauge\", \"value\": 15, \"timestamp\": CURRENT_TIME, \"attributes\": { \"city\": \"Portland\", \"state\": \"Oregon\" } }, { \"name\": \"service.response.duration\", \"type\": \"summary\", \"value\": { \"count\": 5, \"sum\": 0.004382655, \"min\": 0.0005093, \"max\": 0.001708826 }, \"interval.ms\": 10000, \"timestamp\": CURRENT_TIME, \"attributes\": { \"host.name\": \"dev.server.com\", \"app.name\": \"foo\" } } ] } ] Copy Share attributes across metrics with common If you want to include a set of attributes on multiple metrics (and not add the same attributes for each metric), you can use the common block. This is an optional map that specifies information that applies to all associated metric data points. Values in the common section will be overridden if the same key exists on a metric data point. The block can include: Attribute Description timestamp long The metric's start time in Unix time. This defaults to the current time in the UTC timezone. This field also supports seconds, microseconds, and nanoseconds. However, the data will be converted to milliseconds for storage and later querying. interval.ms positive long Required for count and summary.The length of the time window. attributes strings, JSON numbers, or booleans A map of key-value pairs associated with this specific metric. Values can be strings, JSON numbers, or booleans. Example of common attributes In the following example payload, three metrics are sent. All three metrics share app.name and host.name attributes, specified in the common block. Each metric also has a unique value for another attribute, server.response.statuscode. [ { \"common\" : { \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"app.name\": \"foo\", \"host.name\": \"dev.server.com\" } }, \"metrics\": [ { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 9, \"attributes\": { \"service.response.statuscode\": \"400\" } }, { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 4, \"attributes\": { \"service.response.statuscode\": \"500\" } }, { \"name\": \"service.response.duration\", \"type\": \"summary\", \"value\": { \"count\": 5, \"sum\": 0.004382655, \"min\": 0.0005093, \"max\": 0.001708826 }, \"attributes\": { \"service.response.statuscode\": \"200\" } } ] } ] Copy Response validation and status codes The Metric API returns a 202 response code for successful requests. When your data is accepted, an HTTP 202 response code is returned with a response structure like this: HTTP/1.1 202 Accepted Content-Type: application/json; charset=UTF-8 Content-Length: 52 Access-Control-Allow-Methods: GET, POST, PUT, HEAD, OPTIONS Access-Control-Allow-Credentials: true Access-Control-Allow-Origin: * Connection: keep-alive {\"requestId\":\"f0e7bfff-001a-b000-0000-01682bcf4565\"} Copy Missing data with 202 response A 202 code indicates the API did receive your data, and that the data passed basic validation checks. Normally, your data will be available for querying within a few seconds. However, New Relic runs additional validation asynchronously after receiving your data. If you receive a 202 response but can't find your metric, this indicates that New Relic found an error during this asynchronous validation. You can find these errors by querying NrIntegrationError events in the account associated with the Insert API key you used. The requestId for each request will be tagged on the NrIntegrationError event. For more information, see Troubleshoot an NRIntegrationError event. Status codes The Metric API can return the following HTTP status codes: Status code Definition 202 Data accepted. 400 Structure of the request is invalid. 403 Authentication failure. 404 The request path is incorrect. 405 Used a request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. Payloads must be under 1MB (10^6 bytes). 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.72754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Quick start: Send metric <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Use the Metric API to send custom metrics to the New Relic platform. This document includes a quick start to send your first custom metric, plus detailed information on how to format and send your metric <em>data</em>. Quick start: Send metric <em>data</em> We report the metric types count, gauge, and summary"
      },
      "id": "6107859064441f8baf47abd9"
    },
    {
      "sections": [
        "New Relic's data management hub",
        "Important",
        "Where to find the data management hub",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "New Relic's data management hub",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "999fa6106dd47250e9a5d822aa2f92b6ea088c78",
      "image": "https://docs.newrelic.com/static/8a553ce9643c8513be3200af5d924250/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/manage-your-data/",
      "published_at": "2022-01-12T06:19:11Z",
      "updated_at": "2022-01-08T02:14:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. We also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Data management hub: from the account dropdown in the top right of the UI, select Manage your data. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important Not yet a New Relic customer? Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Where to find the data management hub To find the data management UI: From one.newrelic.com click the account dropdown, and the click Manage your data. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. Our data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Important If you're on our original product-based pricing model, you'll see your data ingest, retention, and limits in the data management hub. But on the original pricing plan, you're not billed on data ingest. Not sure which plan you're on? See Overview of pricing and user model. Cost management Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data is uncompressed, decorated with queryable attributes, and evaluated. Elements are dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Want to estimate your data ingest and cost? See Calculate data ingest. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. One solution for improving performance is to drop data to reduce the amount of data stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about adjusting data ingest. Learn about dropping data. For dropping logs, see Drop log data. Learn how to adjust how long data is retained.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.97324,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic&#x27;s <em>data</em> <em>management</em> hub",
        "sections": "New Relic&#x27;s <em>data</em> <em>management</em> hub",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " for cost, performance, and in some cases, compliance reasons. Our <em>data</em> management hub provides the tools you need to <em>understand</em> and control where your <em>data</em> is coming from, and adjust what’s stored and for how long. Important If you&#x27;re on our original product-based pricing model, you&#x27;ll see your <em>data</em> <em>ingest</em>"
      },
      "id": "603e96ff28ccbcf8bceba796"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/introduction-query-builder": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 295.78552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " can use the search feature at any time to search <em>data</em> across New Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> <em>builder</em> features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Use advanced (NRQL) mode to query data",
        "Compare advanced (NRQL) mode query with basic mode specification",
        "Important",
        "Notes about advanced (NRQL) mode"
      ],
      "title": "Use advanced (NRQL) mode to query data",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "9abf8d760b8e1dacd1a1b2b0556f8fa7f92080f5",
      "image": "https://docs.newrelic.com/static/7db331ae854429d71dc7112a168594a2/69538/inline-advanced-nrql_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/use-advanced-nrql-mode-query-data/",
      "published_at": "2022-01-12T05:02:46Z",
      "updated_at": "2021-12-30T20:50:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "While basic mode is an excellent choice for creating charts without needing to know how to write queries, working in advanced (NRQL) mode offers more power and additional features. Any data specified in basic mode can be written as an NRQL query in advanced (NRQL) mode. To see what your basic mode data specification looks like as an NRQL query, click the Advanced (NRQL) link from the basic page. Example of an advanced (NRQL) query. Compare advanced (NRQL) mode query with basic mode specification When you switch from basic mode to advanced (NRQL) mode, the query you see produces the exact same chart as the basic data specification. Important If your query was started using basic mode and if you make changes to that query using advanced (NRQL) mode, you cannot return to basic mode to edit that query. Any additional changes may only be made in advanced (NRQL) mode. Use this table to understand how basic mode specifications correspond to the equivalent NRQL query. To set this In basic mode, you enter ... In advanced (NRQL) mode, you write ... The event type, attribute, and function on that attribute View a chart with Transaction : Name : unique_count SELECT uniqueCount(name) FROM Transaction Narrowing your results to show only those transactions with a 404 page not found error Narrow results to httpResponseCode='404' WHERE httpResponseCode = '404' Enable a preliminary timeline view not needed in basic mode TIMESERIES — enables line chart type (required for initial chart view) To see a separate value for each application with a 404 error Facet by appName FACET `appName` To view the five applications with the most 404 errors Limit 5 — default value is 10 LIMIT 5 To view errors over the last three hours Select Last 3 hrs — converted to seconds in NRQL query SINCE 10800 seconds ago To enhance the results of sampling transaction data This feature is run automatically in basic mode EXTRAPOLATE Notes about advanced (NRQL) mode Queries written directly in NRQL can be more complex than queries written in basic mode. For example, to learn how to create widgets with multiple NRQL queries, watch this short video (3:40 minutes). The NRQL documentation contains both reference information and query examples. This table identifies some additional items to keep in mind. Item Description Prompts For each statement or function in your query, you can view a list of valid options, with tooltips. Example of a prompt in advanced (NRQL) mode. Events You can use multiple event types in an NRQL query. Attributes You can use multiple attributes per event type in an NRQL query. View previous queries Once you run an NRQL query, use the My recent queries dropdown to view up the last 1,000 queries that you ran. The dropdown has a search box to help you find your query. Working with basic mode and NRQL If you start creating a chart using basic mode and then switch to advanced (NRQL), be aware that if you make any changes to the NRQL query, you will lose those changes in basic mode. Autocompleter The query builder’s autocompleter will display events and attributes reported within the last 60 minutes. An example of this is a process that runs once a day, such as a standard system health check that kicks off every morning at 6:00am. If you attempt to query the event at 7:05am, the event and subsequent attributes will not be visible in the autocomplete dropdown. These events and attributes are still queryable by typing the exact string. Multi query When using the TIMESERIES clause you can run and compare up to 10 queries from different accounts. To use multi query, enter your first query with TIMESERIES and run it. Once the results are rendered, the Add another query button is activated and you can add another query.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.0937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use advanced (NRQL) mode to <em>query</em> <em>data</em>",
        "sections": "Use advanced (NRQL) mode to <em>query</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "While basic mode is an excellent choice for creating charts without needing to know how to write queries, working in advanced (NRQL) mode offers more power and additional features. Any <em>data</em> specified in basic mode can be written as an NRQL <em>query</em> in advanced (NRQL) mode. To see what <em>your</em> basic mode"
      },
      "id": "603ea876196a67cc1fa83dd5"
    },
    {
      "sections": [
        "Use your charts",
        "Use open-source charting library",
        "Change the appearance of your chart",
        "Customize your charts",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2022-01-12T10:19:26Z",
      "updated_at": "2021-12-30T20:51:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Use open-source charting library You can use Nerdpacks to create your own custom visualizations. We have also teamed up with Formidable so you can use an open-source charting library, and quickly add unique \"victory charts\" to your New Relic One dashboards. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. Depending on the chart type, additional customization options are available. Format date and time Tables and billboards. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Line charts and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Line charts, area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Bar charts, pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.53625,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  <em>your</em> charts ",
        "sections": "Use <em>your</em> charts",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " in advanced (NRQL) mode or view <em>your</em> chart while using the <em>data</em> explorer to specify <em>data</em>, the <em>query</em> <em>builder</em> analyzes <em>your</em> <em>data</em> and applies a chart type that fits <em>your</em> <em>data</em>. For some queries, you&#x27;ll have several options of chart types to choose from. To change chart type, use the Chart type menu"
      },
      "id": "603ec29a196a67ef5da83d82"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/nrql-console": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 322.914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " can use the search feature at any time to search <em>data</em> across New Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> <em>builder</em> features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Use advanced (NRQL) mode to query data",
        "Compare advanced (NRQL) mode query with basic mode specification",
        "Important",
        "Notes about advanced (NRQL) mode"
      ],
      "title": "Use advanced (NRQL) mode to query data",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "9abf8d760b8e1dacd1a1b2b0556f8fa7f92080f5",
      "image": "https://docs.newrelic.com/static/7db331ae854429d71dc7112a168594a2/69538/inline-advanced-nrql_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/use-advanced-nrql-mode-query-data/",
      "published_at": "2022-01-12T05:02:46Z",
      "updated_at": "2021-12-30T20:50:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "While basic mode is an excellent choice for creating charts without needing to know how to write queries, working in advanced (NRQL) mode offers more power and additional features. Any data specified in basic mode can be written as an NRQL query in advanced (NRQL) mode. To see what your basic mode data specification looks like as an NRQL query, click the Advanced (NRQL) link from the basic page. Example of an advanced (NRQL) query. Compare advanced (NRQL) mode query with basic mode specification When you switch from basic mode to advanced (NRQL) mode, the query you see produces the exact same chart as the basic data specification. Important If your query was started using basic mode and if you make changes to that query using advanced (NRQL) mode, you cannot return to basic mode to edit that query. Any additional changes may only be made in advanced (NRQL) mode. Use this table to understand how basic mode specifications correspond to the equivalent NRQL query. To set this In basic mode, you enter ... In advanced (NRQL) mode, you write ... The event type, attribute, and function on that attribute View a chart with Transaction : Name : unique_count SELECT uniqueCount(name) FROM Transaction Narrowing your results to show only those transactions with a 404 page not found error Narrow results to httpResponseCode='404' WHERE httpResponseCode = '404' Enable a preliminary timeline view not needed in basic mode TIMESERIES — enables line chart type (required for initial chart view) To see a separate value for each application with a 404 error Facet by appName FACET `appName` To view the five applications with the most 404 errors Limit 5 — default value is 10 LIMIT 5 To view errors over the last three hours Select Last 3 hrs — converted to seconds in NRQL query SINCE 10800 seconds ago To enhance the results of sampling transaction data This feature is run automatically in basic mode EXTRAPOLATE Notes about advanced (NRQL) mode Queries written directly in NRQL can be more complex than queries written in basic mode. For example, to learn how to create widgets with multiple NRQL queries, watch this short video (3:40 minutes). The NRQL documentation contains both reference information and query examples. This table identifies some additional items to keep in mind. Item Description Prompts For each statement or function in your query, you can view a list of valid options, with tooltips. Example of a prompt in advanced (NRQL) mode. Events You can use multiple event types in an NRQL query. Attributes You can use multiple attributes per event type in an NRQL query. View previous queries Once you run an NRQL query, use the My recent queries dropdown to view up the last 1,000 queries that you ran. The dropdown has a search box to help you find your query. Working with basic mode and NRQL If you start creating a chart using basic mode and then switch to advanced (NRQL), be aware that if you make any changes to the NRQL query, you will lose those changes in basic mode. Autocompleter The query builder’s autocompleter will display events and attributes reported within the last 60 minutes. An example of this is a process that runs once a day, such as a standard system health check that kicks off every morning at 6:00am. If you attempt to query the event at 7:05am, the event and subsequent attributes will not be visible in the autocomplete dropdown. These events and attributes are still queryable by typing the exact string. Multi query When using the TIMESERIES clause you can run and compare up to 10 queries from different accounts. To use multi query, enter your first query with TIMESERIES and run it. Once the results are rendered, the Add another query button is activated and you can add another query.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.0937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use advanced (<em>NRQL</em>) mode to <em>query</em> <em>data</em>",
        "sections": "Use advanced (<em>NRQL</em>) mode to <em>query</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "While basic mode is an excellent choice for creating charts without needing to know how to write queries, working in advanced (<em>NRQL</em>) mode offers more power and additional features. Any <em>data</em> specified in basic mode can be written as an <em>NRQL</em> <em>query</em> in advanced (<em>NRQL</em>) mode. To see what <em>your</em> basic mode"
      },
      "id": "603ea876196a67cc1fa83dd5"
    },
    {
      "sections": [
        "Use your charts",
        "Use open-source charting library",
        "Change the appearance of your chart",
        "Customize your charts",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2022-01-12T10:19:26Z",
      "updated_at": "2021-12-30T20:51:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Use open-source charting library You can use Nerdpacks to create your own custom visualizations. We have also teamed up with Formidable so you can use an open-source charting library, and quickly add unique \"victory charts\" to your New Relic One dashboards. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. Depending on the chart type, additional customization options are available. Format date and time Tables and billboards. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Line charts and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Line charts, area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Bar charts, pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.53625,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  <em>your</em> charts ",
        "sections": "Use <em>your</em> charts",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " in advanced (<em>NRQL</em>) mode or view <em>your</em> chart while using the <em>data</em> explorer to specify <em>data</em>, the <em>query</em> <em>builder</em> analyzes <em>your</em> <em>data</em> and applies a chart type that fits <em>your</em> <em>data</em>. For some queries, you&#x27;ll have several options of chart types to choose from. To change chart type, use the Chart type menu"
      },
      "id": "603ec29a196a67ef5da83d82"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/query-builder-basic-mode": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 295.78552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " can use the search feature at any time to search <em>data</em> across New Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> <em>builder</em> features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Use advanced (NRQL) mode to query data",
        "Compare advanced (NRQL) mode query with basic mode specification",
        "Important",
        "Notes about advanced (NRQL) mode"
      ],
      "title": "Use advanced (NRQL) mode to query data",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "9abf8d760b8e1dacd1a1b2b0556f8fa7f92080f5",
      "image": "https://docs.newrelic.com/static/7db331ae854429d71dc7112a168594a2/69538/inline-advanced-nrql_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/use-advanced-nrql-mode-query-data/",
      "published_at": "2022-01-12T05:02:46Z",
      "updated_at": "2021-12-30T20:50:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "While basic mode is an excellent choice for creating charts without needing to know how to write queries, working in advanced (NRQL) mode offers more power and additional features. Any data specified in basic mode can be written as an NRQL query in advanced (NRQL) mode. To see what your basic mode data specification looks like as an NRQL query, click the Advanced (NRQL) link from the basic page. Example of an advanced (NRQL) query. Compare advanced (NRQL) mode query with basic mode specification When you switch from basic mode to advanced (NRQL) mode, the query you see produces the exact same chart as the basic data specification. Important If your query was started using basic mode and if you make changes to that query using advanced (NRQL) mode, you cannot return to basic mode to edit that query. Any additional changes may only be made in advanced (NRQL) mode. Use this table to understand how basic mode specifications correspond to the equivalent NRQL query. To set this In basic mode, you enter ... In advanced (NRQL) mode, you write ... The event type, attribute, and function on that attribute View a chart with Transaction : Name : unique_count SELECT uniqueCount(name) FROM Transaction Narrowing your results to show only those transactions with a 404 page not found error Narrow results to httpResponseCode='404' WHERE httpResponseCode = '404' Enable a preliminary timeline view not needed in basic mode TIMESERIES — enables line chart type (required for initial chart view) To see a separate value for each application with a 404 error Facet by appName FACET `appName` To view the five applications with the most 404 errors Limit 5 — default value is 10 LIMIT 5 To view errors over the last three hours Select Last 3 hrs — converted to seconds in NRQL query SINCE 10800 seconds ago To enhance the results of sampling transaction data This feature is run automatically in basic mode EXTRAPOLATE Notes about advanced (NRQL) mode Queries written directly in NRQL can be more complex than queries written in basic mode. For example, to learn how to create widgets with multiple NRQL queries, watch this short video (3:40 minutes). The NRQL documentation contains both reference information and query examples. This table identifies some additional items to keep in mind. Item Description Prompts For each statement or function in your query, you can view a list of valid options, with tooltips. Example of a prompt in advanced (NRQL) mode. Events You can use multiple event types in an NRQL query. Attributes You can use multiple attributes per event type in an NRQL query. View previous queries Once you run an NRQL query, use the My recent queries dropdown to view up the last 1,000 queries that you ran. The dropdown has a search box to help you find your query. Working with basic mode and NRQL If you start creating a chart using basic mode and then switch to advanced (NRQL), be aware that if you make any changes to the NRQL query, you will lose those changes in basic mode. Autocompleter The query builder’s autocompleter will display events and attributes reported within the last 60 minutes. An example of this is a process that runs once a day, such as a standard system health check that kicks off every morning at 6:00am. If you attempt to query the event at 7:05am, the event and subsequent attributes will not be visible in the autocomplete dropdown. These events and attributes are still queryable by typing the exact string. Multi query When using the TIMESERIES clause you can run and compare up to 10 queries from different accounts. To use multi query, enter your first query with TIMESERIES and run it. Once the results are rendered, the Add another query button is activated and you can add another query.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.0937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use advanced (NRQL) mode to <em>query</em> <em>data</em>",
        "sections": "Use advanced (NRQL) mode to <em>query</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "While basic mode is an excellent choice for creating charts without needing to know how to write queries, working in advanced (NRQL) mode offers more power and additional features. Any <em>data</em> specified in basic mode can be written as an NRQL <em>query</em> in advanced (NRQL) mode. To see what <em>your</em> basic mode"
      },
      "id": "603ea876196a67cc1fa83dd5"
    },
    {
      "sections": [
        "Use your charts",
        "Use open-source charting library",
        "Change the appearance of your chart",
        "Customize your charts",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2022-01-12T10:19:26Z",
      "updated_at": "2021-12-30T20:51:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Use open-source charting library You can use Nerdpacks to create your own custom visualizations. We have also teamed up with Formidable so you can use an open-source charting library, and quickly add unique \"victory charts\" to your New Relic One dashboards. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. Depending on the chart type, additional customization options are available. Format date and time Tables and billboards. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Line charts and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Line charts, area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Bar charts, pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.53625,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  <em>your</em> charts ",
        "sections": "Use <em>your</em> charts",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " in advanced (NRQL) mode or view <em>your</em> chart while using the <em>data</em> explorer to specify <em>data</em>, the <em>query</em> <em>builder</em> analyzes <em>your</em> <em>data</em> and applies a chart type that fits <em>your</em> <em>data</em>. For some queries, you&#x27;ll have several options of chart types to choose from. To change chart type, use the Chart type menu"
      },
      "id": "603ec29a196a67ef5da83d82"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/use-advanced-nrql-mode-query-data": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 295.78546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " can use the search feature at any time to search <em>data</em> across New Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> <em>builder</em> features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Use your charts",
        "Use open-source charting library",
        "Change the appearance of your chart",
        "Customize your charts",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2022-01-12T10:19:26Z",
      "updated_at": "2021-12-30T20:51:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Use open-source charting library You can use Nerdpacks to create your own custom visualizations. We have also teamed up with Formidable so you can use an open-source charting library, and quickly add unique \"victory charts\" to your New Relic One dashboards. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. Depending on the chart type, additional customization options are available. Format date and time Tables and billboards. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Line charts and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Line charts, area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Bar charts, pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.53622,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  <em>your</em> charts ",
        "sections": "Use <em>your</em> charts",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " in advanced (NRQL) mode or view <em>your</em> chart while using the <em>data</em> explorer to specify <em>data</em>, the <em>query</em> <em>builder</em> analyzes <em>your</em> <em>data</em> and applies a chart type that fits <em>your</em> <em>data</em>. For some queries, you&#x27;ll have several options of chart types to choose from. To change chart type, use the Chart type menu"
      },
      "id": "603ec29a196a67ef5da83d82"
    },
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2022-01-12T05:59:40Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.62671,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the <em>query</em> <em>builder</em>. NRQL <em>query</em> must contain a FACET clause. Available only for bar charts, heat maps"
      },
      "id": "60445d1e28ccbc23082c60af"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/use-advanced-promql-style-mode-query-data": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 295.78546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " can use the search feature at any time to search <em>data</em> across New Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> <em>builder</em> features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Use advanced (NRQL) mode to query data",
        "Compare advanced (NRQL) mode query with basic mode specification",
        "Important",
        "Notes about advanced (NRQL) mode"
      ],
      "title": "Use advanced (NRQL) mode to query data",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "9abf8d760b8e1dacd1a1b2b0556f8fa7f92080f5",
      "image": "https://docs.newrelic.com/static/7db331ae854429d71dc7112a168594a2/69538/inline-advanced-nrql_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/use-advanced-nrql-mode-query-data/",
      "published_at": "2022-01-12T05:02:46Z",
      "updated_at": "2021-12-30T20:50:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "While basic mode is an excellent choice for creating charts without needing to know how to write queries, working in advanced (NRQL) mode offers more power and additional features. Any data specified in basic mode can be written as an NRQL query in advanced (NRQL) mode. To see what your basic mode data specification looks like as an NRQL query, click the Advanced (NRQL) link from the basic page. Example of an advanced (NRQL) query. Compare advanced (NRQL) mode query with basic mode specification When you switch from basic mode to advanced (NRQL) mode, the query you see produces the exact same chart as the basic data specification. Important If your query was started using basic mode and if you make changes to that query using advanced (NRQL) mode, you cannot return to basic mode to edit that query. Any additional changes may only be made in advanced (NRQL) mode. Use this table to understand how basic mode specifications correspond to the equivalent NRQL query. To set this In basic mode, you enter ... In advanced (NRQL) mode, you write ... The event type, attribute, and function on that attribute View a chart with Transaction : Name : unique_count SELECT uniqueCount(name) FROM Transaction Narrowing your results to show only those transactions with a 404 page not found error Narrow results to httpResponseCode='404' WHERE httpResponseCode = '404' Enable a preliminary timeline view not needed in basic mode TIMESERIES — enables line chart type (required for initial chart view) To see a separate value for each application with a 404 error Facet by appName FACET `appName` To view the five applications with the most 404 errors Limit 5 — default value is 10 LIMIT 5 To view errors over the last three hours Select Last 3 hrs — converted to seconds in NRQL query SINCE 10800 seconds ago To enhance the results of sampling transaction data This feature is run automatically in basic mode EXTRAPOLATE Notes about advanced (NRQL) mode Queries written directly in NRQL can be more complex than queries written in basic mode. For example, to learn how to create widgets with multiple NRQL queries, watch this short video (3:40 minutes). The NRQL documentation contains both reference information and query examples. This table identifies some additional items to keep in mind. Item Description Prompts For each statement or function in your query, you can view a list of valid options, with tooltips. Example of a prompt in advanced (NRQL) mode. Events You can use multiple event types in an NRQL query. Attributes You can use multiple attributes per event type in an NRQL query. View previous queries Once you run an NRQL query, use the My recent queries dropdown to view up the last 1,000 queries that you ran. The dropdown has a search box to help you find your query. Working with basic mode and NRQL If you start creating a chart using basic mode and then switch to advanced (NRQL), be aware that if you make any changes to the NRQL query, you will lose those changes in basic mode. Autocompleter The query builder’s autocompleter will display events and attributes reported within the last 60 minutes. An example of this is a process that runs once a day, such as a standard system health check that kicks off every morning at 6:00am. If you attempt to query the event at 7:05am, the event and subsequent attributes will not be visible in the autocomplete dropdown. These events and attributes are still queryable by typing the exact string. Multi query When using the TIMESERIES clause you can run and compare up to 10 queries from different accounts. To use multi query, enter your first query with TIMESERIES and run it. Once the results are rendered, the Add another query button is activated and you can add another query.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.09363,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use advanced (NRQL) mode to <em>query</em> <em>data</em>",
        "sections": "Use advanced (NRQL) mode to <em>query</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "While basic mode is an excellent choice for creating charts without needing to know how to write queries, working in advanced (NRQL) mode offers more power and additional features. Any <em>data</em> specified in basic mode can be written as an NRQL <em>query</em> in advanced (NRQL) mode. To see what <em>your</em> basic mode"
      },
      "id": "603ea876196a67cc1fa83dd5"
    },
    {
      "sections": [
        "Use your charts",
        "Use open-source charting library",
        "Change the appearance of your chart",
        "Customize your charts",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2022-01-12T10:19:26Z",
      "updated_at": "2021-12-30T20:51:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Use open-source charting library You can use Nerdpacks to create your own custom visualizations. We have also teamed up with Formidable so you can use an open-source charting library, and quickly add unique \"victory charts\" to your New Relic One dashboards. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. Depending on the chart type, additional customization options are available. Format date and time Tables and billboards. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Line charts and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Line charts, area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Bar charts, pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.53622,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  <em>your</em> charts ",
        "sections": "Use <em>your</em> charts",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " in advanced (NRQL) mode or view <em>your</em> chart while using the <em>data</em> explorer to specify <em>data</em>, the <em>query</em> <em>builder</em> analyzes <em>your</em> <em>data</em> and applies a chart type that fits <em>your</em> <em>data</em>. For some queries, you&#x27;ll have several options of chart types to choose from. To change chart type, use the Chart type menu"
      },
      "id": "603ec29a196a67ef5da83d82"
    }
  ],
  "/docs/query-your-data/explore-query-data/use-charts/chart-refresh-rates": [
    {
      "sections": [
        "Real time streaming",
        "Why it matters",
        "Agent version to automatically enable",
        "Caution",
        "Query real time streaming data",
        "Create real time streaming charts"
      ],
      "title": "Real time streaming",
      "type": "docs",
      "tags": [
        "Agents",
        "Manage APM agents",
        "Agent data"
      ],
      "external_id": "47ea348bf8d620acfae2fbf48452147553d329ba",
      "image": "https://docs.newrelic.com/static/bfccf48174daa734a2359d7c15354222/c1b63/RTS-small.png",
      "url": "https://docs.newrelic.com/docs/apm/agents/manage-apm-agents/agent-data/real-time-streaming/",
      "published_at": "2022-01-12T18:11:08Z",
      "updated_at": "2021-10-23T19:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With real time streaming, your APM event data is sent to New Relic every five seconds. You can query and visualize your data for transactions, errors, and custom events in near real time. The smaller payloads result in faster chart refreshes and faster queries of data that is the most important to you. No configuration is needed to take advantage of real time streaming. All you need to do is ensure your APM agent version is up to date. Why it matters Real time streaming doesn't result in more events being sent. The combination of more frequent posts, with a smaller number of events per post, results in approximately the same number of events per minute as there would be without real time streaming. The following image shows a comparison between data sent to New Relic with and without real time streaming. Note that 10,000 is an example number of events; some agents have lower default limits. The overall limits on how many events can be sent per minute haven't changed. Also, non-event data (spans, traces, and metrics) are unaffected; they're still sent every minute. Use real time streaming to quickly understand the impact when something has changed, such as deploying a new app version. Examine key performance indicators (throughput, error rates, charting, etc.) in near real time. Respond quickly to failure conditions and anomalies. Get the most out of New Relic One dashboards. Reduce mean time to detection with APM events reporting every five seconds. Agent version to automatically enable To enable real time streaming, update to the latest APM agent. You don't need to configure anything to enable real time streaming; it will automatically report faster! Real time streaming is supported by all APM agents. Here are the minimum agent versions: C SDK: v1.3.0 or higher Go: v2.8.0 or higher Java: v5.5.0 or higher .NET: v8.23.107.0 or higher Node.js: v5.13.0 or higher PHP: v9.5.0.252 or higher Python: v5.2.0.127 or higher Ruby: v6.7.0.359 or higher Caution If Transaction event reporting is disabled, this can affect some UI elements throughout New Relic. You may see some empty charts on some UI pages that rely on this data. Query real time streaming data When building charts, include the following in your NRQL query: NRQL clause Comments SINCE 5 minutes ago Be sure to add a SINCE 5 minutes ago clause to your NRQL query in order to take advantage of the 5 second chart refresh interval. This is because the chart's refresh interval is based on the time window. TIMESERIES bucket To set the refresh interval for time series charts, you can also specify the bucket size as an optional argument to the TIMESERIES clause. For example, SINCE 30 minutes ago TIMESERIES 5 seconds will display a 30 minute window at a 5 second resolution. You can have a maximum of 366 buckets. Create real time streaming charts You can visualize the results of your NRQL query in New Relic One: Go to one.newrelic.com, and at the top of the page, select Query your data. Use the data explorer to start building a chart. Select the advanced (NRQL) mode to refine your query. In your NRQL query, adjust the SINCE and TIMESERIES clauses to take advantage of the 5 second refresh intervals.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.9973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Create real time streaming <em>charts</em>",
        "body": " <em>refresh</em> interval. This is because the <em>chart</em>&#x27;s <em>refresh</em> interval is based on the time window. TIMESERIES bucket To set the <em>refresh</em> interval for time series charts, you can also specify the bucket size as an optional argument to the TIMESERIES clause. For example, SINCE 30 minutes ago TIMESERIES 5"
      },
      "id": "617e63f228ccbc68a6800a0a"
    },
    {
      "sections": [
        "Understand and manage data ingest",
        "Data ingestion UI",
        "Data ingestion sources",
        "Understand where data is coming from",
        "How ingested data is broken down",
        "Set alerts for data use",
        "Adjust your data ingest",
        "Drop unwanted data",
        "Disable agents and integrations",
        "Adjust APM data ingest",
        "Adjust infrastructure data ingest",
        "Adjust log data ingest"
      ],
      "title": "Understand and manage data ingest",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f1c46558041c874a2076f781fa975a21105f60e4",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/manage-data-coming-new-relic/",
      "published_at": "2022-01-12T06:18:34Z",
      "updated_at": "2022-01-08T03:50:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you report data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing model, you're charged for the number of bytes written to our database that are above and beyond the free per-month amount. If you're trying to estimate the cost of your data ingest, see Calculate data ingest. Data ingestion UI To learn how to easily analyze the data your account is ingesting, watch this short video (3:18 minutes). The Data ingestion tab is located in the Data management UI. The Data ingestion UI shows your ingest rates for the time period specified by the time picker in the upper right. The page shows your daily average GBs, and the total GBs for that time range. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively manage your data ingest in various ways. To see the underlying NRQL query that is used to generate the chart, click View query. From the account dropdown, select Manage your data, and then select Data ingestion. For how to get more details about ingested data, see Get ingest details. Data ingestion sources The data ingestion UI chart shows you a high level breakdown of your billable data usage. The table below explains those sources. In this table, \"usage metric group\" refers to the value of that source's usageMetric attribute value on the NrConsumption event. Data sources Description Metrics In the data ingestion chart, Metrics is a combination of two types of metrics: metric timeslice data and dimensional metrics. Usage metric group: MetricsBytes. Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM This includes APM events, like Transaction and TransactionError. Usage metric group: ApmEventsBytes. Infrastructure Includes several categories of infrastructure monitoring events, described below. Infrastructure host data. Usage metric group:InfraHostBytes. Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data. Infrastructure process data stored in ProcessSample. Usage metric group: InfraProcessBytes. Data related to each process running on the hosts running the infrastructure agent. This feature is turned off by default. For more information, see Process metrics. Infrastructure integrations. Usage metric group: InfraIntegrationBytes. Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created. Usage metric group: LoggingBytes. Log records are stored on the Log data type by default. Additional custom data partitions will create new data types, which are always prefixed with Log_ and are counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our log blobs docs. Default Custom events. Usage metric group: CustomEventsBytes Mobile events Mobile events, including the general Mobile event, MobileRequestError, MobileBreadcrumb, MobileSession, MobileHandledException, MobileCrash. Usage metric group: MobileEventsBytes. Tracing Usage metric group: TracingBytes. This includes the Span data type and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser events Browser events, including the namespaces of Browser, Browser:EventLog, Browser:JSErrors, and PcvPerf (PageView timing). Usage metric group: BrowserEventsBytes. Lambda AWS Lambda events. Usage metric group: ServerlessBytes. Understand where data is coming from You can inspect your data ingest to gain more information about your ingest health. From the data ingestion UI page, you can analyze your usage in more detail. Spending some time understanding your ingested data and where it comes from and how it changes over time can be valuable. You'll know your ingest baselines, and you'll be able to more easily spot anomalies, like ingest spikes, and understand their source. On the data ingestion chart, time is on the X axis and the bands representing data sources are located along the Y axis. Click on a data source band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the data source band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the time range. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. For more about creating more detailed queries: Learn some NRQL basics. See some example usage-related queries. How ingested data is broken down Some of the usage data in this UI can vary depending on your account. This information is intended to help you understand how we're working with your ingest data: The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a one hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use For how to set alerts that will notify you when you're reaching data ingest levels you don't want to cross, see Query and alert on usage data. For example, you might set an alert on logs, which can accumulate quickly in an active system. Adjust your data ingest Here are some ideas for managing your data: Drop unwanted data On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. For how to drop log data, see Drop log data. Disable agents and integrations If you have agents or integrations that you don't need at all, you can uninstall/delete those tools. For instructions, see the specific docs for that tool. Adjust APM data ingest Options for adjusting APM data include: Configure the sampling rate for transaction events. Set appropriate Apdex scores, for example, for frequency of traces. Optimize custom instrumentation and/or custom metrics. Adjust infrastructure data ingest Options for adjusting infrastructure data include: Adjust sampling rate for network, storage, and system events. Disable process metrics. Adjust polling intervals: Polling for cloud integrations. For on-host integrations: edit the configuration file for a specific integration. Control the reporting of specific attributes. Manage Kubernetes events integration. Adjust log data ingest Options for adjusting log data ingest include: Use the log forwarder to filter log events on the sending side. Drop log data, either via the UI or with NerdGraph.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.84806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " is located in the Data management UI. The Data ingestion UI shows your ingest <em>rates</em> for the time period specified by the time picker in the upper right. The page shows your daily average GBs, and the total GBs for that time range. You can toggle between an overall ingest view and an account view"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.33209,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Manage your <em>charts</em> and markdown content",
        "body": ". This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The <em>refresh</em> <em>rate</em> depends on the duration of the time window you are viewing. For more information and examples, see <em>Chart</em> <em>refresh</em> intervals. To change the time"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/explore-query-data/use-charts/chart-types": [
    {
      "sections": [
        "Use your charts",
        "Use open-source charting library",
        "Change the appearance of your chart",
        "Customize your charts",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2022-01-12T10:19:26Z",
      "updated_at": "2021-12-30T20:51:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Use open-source charting library You can use Nerdpacks to create your own custom visualizations. We have also teamed up with Formidable so you can use an open-source charting library, and quickly add unique \"victory charts\" to your New Relic One dashboards. To learn about these custom visualization Nerdpacks, watch this short video (approx. 4 minutes). Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. Depending on the chart type, additional customization options are available. Format date and time Tables and billboards. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Line charts and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Line charts, area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Bar charts, pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 534.8775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  your <em>charts</em> ",
        "sections": "Use your <em>charts</em>",
        "tags": "Use <em>charts</em>",
        "body": " in advanced (NRQL) mode or view your <em>chart</em> while using the data explorer to specify data, the query builder analyzes your data and applies a <em>chart</em> <em>type</em> that fits your data. For some queries, you&#x27;ll have several options of <em>chart</em> <em>types</em> to choose from. To change <em>chart</em> <em>type</em>, use the <em>Chart</em> <em>type</em> menu"
      },
      "id": "603ec29a196a67ef5da83d82"
    },
    {
      "sections": [
        "Customize your visualization with configuration options",
        "Course",
        "Tip",
        "Add a new configuration option",
        "Replace your SegmentedControl with the configurable property",
        "Summary"
      ],
      "title": "Customize your visualization with configuration options",
      "type": "developer",
      "tags": [
        "nr1 cli",
        "NR One Catalog",
        "visualizations"
      ],
      "external_id": "9028e58f383ea362d2c9d3a7ecd6404dbfeac87c",
      "image": "https://developer.newrelic.com/static/429297e04a38e93e7c2bd5bfcada5021/0086b/nav-to-apps.png",
      "url": "https://developer.newrelic.com/build-apps/customize-visualizations-with-configuration/",
      "published_at": "2022-01-12T02:07:01Z",
      "updated_at": "2021-09-30T01:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Customize your visualization using configuration",
      "body": "Course This lesson is part of a course that teaches you how to build a custom visualization in the New Relic One platform. Each lesson in the course builds upon the last, so make sure you've completed the last lesson, Custom visualizations and the New Relic One SDK, before starting this one. In the previous lesson, you built a custom visualization that shows queried data in one of two chart types: RadarChart Treemap You used a SegmentedControl to switch between the two chart types in the visualization UI. This implementation takes up space in the visualization, but it offers your users the choice to switch between two chart types even after you've created an instance of your chart. But what if you only need to be able to select an option once, when initializing the visualization? In this lesson you'll learn how to add a configuration option to your visualization which replaces the SegmentedControl. Tip If you get lost in the code project and would like to see what the files should look like when you're done with each lesson, check out the course project on Github. Add a new configuration option Step 1 of 8 In your visualization's nr1.json file, add an enum configuration object for selectedChart: index.js nr1.json 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 Radar: 'radar', 24 Treemap: 'treemap', 25 }; 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 state = { 55 selectedChart: CHART_TYPES.Radar, 56 }; 57 58 /** 59 * Restructure the data for a non-time-series, facet-based NRQL query into a 60 * form accepted by the Recharts library's RadarChart. 61 * (https://recharts.org/api/RadarChart). 62 */ 63 transformData = (rawData) => { 64 return rawData.map((entry) => ({ 65 name: entry.metadata.name, 66 // Only grabbing the first data value because this is not time-series data. 67 value: entry.data[0].y, 68 })); 69 }; 70 71 /** 72 * Format the given axis tick's numeric value into a string for display. 73 */ 74 formatTick = (value) => { 75 return value.toLocaleString(); 76 }; 77 78 updateSelectedChart = (evt, value) => { 79 this.setState({ selectedChart: value }); 80 }; 81 82 render() { 83 const { nrqlQueries, stroke, fill } = this.props; 84 const { selectedChart } = this.state; 85 86 const nrqlQueryPropsAvailable = 87 nrqlQueries && 88 nrqlQueries[0] && 89 nrqlQueries[0].accountId && 90 nrqlQueries[0].query; 91 92 if (!nrqlQueryPropsAvailable) { 93 return <EmptyState />; 94 } 95 96 return ( 97 <AutoSizer> 98 {({ width, height }) => ( 99 <NrqlQuery 100 query={nrqlQueries[0].query} 101 accountId={parseInt(nrqlQueries[0].accountId)} 102 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 103 > 104 {({ data, loading, error }) => { 105 if (loading) { 106 return <Spinner />; 107 } 108 109 if (error) { 110 return <ErrorState />; 111 } 112 113 const transformedData = this.transformData(data); 114 115 return ( 116 <React.Fragment> 117 <SegmentedControl onChange={this.updateSelectedChart}> 118 <SegmentedControlItem 119 value={CHART_TYPES.Radar} 120 label=\"Radar chart\" 121 /> 122 <SegmentedControlItem 123 value={CHART_TYPES.Treemap} 124 label=\"Treemap chart\" 125 /> 126 </SegmentedControl> 127 {selectedChart === CHART_TYPES.Radar ? ( 128 <RadarChart 129 width={width} 130 height={height} 131 data={transformedData} 132 > 133 <PolarGrid /> 134 <PolarAngleAxis dataKey=\"name\" /> 135 <PolarRadiusAxis tickFormatter={this.formatTick} /> 136 <Radar 137 dataKey=\"value\" 138 stroke={stroke || '#51C9B7'} 139 fill={fill || '#51C9B7'} 140 fillOpacity={0.6} 141 /> 142 </RadarChart> 143 ) : ( 144 <Treemap 145 width={width} 146 height={height} 147 data={transformedData} 148 dataKey=\"value\" 149 ratio={4 / 3} 150 stroke={stroke || '#000000'} 151 fill={fill || '#51C9B7'} 152 /> 153 )} 154 </React.Fragment> 155 ); 156 }} 157 </NrqlQuery> 158 )} 159 </AutoSizer> 160 ); 161 } 162 } 163 164 const EmptyState = () => ( 165 <Card className=\"EmptyState\"> 166 <CardBody className=\"EmptyState-cardBody\"> 167 <HeadingText 168 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 169 type={HeadingText.TYPE.HEADING_3} 170 > 171 Please provide at least one NRQL query & account ID pair 172 </HeadingText> 173 <HeadingText 174 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 175 type={HeadingText.TYPE.HEADING_4} 176 > 177 An example NRQL query you can try is: 178 </HeadingText> 179 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 180 </CardBody> 181 </Card> 182 ); 183 184 const ErrorState = () => ( 185 <Card className=\"ErrorState\"> 186 <CardBody className=\"ErrorState-cardBody\"> 187 <HeadingText 188 className=\"ErrorState-headingText\" 189 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 190 type={HeadingText.TYPE.HEADING_3} 191 > 192 Oops! Something went wrong. 193 </HeadingText> 194 </CardBody> 195 </Card> 196 ); visualizations/radar-or-treemap/index.js Copy 1 { 2 \"schemaType\": \"VISUALIZATION\", 3 \"id\": \"radar-or-treemap\", 4 \"displayName\": \"RadarOrTreemap\", 5 \"description\": \"\", 6 \"configuration\": [ 7 { 8 \"name\": \"selectedChart\", 9 \"title\": \"Select chart\", 10 \"description\": \"Select which chart to display\", 11 \"type\": \"enum\", 12 \"items\": [ 13 { 14 \"title\": \"Radar\", 15 \"value\": \"radar\" 16 }, 17 { 18 \"title\": \"Treemap\", 19 \"value\": \"treemap\" 20 } 21 ] 22 }, 23 { 24 \"name\": \"nrqlQueries\", 25 \"title\": \"NRQL Queries\", 26 \"type\": \"collection\", 27 \"items\": [ 28 { 29 \"name\": \"accountId\", 30 \"title\": \"Account ID\", 31 \"description\": \"Account ID to be associated with the query\", 32 \"type\": \"account-id\" 33 }, 34 { 35 \"name\": \"query\", 36 \"title\": \"Query\", 37 \"description\": \"NRQL query for visualization\", 38 \"type\": \"nrql\" 39 } 40 ] 41 }, 42 { 43 \"name\": \"fill\", 44 \"title\": \"Fill color\", 45 \"description\": \"A fill color to override the default fill color\", 46 \"type\": \"string\" 47 }, 48 { 49 \"name\": \"stroke\", 50 \"title\": \"Stroke color\", 51 \"description\": \"A stroke color to override the default stroke color\", 52 \"type\": \"string\" 53 } 54 ] 55 } visualizations/radar-or-treemap/nr1.json Copy Step 2 of 8 Navigate to the root of your Nerdpack at alternate-viz. Step 3 of 8 Serve your Nerdpack locally: bash Copy $ nr1 nerdpack:serve If you're still serving your Nerdpack from the last lesson, you need to stop it with CTRL-X and serve it again to reflect changes to nr1.json. Step 4 of 8 Go to https://one.newrelic.com/?nerdpacks=local. The nerdpacks=local query string directs the UI to load your visualization from the local server. Step 5 of 8 Open the Apps page: Step 6 of 8 Go to Custom Visualizations, which is favorited by default: Step 7 of 8 In Custom Visualizations, find and click your visualization: Step 8 of 8 Notice the new Select chart configuration option: Selecting a chart type doesn't effect your visualization. This is because you first need to introduce the selectedChart property to the visualization component. Then, you use selectedChart to determine the chart type to render. Replace your SegmentedControl with the configurable property Step 1 of 5 Open your visualization's index.js file. You'll be working here for the rest of the guide. Step 2 of 5 In render(), include selectedChart as a constant you get from destructuring props, and remove your component's state: index.js nr1.json 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 Radar: 'radar', 24 Treemap: 'treemap', 25 }; 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 /** 55 * Restructure the data for a non-time-series, facet-based NRQL query into a 56 * form accepted by the Recharts library's RadarChart. 57 * (https://recharts.org/api/RadarChart). 58 */ 59 transformData = (rawData) => { 60 return rawData.map((entry) => ({ 61 name: entry.metadata.name, 62 // Only grabbing the first data value because this is not time-series data. 63 value: entry.data[0].y, 64 })); 65 }; 66 67 /** 68 * Format the given axis tick's numeric value into a string for display. 69 */ 70 formatTick = (value) => { 71 return value.toLocaleString(); 72 }; 73 74 render() { 75 const { nrqlQueries, stroke, fill, selectedChart } = this.props; 76 77 const nrqlQueryPropsAvailable = 78 nrqlQueries && 79 nrqlQueries[0] && 80 nrqlQueries[0].accountId && 81 nrqlQueries[0].query; 82 83 if (!nrqlQueryPropsAvailable) { 84 return <EmptyState />; 85 } 86 87 return ( 88 <AutoSizer> 89 {({ width, height }) => ( 90 <NrqlQuery 91 query={nrqlQueries[0].query} 92 accountId={parseInt(nrqlQueries[0].accountId)} 93 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 94 > 95 {({ data, loading, error }) => { 96 if (loading) { 97 return <Spinner />; 98 } 99 100 if (error) { 101 return <ErrorState />; 102 } 103 104 const transformedData = this.transformData(data); 105 106 return ( 107 <React.Fragment> 108 <SegmentedControl> 109 <SegmentedControlItem 110 value={CHART_TYPES.Radar} 111 label=\"Radar chart\" 112 /> 113 <SegmentedControlItem 114 value={CHART_TYPES.Treemap} 115 label=\"Treemap chart\" 116 /> 117 </SegmentedControl> 118 {selectedChart === CHART_TYPES.Radar ? ( 119 <RadarChart 120 width={width} 121 height={height} 122 data={transformedData} 123 > 124 <PolarGrid /> 125 <PolarAngleAxis dataKey=\"name\" /> 126 <PolarRadiusAxis tickFormatter={this.formatTick} /> 127 <Radar 128 dataKey=\"value\" 129 stroke={stroke || '#51C9B7'} 130 fill={fill || '#51C9B7'} 131 fillOpacity={0.6} 132 /> 133 </RadarChart> 134 ) : ( 135 <Treemap 136 width={width} 137 height={height} 138 data={transformedData} 139 dataKey=\"value\" 140 ratio={4 / 3} 141 stroke={stroke || '#000000'} 142 fill={fill || '#51C9B7'} 143 /> 144 )} 145 </React.Fragment> 146 ); 147 }} 148 </NrqlQuery> 149 )} 150 </AutoSizer> 151 ); 152 } 153 } 154 155 const EmptyState = () => ( 156 <Card className=\"EmptyState\"> 157 <CardBody className=\"EmptyState-cardBody\"> 158 <HeadingText 159 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 160 type={HeadingText.TYPE.HEADING_3} 161 > 162 Please provide at least one NRQL query & account ID pair 163 </HeadingText> 164 <HeadingText 165 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 166 type={HeadingText.TYPE.HEADING_4} 167 > 168 An example NRQL query you can try is: 169 </HeadingText> 170 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 171 </CardBody> 172 </Card> 173 ); 174 175 const ErrorState = () => ( 176 <Card className=\"ErrorState\"> 177 <CardBody className=\"ErrorState-cardBody\"> 178 <HeadingText 179 className=\"ErrorState-headingText\" 180 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 181 type={HeadingText.TYPE.HEADING_3} 182 > 183 Oops! Something went wrong. 184 </HeadingText> 185 </CardBody> 186 </Card> 187 ); visualizations/radar-or-treemap/index.js Copy 1 { 2 \"schemaType\": \"VISUALIZATION\", 3 \"id\": \"radar-or-treemap\", 4 \"displayName\": \"RadarOrTreemap\", 5 \"description\": \"\", 6 \"configuration\": [ 7 { 8 \"name\": \"selectedChart\", 9 \"title\": \"Select chart\", 10 \"description\": \"Select which chart to display\", 11 \"type\": \"enum\", 12 \"items\": [ 13 { 14 \"title\": \"Radar\", 15 \"value\": \"radar\" 16 }, 17 { 18 \"title\": \"Treemap\", 19 \"value\": \"treemap\" 20 } 21 ] 22 }, 23 { 24 \"name\": \"nrqlQueries\", 25 \"title\": \"NRQL Queries\", 26 \"type\": \"collection\", 27 \"items\": [ 28 { 29 \"name\": \"accountId\", 30 \"title\": \"Account ID\", 31 \"description\": \"Account ID to be associated with the query\", 32 \"type\": \"account-id\" 33 }, 34 { 35 \"name\": \"query\", 36 \"title\": \"Query\", 37 \"description\": \"NRQL query for visualization\", 38 \"type\": \"nrql\" 39 } 40 ] 41 }, 42 { 43 \"name\": \"fill\", 44 \"title\": \"Fill color\", 45 \"description\": \"A fill color to override the default fill color\", 46 \"type\": \"string\" 47 }, 48 { 49 \"name\": \"stroke\", 50 \"title\": \"Stroke color\", 51 \"description\": \"A stroke color to override the default stroke color\", 52 \"type\": \"string\" 53 } 54 ] 55 } visualizations/radar-or-treemap/nr1.json Copy Now that you're using selectedChart from the configuration options instead of component state, you can select a chart in the configuration panel and watch the visualization change. Unfortunately, there's a bug. The default chart option is Radar, but the initial render shows a Treemap. Step 3 of 5 Update your ternary expression to account for the case where there is no selectedChart: index.js nr1.json 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 Radar: 'radar', 24 Treemap: 'treemap', 25 }; 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 /** 55 * Restructure the data for a non-time-series, facet-based NRQL query into a 56 * form accepted by the Recharts library's RadarChart. 57 * (https://recharts.org/api/RadarChart). 58 */ 59 transformData = (rawData) => { 60 return rawData.map((entry) => ({ 61 name: entry.metadata.name, 62 // Only grabbing the first data value because this is not time-series data. 63 value: entry.data[0].y, 64 })); 65 }; 66 67 /** 68 * Format the given axis tick's numeric value into a string for display. 69 */ 70 formatTick = (value) => { 71 return value.toLocaleString(); 72 }; 73 74 render() { 75 const { nrqlQueries, stroke, fill, selectedChart } = this.props; 76 77 const nrqlQueryPropsAvailable = 78 nrqlQueries && 79 nrqlQueries[0] && 80 nrqlQueries[0].accountId && 81 nrqlQueries[0].query; 82 83 if (!nrqlQueryPropsAvailable) { 84 return <EmptyState />; 85 } 86 87 return ( 88 <AutoSizer> 89 {({ width, height }) => ( 90 <NrqlQuery 91 query={nrqlQueries[0].query} 92 accountId={parseInt(nrqlQueries[0].accountId)} 93 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 94 > 95 {({ data, loading, error }) => { 96 if (loading) { 97 return <Spinner />; 98 } 99 100 if (error) { 101 return <ErrorState />; 102 } 103 104 const transformedData = this.transformData(data); 105 106 return ( 107 <React.Fragment> 108 <SegmentedControl> 109 <SegmentedControlItem 110 value={CHART_TYPES.Radar} 111 label=\"Radar chart\" 112 /> 113 <SegmentedControlItem 114 value={CHART_TYPES.Treemap} 115 label=\"Treemap chart\" 116 /> 117 </SegmentedControl> 118 {!selectedChart || selectedChart === CHART_TYPES.Radar ? ( 119 <RadarChart 120 width={width} 121 height={height} 122 data={transformedData} 123 > 124 <PolarGrid /> 125 <PolarAngleAxis dataKey=\"name\" /> 126 <PolarRadiusAxis tickFormatter={this.formatTick} /> 127 <Radar 128 dataKey=\"value\" 129 stroke={stroke || '#51C9B7'} 130 fill={fill || '#51C9B7'} 131 fillOpacity={0.6} 132 /> 133 </RadarChart> 134 ) : ( 135 <Treemap 136 width={width} 137 height={height} 138 data={transformedData} 139 dataKey=\"value\" 140 ratio={4 / 3} 141 stroke={stroke || '#000000'} 142 fill={fill || '#51C9B7'} 143 /> 144 )} 145 </React.Fragment> 146 ); 147 }} 148 </NrqlQuery> 149 )} 150 </AutoSizer> 151 ); 152 } 153 } 154 155 const EmptyState = () => ( 156 <Card className=\"EmptyState\"> 157 <CardBody className=\"EmptyState-cardBody\"> 158 <HeadingText 159 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 160 type={HeadingText.TYPE.HEADING_3} 161 > 162 Please provide at least one NRQL query & account ID pair 163 </HeadingText> 164 <HeadingText 165 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 166 type={HeadingText.TYPE.HEADING_4} 167 > 168 An example NRQL query you can try is: 169 </HeadingText> 170 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 171 </CardBody> 172 </Card> 173 ); 174 175 const ErrorState = () => ( 176 <Card className=\"ErrorState\"> 177 <CardBody className=\"ErrorState-cardBody\"> 178 <HeadingText 179 className=\"ErrorState-headingText\" 180 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 181 type={HeadingText.TYPE.HEADING_3} 182 > 183 Oops! Something went wrong. 184 </HeadingText> 185 </CardBody> 186 </Card> 187 ); visualizations/radar-or-treemap/index.js Copy 1 { 2 \"schemaType\": \"VISUALIZATION\", 3 \"id\": \"radar-or-treemap\", 4 \"displayName\": \"RadarOrTreemap\", 5 \"description\": \"\", 6 \"configuration\": [ 7 { 8 \"name\": \"selectedChart\", 9 \"title\": \"Select chart\", 10 \"description\": \"Select which chart to display\", 11 \"type\": \"enum\", 12 \"items\": [ 13 { 14 \"title\": \"Radar\", 15 \"value\": \"radar\" 16 }, 17 { 18 \"title\": \"Treemap\", 19 \"value\": \"treemap\" 20 } 21 ] 22 }, 23 { 24 \"name\": \"nrqlQueries\", 25 \"title\": \"NRQL Queries\", 26 \"type\": \"collection\", 27 \"items\": [ 28 { 29 \"name\": \"accountId\", 30 \"title\": \"Account ID\", 31 \"description\": \"Account ID to be associated with the query\", 32 \"type\": \"account-id\" 33 }, 34 { 35 \"name\": \"query\", 36 \"title\": \"Query\", 37 \"description\": \"NRQL query for visualization\", 38 \"type\": \"nrql\" 39 } 40 ] 41 }, 42 { 43 \"name\": \"fill\", 44 \"title\": \"Fill color\", 45 \"description\": \"A fill color to override the default fill color\", 46 \"type\": \"string\" 47 }, 48 { 49 \"name\": \"stroke\", 50 \"title\": \"Stroke color\", 51 \"description\": \"A stroke color to override the default stroke color\", 52 \"type\": \"string\" 53 } 54 ] 55 } visualizations/radar-or-treemap/nr1.json Copy Now, your data is rendered in a RadarChart if you haven't yet configured the option. Step 4 of 5 Remove SegmentedControl from render(): index.js nr1.json 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 Spinner, 18 } from 'nr1'; 19 20 const CHART_TYPES = { 21 Radar: 'radar', 22 Treemap: 'treemap', 23 }; 24 25 export default class RadarOrTreemapVisualization extends React.Component { 26 // Custom props you wish to be configurable in the UI must also be defined in 27 // the nr1.json file for the visualization. See docs for more details. 28 static propTypes = { 29 /** 30 * A fill color to override the default fill color. This is an example of 31 * a custom chart configuration. 32 */ 33 fill: PropTypes.string, 34 35 /** 36 * A stroke color to override the default stroke color. This is an example of 37 * a custom chart configuration. 38 */ 39 stroke: PropTypes.string, 40 /** 41 * An array of objects consisting of a nrql `query` and `accountId`. 42 * This should be a standard prop for any NRQL based visualizations. 43 */ 44 nrqlQueries: PropTypes.arrayOf( 45 PropTypes.shape({ 46 accountId: PropTypes.number, 47 query: PropTypes.string, 48 }) 49 ), 50 }; 51 52 /** 53 * Restructure the data for a non-time-series, facet-based NRQL query into a 54 * form accepted by the Recharts library's RadarChart. 55 * (https://recharts.org/api/RadarChart). 56 */ 57 transformData = (rawData) => { 58 return rawData.map((entry) => ({ 59 name: entry.metadata.name, 60 // Only grabbing the first data value because this is not time-series data. 61 value: entry.data[0].y, 62 })); 63 }; 64 65 /** 66 * Format the given axis tick's numeric value into a string for display. 67 */ 68 formatTick = (value) => { 69 return value.toLocaleString(); 70 }; 71 72 render() { 73 const { nrqlQueries, stroke, fill, selectedChart } = this.props; 74 75 const nrqlQueryPropsAvailable = 76 nrqlQueries && 77 nrqlQueries[0] && 78 nrqlQueries[0].accountId && 79 nrqlQueries[0].query; 80 81 if (!nrqlQueryPropsAvailable) { 82 return <EmptyState />; 83 } 84 85 return ( 86 <AutoSizer> 87 {({ width, height }) => ( 88 <NrqlQuery 89 query={nrqlQueries[0].query} 90 accountId={parseInt(nrqlQueries[0].accountId)} 91 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 92 > 93 {({ data, loading, error }) => { 94 if (loading) { 95 return <Spinner />; 96 } 97 98 if (error) { 99 return <ErrorState />; 100 } 101 102 const transformedData = this.transformData(data); 103 104 return ( 105 <React.Fragment> 106 {!selectedChart || selectedChart === CHART_TYPES.Radar ? ( 107 <RadarChart 108 width={width} 109 height={height} 110 data={transformedData} 111 > 112 <PolarGrid /> 113 <PolarAngleAxis dataKey=\"name\" /> 114 <PolarRadiusAxis tickFormatter={this.formatTick} /> 115 <Radar 116 dataKey=\"value\" 117 stroke={stroke || '#51C9B7'} 118 fill={fill || '#51C9B7'} 119 fillOpacity={0.6} 120 /> 121 </RadarChart> 122 ) : ( 123 <Treemap 124 width={width} 125 height={height} 126 data={transformedData} 127 dataKey=\"value\" 128 ratio={4 / 3} 129 stroke={stroke || '#000000'} 130 fill={fill || '#51C9B7'} 131 /> 132 )} 133 </React.Fragment> 134 ); 135 }} 136 </NrqlQuery> 137 )} 138 </AutoSizer> 139 ); 140 } 141 } 142 143 const EmptyState = () => ( 144 <Card className=\"EmptyState\"> 145 <CardBody className=\"EmptyState-cardBody\"> 146 <HeadingText 147 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 148 type={HeadingText.TYPE.HEADING_3} 149 > 150 Please provide at least one NRQL query & account ID pair 151 </HeadingText> 152 <HeadingText 153 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 154 type={HeadingText.TYPE.HEADING_4} 155 > 156 An example NRQL query you can try is: 157 </HeadingText> 158 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 159 </CardBody> 160 </Card> 161 ); 162 163 const ErrorState = () => ( 164 <Card className=\"ErrorState\"> 165 <CardBody className=\"ErrorState-cardBody\"> 166 <HeadingText 167 className=\"ErrorState-headingText\" 168 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 169 type={HeadingText.TYPE.HEADING_3} 170 > 171 Oops! Something went wrong. 172 </HeadingText> 173 </CardBody> 174 </Card> 175 ); visualizations/radar-or-treemap/index.js Copy 1 { 2 \"schemaType\": \"VISUALIZATION\", 3 \"id\": \"radar-or-treemap\", 4 \"displayName\": \"RadarOrTreemap\", 5 \"description\": \"\", 6 \"configuration\": [ 7 { 8 \"name\": \"selectedChart\", 9 \"title\": \"Select chart\", 10 \"description\": \"Select which chart to display\", 11 \"type\": \"enum\", 12 \"items\": [ 13 { 14 \"title\": \"Radar\", 15 \"value\": \"radar\" 16 }, 17 { 18 \"title\": \"Treemap\", 19 \"value\": \"treemap\" 20 } 21 ] 22 }, 23 { 24 \"name\": \"nrqlQueries\", 25 \"title\": \"NRQL Queries\", 26 \"type\": \"collection\", 27 \"items\": [ 28 { 29 \"name\": \"accountId\", 30 \"title\": \"Account ID\", 31 \"description\": \"Account ID to be associated with the query\", 32 \"type\": \"account-id\" 33 }, 34 { 35 \"name\": \"query\", 36 \"title\": \"Query\", 37 \"description\": \"NRQL query for visualization\", 38 \"type\": \"nrql\" 39 } 40 ] 41 }, 42 { 43 \"name\": \"fill\", 44 \"title\": \"Fill color\", 45 \"description\": \"A fill color to override the default fill color\", 46 \"type\": \"string\" 47 }, 48 { 49 \"name\": \"stroke\", 50 \"title\": \"Stroke color\", 51 \"description\": \"A stroke color to override the default stroke color\", 52 \"type\": \"string\" 53 } 54 ] 55 } visualizations/radar-or-treemap/nr1.json Copy Step 5 of 5 Serve your Nerdpack locally, and view it in the Custom Visualizations app in New Relic. Select a chart type from the dropdown in the configuration sidebar, and see your visualization update to show the matching chart type: Summary Congratulations on completing this lesson! You've learned how to customize your visualization using nr1.json configuration. Course This lesson is part of a course that teaches you how to build a custom visualization in the New Relic One platform. When you're ready, continue on to the next lesson: Add custom visualizations to your dashboards.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 414.28522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ". In the previous lesson, you built a custom visualization that shows queried data in one of two <em>chart</em> <em>types</em>: Radar<em>Chart</em> Treemap You used a SegmentedControl to switch between the two <em>chart</em> <em>types</em> in the visualization UI. This implementation takes up space in the visualization, but it offers your users"
      },
      "id": "6091fa3ae7b9d2df595068c1"
    },
    {
      "sections": [
        "Customize your visualization with SDK components",
        "Course",
        "Tip",
        "Before you begin",
        "Create your visualization",
        "Set up your component state",
        "Add SegmentedControl components",
        "Connect your component's state to the SegmentedControl",
        "Implement a Treemap option",
        "Technical detail",
        "Switch between charts with your component's state",
        "Summary"
      ],
      "title": "Customize your visualization with SDK components",
      "type": "developer",
      "tags": [
        "nr1 cli",
        "NR One Catalog",
        "Subscribe visualizations"
      ],
      "external_id": "8317cf0361e92ab36c922dd87720e01a69530f9b",
      "image": "https://developer.newrelic.com/static/ae9d817689607337734a3d66e12d1dc4/ba3ac/radar-chart-with-segmented-control.png",
      "url": "https://developer.newrelic.com/build-apps/custom-visualizations-and-the-new-relic-one-sdk/",
      "published_at": "2022-01-12T02:07:02Z",
      "updated_at": "2021-05-13T01:45:29Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Customize your visualization",
      "body": "Course This lesson is part of a course that teaches you how to build a custom visualization in the New Relic One platform. Use New Relic One custom visualizations to display your data, whether it's from New Relic's database or an external source, in unique ways that are distinct from the charts offered by the New Relic platform. In this lesson, you build a visualization that displays your data in one of two chart types: RadarChart or Treemap. You then implement a SegmentedControl component from the New Relic One SDK, which allows you to alternate between the two chart types. Ultimately, this gives you freedom to view your data in a dynamic way that isn't possible with New Relic's base offerings. Tip If you get lost in the code project and would like to see what the files should look like when you're done with each lesson, check out the course project on Github. Before you begin Explore our custom visualization guides and build your first visualization. After you're done, you'll have a better foundation for building more complex visualizations, such as the one you'll build in this course. Finally, if you haven't already: Sign up for a New Relic account Install Node.js Complete the steps in the nr1 quick start to install and configure the CLI Create your visualization Step 1 of 2 Ensure you're working with the latest version of the New Relic One CLI: bash Copy $ nr1 update Step 2 of 2 Create a visualization, called radar-or-treemap, in a Nerdpack, called alternate-viz: bash Copy $ nr1 create --type visualization --name radar-or-treemap ✔ You’re trying to create a visualization outside of a Nerdpack. We’ll create a Nerdpack for you—what do you want to name it? … alternate-viz ✔ nerdpack created successfully! nerdpack alternate-viz is available at \"./alternate-viz\" ✔ visualization created successfully! visualization radar-or-treemap is available at \"./alternate-viz/visualizations/radar-or-treemap\" Tip If you receive a RequestError for a self-signed certificate when you run nr1 create, you may need to add a certificate to Node's certificate chain. Read more about this and other advanced configurations in Enable advanced configurations for your Nerdpack. As a result, you have a new visualizations/radar-or-treemap directory under alternate-viz: bash Copy $ cd alternate-viz $ ls visualizations/radar-or-treemap index.js nr1.json styles.scss Set up your component state Add component state to the default visualization template that nr1 created for you. Step 1 of 3 Navigate to alternate-viz/visualizations/radar-or-treemap/index.js. You'll work in here for the rest of this lesson. Step 2 of 3 Add a constant called CHART_TYPES: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import {Card, CardBody, HeadingText, NrqlQuery, Spinner, AutoSizer} from 'nr1'; 11 12 const CHART_TYPES = { 13 'Radar': 'radar', 14 'Treemap': 'treemap' 15 } 16 17 export default class RadarOrTreemapVisualization extends React.Component { 18 // Custom props you wish to be configurable in the UI must also be defined in 19 // the nr1.json file for the visualization. See docs for more details. 20 static propTypes = { 21 /** 22 * A fill color to override the default fill color. This is an example of 23 * a custom chart configuration. 24 */ 25 fill: PropTypes.string, 26 27 /** 28 * A stroke color to override the default stroke color. This is an example of 29 * a custom chart configuration. 30 */ 31 stroke: PropTypes.string, 32 /** 33 * An array of objects consisting of a nrql `query` and `accountId`. 34 * This should be a standard prop for any NRQL based visualizations. 35 */ 36 nrqlQueries: PropTypes.arrayOf( 37 PropTypes.shape({ 38 accountId: PropTypes.number, 39 query: PropTypes.string, 40 }) 41 ), 42 }; 43 44 /** 45 * Restructure the data for a non-time-series, facet-based NRQL query into a 46 * form accepted by the Recharts library's RadarChart. 47 * (https://recharts.org/api/RadarChart). 48 */ 49 transformData = (rawData) => { 50 return rawData.map((entry) => ({ 51 name: entry.metadata.name, 52 // Only grabbing the first data value because this is not time-series data. 53 value: entry.data[0].y, 54 })); 55 }; 56 57 /** 58 * Format the given axis tick's numeric value into a string for display. 59 */ 60 formatTick = (value) => { 61 return value.toLocaleString(); 62 }; 63 64 render() { 65 const {nrqlQueries, stroke, fill} = this.props; 66 67 const nrqlQueryPropsAvailable = 68 nrqlQueries && 69 nrqlQueries[0] && 70 nrqlQueries[0].accountId && 71 nrqlQueries[0].query; 72 73 if (!nrqlQueryPropsAvailable) { 74 return <EmptyState />; 75 } 76 77 return ( 78 <AutoSizer> 79 {({width, height}) => ( 80 <NrqlQuery 81 query={nrqlQueries[0].query} 82 accountId={parseInt(nrqlQueries[0].accountId)} 83 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 84 > 85 {({data, loading, error}) => { 86 if (loading) { 87 return <Spinner />; 88 } 89 90 if (error) { 91 return <ErrorState />; 92 } 93 94 const transformedData = this.transformData(data); 95 96 return ( 97 <RadarChart 98 width={width} 99 height={height} 100 data={transformedData} 101 > 102 <PolarGrid /> 103 <PolarAngleAxis dataKey=\"name\" /> 104 <PolarRadiusAxis tickFormatter={this.formatTick} /> 105 <Radar 106 dataKey=\"value\" 107 stroke={stroke || '#51C9B7'} 108 fill={fill || '#51C9B7'} 109 fillOpacity={0.6} 110 /> 111 </RadarChart> 112 ); 113 }} 114 </NrqlQuery> 115 )} 116 </AutoSizer> 117 ); 118 } 119 } 120 121 const EmptyState = () => ( 122 <Card className=\"EmptyState\"> 123 <CardBody className=\"EmptyState-cardBody\"> 124 <HeadingText 125 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 126 type={HeadingText.TYPE.HEADING_3} 127 > 128 Please provide at least one NRQL query & account ID pair 129 </HeadingText> 130 <HeadingText 131 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 132 type={HeadingText.TYPE.HEADING_4} 133 > 134 An example NRQL query you can try is: 135 </HeadingText> 136 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 137 </CardBody> 138 </Card> 139 ); 140 141 const ErrorState = () => ( 142 <Card className=\"ErrorState\"> 143 <CardBody className=\"ErrorState-cardBody\"> 144 <HeadingText 145 className=\"ErrorState-headingText\" 146 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 147 type={HeadingText.TYPE.HEADING_3} 148 > 149 Oops! Something went wrong. 150 </HeadingText> 151 </CardBody> 152 </Card> 153 ); visualizations/radar-or-treemap/index.js Copy CHART_TYPES enumerates the two chart types you'll alternate between in your visualization. Step 3 of 3 Initialize selectedChart in your component's state: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import {Card, CardBody, HeadingText, NrqlQuery, Spinner, AutoSizer} from 'nr1'; 11 12 const CHART_TYPES = { 13 'Radar': 'radar', 14 'Treemap': 'treemap' 15 } 16 17 export default class RadarOrTreemapVisualization extends React.Component { 18 // Custom props you wish to be configurable in the UI must also be defined in 19 // the nr1.json file for the visualization. See docs for more details. 20 static propTypes = { 21 /** 22 * A fill color to override the default fill color. This is an example of 23 * a custom chart configuration. 24 */ 25 fill: PropTypes.string, 26 27 /** 28 * A stroke color to override the default stroke color. This is an example of 29 * a custom chart configuration. 30 */ 31 stroke: PropTypes.string, 32 /** 33 * An array of objects consisting of a nrql `query` and `accountId`. 34 * This should be a standard prop for any NRQL based visualizations. 35 */ 36 nrqlQueries: PropTypes.arrayOf( 37 PropTypes.shape({ 38 accountId: PropTypes.number, 39 query: PropTypes.string, 40 }) 41 ), 42 }; 43 44 state = { 45 selectedChart: CHART_TYPES.Radar, 46 }; 47 48 /** 49 * Restructure the data for a non-time-series, facet-based NRQL query into a 50 * form accepted by the Recharts library's RadarChart. 51 * (https://recharts.org/api/RadarChart). 52 */ 53 transformData = (rawData) => { 54 return rawData.map((entry) => ({ 55 name: entry.metadata.name, 56 // Only grabbing the first data value because this is not time-series data. 57 value: entry.data[0].y, 58 })); 59 }; 60 61 /** 62 * Format the given axis tick's numeric value into a string for display. 63 */ 64 formatTick = (value) => { 65 return value.toLocaleString(); 66 }; 67 68 render() { 69 const {nrqlQueries, stroke, fill} = this.props; 70 71 const nrqlQueryPropsAvailable = 72 nrqlQueries && 73 nrqlQueries[0] && 74 nrqlQueries[0].accountId && 75 nrqlQueries[0].query; 76 77 if (!nrqlQueryPropsAvailable) { 78 return <EmptyState />; 79 } 80 81 return ( 82 <AutoSizer> 83 {({width, height}) => ( 84 <NrqlQuery 85 query={nrqlQueries[0].query} 86 accountId={parseInt(nrqlQueries[0].accountId)} 87 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 88 > 89 {({data, loading, error}) => { 90 if (loading) { 91 return <Spinner />; 92 } 93 94 if (error) { 95 return <ErrorState />; 96 } 97 98 const transformedData = this.transformData(data); 99 100 return ( 101 <RadarChart 102 width={width} 103 height={height} 104 data={transformedData} 105 > 106 <PolarGrid /> 107 <PolarAngleAxis dataKey=\"name\" /> 108 <PolarRadiusAxis tickFormatter={this.formatTick} /> 109 <Radar 110 dataKey=\"value\" 111 stroke={stroke || '#51C9B7'} 112 fill={fill || '#51C9B7'} 113 fillOpacity={0.6} 114 /> 115 </RadarChart> 116 ); 117 }} 118 </NrqlQuery> 119 )} 120 </AutoSizer> 121 ); 122 } 123 } 124 125 const EmptyState = () => ( 126 <Card className=\"EmptyState\"> 127 <CardBody className=\"EmptyState-cardBody\"> 128 <HeadingText 129 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 130 type={HeadingText.TYPE.HEADING_3} 131 > 132 Please provide at least one NRQL query & account ID pair 133 </HeadingText> 134 <HeadingText 135 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 136 type={HeadingText.TYPE.HEADING_4} 137 > 138 An example NRQL query you can try is: 139 </HeadingText> 140 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 141 </CardBody> 142 </Card> 143 ); 144 145 const ErrorState = () => ( 146 <Card className=\"ErrorState\"> 147 <CardBody className=\"ErrorState-cardBody\"> 148 <HeadingText 149 className=\"ErrorState-headingText\" 150 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 151 type={HeadingText.TYPE.HEADING_3} 152 > 153 Oops! Something went wrong. 154 </HeadingText> 155 </CardBody> 156 </Card> 157 ); visualizations/radar-or-treemap/index.js Copy This state value stores the chart type in which you want to show your data. Now that you've created an object which enumerates the chart type options for your visualization, and you've initialized state.selectedChart, you're ready to implement a control UI for switching between the two chart types. Add SegmentedControl components state.selectedChart isn't useful unless your visualization's users can actually select a chart type. Use SegmentedControl and SegmentedControlItem to switch between the two chart types. Tip To learn more about the components available in the New Relic One SDK, go to our Intro to New Relic One SDK. Step 1 of 7 Import SegmentedControl and SegmentedControlItem from nr1: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 render() { 78 const {nrqlQueries, stroke, fill} = this.props; 79 80 const nrqlQueryPropsAvailable = 81 nrqlQueries && 82 nrqlQueries[0] && 83 nrqlQueries[0].accountId && 84 nrqlQueries[0].query; 85 86 if (!nrqlQueryPropsAvailable) { 87 return <EmptyState />; 88 } 89 90 return ( 91 <AutoSizer> 92 {({width, height}) => ( 93 <NrqlQuery 94 query={nrqlQueries[0].query} 95 accountId={parseInt(nrqlQueries[0].accountId)} 96 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 97 > 98 {({data, loading, error}) => { 99 if (loading) { 100 return <Spinner />; 101 } 102 103 if (error) { 104 return <ErrorState />; 105 } 106 107 const transformedData = this.transformData(data); 108 109 return ( 110 <RadarChart 111 width={width} 112 height={height} 113 data={transformedData} 114 > 115 <PolarGrid /> 116 <PolarAngleAxis dataKey=\"name\" /> 117 <PolarRadiusAxis tickFormatter={this.formatTick} /> 118 <Radar 119 dataKey=\"value\" 120 stroke={stroke || '#51C9B7'} 121 fill={fill || '#51C9B7'} 122 fillOpacity={0.6} 123 /> 124 </RadarChart> 125 ); 126 }} 127 </NrqlQuery> 128 )} 129 </AutoSizer> 130 ); 131 } 132 } 133 134 const EmptyState = () => ( 135 <Card className=\"EmptyState\"> 136 <CardBody className=\"EmptyState-cardBody\"> 137 <HeadingText 138 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 139 type={HeadingText.TYPE.HEADING_3} 140 > 141 Please provide at least one NRQL query & account ID pair 142 </HeadingText> 143 <HeadingText 144 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 145 type={HeadingText.TYPE.HEADING_4} 146 > 147 An example NRQL query you can try is: 148 </HeadingText> 149 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 150 </CardBody> 151 </Card> 152 ); 153 154 const ErrorState = () => ( 155 <Card className=\"ErrorState\"> 156 <CardBody className=\"ErrorState-cardBody\"> 157 <HeadingText 158 className=\"ErrorState-headingText\" 159 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 160 type={HeadingText.TYPE.HEADING_3} 161 > 162 Oops! Something went wrong. 163 </HeadingText> 164 </CardBody> 165 </Card> 166 ); visualizations/radar-or-treemap/index.js Copy Step 2 of 7 In render(), wrap RadarChart in a React.Fragment: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 render() { 78 const {nrqlQueries, stroke, fill} = this.props; 79 80 const nrqlQueryPropsAvailable = 81 nrqlQueries && 82 nrqlQueries[0] && 83 nrqlQueries[0].accountId && 84 nrqlQueries[0].query; 85 86 if (!nrqlQueryPropsAvailable) { 87 return <EmptyState />; 88 } 89 90 return ( 91 <AutoSizer> 92 {({width, height}) => ( 93 <NrqlQuery 94 query={nrqlQueries[0].query} 95 accountId={parseInt(nrqlQueries[0].accountId)} 96 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 97 > 98 {({data, loading, error}) => { 99 if (loading) { 100 return <Spinner />; 101 } 102 103 if (error) { 104 return <ErrorState />; 105 } 106 107 const transformedData = this.transformData(data); 108 109 return ( 110 <React.Fragment> 111 <RadarChart 112 width={width} 113 height={height} 114 data={transformedData} 115 > 116 <PolarGrid /> 117 <PolarAngleAxis dataKey=\"name\" /> 118 <PolarRadiusAxis tickFormatter={this.formatTick} /> 119 <Radar 120 dataKey=\"value\" 121 stroke={stroke || '#51C9B7'} 122 fill={fill || '#51C9B7'} 123 fillOpacity={0.6} 124 /> 125 </RadarChart> 126 </React.Fragment> 127 ); 128 }} 129 </NrqlQuery> 130 )} 131 </AutoSizer> 132 ); 133 } 134 } 135 136 const EmptyState = () => ( 137 <Card className=\"EmptyState\"> 138 <CardBody className=\"EmptyState-cardBody\"> 139 <HeadingText 140 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 141 type={HeadingText.TYPE.HEADING_3} 142 > 143 Please provide at least one NRQL query & account ID pair 144 </HeadingText> 145 <HeadingText 146 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 147 type={HeadingText.TYPE.HEADING_4} 148 > 149 An example NRQL query you can try is: 150 </HeadingText> 151 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 152 </CardBody> 153 </Card> 154 ); 155 156 const ErrorState = () => ( 157 <Card className=\"ErrorState\"> 158 <CardBody className=\"ErrorState-cardBody\"> 159 <HeadingText 160 className=\"ErrorState-headingText\" 161 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 162 type={HeadingText.TYPE.HEADING_3} 163 > 164 Oops! Something went wrong. 165 </HeadingText> 166 </CardBody> 167 </Card> 168 ); visualizations/radar-or-treemap/index.js Copy This allows you to return multiple components from the same render(). Step 3 of 7 Add a SegmentedControl and two SegmentedControlItem components, each with a value and a label: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 render() { 78 const {nrqlQueries, stroke, fill} = this.props; 79 80 const nrqlQueryPropsAvailable = 81 nrqlQueries && 82 nrqlQueries[0] && 83 nrqlQueries[0].accountId && 84 nrqlQueries[0].query; 85 86 if (!nrqlQueryPropsAvailable) { 87 return <EmptyState />; 88 } 89 90 return ( 91 <AutoSizer> 92 {({width, height}) => ( 93 <NrqlQuery 94 query={nrqlQueries[0].query} 95 accountId={parseInt(nrqlQueries[0].accountId)} 96 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 97 > 98 {({data, loading, error}) => { 99 if (loading) { 100 return <Spinner />; 101 } 102 103 if (error) { 104 return <ErrorState />; 105 } 106 107 const transformedData = this.transformData(data); 108 109 return ( 110 <React.Fragment> 111 <SegmentedControl 112 onChange={(event, value) => console.log(value)} 113 > 114 <SegmentedControlItem 115 value={CHART_TYPES.Radar} 116 label=\"Radar chart\" 117 /> 118 <SegmentedControlItem 119 value={CHART_TYPES.Treemap} 120 label=\"Treemap chart\" 121 /> 122 </SegmentedControl> 123 <RadarChart 124 width={width} 125 height={height} 126 data={transformedData} 127 > 128 <PolarGrid /> 129 <PolarAngleAxis dataKey=\"name\" /> 130 <PolarRadiusAxis tickFormatter={this.formatTick} /> 131 <Radar 132 dataKey=\"value\" 133 stroke={stroke || '#51C9B7'} 134 fill={fill || '#51C9B7'} 135 fillOpacity={0.6} 136 /> 137 </RadarChart> 138 </React.Fragment> 139 ); 140 }} 141 </NrqlQuery> 142 )} 143 </AutoSizer> 144 ); 145 } 146 } 147 148 const EmptyState = () => ( 149 <Card className=\"EmptyState\"> 150 <CardBody className=\"EmptyState-cardBody\"> 151 <HeadingText 152 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 153 type={HeadingText.TYPE.HEADING_3} 154 > 155 Please provide at least one NRQL query & account ID pair 156 </HeadingText> 157 <HeadingText 158 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 159 type={HeadingText.TYPE.HEADING_4} 160 > 161 An example NRQL query you can try is: 162 </HeadingText> 163 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 164 </CardBody> 165 </Card> 166 ); 167 168 const ErrorState = () => ( 169 <Card className=\"ErrorState\"> 170 <CardBody className=\"ErrorState-cardBody\"> 171 <HeadingText 172 className=\"ErrorState-headingText\" 173 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 174 type={HeadingText.TYPE.HEADING_3} 175 > 176 Oops! Something went wrong. 177 </HeadingText> 178 </CardBody> 179 </Card> 180 ); visualizations/radar-or-treemap/index.js Copy Here, your SegmentedControl logs the SegmentedControlItem.value to the console when you change your selection. The values you've defined for your SegmentedControlItem components correspond to the two CHART_TYPES you created in a previous step. Step 4 of 7 Navigate to the root of your Nerdpack at alternate-viz. Step 5 of 7 Serve your Nerdpack locally: bash Copy $ nr1 nerdpack:serve Step 6 of 7 Open the link to your visualization that's shown in the terminal when the Node server starts: bash Copy Visualizations: ⁎ radar-or-treemap https://one.nr/012ab3cd4Ef Step 7 of 7 Configure your visualization with an account ID and a query: With some required data for your chart to process, you now see a RadarChart with the SegmentedControl at the top of the view. Look at your browser's console to see your SegmentedControl logs: Connect your component's state to the SegmentedControl Add a method to update state and connect that method with the SegmentedControl you added in the last section. Step 1 of 2 Add a component method, called updateSelectedChart(): index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 updateSelectedChart = (evt, value) => { 78 this.setState({ selectedChart: value }) 79 }; 80 81 render() { 82 const {nrqlQueries, stroke, fill} = this.props; 83 84 const nrqlQueryPropsAvailable = 85 nrqlQueries && 86 nrqlQueries[0] && 87 nrqlQueries[0].accountId && 88 nrqlQueries[0].query; 89 90 if (!nrqlQueryPropsAvailable) { 91 return <EmptyState />; 92 } 93 94 return ( 95 <AutoSizer> 96 {({width, height}) => ( 97 <NrqlQuery 98 query={nrqlQueries[0].query} 99 accountId={parseInt(nrqlQueries[0].accountId)} 100 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 101 > 102 {({data, loading, error}) => { 103 if (loading) { 104 return <Spinner />; 105 } 106 107 if (error) { 108 return <ErrorState />; 109 } 110 111 const transformedData = this.transformData(data); 112 113 return ( 114 <React.Fragment> 115 <SegmentedControl 116 onChange={(event, value) => console.log(value)} 117 > 118 <SegmentedControlItem 119 value={CHART_TYPES.Radar} 120 label=\"Radar chart\" 121 /> 122 <SegmentedControlItem 123 value={CHART_TYPES.Treemap} 124 label=\"Treemap chart\" 125 /> 126 </SegmentedControl> 127 <RadarChart 128 width={width} 129 height={height} 130 data={transformedData} 131 > 132 <PolarGrid /> 133 <PolarAngleAxis dataKey=\"name\" /> 134 <PolarRadiusAxis tickFormatter={this.formatTick} /> 135 <Radar 136 dataKey=\"value\" 137 stroke={stroke || '#51C9B7'} 138 fill={fill || '#51C9B7'} 139 fillOpacity={0.6} 140 /> 141 </RadarChart> 142 </React.Fragment> 143 ); 144 }} 145 </NrqlQuery> 146 )} 147 </AutoSizer> 148 ); 149 } 150 } 151 152 const EmptyState = () => ( 153 <Card className=\"EmptyState\"> 154 <CardBody className=\"EmptyState-cardBody\"> 155 <HeadingText 156 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 157 type={HeadingText.TYPE.HEADING_3} 158 > 159 Please provide at least one NRQL query & account ID pair 160 </HeadingText> 161 <HeadingText 162 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 163 type={HeadingText.TYPE.HEADING_4} 164 > 165 An example NRQL query you can try is: 166 </HeadingText> 167 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 168 </CardBody> 169 </Card> 170 ); 171 172 const ErrorState = () => ( 173 <Card className=\"ErrorState\"> 174 <CardBody className=\"ErrorState-cardBody\"> 175 <HeadingText 176 className=\"ErrorState-headingText\" 177 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 178 type={HeadingText.TYPE.HEADING_3} 179 > 180 Oops! Something went wrong. 181 </HeadingText> 182 </CardBody> 183 </Card> 184 ); visualizations/radar-or-treemap/index.js Copy This new method takes a value argument and sets state.selectedChart to that value. Step 2 of 2 Set SegmentedControl.onChange to updateSelectedChart(): index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 updateSelectedChart = (evt, value) => { 78 this.setState({ selectedChart: value }) 79 }; 80 81 render() { 82 const {nrqlQueries, stroke, fill} = this.props; 83 84 const nrqlQueryPropsAvailable = 85 nrqlQueries && 86 nrqlQueries[0] && 87 nrqlQueries[0].accountId && 88 nrqlQueries[0].query; 89 90 if (!nrqlQueryPropsAvailable) { 91 return <EmptyState />; 92 } 93 94 return ( 95 <AutoSizer> 96 {({width, height}) => ( 97 <NrqlQuery 98 query={nrqlQueries[0].query} 99 accountId={parseInt(nrqlQueries[0].accountId)} 100 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 101 > 102 {({data, loading, error}) => { 103 if (loading) { 104 return <Spinner />; 105 } 106 107 if (error) { 108 return <ErrorState />; 109 } 110 111 const transformedData = this.transformData(data); 112 113 return ( 114 <React.Fragment> 115 <SegmentedControl 116 onChange={this.updateSelectedChart} 117 > 118 <SegmentedControlItem 119 value={CHART_TYPES.Radar} 120 label=\"Radar chart\" 121 /> 122 <SegmentedControlItem 123 value={CHART_TYPES.Treemap} 124 label=\"Treemap chart\" 125 /> 126 </SegmentedControl> 127 <RadarChart 128 width={width} 129 height={height} 130 data={transformedData} 131 > 132 <PolarGrid /> 133 <PolarAngleAxis dataKey=\"name\" /> 134 <PolarRadiusAxis tickFormatter={this.formatTick} /> 135 <Radar 136 dataKey=\"value\" 137 stroke={stroke || '#51C9B7'} 138 fill={fill || '#51C9B7'} 139 fillOpacity={0.6} 140 /> 141 </RadarChart> 142 </React.Fragment> 143 ); 144 }} 145 </NrqlQuery> 146 )} 147 </AutoSizer> 148 ); 149 } 150 } 151 152 const EmptyState = () => ( 153 <Card className=\"EmptyState\"> 154 <CardBody className=\"EmptyState-cardBody\"> 155 <HeadingText 156 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 157 type={HeadingText.TYPE.HEADING_3} 158 > 159 Please provide at least one NRQL query & account ID pair 160 </HeadingText> 161 <HeadingText 162 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 163 type={HeadingText.TYPE.HEADING_4} 164 > 165 An example NRQL query you can try is: 166 </HeadingText> 167 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 168 </CardBody> 169 </Card> 170 ); 171 172 const ErrorState = () => ( 173 <Card className=\"ErrorState\"> 174 <CardBody className=\"ErrorState-cardBody\"> 175 <HeadingText 176 className=\"ErrorState-headingText\" 177 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 178 type={HeadingText.TYPE.HEADING_3} 179 > 180 Oops! Something went wrong. 181 </HeadingText> 182 </CardBody> 183 </Card> 184 ); visualizations/radar-or-treemap/index.js Copy Now, when you change your selection in the SegmentedControl, your selection will be set in state. Implement a Treemap option Add a Treemap to your visualization. This map will be an alternative to the existing RadarChart. Technical detail This guide uses Recharts components for third-party charts, but you can use any other JavaScript charting libraries that are compatible with the current React version when you build New Relic One visualizations and apps. Step 1 of 3 Import Treemap from recharts: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 'Radar': 'radar', 24 'Treemap': 'treemap' 25 } 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 state = { 55 selectedChart: CHART_TYPES.Radar, 56 }; 57 58 /** 59 * Restructure the data for a non-time-series, facet-based NRQL query into a 60 * form accepted by the Recharts library's RadarChart. 61 * (https://recharts.org/api/RadarChart). 62 */ 63 transformData = (rawData) => { 64 return rawData.map((entry) => ({ 65 name: entry.metadata.name, 66 // Only grabbing the first data value because this is not time-series data. 67 value: entry.data[0].y, 68 })); 69 }; 70 71 /** 72 * Format the given axis tick's numeric value into a string for display. 73 */ 74 formatTick = (value) => { 75 return value.toLocaleString(); 76 }; 77 78 updateSelectedChart = (evt, value) => { 79 this.setState({ selectedChart: value }) 80 }; 81 82 render() { 83 const {nrqlQueries, stroke, fill} = this.props; 84 85 const nrqlQueryPropsAvailable = 86 nrqlQueries && 87 nrqlQueries[0] && 88 nrqlQueries[0].accountId && 89 nrqlQueries[0].query; 90 91 if (!nrqlQueryPropsAvailable) { 92 return <EmptyState />; 93 } 94 95 return ( 96 <AutoSizer> 97 {({width, height}) => ( 98 <NrqlQuery 99 query={nrqlQueries[0].query} 100 accountId={parseInt(nrqlQueries[0].accountId)} 101 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 102 > 103 {({data, loading, error}) => { 104 if (loading) { 105 return <Spinner />; 106 } 107 108 if (error) { 109 return <ErrorState />; 110 } 111 112 const transformedData = this.transformData(data); 113 114 return ( 115 <React.Fragment> 116 <SegmentedControl 117 onChange={this.updateSelectedChart} 118 > 119 <SegmentedControlItem 120 value={CHART_TYPES.Radar} 121 label=\"Radar chart\" 122 /> 123 <SegmentedControlItem 124 value={CHART_TYPES.Treemap} 125 label=\"Treemap chart\" 126 /> 127 </SegmentedControl> 128 <RadarChart 129 width={width} 130 height={height} 131 data={transformedData} 132 > 133 <PolarGrid /> 134 <PolarAngleAxis dataKey=\"name\" /> 135 <PolarRadiusAxis tickFormatter={this.formatTick} /> 136 <Radar 137 dataKey=\"value\" 138 stroke={stroke || '#51C9B7'} 139 fill={fill || '#51C9B7'} 140 fillOpacity={0.6} 141 /> 142 </RadarChart> 143 </React.Fragment> 144 ); 145 }} 146 </NrqlQuery> 147 )} 148 </AutoSizer> 149 ); 150 } 151 } 152 153 const EmptyState = () => ( 154 <Card className=\"EmptyState\"> 155 <CardBody className=\"EmptyState-cardBody\"> 156 <HeadingText 157 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 158 type={HeadingText.TYPE.HEADING_3} 159 > 160 Please provide at least one NRQL query & account ID pair 161 </HeadingText> 162 <HeadingText 163 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 164 type={HeadingText.TYPE.HEADING_4} 165 > 166 An example NRQL query you can try is: 167 </HeadingText> 168 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 169 </CardBody> 170 </Card> 171 ); 172 173 const ErrorState = () => ( 174 <Card className=\"ErrorState\"> 175 <CardBody className=\"ErrorState-cardBody\"> 176 <HeadingText 177 className=\"ErrorState-headingText\" 178 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 179 type={HeadingText.TYPE.HEADING_3} 180 > 181 Oops! Something went wrong. 182 </HeadingText> 183 </CardBody> 184 </Card> 185 ); visualizations/radar-or-treemap/index.js Copy Now, you can use Treemap in your visualization component. Step 2 of 3 In render(), add a Treemap component: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 'Radar': 'radar', 24 'Treemap': 'treemap' 25 } 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 state = { 55 selectedChart: CHART_TYPES.Radar, 56 }; 57 58 /** 59 * Restructure the data for a non-time-series, facet-based NRQL query into a 60 * form accepted by the Recharts library's RadarChart. 61 * (https://recharts.org/api/RadarChart). 62 */ 63 transformData = (rawData) => { 64 return rawData.map((entry) => ({ 65 name: entry.metadata.name, 66 // Only grabbing the first data value because this is not time-series data. 67 value: entry.data[0].y, 68 })); 69 }; 70 71 /** 72 * Format the given axis tick's numeric value into a string for display. 73 */ 74 formatTick = (value) => { 75 return value.toLocaleString(); 76 }; 77 78 updateSelectedChart = (evt, value) => { 79 this.setState({ selectedChart: value }) 80 }; 81 82 render() { 83 const {nrqlQueries, stroke, fill} = this.props; 84 85 const nrqlQueryPropsAvailable = 86 nrqlQueries && 87 nrqlQueries[0] && 88 nrqlQueries[0].accountId && 89 nrqlQueries[0].query; 90 91 if (!nrqlQueryPropsAvailable) { 92 return <EmptyState />; 93 } 94 95 return ( 96 <AutoSizer> 97 {({width, height}) => ( 98 <NrqlQuery 99 query={nrqlQueries[0].query} 100 accountId={parseInt(nrqlQueries[0].accountId)} 101 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 102 > 103 {({data, loading, error}) => { 104 if (loading) { 105 return <Spinner />; 106 } 107 108 if (error) { 109 return <ErrorState />; 110 } 111 112 const transformedData = this.transformData(data); 113 114 return ( 115 <React.Fragment> 116 <SegmentedControl 117 onChange={this.updateSelectedChart} 118 > 119 <SegmentedControlItem 120 value={CHART_TYPES.Radar} 121 label=\"Radar chart\" 122 /> 123 <SegmentedControlItem 124 value={CHART_TYPES.Treemap} 125 label=\"Treemap chart\" 126 /> 127 </SegmentedControl> 128 <RadarChart 129 width={width} 130 height={height} 131 data={transformedData} 132 > 133 <PolarGrid /> 134 <PolarAngleAxis dataKey=\"name\" /> 135 <PolarRadiusAxis tickFormatter={this.formatTick} /> 136 <Radar 137 dataKey=\"value\" 138 stroke={stroke || '#51C9B7'} 139 fill={fill || '#51C9B7'} 140 fillOpacity={0.6} 141 /> 142 </RadarChart> 143 <Treemap 144 width={width} 145 height={height} 146 data={transformedData} 147 dataKey=\"value\" 148 ratio={4 / 3} 149 stroke={stroke || '#000000'} 150 fill={fill || '#51C9B7'} 151 /> 152 </React.Fragment> 153 ); 154 }} 155 </NrqlQuery> 156 )} 157 </AutoSizer> 158 ); 159 } 160 } 161 162 const EmptyState = () => ( 163 <Card className=\"EmptyState\"> 164 <CardBody className=\"EmptyState-cardBody\"> 165 <HeadingText 166 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 167 type={HeadingText.TYPE.HEADING_3} 168 > 169 Please provide at least one NRQL query & account ID pair 170 </HeadingText> 171 <HeadingText 172 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 173 type={HeadingText.TYPE.HEADING_4} 174 > 175 An example NRQL query you can try is: 176 </HeadingText> 177 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 178 </CardBody> 179 </Card> 180 ); 181 182 const ErrorState = () => ( 183 <Card className=\"ErrorState\"> 184 <CardBody className=\"ErrorState-cardBody\"> 185 <HeadingText 186 className=\"ErrorState-headingText\" 187 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 188 type={HeadingText.TYPE.HEADING_3} 189 > 190 Oops! Something went wrong. 191 </HeadingText> 192 </CardBody> 193 </Card> 194 ); visualizations/radar-or-treemap/index.js Copy Here, you've defined a new Treemap component with some props, including height, width, fill, and stroke. Step 3 of 3 With your Nerdpack served locally, view your visualization. The SegmentedControl and RadarChart are at the top of the view, but if you scroll down, you'll see your new Treemap: Switch between charts with your component's state Use state.selectedChart to determine which chart to show: the RadarChart or the Treemap. Step 1 of 1 Destructure this.state to access selectedChart as a separate constant. Then, compare selectedChart to CHART_TYPES.Radar. If they are the same, render a RadarChart. Otherwise, render a Treemap: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 'Radar': 'radar', 24 'Treemap': 'treemap' 25 } 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 state = { 55 selectedChart: CHART_TYPES.Radar, 56 }; 57 58 /** 59 * Restructure the data for a non-time-series, facet-based NRQL query into a 60 * form accepted by the Recharts library's RadarChart. 61 * (https://recharts.org/api/RadarChart). 62 */ 63 transformData = (rawData) => { 64 return rawData.map((entry) => ({ 65 name: entry.metadata.name, 66 // Only grabbing the first data value because this is not time-series data. 67 value: entry.data[0].y, 68 })); 69 }; 70 71 /** 72 * Format the given axis tick's numeric value into a string for display. 73 */ 74 formatTick = (value) => { 75 return value.toLocaleString(); 76 }; 77 78 updateSelectedChart = (evt, value) => { 79 this.setState({ selectedChart: value }) 80 }; 81 82 render() { 83 const {nrqlQueries, stroke, fill} = this.props; 84 const {selectedChart} = this.state; 85 86 const nrqlQueryPropsAvailable = 87 nrqlQueries && 88 nrqlQueries[0] && 89 nrqlQueries[0].accountId && 90 nrqlQueries[0].query; 91 92 if (!nrqlQueryPropsAvailable) { 93 return <EmptyState />; 94 } 95 96 return ( 97 <AutoSizer> 98 {({width, height}) => ( 99 <NrqlQuery 100 query={nrqlQueries[0].query} 101 accountId={parseInt(nrqlQueries[0].accountId)} 102 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 103 > 104 {({data, loading, error}) => { 105 if (loading) { 106 return <Spinner />; 107 } 108 109 if (error) { 110 return <ErrorState />; 111 } 112 113 const transformedData = this.transformData(data); 114 115 return ( 116 <React.Fragment> 117 <SegmentedControl 118 onChange={this.updateSelectedChart} 119 > 120 <SegmentedControlItem 121 value={CHART_TYPES.Radar} 122 label=\"Radar chart\" 123 /> 124 <SegmentedControlItem 125 value={CHART_TYPES.Treemap} 126 label=\"Treemap chart\" 127 /> 128 </SegmentedControl> 129 {selectedChart === CHART_TYPES.Radar ? ( 130 <RadarChart 131 width={width} 132 height={height} 133 data={transformedData} 134 > 135 <PolarGrid /> 136 <PolarAngleAxis dataKey=\"name\" /> 137 <PolarRadiusAxis tickFormatter={this.formatTick} /> 138 <Radar 139 dataKey=\"value\" 140 stroke={stroke || '#51C9B7'} 141 fill={fill || '#51C9B7'} 142 fillOpacity={0.6} 143 /> 144 </RadarChart> 145 ) : ( 146 <Treemap 147 width={width} 148 height={height} 149 data={transformedData} 150 dataKey=\"value\" 151 ratio={4 / 3} 152 stroke={stroke || '#000000'} 153 fill={fill || '#51C9B7'} 154 /> 155 )} 156 </React.Fragment> 157 ); 158 }} 159 </NrqlQuery> 160 )} 161 </AutoSizer> 162 ); 163 } 164 } 165 166 const EmptyState = () => ( 167 <Card className=\"EmptyState\"> 168 <CardBody className=\"EmptyState-cardBody\"> 169 <HeadingText 170 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 171 type={HeadingText.TYPE.HEADING_3} 172 > 173 Please provide at least one NRQL query & account ID pair 174 </HeadingText> 175 <HeadingText 176 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 177 type={HeadingText.TYPE.HEADING_4} 178 > 179 An example NRQL query you can try is: 180 </HeadingText> 181 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 182 </CardBody> 183 </Card> 184 ); 185 186 const ErrorState = () => ( 187 <Card className=\"ErrorState\"> 188 <CardBody className=\"ErrorState-cardBody\"> 189 <HeadingText 190 className=\"ErrorState-headingText\" 191 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 192 type={HeadingText.TYPE.HEADING_3} 193 > 194 Oops! Something went wrong. 195 </HeadingText> 196 </CardBody> 197 </Card> 198 ); visualizations/radar-or-treemap/index.js Copy Here, you used a ternary expression to render a RadarChart or a Treemap. The rendered chart is determined by the value of selectedChart. With your Nerdpack served locally, view your visualization. Select Radar chart from the SegmentedControl: Select Treemap chart from the SegmentedControl: Summary Congratulations! In this lesson, you learned how to: Customize your visualization using New Relic One SDK components Add a new chart type to your visualization Create a user interaction in your visualization Course This lesson is part of a course that teaches you how to build a custom visualization in the New Relic One platform. When you're ready, continue on to the next lesson: Customize visualizations with configuration.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 381.56836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Switch between <em>charts</em> with your component&#x27;s state",
        "body": " spacing<em>Type</em>={[HeadingText.SPACING_<em>TYPE</em>.LARGE]} 147 <em>type</em>={HeadingText.<em>TYPE</em>.HEADING_3} 148 &gt; 149 Oops! Something went wrong. 150 &lt;&#x2F;HeadingText&gt; 151 &lt;&#x2F;CardBody&gt; 152 &lt;&#x2F;Card&gt; 153 ); visualizations&#x2F;radar-or-treemap&#x2F;index.js Copy <em>CHART_TYPES</em> enumerates the two <em>chart</em> <em>types</em> you&#x27;ll alternate between in your"
      },
      "id": "6091fa3b196a679beed52a6b"
    }
  ],
  "/docs/query-your-data/explore-query-data/use-charts/use-your-charts": [
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data",
        "Recover deleted dashboard"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2022-01-12T10:18:18Z",
      "updated_at": "2021-12-30T20:48:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options. Recover deleted dashboard If you accidentally deleted your dashboard, you can quickly restore it with NerdGraph. To learn how, read the Explorers Hub post, or watch this short video (2:13 minutes).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.25797,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Manage <em>your</em> <em>charts</em> <em>and</em> markdown content",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One dashboards to create or manage <em>your</em> <em>charts</em> directly from the <em>chart</em> menu, customize <em>your</em> dashboard&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> dashboard and built <em>your</em> <em>charts</em>, <em>use</em> our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Use advanced (NRQL) mode to query data",
        "Compare advanced (NRQL) mode query with basic mode specification",
        "Important",
        "Notes about advanced (NRQL) mode"
      ],
      "title": "Use advanced (NRQL) mode to query data",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "9abf8d760b8e1dacd1a1b2b0556f8fa7f92080f5",
      "image": "https://docs.newrelic.com/static/7db331ae854429d71dc7112a168594a2/69538/inline-advanced-nrql_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/use-advanced-nrql-mode-query-data/",
      "published_at": "2022-01-12T05:02:46Z",
      "updated_at": "2021-12-30T20:50:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "While basic mode is an excellent choice for creating charts without needing to know how to write queries, working in advanced (NRQL) mode offers more power and additional features. Any data specified in basic mode can be written as an NRQL query in advanced (NRQL) mode. To see what your basic mode data specification looks like as an NRQL query, click the Advanced (NRQL) link from the basic page. Example of an advanced (NRQL) query. Compare advanced (NRQL) mode query with basic mode specification When you switch from basic mode to advanced (NRQL) mode, the query you see produces the exact same chart as the basic data specification. Important If your query was started using basic mode and if you make changes to that query using advanced (NRQL) mode, you cannot return to basic mode to edit that query. Any additional changes may only be made in advanced (NRQL) mode. Use this table to understand how basic mode specifications correspond to the equivalent NRQL query. To set this In basic mode, you enter ... In advanced (NRQL) mode, you write ... The event type, attribute, and function on that attribute View a chart with Transaction : Name : unique_count SELECT uniqueCount(name) FROM Transaction Narrowing your results to show only those transactions with a 404 page not found error Narrow results to httpResponseCode='404' WHERE httpResponseCode = '404' Enable a preliminary timeline view not needed in basic mode TIMESERIES — enables line chart type (required for initial chart view) To see a separate value for each application with a 404 error Facet by appName FACET `appName` To view the five applications with the most 404 errors Limit 5 — default value is 10 LIMIT 5 To view errors over the last three hours Select Last 3 hrs — converted to seconds in NRQL query SINCE 10800 seconds ago To enhance the results of sampling transaction data This feature is run automatically in basic mode EXTRAPOLATE Notes about advanced (NRQL) mode Queries written directly in NRQL can be more complex than queries written in basic mode. For example, to learn how to create widgets with multiple NRQL queries, watch this short video (3:40 minutes). The NRQL documentation contains both reference information and query examples. This table identifies some additional items to keep in mind. Item Description Prompts For each statement or function in your query, you can view a list of valid options, with tooltips. Example of a prompt in advanced (NRQL) mode. Events You can use multiple event types in an NRQL query. Attributes You can use multiple attributes per event type in an NRQL query. View previous queries Once you run an NRQL query, use the My recent queries dropdown to view up the last 1,000 queries that you ran. The dropdown has a search box to help you find your query. Working with basic mode and NRQL If you start creating a chart using basic mode and then switch to advanced (NRQL), be aware that if you make any changes to the NRQL query, you will lose those changes in basic mode. Autocompleter The query builder’s autocompleter will display events and attributes reported within the last 60 minutes. An example of this is a process that runs once a day, such as a standard system health check that kicks off every morning at 6:00am. If you attempt to query the event at 7:05am, the event and subsequent attributes will not be visible in the autocomplete dropdown. These events and attributes are still queryable by typing the exact string. Multi query When using the TIMESERIES clause you can run and compare up to 10 queries from different accounts. To use multi query, enter your first query with TIMESERIES and run it. Once the results are rendered, the Add another query button is activated and you can add another query.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.93307,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> advanced (NRQL) mode to <em>query</em> <em>data</em>",
        "sections": "<em>Use</em> advanced (NRQL) mode to <em>query</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " <em>chart</em> as the basic <em>data</em> specification. Important If <em>your</em> <em>query</em> was started using basic mode and if you make changes to that <em>query</em> using advanced (NRQL) mode, you cannot return to basic mode to edit that <em>query</em>. Any additional changes may only be made in advanced (NRQL) mode. <em>Use</em> this table"
      },
      "id": "603ea876196a67cc1fa83dd5"
    },
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2022-01-12T05:59:40Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.2265,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Why <em>use</em> facet filtering?",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " on an existing dashboard. To see this feature in action, see the example <em>use</em> case. Requirements Requirements to <em>use</em> this feature: Must be in New Relic One dashboards. Will not work on a standalone <em>chart</em> in the <em>query</em> builder. NRQL <em>query</em> must contain a FACET clause. Available only for bar <em>charts</em>, heat maps"
      },
      "id": "60445d1e28ccbc23082c60af"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2022-01-12T11:33:08Z",
      "updated_at": "2021-12-30T17:52:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. When using NRQL, you can set a UTC timestamp or a relative time range: Timestamps use the format YYYY-MM-DD HH:MM:SS ZZZZ. For instance, FROM Transaction SELECT count(*) SINCE '2021-12-25 00:00:00 +0000' UNTIL '2021-12-25 23:59:59 +0000'. We support the following relative time ranges: YESTERDAY, TODAY, SUNDAY, MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY. For example, SINCE YESTERDAY UNTIL NOW. We also support YEAR, QUARTER, MONTH, WEEK, DAY, HOUR, MINUTE, SECOND. For these cases, you can combine SINCE with THIS or LAST. For instance, SINCE LAST MONTH UNTIL THIS WEEK. You can also include AGO, as in SINCE 3 WEEKS AGO UNTIL 10 MINUTES AGO. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Or, watch this short video (approx. 3:20 minutes). Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 279.9357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> metric <em>data</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL math using SELECT",
        "Use basic math operators with SELECT",
        "Use advanced math operators with SELECT",
        "abs",
        "clamp_max, clamp_min",
        "exp",
        "Logarithmic functions: ln, log, log2, log10",
        "pow",
        "pow(n, m) computes n raised to the power m. (I.e. n * n * ... * n, with m copies of n)",
        "Rounding functions: round, floor, ceil",
        "sqrt",
        "Results with STRING or FLOAT",
        "Tip"
      ],
      "title": "NRQL math using SELECT",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "99bfd8fb7663a1c589160ea026ff585acf9d4023",
      "image": "https://docs.newrelic.com/static/8bfef938a82b9feb0fc18864699f176a/c1b63/clamp.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select/",
      "published_at": "2022-01-12T10:19:24Z",
      "updated_at": "2021-11-13T23:43:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL supports the use of basic and advanced mathematical operators within a SELECT clause. You can apply mathematical calculations on both individual attributes and also the results of aggregator functions. Use basic math operators with SELECT To use basic math functions in NRQL, include operators within the SELECT clause: Addition: + Subtraction: - Multiplication: * Division: / Here are some examples: SELECT duration-databaseDuration FROM Transaction Copy SELECT count(*)/uniqueCount(session) FROM PageView Copy SELECT average(duration-databaseDuration) FROM Transaction Copy Use advanced math operators with SELECT NRQL also includes some advanced mathematical capabilities that can be used for complex calculations. This is helpful if you want to process data to display it more effectively in the UI, or make statistical or psychometric calculations on queried results in a single step. abs abs(n) returns the absolute value of n. For non-negative n it returns n, and for negative n it returns the positive number -n. For example abs(2) = 2, and abs(-4) = 4. clamp_max, clamp_min The clamping functions impose an upper or lower bound on values. For example, clamp_max(duration, 10) returns the duration, unless it exceeds 10, in which case 10 is returned. Similarly clamp_min(duration, 1) will not return any value lower than 1. The following chart shows the result of clamping both min and max to keep the value in the range 70-90. Sample graph showing raw data with clamp function applied. exp Computes the natural exponential function of the argument: exp(n) = pow(e, n). Logarithmic functions: ln, log, log2, log10 These functions compute the logarithm of the argument for various bases. ln(n) computes the natural logarithm: the logarithm base e. log2(n) computes the logarithm base 2. log10(n) computes the logarithm base 10. log(n, b) allows logarithms to be computed with an arbitrary base b. All logarithms satisfy the identity: log(pow(b, n), b) = n. Note that log(0) is undefined, for all bases. Be aware that if you take the logarithm of something that might be zero, you may end up getting no value back from your query. pow pow(n, m) computes n raised to the power m. (I.e. n * n * ... * n, with m copies of n) abs(n) returns the absolute value of n. For non-negative n it returns n, and for negative n it returns the positive number -n. For example abs(2) = 2 and abs(-4) = 4. Rounding functions: round, floor, ceil These three functions force decimal numbers to one of the neighboring integers. floor(n) returns the closest integer less than or equal to n. ceil(n) (short for \"ceiling\") returns the closest integer greater than or equal to n. round(n) returns the closest integer to n in either direction. Sample graph showing raw data, with floor, round, and ceiling functions applied. sqrt sqrt(n) returns the square root of n, that is, the number such that sqrt(n) * sqrt(n) = n. Results with STRING or FLOAT Here is how NRQL handles strings present in math calculations: pow(n, m) computes n raised to the power m. (for example, n * n * ... * n, with m copies of n) Examples: sum(1+STRING) = 0 sum(1+MIXED) = skips records where MIXED is a string average(1+STRING) = 0 average(1+MIXED) = skips records where MIXED is a string NULL and zero both appear as 0 in the dashboard. To override NULL values with another numeric value, use the syntax: SELECT average(purchasePrice OR 0) Copy This will replace NULL values with 0 or any number specified. Tip This can also be used to test whether something returns NULL or zero. (zero) OR 1 returns 0. (NULL) OR 1 returns 1.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.30988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> math using SELECT",
        "sections": "<em>NRQL</em> math using SELECT",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": " operators with SELECT <em>NRQL</em> also includes some advanced mathematical capabilities that can be used for complex calculations. This is helpful if you want to process <em>data</em> to display it more effectively in the UI, or make statistical or psychometric calculations on queried results in a single step. abs"
      },
      "id": "603ec31864441f942b4e884c"
    },
    {
      "sections": [
        "Introduction to New Relic",
        "Get started with New Relic",
        "All the answers in one place",
        "Bring all your data together",
        "Analyze your data",
        "Respond to incidents faster",
        "Troubleshoot from anywhere in your stack"
      ],
      "title": "Introduction to New Relic",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "f47a40a9afd699e69c351f5e87f64ed5dadd7e43",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/intro-new-relic/",
      "published_at": "2022-01-12T18:27:10Z",
      "updated_at": "2022-01-12T18:27:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic is an observability platform that helps you build better software. You can bring in data from any digital source so that you can fully understand your system and how to improve it. This short video shows twenty of the most common ways to get your data into New Relic (approx. 5:22 minutes): With New Relic, you can: Bring all your data together: Instrument everything and import data from across your technology stack using our agents, integrations, and APIs, and access it from a single UI. Analyze your data: Get all your data at your fingertips to find the root causes of problems and optimize your systems. Build dashboards and charts or use our powerful query language. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. Get started with New Relic Here's how you can quickly get started capturing and analyzing your data: If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever! Follow the steps in our Add your data UI page to get data flowing in. For your first install, we recommend the Guided install option, which will set up many integrations with a single command. Once you have data coming into New Relic, learn more about the New Relic UI or set up Alerts. All the answers in one place New Relic is built for full stack observability. It links all relevant data so that you get the whole picture of everything that enables your systems to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Monitoring vs. observability: New Relic provides answers to essential questions in one place. As just one example of what you can do with New Relic, imagine you are a Kubernetes administrator overseeing many clusters and pods of software containers. Where do you start troubleshooting? This short video shows how you can locate a problem cluster and use distributed tracing to find relevant logs: Bring all your data together Capture, organize, and make sense of your data in New Relic One, no matter where it comes from. Use our agents and integrations to automatically collect data from common frameworks and tools, or use our APIs for data that’s more specific to your business or technology. If you don't see your technologies or tasks listed here, see a larger list at New Relic Instant Observability. There you will find integrations bundled into quickstarts, providing you instant access to pre-built dashboards and alerts specific to your technology. If you want to... New Relic can help you... Instrument your application Instrument your code: Use our APM agents to automatically instrument your applications in C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Track transactions: Gather distributed tracing details as your transactions cross boundaries between apps and services. Instrument your environment Instrument your infrastructure: Observe your entire environment (including Linux, Windows, AWS, Azure, Google Cloud Platform, Kubernetes, Docker, and more). Collect and centralize logs: See your log data in context with your other application and infrastructure data. Save time switching between tools and reach solutions more quickly. Instrument your digital experiences Enhance browser performance: Decrease page load times, as well as triage and eliminate errors. Monitor mobile apps: Troubleshoot crashes and check the health of your Android and iOS apps with our mobile agents. Simulate user activity: Ensure you’re meeting customer expectations by running automated checks to monitor key user flows and experiences. Send data via APIs or build your own solution Collect data without an agent: Call our APIs directly if you prefer to use OpenTelemetry or other agents. Build your own integration: You can use our Flex tool, or one of language-specific SDKs for creating your own exporters to send data to New Relic. New Relic One gives you access to a wide range of observability tools, including: Application monitoring Browser monitoring Mobile monitoring Synthetic monitoring Serverless monitoring Infrastructure monitoring Log management You can start anywhere, but you'll never get lost. True observability across your entire stack means that you're in control. Analyze your data With your data secure at New Relic, our platform can alert you to problems and help you organize, process, and understand your data, whether it's metrics, events, logs, or traces: Explore your data visually: Jump into our data explorer to navigate all your data and make connections between your entities without any knowledge of query languages. Query and visualize your data: Use our curated dashboard visualizations or create your own. Use NRQL (New Relic Query Language) to slice and dice your data and dig deeper into questions. Query your data programmatically: Access your data through our NerdGraph GraphQL API. Easily prototype queries in our GraphiQL editor. Respond to incidents faster DevOps, site-reliability, and network operation teams need reliable, real-time alerts and anomaly detection to ensure their systems are always up and running efficiently. Let Applied Intelligence, our hybrid machine learning engine, automatically detect anomalies, reduce alert noise, and enrich incidents with context so that you can respond faster to incidents. Proactive detection: Be notified of unusual app behavior and get an analysis of this unusual behavior sent to Slack. Not using Slack? Set up a webhook to deliver messages when you need them. Get notifications: Set up alerts across your data sources and get notified when systems need your attention. Preserve your attention and control how many threshold violations should fire before you're notified. Troubleshoot from anywhere in your stack Being fully connected, the New Relic UI allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but they can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.66902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " and optimize <em>your</em> systems. Build dashboards and charts or use our powerful <em>query</em> <em>language</em>. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. <em>Get</em> <em>started</em> with <em>New</em> <em>Relic</em> Here&#x27;s how you can quickly <em>get</em> <em>started</em>"
      },
      "id": "619d5b3e196a6705bda0837d"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2022-01-12T11:33:08Z",
      "updated_at": "2021-12-30T17:52:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. When using NRQL, you can set a UTC timestamp or a relative time range: Timestamps use the format YYYY-MM-DD HH:MM:SS ZZZZ. For instance, FROM Transaction SELECT count(*) SINCE '2021-12-25 00:00:00 +0000' UNTIL '2021-12-25 23:59:59 +0000'. We support the following relative time ranges: YESTERDAY, TODAY, SUNDAY, MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY. For example, SINCE YESTERDAY UNTIL NOW. We also support YEAR, QUARTER, MONTH, WEEK, DAY, HOUR, MINUTE, SECOND. For these cases, you can combine SINCE with THIS or LAST. For instance, SINCE LAST MONTH UNTIL THIS WEEK. You can also include AGO, as in SINCE 3 WEEKS AGO UNTIL 10 MINUTES AGO. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Or, watch this short video (approx. 3:20 minutes). Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 279.93567,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> metric <em>data</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2022-01-12T10:19:25Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.58267,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": ", clauses, and functions. Ready to <em>get</em> <em>started</em>? If you haven&#x27;t already, be sure to sign up for a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. What is <em>NRQL</em>? <em>NRQL</em> is <em>New</em> <em>Relic</em>&#x27;s SQL-like <em>query</em> <em>language</em>. You can use <em>NRQL</em> to retrieve detailed <em>New</em> <em>Relic</em> <em>data</em> and <em>get</em> insight into <em>your</em> applications, hosts"
      },
      "id": "60445a0e196a67cb09960f6e"
    },
    {
      "sections": [
        "Introduction to New Relic",
        "Get started with New Relic",
        "All the answers in one place",
        "Bring all your data together",
        "Analyze your data",
        "Respond to incidents faster",
        "Troubleshoot from anywhere in your stack"
      ],
      "title": "Introduction to New Relic",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "f47a40a9afd699e69c351f5e87f64ed5dadd7e43",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/intro-new-relic/",
      "published_at": "2022-01-12T18:27:10Z",
      "updated_at": "2022-01-12T18:27:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic is an observability platform that helps you build better software. You can bring in data from any digital source so that you can fully understand your system and how to improve it. This short video shows twenty of the most common ways to get your data into New Relic (approx. 5:22 minutes): With New Relic, you can: Bring all your data together: Instrument everything and import data from across your technology stack using our agents, integrations, and APIs, and access it from a single UI. Analyze your data: Get all your data at your fingertips to find the root causes of problems and optimize your systems. Build dashboards and charts or use our powerful query language. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. Get started with New Relic Here's how you can quickly get started capturing and analyzing your data: If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever! Follow the steps in our Add your data UI page to get data flowing in. For your first install, we recommend the Guided install option, which will set up many integrations with a single command. Once you have data coming into New Relic, learn more about the New Relic UI or set up Alerts. All the answers in one place New Relic is built for full stack observability. It links all relevant data so that you get the whole picture of everything that enables your systems to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Monitoring vs. observability: New Relic provides answers to essential questions in one place. As just one example of what you can do with New Relic, imagine you are a Kubernetes administrator overseeing many clusters and pods of software containers. Where do you start troubleshooting? This short video shows how you can locate a problem cluster and use distributed tracing to find relevant logs: Bring all your data together Capture, organize, and make sense of your data in New Relic One, no matter where it comes from. Use our agents and integrations to automatically collect data from common frameworks and tools, or use our APIs for data that’s more specific to your business or technology. If you don't see your technologies or tasks listed here, see a larger list at New Relic Instant Observability. There you will find integrations bundled into quickstarts, providing you instant access to pre-built dashboards and alerts specific to your technology. If you want to... New Relic can help you... Instrument your application Instrument your code: Use our APM agents to automatically instrument your applications in C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Track transactions: Gather distributed tracing details as your transactions cross boundaries between apps and services. Instrument your environment Instrument your infrastructure: Observe your entire environment (including Linux, Windows, AWS, Azure, Google Cloud Platform, Kubernetes, Docker, and more). Collect and centralize logs: See your log data in context with your other application and infrastructure data. Save time switching between tools and reach solutions more quickly. Instrument your digital experiences Enhance browser performance: Decrease page load times, as well as triage and eliminate errors. Monitor mobile apps: Troubleshoot crashes and check the health of your Android and iOS apps with our mobile agents. Simulate user activity: Ensure you’re meeting customer expectations by running automated checks to monitor key user flows and experiences. Send data via APIs or build your own solution Collect data without an agent: Call our APIs directly if you prefer to use OpenTelemetry or other agents. Build your own integration: You can use our Flex tool, or one of language-specific SDKs for creating your own exporters to send data to New Relic. New Relic One gives you access to a wide range of observability tools, including: Application monitoring Browser monitoring Mobile monitoring Synthetic monitoring Serverless monitoring Infrastructure monitoring Log management You can start anywhere, but you'll never get lost. True observability across your entire stack means that you're in control. Analyze your data With your data secure at New Relic, our platform can alert you to problems and help you organize, process, and understand your data, whether it's metrics, events, logs, or traces: Explore your data visually: Jump into our data explorer to navigate all your data and make connections between your entities without any knowledge of query languages. Query and visualize your data: Use our curated dashboard visualizations or create your own. Use NRQL (New Relic Query Language) to slice and dice your data and dig deeper into questions. Query your data programmatically: Access your data through our NerdGraph GraphQL API. Easily prototype queries in our GraphiQL editor. Respond to incidents faster DevOps, site-reliability, and network operation teams need reliable, real-time alerts and anomaly detection to ensure their systems are always up and running efficiently. Let Applied Intelligence, our hybrid machine learning engine, automatically detect anomalies, reduce alert noise, and enrich incidents with context so that you can respond faster to incidents. Proactive detection: Be notified of unusual app behavior and get an analysis of this unusual behavior sent to Slack. Not using Slack? Set up a webhook to deliver messages when you need them. Get notifications: Set up alerts across your data sources and get notified when systems need your attention. Preserve your attention and control how many threshold violations should fire before you're notified. Troubleshoot from anywhere in your stack Being fully connected, the New Relic UI allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but they can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.66887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " and optimize <em>your</em> systems. Build dashboards and charts or use our powerful <em>query</em> <em>language</em>. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. <em>Get</em> <em>started</em> with <em>New</em> <em>Relic</em> Here&#x27;s how you can quickly <em>get</em> <em>started</em>"
      },
      "id": "619d5b3e196a6705bda0837d"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions": [
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2022-01-12T10:19:25Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.19603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": ", clauses, and functions. Ready to <em>get</em> <em>started</em>? If you haven&#x27;t already, be sure to sign up for a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. What is <em>NRQL</em>? <em>NRQL</em> is <em>New</em> <em>Relic</em>&#x27;s SQL-like <em>query</em> <em>language</em>. You can use <em>NRQL</em> to retrieve detailed <em>New</em> <em>Relic</em> <em>data</em> and <em>get</em> insight into <em>your</em> applications, hosts"
      },
      "id": "60445a0e196a67cb09960f6e"
    },
    {
      "sections": [
        "NRQL math using SELECT",
        "Use basic math operators with SELECT",
        "Use advanced math operators with SELECT",
        "abs",
        "clamp_max, clamp_min",
        "exp",
        "Logarithmic functions: ln, log, log2, log10",
        "pow",
        "pow(n, m) computes n raised to the power m. (I.e. n * n * ... * n, with m copies of n)",
        "Rounding functions: round, floor, ceil",
        "sqrt",
        "Results with STRING or FLOAT",
        "Tip"
      ],
      "title": "NRQL math using SELECT",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "99bfd8fb7663a1c589160ea026ff585acf9d4023",
      "image": "https://docs.newrelic.com/static/8bfef938a82b9feb0fc18864699f176a/c1b63/clamp.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select/",
      "published_at": "2022-01-12T10:19:24Z",
      "updated_at": "2021-11-13T23:43:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL supports the use of basic and advanced mathematical operators within a SELECT clause. You can apply mathematical calculations on both individual attributes and also the results of aggregator functions. Use basic math operators with SELECT To use basic math functions in NRQL, include operators within the SELECT clause: Addition: + Subtraction: - Multiplication: * Division: / Here are some examples: SELECT duration-databaseDuration FROM Transaction Copy SELECT count(*)/uniqueCount(session) FROM PageView Copy SELECT average(duration-databaseDuration) FROM Transaction Copy Use advanced math operators with SELECT NRQL also includes some advanced mathematical capabilities that can be used for complex calculations. This is helpful if you want to process data to display it more effectively in the UI, or make statistical or psychometric calculations on queried results in a single step. abs abs(n) returns the absolute value of n. For non-negative n it returns n, and for negative n it returns the positive number -n. For example abs(2) = 2, and abs(-4) = 4. clamp_max, clamp_min The clamping functions impose an upper or lower bound on values. For example, clamp_max(duration, 10) returns the duration, unless it exceeds 10, in which case 10 is returned. Similarly clamp_min(duration, 1) will not return any value lower than 1. The following chart shows the result of clamping both min and max to keep the value in the range 70-90. Sample graph showing raw data with clamp function applied. exp Computes the natural exponential function of the argument: exp(n) = pow(e, n). Logarithmic functions: ln, log, log2, log10 These functions compute the logarithm of the argument for various bases. ln(n) computes the natural logarithm: the logarithm base e. log2(n) computes the logarithm base 2. log10(n) computes the logarithm base 10. log(n, b) allows logarithms to be computed with an arbitrary base b. All logarithms satisfy the identity: log(pow(b, n), b) = n. Note that log(0) is undefined, for all bases. Be aware that if you take the logarithm of something that might be zero, you may end up getting no value back from your query. pow pow(n, m) computes n raised to the power m. (I.e. n * n * ... * n, with m copies of n) abs(n) returns the absolute value of n. For non-negative n it returns n, and for negative n it returns the positive number -n. For example abs(2) = 2 and abs(-4) = 4. Rounding functions: round, floor, ceil These three functions force decimal numbers to one of the neighboring integers. floor(n) returns the closest integer less than or equal to n. ceil(n) (short for \"ceiling\") returns the closest integer greater than or equal to n. round(n) returns the closest integer to n in either direction. Sample graph showing raw data, with floor, round, and ceiling functions applied. sqrt sqrt(n) returns the square root of n, that is, the number such that sqrt(n) * sqrt(n) = n. Results with STRING or FLOAT Here is how NRQL handles strings present in math calculations: pow(n, m) computes n raised to the power m. (for example, n * n * ... * n, with m copies of n) Examples: sum(1+STRING) = 0 sum(1+MIXED) = skips records where MIXED is a string average(1+STRING) = 0 average(1+MIXED) = skips records where MIXED is a string NULL and zero both appear as 0 in the dashboard. To override NULL values with another numeric value, use the syntax: SELECT average(purchasePrice OR 0) Copy This will replace NULL values with 0 or any number specified. Tip This can also be used to test whether something returns NULL or zero. (zero) OR 1 returns 0. (NULL) OR 1 returns 1.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.90837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> math using SELECT",
        "sections": "<em>NRQL</em> math using SELECT",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": " operators with SELECT <em>NRQL</em> also includes some advanced mathematical capabilities that can be used for complex calculations. This is helpful if you want to process <em>data</em> to display it more effectively in the UI, or make statistical or psychometric calculations on queried results in a single step. abs"
      },
      "id": "603ec31864441f942b4e884c"
    },
    {
      "sections": [
        "Introduction to New Relic",
        "Get started with New Relic",
        "All the answers in one place",
        "Bring all your data together",
        "Analyze your data",
        "Respond to incidents faster",
        "Troubleshoot from anywhere in your stack"
      ],
      "title": "Introduction to New Relic",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "f47a40a9afd699e69c351f5e87f64ed5dadd7e43",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/intro-new-relic/",
      "published_at": "2022-01-12T18:27:10Z",
      "updated_at": "2022-01-12T18:27:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic is an observability platform that helps you build better software. You can bring in data from any digital source so that you can fully understand your system and how to improve it. This short video shows twenty of the most common ways to get your data into New Relic (approx. 5:22 minutes): With New Relic, you can: Bring all your data together: Instrument everything and import data from across your technology stack using our agents, integrations, and APIs, and access it from a single UI. Analyze your data: Get all your data at your fingertips to find the root causes of problems and optimize your systems. Build dashboards and charts or use our powerful query language. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. Get started with New Relic Here's how you can quickly get started capturing and analyzing your data: If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever! Follow the steps in our Add your data UI page to get data flowing in. For your first install, we recommend the Guided install option, which will set up many integrations with a single command. Once you have data coming into New Relic, learn more about the New Relic UI or set up Alerts. All the answers in one place New Relic is built for full stack observability. It links all relevant data so that you get the whole picture of everything that enables your systems to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Monitoring vs. observability: New Relic provides answers to essential questions in one place. As just one example of what you can do with New Relic, imagine you are a Kubernetes administrator overseeing many clusters and pods of software containers. Where do you start troubleshooting? This short video shows how you can locate a problem cluster and use distributed tracing to find relevant logs: Bring all your data together Capture, organize, and make sense of your data in New Relic One, no matter where it comes from. Use our agents and integrations to automatically collect data from common frameworks and tools, or use our APIs for data that’s more specific to your business or technology. If you don't see your technologies or tasks listed here, see a larger list at New Relic Instant Observability. There you will find integrations bundled into quickstarts, providing you instant access to pre-built dashboards and alerts specific to your technology. If you want to... New Relic can help you... Instrument your application Instrument your code: Use our APM agents to automatically instrument your applications in C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Track transactions: Gather distributed tracing details as your transactions cross boundaries between apps and services. Instrument your environment Instrument your infrastructure: Observe your entire environment (including Linux, Windows, AWS, Azure, Google Cloud Platform, Kubernetes, Docker, and more). Collect and centralize logs: See your log data in context with your other application and infrastructure data. Save time switching between tools and reach solutions more quickly. Instrument your digital experiences Enhance browser performance: Decrease page load times, as well as triage and eliminate errors. Monitor mobile apps: Troubleshoot crashes and check the health of your Android and iOS apps with our mobile agents. Simulate user activity: Ensure you’re meeting customer expectations by running automated checks to monitor key user flows and experiences. Send data via APIs or build your own solution Collect data without an agent: Call our APIs directly if you prefer to use OpenTelemetry or other agents. Build your own integration: You can use our Flex tool, or one of language-specific SDKs for creating your own exporters to send data to New Relic. New Relic One gives you access to a wide range of observability tools, including: Application monitoring Browser monitoring Mobile monitoring Synthetic monitoring Serverless monitoring Infrastructure monitoring Log management You can start anywhere, but you'll never get lost. True observability across your entire stack means that you're in control. Analyze your data With your data secure at New Relic, our platform can alert you to problems and help you organize, process, and understand your data, whether it's metrics, events, logs, or traces: Explore your data visually: Jump into our data explorer to navigate all your data and make connections between your entities without any knowledge of query languages. Query and visualize your data: Use our curated dashboard visualizations or create your own. Use NRQL (New Relic Query Language) to slice and dice your data and dig deeper into questions. Query your data programmatically: Access your data through our NerdGraph GraphQL API. Easily prototype queries in our GraphiQL editor. Respond to incidents faster DevOps, site-reliability, and network operation teams need reliable, real-time alerts and anomaly detection to ensure their systems are always up and running efficiently. Let Applied Intelligence, our hybrid machine learning engine, automatically detect anomalies, reduce alert noise, and enrich incidents with context so that you can respond faster to incidents. Proactive detection: Be notified of unusual app behavior and get an analysis of this unusual behavior sent to Slack. Not using Slack? Set up a webhook to deliver messages when you need them. Get notifications: Set up alerts across your data sources and get notified when systems need your attention. Preserve your attention and control how many threshold violations should fire before you're notified. Troubleshoot from anywhere in your stack Being fully connected, the New Relic UI allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but they can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.71451,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " and optimize <em>your</em> systems. Build dashboards and charts or use our powerful <em>query</em> <em>language</em>. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. <em>Get</em> <em>started</em> with <em>New</em> <em>Relic</em> Here&#x27;s how you can quickly <em>get</em> <em>started</em>"
      },
      "id": "619d5b3e196a6705bda0837d"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/rate-limits-nrql-queries": [
    {
      "sections": [
        "NerdGraph tutorial: Query your data using NRQL",
        "Basic NRQL queries with NerdGraph",
        "Create embeddable charts",
        "Suggested facets",
        "Rules governing suggested facets",
        "Example of returning suggested attributes"
      ],
      "title": "NerdGraph tutorial: Query your data using NRQL",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "b56b0e93848c3830a3d0767278e844700c958531",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/examples/nerdgraph-nrql-tutorial/",
      "published_at": "2022-01-12T08:58:27Z",
      "updated_at": "2021-11-06T05:45:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic NerdGraph GraphiQL explorer to make New Relic Query Language (NRQL) queries. To learn how to construct these queries and see responses, go to the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. This document explains some of the available functions for NRQL queries. NRQL queries made through NerdGraph are subject to NRQL Query Rate Limits. Basic NRQL queries with NerdGraph To make NRQL queries using NerdGraph: Go to the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. Pass the NRQL query as a string argument to the NRQL object, and include the results field in your NerdGraph query. For example, to get a count of all transaction events in the last hour, use the following query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This NerdGraph query example returns the following results: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your transaction data. Use the NerdGraph GraphiQL explorer to experiment with queries. Create embeddable charts In addition to returning raw data, you can fetch embeddable chart links for the data to use in an application. For example, instead of a single count of transaction, you can create a chart that illustrates a timeseries of bucketed counts over time. Add TIMESERIES to your query with embeddedChartUrl: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) from Transaction TIMESERIES\") { embeddedChartUrl } } } } Copy This NerdGraph query example returns the URL for the chart in the following response: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \" embeddedChartUrl \": \"https://chart-embed.service.newrelic.com/charts/EMBEDDABLE-CHART-ID\" } } } } } Copy If you view the embedded chart URL using any standard HTTP client, it returns an image showing a visualization of the response to the query you submitted. These charts follow the same embedded chart rules as embedded charts that are created elsewhere. To change the style of the data visualization, pass a chartType argument to embeddedChartUrl. Suggested facets When using NerdGraph to explore your data, you can use the suggestedFacets field to return suggested attributes for use in faceted NRQL queries. Rules governing suggested facets Here are some of the rules that govern what attributes are suggested: Built-in suggestions. Each event type comes with its own set of recommended attributes. These are attributes chosen by New Relic for their importance and popularity. Usage-based suggestions. Some attribute suggestions are based on the queries that have been frequently used by your account. These suggestions can include custom attributes. Role restriction. Restricted users do not have access to account-related facet suggestions. To disable the use of account data for determining suggested queries, contact Support. Example of returning suggested attributes Here's an example of returning suggested attributes for faceting transaction counts. The response suggests the host attribute. Faceting by host can reveal that one host is servicing more requests than other hosts. { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) from Transaction TIMESERIES\") { suggestedFacets { attributes } } } } } Copy This NerdGraph query example returns a response similar to this: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \" suggestedFacets \": [ \"attributes\": [\"host\"] ] } } } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1272.8813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NerdGraph tutorial: <em>Query</em> your data using <em>NRQL</em>",
        "sections": "Basic <em>NRQL</em> <em>queries</em> with NerdGraph",
        "body": " <em>queries</em>. <em>NRQL</em> <em>queries</em> made through NerdGraph are subject to <em>NRQL</em> Query <em>Rate</em> <em>Limits</em>. Basic <em>NRQL</em> <em>queries</em> with NerdGraph To make <em>NRQL</em> <em>queries</em> using NerdGraph: Go to the NerdGraph GraphiQL explorer at api.newrelic.com&#x2F;graphiql. Pass the <em>NRQL</em> query as a string argument to the <em>NRQL</em> object, and include"
      },
      "id": "6044058c196a67976b960f3d"
    },
    {
      "sections": [
        "Query system limits",
        "Important",
        "What happens when you reach a limit",
        "Tip",
        "Create a dashboard to view your limit status",
        "Resource Consumption Limits as a %",
        "Max % Consumption in an hour",
        "APM Agent API transaction events request per minute",
        "Trace API With limit line",
        "Impact FACET",
        "NrIntegrationError by limit",
        "Multi-Account limits (on time series charts only)",
        "Limit list and NrIntegrationError",
        "Limit metrics",
        "newrelic.resourceConsumption.limitValue",
        "newrelic.resourceConsumption.currentValue",
        "newrelic.resourceConsumption.impact",
        "Metric attributes",
        "Set alerts on resource metrics",
        "Limits faceted by LimitName and scoped by Timewindow",
        "Alert on a single limit",
        "Alert on limit impact faceted by dataType, impact, resource, and reason",
        "Alert on impact of a single dataType"
      ],
      "title": "Query system limits",
      "type": "docs",
      "tags": [
        "Ingest data manage data",
        "Manage data",
        "Resource metrics",
        "system limits"
      ],
      "external_id": "7ac33e47dfcfb91089e020a39097c9d648389f51",
      "image": "https://docs.newrelic.com/static/16cb17d5244a118d794df354f67bab81/c1b63/limits-dashboard.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/query-limits/",
      "published_at": "2022-01-12T08:24:52Z",
      "updated_at": "2021-11-13T19:58:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has resource limits in place to protect your experience, our systems, and our other customers. These limits range from the maximum number of characters you can have in a query, to API request rates, to how many events your queries inspect, and more. This page describes the limit metrics and NrIntegrationError events that enable you to view your limits, your current data usage and overall resource consumption as compared to those limits, and the impact of experiencing a limit event. We also provide a handful of queries that, when compiled into a dashboard, can give you consistent insight into your limits status. Important While NrIntegrationError events provide data on many limits types, resource limit metrics currently only cover request rate ingestion and API query rate limits. What happens when you reach a limit Our response to reaching a limit depends on a handful of factors: the type of limit that’s reached, as well as the duration, frequency, and amount at which you exceed the limit. Exceeding a limit doesn’t always mean you experience a limit event, such as dropped data, rejected traffic, or having your data turned off for the rest of the day. We sometimes allow a small buffer before enforcing a limit. That said, any resource consumed above 100% is at risk for limit impact at any time. Many of our rate limits apply proportionally. That means if you’re barely exceeding the limit, we will take less action than if you're exceeding by 200%. Limit metrics are only visible if you're sending data in to a corresponding dataType or limitName API. For example, if you send in data via the Metric API, you’ll see the Metric API resource metrics, but if you don't send any APM data in, you won't see APM resource metrics. Tip Impact metrics will be generated regardless of impact; if there's no impact, you’ll see a 0. An NrIntegrationError event is generated when you experience impact and is a good way to quickly see if you’re experiencing any limit events. See View System Limits for more information. Create a dashboard to view your limit status Using three limit metrics together on a dashboard, you can quickly see detailed visuals of your Ingest Resource Request Per Minute limits, and with NrIntegrationError get a view into more limits. Dashboard displaying limits status using a handful of queries. We used the following queries to create this dashboard. To make a dashboard like this in New Relic One, select Dashboards, and then Create a dashboard. Then, add a new chart for each query you want to regularly monitor. The three limits metrics included in these queries are described in a separate section, below. From left to right, top to bottom: Resource Consumption Limits as a % FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) /latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName where limitTimeInterval = '1 minute' timeseries limit max Copy Max % Consumption in an hour SELECT max(`usage`) FROM (FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 as 'usage' facet limitName timeseries ) facet limitName limit max Copy APM Agent API transaction events request per minute FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) where limitName = 'APM Agent API transaction events requests per minute' TIMESERIES Copy Trace API With limit line FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) as 'usage', latest(newrelic.resourceConsumption.limitValue) as 'limit' where limitName = 'Trace API requests per minute' TIMESERIES Copy Impact FACET From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource TIMESERIES 1 minute limit max Copy NrIntegrationError by limit FROM NrIntegrationError select count(*) facet limitName TIMESERIES MAX since 1 day ago limit max Copy Multi-Account limits (on time series charts only) If you want to see limits for multiple accounts on one chart: run this query from one of the accounts: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName, consumingAccountId where limitTimeInterval = '1 minute' timeseries limit max Copy Click Add another query. Select a different account. Then run this query again: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName, consumingAccountId where limitTimeInterval = '1 minute' timeseries limit max Copy Finally, save it. Limit list and NrIntegrationError FROM Metric, NrIntegrationError select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) as 'Per Minute Count',latest(newrelic.resourceConsumption.limitValue) as ' limit Value',(rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue)*100)as 'Percent Used', filter (count(*), where NrIntegrationError.limitValue is not null) as 'limit reached count' facet limitName limit 1000 Copy Limit metrics These metrics, used in the dashboard queries above, can hone in on a single limit or resource. Or, with the help of FACET limitName or resource provide a view across all your limits. newrelic.resourceConsumption.limitValue limitValue allows you to see the setting for a limit by limitName and understand more about what resource is linked to this limit. The following examples use the limit value metric in the query: Example for Metric API requests per minute. FROM Metric select latest(newrelic.resourceConsumption.limitValue) where limitName = 'Metric API requests per minute' Copy To show all limits, add FACET limitName and consider grouping by limitTimeInterval. FROM Metric select latest(newrelic.resourceConsumption.limitValue) WHERE limitTimeInterval = '1 minute' FACET limitName limit max Copy newrelic.resourceConsumption.currentValue currentValue shows you how much of a given resource you’re currently consuming. To get a better glimpse into how our systems are viewing your consumption, use a rate() function with the time period that aligns with the limitTimeInterval. Limit 200. Example for Metric API request per minute: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue),1 minute) where limitName = 'Metric API requests per minute' Copy To show all limits, add FACET limitName and consider grouping by limitTimeInterval. FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue),1 minute) where limitTimeInterval = '1 minute' FACET limitName limit max Copy newrelic.resourceConsumption.impact impact lets you know for any given resource what impact limit events are having. Zeros mean you are not currently impacted. The most granular we have is dataType. It is possible for multiple instances of limitName to impact a single type, such as Metric RPM and DPM. If we know, we will display limitName. From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, resource, impact, limitName TIMESERIES limit max Copy Metric attributes Attributes on newrelic.resourceConsumption.limitValue and newrelic.resourceConsumption.currentValue: limitName: The Name of the limit for the metric data, for example RPM Metric API. dataType: What kind of data the metric is tracking, for example Metric, Log, or APM. Resource: What resource is being consumed, for example Requests or DPM. limitTimeInterval: What time window this resource is evaluated for limiting. consumingAccountId: The New Relic account where the resource is being consumed. Attributes on newrelic.resourceConsumption.impact dataType: The kind of data that is being impacted, for example Metric, Log, or APM. Resource: What resource is being impacted, for example Request Rate. Impact: A count of what is happening when resource has exceeded set limit, for example dropped requests. consumingAccountId: The New Relic account where the resource is being consumed. Set alerts on resource metrics While building a dashboard to see all your limits is handy, being able to automate it is even better. You can set alerts on your limit metrics to provide updates on limits changes. Tip Because we currently only have metrics on 1 minute time windows, setting TimeWindow = 1 minute, will cover them all. Eventually, we make more metrics available, you might want to set separate alerts for limits that are enforced by different time windows. You can use the following NRQL queries to create alerts. Learn about creating alerts with NRQL queries here. Limits faceted by LimitName and scoped by Timewindow From Metric select (rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue))*100 facet limitName Copy Alert on a single limit From Metric select (rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue))*100 where limitName = 'my limit' Copy Alert on limit impact faceted by dataType, impact, resource, and reason From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource, reason Copy Alert on impact of a single dataType From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource, reason WHERE dataType = 'important things' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.86601,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> system <em>limits</em>",
        "sections": "<em>Query</em> system <em>limits</em>",
        "tags": "system <em>limits</em>",
        "body": ", will cover them all. Eventually, we make more metrics available, you might want to set separate alerts for <em>limits</em> that are enforced by different time windows. You can use the following <em>NRQL</em> <em>queries</em> to create alerts. Learn about creating alerts with <em>NRQL</em> <em>queries</em> here. <em>Limits</em> faceted by <em>Limit</em>Name and scoped"
      },
      "id": "608abed9196a67a63064a7a6"
    },
    {
      "sections": [
        "Know your data limits",
        "Responses to limit violations",
        "System limits UI",
        "Troubleshooting system limits",
        "Account-level limits",
        "Data ingest API limits",
        "Finding other agent and integration limits"
      ],
      "title": "Know your data limits",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "7c540d94a8b5e4f024d175ad53cab9fab343187c",
      "image": "https://docs.newrelic.com/static/8ee61e3091f6e044202cff92026afada/8c557/limits-graph.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/view-system-limits/",
      "published_at": "2022-01-12T06:19:45Z",
      "updated_at": "2021-10-31T06:37:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure our systems are always up and ready to support you, and to keep you from unintended use, we place limits on the amount of data you can send, query, and store. Responses to limit violations Limits are enforced per child account, and across our APIs. You might reach a limit if you start monitoring a new high-traffic application, or have a sudden data spike. When you do reach a limit, New Relic responds according to the type of data and the limit that’s reached. For example: We place a limit on the number of ingested requests per minute (RPM) per data type. When this limit is reached, we stop accepting data and return a 429 status code for the duration of the minute. For queries, we place limits on the number of queries per minute and the number of records inspected (see query limits). When the number of queries per minute limit is reached, New Relic will begin rejecting queries until the number of queries is below the limit. When the records inspected limit is reached, New Relic will reject traffic from the source scanning the largest number of records and attempt to allow traffic from other sources. For metrics, we place a limit on the number of unique timeseries (cardinality) per account and per metric. When this limit is reached, aggregated data is turned off for the rest of the UTC day. For every major limit violation, New Relic creates an NrIntegrationError event for that account, which has these limit-related attributes: Attribute Description category RateLimit or ApiLimit. The RateLimit category is used for limits based on a unit of time such as the number of requests ingested per minute. The ApiLimit is used for constant limits, such as the number of attributes on a record. limitName The name of the limit. message Describes the limit and the impact. limitValue The limit reached. System limits UI The system Limits page (from the account dropdown, click Manage your data and click Limits on the left) displays when your account has encountered a rate limit in the specified time period. The page displays a default period of 24 hours; you can set a custom range from the top-right of the page. Non-limit-related NrIntegrationError events are not displayed here. In addition, this page does not display information about limits you have not hit, or how close you are to reaching a limit. For more on creating queries and alerts for data ingest and billing metrics, see Query billing/usage data. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a chart on the Limits UI page displaying a cardinality violation limit issue. To add more detail, or build a dashboard, click the View NRQL button on the chart to see the NRQL powering this view. The graph displays each unique limit type that was reached during the selected time-period. This can help you find any trends based on time. The Limits page also provides a table where you can find the limit name, the limit event message associated with it, and last occurrence time and date. If you click a limit in the table, you see more about what happened, and when. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a limit events table on the Limits UI page. Troubleshooting system limits To troubleshoot limits when you reach them, click the limit info in the table, and then follow the docs link that's provided. Different limits have different solutions. Account-level limits The following table includes general max limits that apply across all New Relic accounts. Specific New Relic tools, like agents and integrations, have their own limits and configurations, and might be lower than these theoretical maximum limits. Limited condition Limit Rate of NRDB record * ingest 55 million per account per minute Max NRDB records * ingested per API call 1MB (10^6 bytes) Max attribute value size 1KB (10^3 bytes) Max payload size 1MB (10^6 bytes) Max total attributes per data type (including default attributes) 254 (less for some tools; for example, 64 for agents) Number of unique custom data types 250 per account per day (applies to custom events because that's source of new data types) APM limits Agent instances: 50K per account Agent instances per app: 10K APM apps/services: 10K per second Browser: number of page views 1M per minute per app Distributed tracing: Max age of span timestamp values 20 minutes. Timestamp must be within 20 minutes of current time at ingest or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Distributed tracing: Max spans per minute per account Dependent on agreement. Max limit: 2M. Distributed tracing: Max spans per trace 50K Distributed tracing: Max attributes per span 200 Rate of metric timeslice data (used by APM, browser, mobile) Ingest: 2 million per minute Rate of names: 4 million per minute per account Number per monitored app: 300K Mobile monitoring: number of crashes reported 10K per hour Infrastructure agents, integrations Number of infrastructure agents and/or integrations: 5K per account Gross number of new monitored containers: 5K per hour per account Query limits NRDB records * inspected: 100 billion per account per hour Rate of queries: 20 per account per second See other query limits * NRDB records refers to database records for our core data types, which includes events, metrics (dimensional), logs, and distributed tracing (span) data, all stored in the New Relic database (NRDB). This does not include metric timeslice data. Data ingest API limits Our ingest APIs have additional limits that may override the more general account-level limits. Note that these limits also apply to our tools that use these APIs (like our Telemetry SDKs or our open source telemetry integrations). Metric API (dimensional metrics) Event API Log API Trace API Finding other agent and integration limits To find limits for our other agents and integrations, which will override more general account-level limits, see the docs for those tools: you can search our quickstarts here. Some default reporting limits are located in these tools' configuration docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.197464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Know your data <em>limits</em>",
        "sections": "Know your data <em>limits</em>",
        "body": ", we stop accepting data and return a 429 status code for the duration of the minute. For <em>queries</em>, we place <em>limits</em> on the number of <em>queries</em> per minute and the number of records inspected (see query <em>limits</em>). When the number of <em>queries</em> per minute <em>limit</em> is reached, New Relic will begin rejecting <em>queries</em>"
      },
      "id": "60446a7c64441f48d7378f2b"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/app-data-nrql-query-examples": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2022-01-12T11:33:08Z",
      "updated_at": "2021-12-30T17:52:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. When using NRQL, you can set a UTC timestamp or a relative time range: Timestamps use the format YYYY-MM-DD HH:MM:SS ZZZZ. For instance, FROM Transaction SELECT count(*) SINCE '2021-12-25 00:00:00 +0000' UNTIL '2021-12-25 23:59:59 +0000'. We support the following relative time ranges: YESTERDAY, TODAY, SUNDAY, MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY. For example, SINCE YESTERDAY UNTIL NOW. We also support YEAR, QUARTER, MONTH, WEEK, DAY, HOUR, MINUTE, SECOND. For these cases, you can combine SINCE with THIS or LAST. For instance, SINCE LAST MONTH UNTIL THIS WEEK. You can also include AGO, as in SINCE 3 WEEKS AGO UNTIL 10 MINUTES AGO. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Or, watch this short video (approx. 3:20 minutes). Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.3122,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2022-01-12T02:25:05Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.12048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "BETA FEATURE",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2022-01-12T10:30:52Z",
      "updated_at": "2021-09-14T20:46:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.28845,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits"
      },
      "id": "603e95e8e7b9d286642a07fa"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/browserspa-nrql-query-examples": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2022-01-12T11:33:08Z",
      "updated_at": "2021-12-30T17:52:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. When using NRQL, you can set a UTC timestamp or a relative time range: Timestamps use the format YYYY-MM-DD HH:MM:SS ZZZZ. For instance, FROM Transaction SELECT count(*) SINCE '2021-12-25 00:00:00 +0000' UNTIL '2021-12-25 23:59:59 +0000'. We support the following relative time ranges: YESTERDAY, TODAY, SUNDAY, MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY. For example, SINCE YESTERDAY UNTIL NOW. We also support YEAR, QUARTER, MONTH, WEEK, DAY, HOUR, MINUTE, SECOND. For these cases, you can combine SINCE with THIS or LAST. For instance, SINCE LAST MONTH UNTIL THIS WEEK. You can also include AGO, as in SINCE 3 WEEKS AGO UNTIL 10 MINUTES AGO. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Or, watch this short video (approx. 3:20 minutes). Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.31215,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2022-01-12T02:25:05Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.12048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "BETA FEATURE",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2022-01-12T10:30:52Z",
      "updated_at": "2021-09-14T20:46:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.28845,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits"
      },
      "id": "603e95e8e7b9d286642a07fa"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2022-01-12T11:33:08Z",
      "updated_at": "2021-12-30T17:52:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. When using NRQL, you can set a UTC timestamp or a relative time range: Timestamps use the format YYYY-MM-DD HH:MM:SS ZZZZ. For instance, FROM Transaction SELECT count(*) SINCE '2021-12-25 00:00:00 +0000' UNTIL '2021-12-25 23:59:59 +0000'. We support the following relative time ranges: YESTERDAY, TODAY, SUNDAY, MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY. For example, SINCE YESTERDAY UNTIL NOW. We also support YEAR, QUARTER, MONTH, WEEK, DAY, HOUR, MINUTE, SECOND. For these cases, you can combine SINCE with THIS or LAST. For instance, SINCE LAST MONTH UNTIL THIS WEEK. You can also include AGO, as in SINCE 3 WEEKS AGO UNTIL 10 MINUTES AGO. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Or, watch this short video (approx. 3:20 minutes). Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.31215,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2022-01-12T02:25:05Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.12048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "BETA FEATURE",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2022-01-12T10:30:52Z",
      "updated_at": "2021-09-14T20:46:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.28845,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits"
      },
      "id": "603e95e8e7b9d286642a07fa"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/funnels-evaluate-data-series-related-events": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2022-01-12T11:33:08Z",
      "updated_at": "2021-12-30T17:52:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. When using NRQL, you can set a UTC timestamp or a relative time range: Timestamps use the format YYYY-MM-DD HH:MM:SS ZZZZ. For instance, FROM Transaction SELECT count(*) SINCE '2021-12-25 00:00:00 +0000' UNTIL '2021-12-25 23:59:59 +0000'. We support the following relative time ranges: YESTERDAY, TODAY, SUNDAY, MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY. For example, SINCE YESTERDAY UNTIL NOW. We also support YEAR, QUARTER, MONTH, WEEK, DAY, HOUR, MINUTE, SECOND. For these cases, you can combine SINCE with THIS or LAST. For instance, SINCE LAST MONTH UNTIL THIS WEEK. You can also include AGO, as in SINCE 3 WEEKS AGO UNTIL 10 MINUTES AGO. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Or, watch this short video (approx. 3:20 minutes). Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.3121,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2022-01-12T02:25:05Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.12048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "BETA FEATURE",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2022-01-12T10:30:52Z",
      "updated_at": "2021-09-14T20:46:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.28844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits"
      },
      "id": "603e95e8e7b9d286642a07fa"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/improvements-nrql-percentile": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2022-01-12T11:33:08Z",
      "updated_at": "2021-12-30T17:52:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. When using NRQL, you can set a UTC timestamp or a relative time range: Timestamps use the format YYYY-MM-DD HH:MM:SS ZZZZ. For instance, FROM Transaction SELECT count(*) SINCE '2021-12-25 00:00:00 +0000' UNTIL '2021-12-25 23:59:59 +0000'. We support the following relative time ranges: YESTERDAY, TODAY, SUNDAY, MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY. For example, SINCE YESTERDAY UNTIL NOW. We also support YEAR, QUARTER, MONTH, WEEK, DAY, HOUR, MINUTE, SECOND. For these cases, you can combine SINCE with THIS or LAST. For instance, SINCE LAST MONTH UNTIL THIS WEEK. You can also include AGO, as in SINCE 3 WEEKS AGO UNTIL 10 MINUTES AGO. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Or, watch this short video (approx. 3:20 minutes). Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.31206,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2022-01-12T02:25:05Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.12048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "BETA FEATURE",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2022-01-12T10:30:52Z",
      "updated_at": "2021-09-14T20:46:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.28844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits"
      },
      "id": "603e95e8e7b9d286642a07fa"
    }
  ]
}