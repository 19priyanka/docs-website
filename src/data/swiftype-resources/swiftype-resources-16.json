{
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-09-02T12:17:14Z",
      "updated_at": "2021-09-02T12:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (e.g., SELECT median(one_metric</var>), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b' Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.07596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> metric <em>data</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-09-03T01:42:45Z",
      "updated_at": "2021-07-21T13:27:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by New Relic APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.99312,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ", clauses, and functions. What is <em>NRQL</em>? <em>NRQL</em> is <em>New</em> <em>Relic</em>&#x27;s SQL-like <em>query</em> <em>language</em>. You can use <em>NRQL</em> to retrieve detailed <em>New</em> <em>Relic</em> <em>data</em> and <em>get</em> insight into <em>your</em> applications, hosts, and business-important activity. Reasons to use <em>NRQL</em> include: To answer a question for the purpose of troubleshooting"
      },
      "id": "60445a0e196a67cb09960f6e"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-09-01T18:10:10Z",
      "updated_at": "2021-08-03T00:48:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.6189,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " provider = &#x27;LambdaFunction&#x27; Copy <em>Query</em> with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy <em>Get</em> <em>started</em> No agent or integration updates are required to use these metrics. <em>NRQL</em> alerting based on dimensional metrics is also supported, except for <em>data</em> coming from cloud integrations"
      },
      "id": "603e95e8e7b9d286642a07fa"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions": [
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-09-03T01:42:45Z",
      "updated_at": "2021-07-21T13:27:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by New Relic APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.99312,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": ", clauses, and functions. What is <em>NRQL</em>? <em>NRQL</em> is <em>New</em> <em>Relic</em>&#x27;s SQL-like <em>query</em> <em>language</em>. You can use <em>NRQL</em> to retrieve detailed <em>New</em> <em>Relic</em> <em>data</em> and <em>get</em> insight into <em>your</em> applications, hosts, and business-important activity. Reasons to use <em>NRQL</em> include: To answer a question for the purpose of troubleshooting"
      },
      "id": "60445a0e196a67cb09960f6e"
    },
    {
      "sections": [
        "NRQL math using SELECT",
        "Use math operators with SELECT",
        "Results with STRING or FLOAT",
        "Tip",
        "Advanced math functions",
        "abs",
        "round, floor, ceil(ing)",
        "clamp_max, clamp_min",
        "pow",
        "sqrt",
        "exp",
        "ln, log2, log10, log",
        "For more help"
      ],
      "title": "NRQL math using SELECT",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "99bfd8fb7663a1c589160ea026ff585acf9d4023",
      "image": "https://docs.newrelic.com/static/dbeb9b9f1fc039e9d5357d7c2206ad18/c1b63/floor-round-ceil.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select/",
      "published_at": "2021-09-02T17:48:37Z",
      "updated_at": "2021-03-16T10:24:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Query Language (NRQL) supports basic math functions within a SELECT clause. You can apply addition, subtraction, multiplication, and division on both individual attributes as well as the results of aggregator functions. Use math operators with SELECT To use basic math functions in NRQL, include operators within the SELECT clause: Addition: + Subtraction: - Multiplication: * Division: / Here are some examples: SELECT duration-databaseDuration FROM Transaction Copy SELECT count(*)/uniqueCount(session) FROM PageView Copy SELECT average(duration-databaseDuration) FROM Transaction Copy Results with STRING or FLOAT Here is how NRQL handles strings present in math calculations: Examples: sum(1+STRING) = 0 sum(1+MIXED) = skips records where MIXED is a string average(1+STRING) = 0 average(1+MIXED) = skips records where MIXED is a string NULL and zero both appear as 0 in the dashboard. To override NULL values with another numeric value, use the syntax: SELECT average(purchasePrice OR 0) Copy This will replace NULL values with 0 or any number specified. Tip This can also be used to test whether something returns NULL or zero. (zero) OR 1 returns 0. (NULL) OR 1 returns 1. Advanced math functions NRQL includes advanced mathematical functions that can be used for complex calculations and for processing data to display more effectively in the UI. abs abs(n) returns the absolute value of n. For non-negative n it returns n, and for negative n it returns the positive number -n. For example abs(2) = 2, and abs(-4) = 4. round, floor, ceil(ing) These three functions force decimal numbers to one of the neighboring integers. floor(n) returns the closest integer less than or equal to n. ceil(n) returns the closest integer greater than or equal to n. round(n) returns the closest integer to n in either direction. Sample graph showing raw data, with floor, round, and ceiling functions applied. clamp_max, clamp_min The clamping functions impose an upper or lower bound on values. For example, clamp_max(duration, 10) returns the duration, unless it exceeds 10, in which case 10 is returned. Similarly clamp_min(duration, 1) will not return any value lower than 1. The following chart shows the result of clamping both min and max to keep the value in the range 70-90. Sample graph showing raw data with clamp function applied. pow pow(n, m) computes n raised to the power m. (I.e. n * n * ... * n, with m copies of n) sqrt sqrt(n) returns the square root of n, that is, the number such that sqrt(n) * sqrt(n) = n. exp Computes the natural exponential function of the argument: exp(n) = pow(e, n). ln, log2, log10, log These functions compute the logarithm of the argument for various bases. ln(n) computes the natural logarithm: the logarithm base e. log2(n) computes the logarithm base 2. log10(n) computes the logarithm base 10. log(n, b) allows logarithms to be computed with an arbitrary base b. All logarithms satisfy the identity: log(pow(b, n), b) = n. Note that log(0) is undefined, for all bases. Be aware that if you take the logarithm of something that might be zero, you may end up getting \"No Value\" back from your query. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.83554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> math using SELECT",
        "sections": "<em>NRQL</em> math using SELECT",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>) supports basic math functions within a SELECT clause. You can apply addition, subtraction, multiplication, and division on both individual attributes as well as the results of aggregator functions. Use math operators with SELECT To use basic math functions in <em>NRQL</em>"
      },
      "id": "603ec31864441f942b4e884c"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-09-01T18:10:10Z",
      "updated_at": "2021-08-03T00:48:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.6189,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " provider = &#x27;LambdaFunction&#x27; Copy <em>Query</em> with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy <em>Get</em> <em>started</em> No agent or integration updates are required to use these metrics. <em>NRQL</em> alerting based on dimensional metrics is also supported, except for <em>data</em> coming from cloud integrations"
      },
      "id": "603e95e8e7b9d286642a07fa"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/rate-limits-nrql-queries": [
    {
      "sections": [
        "View system limits",
        "Responses to limit violations",
        "System limits UI",
        "Troubleshooting limits"
      ],
      "title": "View system limits",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "d6ff940e92c5d1a3ae34f391e9fa3be5dfa21c2f",
      "image": "https://docs.newrelic.com/static/8ee61e3091f6e044202cff92026afada/8c557/limits-graph.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/view-system-limits/",
      "published_at": "2021-09-01T19:46:21Z",
      "updated_at": "2021-08-09T00:31:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure our systems are always up and ready to support you, and to keep you from unintended use, we place limits on the amount of data you can send, query, and store. Responses to limit violations Limits are enforced per child account, and across our APIs. You might reach a limit if you start monitoring a new high-traffic application, or have a sudden data spike. When you do reach a limit, New Relic responds according to the type of data and the limit that’s reached. For example: We place a limit on the number of ingested requests per minute (RPM) per data type. When this limit is reached, we stop accepting data and return a 429 status code for the duration of the minute. For queries, we place limits on the number of queries per minute and the number of records inspected (see query limits). When the number of queries per minute limit is reached, New Relic will begin rejecting queries until the number of queries is below the limit. When the records inspected limit is reached, New Relic will reject traffic from the source scanning the largest number of records and attempt to allow traffic from other sources. For metrics, we place a limit on the number of unique timeseries (cardinality) per account and per metric. When this limit is reached, aggregated data is turned off for the rest of the UTC day. For every major limit violation, New Relic creates an NrIntegrationError event for that account, which has these limit-related attributes: Attribute Description category RateLimit or ApiLimit. The RateLimit category is used for limits based on a unit of time such as the number of requests ingested per minute. The ApiLimit is used for constant limits, such as the number of attributes on a record. limitName The name of the limit. message Describes the limit and the impact. limitValue The limit reached. System limits UI The system Limits page (from the account dropdown, click Manage your data and click Limits on the left) displays when your account has encountered a rate limit in the specified time period. The page displays a default period of 24 hours; you can set a custom range from the top-right of the page. Non-limit-related NrIntegrationError events are not displayed here. In addition, this page does not display information about limits you have not hit, or how close you are to reaching a limit. For more on creating queries and alerts for data ingest and billing metrics, see Query billing/usage data. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a chart on the Limits UI page displaying a cardinality violation limit issue. To add more detail, or build a dashboard, click the View NRQL button on the chart to see the NRQL powering this view. The graph displays each unique limit type that was reached during the selected time-period. This can help you find any trends based on time. The Limits page also provides a table where you can find the limit name, the limit event message associated with it, and last occurrence time and date. If you click a limit in the table, you see more about what happened, and when. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a limit events table on the Limits UI page. Troubleshooting limits To troubleshoot limits when you reach them, click the limit info in the table, and then follow the docs link that's provided. Different limits have different solutions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.55054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View system <em>limits</em>",
        "sections": "View system <em>limits</em>",
        "body": ", we stop accepting data and return a 429 status code for the duration of the minute. For <em>queries</em>, we place <em>limits</em> on the number of <em>queries</em> per minute and the number of records inspected (see query <em>limits</em>). When the number of <em>queries</em> per minute <em>limit</em> is reached, New Relic will begin rejecting <em>queries</em>"
      },
      "id": "60446a7c64441f48d7378f2b"
    },
    {
      "sections": [
        "Query system limits",
        "Important",
        "What happens when you reach a limit",
        "Tip",
        "Create a dashboard to view your limit status",
        "Resource Consumption Limits as a %",
        "Max % Consumption in an hour",
        "APM Agent API transaction events request per minute",
        "Trace API With limit line",
        "Impact FACET",
        "NrIntegrationError by limit",
        "Multi-Account limits (on time series charts only)",
        "Limit list and NrIntegrationError",
        "Limit metrics",
        "newrelic.resourceConsumption.limitValue",
        "newrelic.resourceConsumption.currentValue",
        "newrelic.resourceConsumption.impact",
        "Metric attributes",
        "Set alerts on resource metrics",
        "Limits faceted by LimitName and scoped by Timewindow",
        "Alert on a single limit",
        "Alert on limit impact faceted by dataType, impact, resource, and reason",
        "Alert on impact of a single dataType"
      ],
      "title": "Query system limits",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest data manage data",
        "Manage data",
        "Resource metrics",
        "system limits"
      ],
      "external_id": "f8ca2368c70e4e339cd838d0ad192dd2c40fac0a",
      "image": "https://docs.newrelic.com/static/16cb17d5244a118d794df354f67bab81/c1b63/limits-dashboard.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/query-limits/",
      "published_at": "2021-09-01T19:47:32Z",
      "updated_at": "2021-08-09T00:31:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has resource limits in place to protect your experience, our systems, and our other customers. These limits range from the maximum number of characters you can have in a query, to API request rates, to how many events your queries inspect, and more. This page describes the limit metrics and NrIntegrationError events that enable you to view your limits, your current data usage and overall resource consumption as compared to those limits, and the impact of experiencing a limit event. We also provide a handful of queries that, when compiled into a dashboard, can give you consistent insight into your limits status. Important While NrIntegrationError events provide data on many limits types, resource limit metrics currently only cover request rate ingestion and API query rate limits. What happens when you reach a limit Our response to reaching a limit depends on a handful of factors: the type of limit that’s reached, as well as the duration, frequency, and amount at which you exceed the limit. Exceeding a limit doesn’t always mean you experience a limit event, such as dropped data, rejected traffic, or having your data turned off for the rest of the day. We sometimes allow a small buffer before enforcing a limit. That said, any resource consumed above 100% is at risk for limit impact at any time. Many of our rate limits apply proportionally. That means if you’re barely exceeding the limit, we will take less action than if you're exceeding by 200%. Limit metrics are only visible if you're sending data in to a corresponding dataType or limitName API. For example, if you send in data via the Metric API, you’ll see the Metric API resource metrics, but if you don't send any APM data in, you won't see APM resource metrics. Tip Impact metrics will be generated regardless of impact; if there's no impact, you’ll see a 0. An NrIntegrationError event is generated when you experience impact and is a good way to quickly see if you’re experiencing any limit events. See View System Limits for more information. Create a dashboard to view your limit status Using three limit metrics together on a dashboard, you can quickly see detailed visuals of your Ingest Resource Request Per Minute limits, and with NrIntegrationError get a view into more limits. Dashboard displaying limits status using a handful of queries. We used the following queries to create this dashboard. To make a dashboard like this in New Relic One, select Dashboards, and then Create a dashboard. Then, add a new chart for each query you want to regularly monitor. The three limits metrics included in these queries are described in a separate section, below. From left to right, top to bottom: Resource Consumption Limits as a % FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) /latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName where limitTimeInterval = '1 minute' timeseries limit max Copy Max % Consumption in an hour SELECT max(`usage`) FROM (FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 as 'usage' facet limitName timeseries ) facet limitName limit max Copy APM Agent API transaction events request per minute FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) where limitName = 'APM Agent API transaction events requests per minute' TIMESERIES Copy Trace API With limit line FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) as 'usage', latest(newrelic.resourceConsumption.limitValue) as 'limit' where limitName = 'Trace API requests per minute' TIMESERIES Copy Impact FACET From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource TIMESERIES 1 minute limit max Copy NrIntegrationError by limit FROM NrIntegrationError select count(*) facet limitName TIMESERIES MAX since 1 day ago limit max Copy Multi-Account limits (on time series charts only) If you want to see limits for multiple accounts on one chart: run this query from one of the accounts: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName, consumingAccountId where limitTimeInterval = '1 minute' timeseries limit max Copy Click Add another query. Select a different account. Then run this query again: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName, consumingAccountId where limitTimeInterval = '1 minute' timeseries limit max Copy Finally, save it. Limit list and NrIntegrationError FROM Metric, NrIntegrationError select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) as 'Per Minute Count',latest(newrelic.resourceConsumption.limitValue) as ' limit Value',(rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue)*100)as 'Percent Used', filter (count(*), where NrIntegrationError.limitValue is not null) as 'limit reached count' facet limitName limit 1000 Copy Limit metrics These metrics, used in the dashboard queries above, can hone in on a single limit or resource. Or, with the help of FACET limitName or resource provide a view across all your limits. newrelic.resourceConsumption.limitValue limitValue allows you to see the setting for a limit by limitName and understand more about what resource is linked to this limit. The following examples use the limit value metric in the query: Example for Metric API requests per minute. FROM Metric select latest(newrelic.resourceConsumption.limitValue) where limitName = 'Metric API requests per minute' Copy To show all limits, add FACET limitName and consider grouping by limitTimeInterval. FROM Metric select latest(newrelic.resourceConsumption.limitValue) WHERE limitTimeInterval = '1 minute' FACET limitName limit max Copy newrelic.resourceConsumption.currentValue currentValue shows you how much of a given resource you’re currently consuming. To get a better glimpse into how our systems are viewing your consumption, use a rate() function with the time period that aligns with the limitTimeInterval. Limit 200. Example for Metric API request per minute: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue),1 minute) where limitName = 'Metric API requests per minute' Copy To show all limits, add FACET limitName and consider grouping by limitTimeInterval. FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue),1 minute) where limitTimeInterval = '1 minute' FACET limitName limit max Copy newrelic.resourceConsumption.impact impact lets you know for any given resource what impact limit events are having. Zeros mean you are not currently impacted. The most granular we have is dataType. It is possible for multiple instances of limitName to impact a single type, such as Metric RPM and DPM. If we know, we will display limitName. From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, resource, impact, limitName TIMESERIES limit max Copy Metric attributes Attributes on newrelic.resourceConsumption.limitValue and newrelic.resourceConsumption.currentValue: limitName - The Name of the limit for the metric data, i.e RPM Metric API. dataType - What kind of data the metric is tracking, i.e Metric, Log, or APM. Resource - What resource is being consumed, i.e. Requests, or DPM. limitTimeInterval - What time window this resource is evaluated for limiting. consumingAccountId - The New Relic account where the resource is being consumed. Attributes on newrelic.resourceConsumption.impact dataType - The kind of data that is being impacted, i.e Metric, Log, APM. Resource - What resource is being impacted, i.e Request Rate. Impact - A count of what is happening when resource has exceeded set limit, i.e dropped requests. consumingAccountId - The New Relic account where the resource is being consumed. Set alerts on resource metrics While building a dashboard to see all your limits is handy, being able to automate it is even better. You can set alerts on your limit metrics to provide updates on limits changes. Tip Because we currently only have metrics on 1 minute time windows, setting TimeWindow = 1 minute, will cover them all. Eventually, we make more metrics available, you might want to set separate alerts for limits that are enforced by different time windows. You can use the following NRQL queries to create alerts. Learn about creating alerts with NRQL queries here. Limits faceted by LimitName and scoped by Timewindow From Metric select (rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue))*100 facet limitName Copy Alert on a single limit From Metric select (rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue))*100 where limitName = 'my limit' Copy Alert on limit impact faceted by dataType, impact, resource, and reason From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource, reason Copy Alert on impact of a single dataType From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource, reason WHERE dataType = 'important things' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.81613,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> system <em>limits</em>",
        "sections": "<em>Query</em> system <em>limits</em>",
        "tags": "system <em>limits</em>",
        "body": " metrics available, you might want to set separate alerts for <em>limits</em> that are enforced by different time windows. You can use the following <em>NRQL</em> <em>queries</em> to create alerts. Learn about creating alerts with <em>NRQL</em> <em>queries</em> here. <em>Limits</em> faceted by <em>Limit</em>Name and scoped by Timewindow From Metric select (<em>rate</em>"
      },
      "id": "608abed9196a67a63064a7a6"
    },
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-09-02T12:17:14Z",
      "updated_at": "2021-09-02T12:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (e.g., SELECT median(one_metric</var>), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b' Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.08963,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> using <em>LIMIT</em>",
        "tags": "<em>NRQL</em>: New Relic <em>Query</em> Language",
        "body": ", it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error <em>rate</em>). It&#x27;s not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with <em>NRQL</em> <em>queries</em> that use one of the following"
      },
      "id": "604456c1196a678db8960f41"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/app-data-nrql-query-examples": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-09-02T12:17:14Z",
      "updated_at": "2021-09-02T12:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (e.g., SELECT median(one_metric</var>), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b' Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.80334,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-09-01T18:10:10Z",
      "updated_at": "2021-08-03T00:48:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.2716,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how"
      },
      "id": "603e95e8e7b9d286642a07fa"
    },
    {
      "sections": [
        "NRQL query examples for mobile monitoring",
        "Mobile, MobileSession, and MobileCrash event query examples",
        "Interactions: Which interactions are most popular among my users?",
        "Location: Which regions of China have the most users?",
        "Device profile: How many users use the latest OS versions?",
        "App version: Have we seen an increase in session duration since yesterday's release?",
        "Performance: How much memory does my app use for sessions longer than 5 seconds?",
        "Crashes: What are my app's most common crashes?",
        "Crash rate: What is the crash rate for different versions of my app?",
        "MobileRequest event query examples",
        "Error rate by request domain",
        "Error rate for business-critical API",
        "Response time percentiles of important APIs",
        "Volume of network requests",
        "Slow response user impact",
        "Response time distribution by domain, carrier, ASN owner, country, etc.",
        "Percentile response time",
        "Requests per session",
        "MobileRequestError event query examples",
        "HTTP errors",
        "Network failures",
        "Error rate: Percentage of users impacted",
        "Errors by version",
        "Unique devices (by UUID)",
        "Historical HTTP error counts",
        "MobileHandledException event query examples",
        "App exceptions",
        "Top exception locations",
        "Most common interaction generating exceptions",
        "Most common exception message",
        "Most common method reporting exceptions",
        "Handled exception rate"
      ],
      "title": "NRQL query examples for mobile monitoring",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "2844422852b86681e69a3ef9333f2268deacbecb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-query-examples-mobile-monitoring/",
      "published_at": "2021-09-01T18:09:11Z",
      "updated_at": "2021-08-03T00:46:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways to query your data. This document will show you some example NRQL queries from mobile monitoring data. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event query examples Mobile queries allow you to understand and compare a wide variety of mobile data, including interactions, location, device profile, app version, crashes, and performance. These examples use queries made on the Mobile, MobileSession, and MobileCrash event types: Interactions: Which interactions are most popular among my users? SELECT uniqueCount(uuid) FROM Mobile SINCE 1 day ago FACET name Copy Location: Which regions of China have the most users? SELECT uniqueCount(uuid) FROM MobileSession WHERE countryCode='CN' FACET regionCode SINCE 7 days ago Copy Device profile: How many users use the latest OS versions? SELECT uniqueCount(uuid) FROM MobileSession FACET osVersion SINCE 7 days ago Copy App version: Have we seen an increase in session duration since yesterday's release? SELECT percentile(sessionDuration, 90) FROM MobileSession since 1 day ago compare with 2 days ago Copy Performance: How much memory does my app use for sessions longer than 5 seconds? SELECT histogram(memUsageMb) FROM MobileSession WHERE sessionDuration > 5 Copy Crashes: What are my app's most common crashes? SELECT count(*) FROM MobileCrash FACET crashException Copy Crash rate: What is the crash rate for different versions of my app? SELECT percentage(uniqueCount(sessionId), WHERE category = 'Crash') as `Crash rate` FROM MobileSession, MobileCrash facet appVersion since 90 days ago Copy MobileRequest event query examples This feature requires mobile monitoring agent version 5.14.0 or higher. MobileRequest data is enabled by default for: Android version 5.15.2 or higher iOS version 6.0.0 or higher For earlier versions, starting with Android version 5.14.0 or iOS version 5.14.0, you must enable the feature. Upgrade to the latest Android or iOS version, or add the required feature flag to your app. Below are some NRQL queries that address common use cases. Use the MobileRequest attributes to make your own NRQL queries. The last two examples use MobileRequestError events in addition to MobileRequest to get an error rate. Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate seen by our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Response time percentiles of important APIs For important requests in the 90th percentile, what is the response time by URL? SELECT percentile(responseTime, 90), latest(requestUrl) as 'Latest URL' from MobileRequest facet cases(where requestUrl like '%{YOUR_CORE_API}%' as 'Core API', where requestUrl like '%{YOUR_FEATURE_API}%' as 'New Feature API') Copy Volume of network requests How much network traffic from the apps are backend services receiving? SELECT count(*) FROM MobileRequest FACET requestDomain since 3 days ago Copy Slow response user impact What % of users are impacted by http response times greater than 3 seconds? SELECT filter(uniqueCount(MobileRequest.uuid), WHERE responseTime > 3) / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted' FROM MobileRequest, MobileSession since 1 day ago timeseries compare with 2 days ago Copy Response time distribution by domain, carrier, ASN owner, country, etc. What is the distribution of response time and request count across domain, country, carrier, or ASN owner? SELECT histogram(responseTime, 20, 20) FROM MobileRequest since 3 days ago facet asnOwner Copy Percentile response time What is the breakdown of response time by different percentiles? SELECT percentile(responseTime, 98) as '98 percentile (sec)', percentile(responseTime, 90) as '90 percentile (sec)', percentile(responseTime, 50) as '50 percentile (sec)' from MobileRequest since 3 days ago Copy Requests per session How do requests per session compare across different apps or subsequent builds of those apps? SELECT count(*)/uniqueCount(sessionId) from MobileRequest, MobileSession facet appName timeseries Copy MobileRequestError event query examples Below are some NRQL queries that address common use cases. Use the MobileRequestError attributes to make your own NRQL queries. HTTP errors Which queries are causing the most errors? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestUrl Copy Network failures What network failures are most common for my application? SELECT count(*) FROM MobileRequestError where errorType = 'NetworkFailure' facet networkError Copy Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate in our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Error rate: Percentage of users impacted How many users are experiencing errors as compared to my total user count? SELECT filter(uniqueCount(MobileRequestError.uuid), WHERE errorType = 'HTTPError') / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted by Errors' FROM MobileRequestError, MobileSession COMPARE WITH 7 days AGO Copy Errors by version Which version(s) of my app are causing the most errors? SELECT count(*) FROM MobileRequestError FACET appVersion Copy Unique devices (by UUID) Which unique devices (by UUID) are having the most issues with my application? SELECT count(*), latest(device), latest(carrier), latest(asnOwner), latest(countryCode) FROM MobileRequestError FACET deviceUuid limit 100 SINCE 1 days ago Copy Historical HTTP error counts What does my historical HTTP Error count look like (by domain)? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestDomain timeseries Copy MobileHandledException event query examples Below are some NRQL queries for common handled exception use cases. Use the MobileHandledException attributes to make your own NRQL queries. App exceptions Which apps have reported the most number of handled exceptions? SELECT count(*) FROM MobileHandledException FACET appName SINCE 3 days ago Copy Top exception locations What are most common exception locations for my application? How many exceptions do we have, and where do they occur? SELECT count(*) FROM MobileHandledException FACET exceptionLocation SINCE 3 days ago Copy Most common interaction generating exceptions Which interaction produces the most exceptions? SELECT count(*) FROM MobileHandledException FACET lastInteraction SINCE 3 days ago Copy Most common exception message What are the most common reported exception messages? SELECT count(*) FROM MobileHandledException FACET exceptionMessage SINCE 3 days ago Copy Most common method reporting exceptions What are the most common methods reporting exceptions? SELECT count(*) FROM MobileHandledException FACET exceptionLocationMethod SINCE 3 days ago Copy Handled exception rate How often are handled exceptions encountered by our users? SELECT percentage(uniqueCount(sessionId), WHERE exceptionLocation IS NOT NULL) FROM MobileSession,MobileHandledException SINCE 3 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.27002,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "sections": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "There are several ways to <em>query</em> <em>your</em> <em>data</em>. This document will show you some example <em>NRQL</em> queries from mobile monitoring <em>data</em>. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event <em>query</em> examples Mobile queries"
      },
      "id": "60445a6128ccbc6b6a2c60ca"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/browserspa-nrql-query-examples": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-09-02T12:17:14Z",
      "updated_at": "2021-09-02T12:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (e.g., SELECT median(one_metric</var>), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b' Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.8032,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-09-01T18:10:10Z",
      "updated_at": "2021-08-03T00:48:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.2716,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how"
      },
      "id": "603e95e8e7b9d286642a07fa"
    },
    {
      "sections": [
        "NRQL query examples for mobile monitoring",
        "Mobile, MobileSession, and MobileCrash event query examples",
        "Interactions: Which interactions are most popular among my users?",
        "Location: Which regions of China have the most users?",
        "Device profile: How many users use the latest OS versions?",
        "App version: Have we seen an increase in session duration since yesterday's release?",
        "Performance: How much memory does my app use for sessions longer than 5 seconds?",
        "Crashes: What are my app's most common crashes?",
        "Crash rate: What is the crash rate for different versions of my app?",
        "MobileRequest event query examples",
        "Error rate by request domain",
        "Error rate for business-critical API",
        "Response time percentiles of important APIs",
        "Volume of network requests",
        "Slow response user impact",
        "Response time distribution by domain, carrier, ASN owner, country, etc.",
        "Percentile response time",
        "Requests per session",
        "MobileRequestError event query examples",
        "HTTP errors",
        "Network failures",
        "Error rate: Percentage of users impacted",
        "Errors by version",
        "Unique devices (by UUID)",
        "Historical HTTP error counts",
        "MobileHandledException event query examples",
        "App exceptions",
        "Top exception locations",
        "Most common interaction generating exceptions",
        "Most common exception message",
        "Most common method reporting exceptions",
        "Handled exception rate"
      ],
      "title": "NRQL query examples for mobile monitoring",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "2844422852b86681e69a3ef9333f2268deacbecb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-query-examples-mobile-monitoring/",
      "published_at": "2021-09-01T18:09:11Z",
      "updated_at": "2021-08-03T00:46:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways to query your data. This document will show you some example NRQL queries from mobile monitoring data. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event query examples Mobile queries allow you to understand and compare a wide variety of mobile data, including interactions, location, device profile, app version, crashes, and performance. These examples use queries made on the Mobile, MobileSession, and MobileCrash event types: Interactions: Which interactions are most popular among my users? SELECT uniqueCount(uuid) FROM Mobile SINCE 1 day ago FACET name Copy Location: Which regions of China have the most users? SELECT uniqueCount(uuid) FROM MobileSession WHERE countryCode='CN' FACET regionCode SINCE 7 days ago Copy Device profile: How many users use the latest OS versions? SELECT uniqueCount(uuid) FROM MobileSession FACET osVersion SINCE 7 days ago Copy App version: Have we seen an increase in session duration since yesterday's release? SELECT percentile(sessionDuration, 90) FROM MobileSession since 1 day ago compare with 2 days ago Copy Performance: How much memory does my app use for sessions longer than 5 seconds? SELECT histogram(memUsageMb) FROM MobileSession WHERE sessionDuration > 5 Copy Crashes: What are my app's most common crashes? SELECT count(*) FROM MobileCrash FACET crashException Copy Crash rate: What is the crash rate for different versions of my app? SELECT percentage(uniqueCount(sessionId), WHERE category = 'Crash') as `Crash rate` FROM MobileSession, MobileCrash facet appVersion since 90 days ago Copy MobileRequest event query examples This feature requires mobile monitoring agent version 5.14.0 or higher. MobileRequest data is enabled by default for: Android version 5.15.2 or higher iOS version 6.0.0 or higher For earlier versions, starting with Android version 5.14.0 or iOS version 5.14.0, you must enable the feature. Upgrade to the latest Android or iOS version, or add the required feature flag to your app. Below are some NRQL queries that address common use cases. Use the MobileRequest attributes to make your own NRQL queries. The last two examples use MobileRequestError events in addition to MobileRequest to get an error rate. Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate seen by our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Response time percentiles of important APIs For important requests in the 90th percentile, what is the response time by URL? SELECT percentile(responseTime, 90), latest(requestUrl) as 'Latest URL' from MobileRequest facet cases(where requestUrl like '%{YOUR_CORE_API}%' as 'Core API', where requestUrl like '%{YOUR_FEATURE_API}%' as 'New Feature API') Copy Volume of network requests How much network traffic from the apps are backend services receiving? SELECT count(*) FROM MobileRequest FACET requestDomain since 3 days ago Copy Slow response user impact What % of users are impacted by http response times greater than 3 seconds? SELECT filter(uniqueCount(MobileRequest.uuid), WHERE responseTime > 3) / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted' FROM MobileRequest, MobileSession since 1 day ago timeseries compare with 2 days ago Copy Response time distribution by domain, carrier, ASN owner, country, etc. What is the distribution of response time and request count across domain, country, carrier, or ASN owner? SELECT histogram(responseTime, 20, 20) FROM MobileRequest since 3 days ago facet asnOwner Copy Percentile response time What is the breakdown of response time by different percentiles? SELECT percentile(responseTime, 98) as '98 percentile (sec)', percentile(responseTime, 90) as '90 percentile (sec)', percentile(responseTime, 50) as '50 percentile (sec)' from MobileRequest since 3 days ago Copy Requests per session How do requests per session compare across different apps or subsequent builds of those apps? SELECT count(*)/uniqueCount(sessionId) from MobileRequest, MobileSession facet appName timeseries Copy MobileRequestError event query examples Below are some NRQL queries that address common use cases. Use the MobileRequestError attributes to make your own NRQL queries. HTTP errors Which queries are causing the most errors? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestUrl Copy Network failures What network failures are most common for my application? SELECT count(*) FROM MobileRequestError where errorType = 'NetworkFailure' facet networkError Copy Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate in our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Error rate: Percentage of users impacted How many users are experiencing errors as compared to my total user count? SELECT filter(uniqueCount(MobileRequestError.uuid), WHERE errorType = 'HTTPError') / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted by Errors' FROM MobileRequestError, MobileSession COMPARE WITH 7 days AGO Copy Errors by version Which version(s) of my app are causing the most errors? SELECT count(*) FROM MobileRequestError FACET appVersion Copy Unique devices (by UUID) Which unique devices (by UUID) are having the most issues with my application? SELECT count(*), latest(device), latest(carrier), latest(asnOwner), latest(countryCode) FROM MobileRequestError FACET deviceUuid limit 100 SINCE 1 days ago Copy Historical HTTP error counts What does my historical HTTP Error count look like (by domain)? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestDomain timeseries Copy MobileHandledException event query examples Below are some NRQL queries for common handled exception use cases. Use the MobileHandledException attributes to make your own NRQL queries. App exceptions Which apps have reported the most number of handled exceptions? SELECT count(*) FROM MobileHandledException FACET appName SINCE 3 days ago Copy Top exception locations What are most common exception locations for my application? How many exceptions do we have, and where do they occur? SELECT count(*) FROM MobileHandledException FACET exceptionLocation SINCE 3 days ago Copy Most common interaction generating exceptions Which interaction produces the most exceptions? SELECT count(*) FROM MobileHandledException FACET lastInteraction SINCE 3 days ago Copy Most common exception message What are the most common reported exception messages? SELECT count(*) FROM MobileHandledException FACET exceptionMessage SINCE 3 days ago Copy Most common method reporting exceptions What are the most common methods reporting exceptions? SELECT count(*) FROM MobileHandledException FACET exceptionLocationMethod SINCE 3 days ago Copy Handled exception rate How often are handled exceptions encountered by our users? SELECT percentage(uniqueCount(sessionId), WHERE exceptionLocation IS NOT NULL) FROM MobileSession,MobileHandledException SINCE 3 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.27,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "sections": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "There are several ways to <em>query</em> <em>your</em> <em>data</em>. This document will show you some example <em>NRQL</em> queries from mobile monitoring <em>data</em>. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event <em>query</em> examples Mobile queries"
      },
      "id": "60445a6128ccbc6b6a2c60ca"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-09-02T12:17:14Z",
      "updated_at": "2021-09-02T12:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (e.g., SELECT median(one_metric</var>), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b' Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.80304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-09-01T18:10:10Z",
      "updated_at": "2021-08-03T00:48:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.27159,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how"
      },
      "id": "603e95e8e7b9d286642a07fa"
    },
    {
      "sections": [
        "NRQL query examples for mobile monitoring",
        "Mobile, MobileSession, and MobileCrash event query examples",
        "Interactions: Which interactions are most popular among my users?",
        "Location: Which regions of China have the most users?",
        "Device profile: How many users use the latest OS versions?",
        "App version: Have we seen an increase in session duration since yesterday's release?",
        "Performance: How much memory does my app use for sessions longer than 5 seconds?",
        "Crashes: What are my app's most common crashes?",
        "Crash rate: What is the crash rate for different versions of my app?",
        "MobileRequest event query examples",
        "Error rate by request domain",
        "Error rate for business-critical API",
        "Response time percentiles of important APIs",
        "Volume of network requests",
        "Slow response user impact",
        "Response time distribution by domain, carrier, ASN owner, country, etc.",
        "Percentile response time",
        "Requests per session",
        "MobileRequestError event query examples",
        "HTTP errors",
        "Network failures",
        "Error rate: Percentage of users impacted",
        "Errors by version",
        "Unique devices (by UUID)",
        "Historical HTTP error counts",
        "MobileHandledException event query examples",
        "App exceptions",
        "Top exception locations",
        "Most common interaction generating exceptions",
        "Most common exception message",
        "Most common method reporting exceptions",
        "Handled exception rate"
      ],
      "title": "NRQL query examples for mobile monitoring",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "2844422852b86681e69a3ef9333f2268deacbecb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-query-examples-mobile-monitoring/",
      "published_at": "2021-09-01T18:09:11Z",
      "updated_at": "2021-08-03T00:46:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways to query your data. This document will show you some example NRQL queries from mobile monitoring data. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event query examples Mobile queries allow you to understand and compare a wide variety of mobile data, including interactions, location, device profile, app version, crashes, and performance. These examples use queries made on the Mobile, MobileSession, and MobileCrash event types: Interactions: Which interactions are most popular among my users? SELECT uniqueCount(uuid) FROM Mobile SINCE 1 day ago FACET name Copy Location: Which regions of China have the most users? SELECT uniqueCount(uuid) FROM MobileSession WHERE countryCode='CN' FACET regionCode SINCE 7 days ago Copy Device profile: How many users use the latest OS versions? SELECT uniqueCount(uuid) FROM MobileSession FACET osVersion SINCE 7 days ago Copy App version: Have we seen an increase in session duration since yesterday's release? SELECT percentile(sessionDuration, 90) FROM MobileSession since 1 day ago compare with 2 days ago Copy Performance: How much memory does my app use for sessions longer than 5 seconds? SELECT histogram(memUsageMb) FROM MobileSession WHERE sessionDuration > 5 Copy Crashes: What are my app's most common crashes? SELECT count(*) FROM MobileCrash FACET crashException Copy Crash rate: What is the crash rate for different versions of my app? SELECT percentage(uniqueCount(sessionId), WHERE category = 'Crash') as `Crash rate` FROM MobileSession, MobileCrash facet appVersion since 90 days ago Copy MobileRequest event query examples This feature requires mobile monitoring agent version 5.14.0 or higher. MobileRequest data is enabled by default for: Android version 5.15.2 or higher iOS version 6.0.0 or higher For earlier versions, starting with Android version 5.14.0 or iOS version 5.14.0, you must enable the feature. Upgrade to the latest Android or iOS version, or add the required feature flag to your app. Below are some NRQL queries that address common use cases. Use the MobileRequest attributes to make your own NRQL queries. The last two examples use MobileRequestError events in addition to MobileRequest to get an error rate. Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate seen by our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Response time percentiles of important APIs For important requests in the 90th percentile, what is the response time by URL? SELECT percentile(responseTime, 90), latest(requestUrl) as 'Latest URL' from MobileRequest facet cases(where requestUrl like '%{YOUR_CORE_API}%' as 'Core API', where requestUrl like '%{YOUR_FEATURE_API}%' as 'New Feature API') Copy Volume of network requests How much network traffic from the apps are backend services receiving? SELECT count(*) FROM MobileRequest FACET requestDomain since 3 days ago Copy Slow response user impact What % of users are impacted by http response times greater than 3 seconds? SELECT filter(uniqueCount(MobileRequest.uuid), WHERE responseTime > 3) / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted' FROM MobileRequest, MobileSession since 1 day ago timeseries compare with 2 days ago Copy Response time distribution by domain, carrier, ASN owner, country, etc. What is the distribution of response time and request count across domain, country, carrier, or ASN owner? SELECT histogram(responseTime, 20, 20) FROM MobileRequest since 3 days ago facet asnOwner Copy Percentile response time What is the breakdown of response time by different percentiles? SELECT percentile(responseTime, 98) as '98 percentile (sec)', percentile(responseTime, 90) as '90 percentile (sec)', percentile(responseTime, 50) as '50 percentile (sec)' from MobileRequest since 3 days ago Copy Requests per session How do requests per session compare across different apps or subsequent builds of those apps? SELECT count(*)/uniqueCount(sessionId) from MobileRequest, MobileSession facet appName timeseries Copy MobileRequestError event query examples Below are some NRQL queries that address common use cases. Use the MobileRequestError attributes to make your own NRQL queries. HTTP errors Which queries are causing the most errors? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestUrl Copy Network failures What network failures are most common for my application? SELECT count(*) FROM MobileRequestError where errorType = 'NetworkFailure' facet networkError Copy Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate in our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Error rate: Percentage of users impacted How many users are experiencing errors as compared to my total user count? SELECT filter(uniqueCount(MobileRequestError.uuid), WHERE errorType = 'HTTPError') / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted by Errors' FROM MobileRequestError, MobileSession COMPARE WITH 7 days AGO Copy Errors by version Which version(s) of my app are causing the most errors? SELECT count(*) FROM MobileRequestError FACET appVersion Copy Unique devices (by UUID) Which unique devices (by UUID) are having the most issues with my application? SELECT count(*), latest(device), latest(carrier), latest(asnOwner), latest(countryCode) FROM MobileRequestError FACET deviceUuid limit 100 SINCE 1 days ago Copy Historical HTTP error counts What does my historical HTTP Error count look like (by domain)? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestDomain timeseries Copy MobileHandledException event query examples Below are some NRQL queries for common handled exception use cases. Use the MobileHandledException attributes to make your own NRQL queries. App exceptions Which apps have reported the most number of handled exceptions? SELECT count(*) FROM MobileHandledException FACET appName SINCE 3 days ago Copy Top exception locations What are most common exception locations for my application? How many exceptions do we have, and where do they occur? SELECT count(*) FROM MobileHandledException FACET exceptionLocation SINCE 3 days ago Copy Most common interaction generating exceptions Which interaction produces the most exceptions? SELECT count(*) FROM MobileHandledException FACET lastInteraction SINCE 3 days ago Copy Most common exception message What are the most common reported exception messages? SELECT count(*) FROM MobileHandledException FACET exceptionMessage SINCE 3 days ago Copy Most common method reporting exceptions What are the most common methods reporting exceptions? SELECT count(*) FROM MobileHandledException FACET exceptionLocationMethod SINCE 3 days ago Copy Handled exception rate How often are handled exceptions encountered by our users? SELECT percentage(uniqueCount(sessionId), WHERE exceptionLocation IS NOT NULL) FROM MobileSession,MobileHandledException SINCE 3 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.26999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "sections": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "There are several ways to <em>query</em> <em>your</em> <em>data</em>. This document will show you some example <em>NRQL</em> queries from mobile monitoring <em>data</em>. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event <em>query</em> examples Mobile queries"
      },
      "id": "60445a6128ccbc6b6a2c60ca"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/funnels-evaluate-data-series-related-events": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-09-02T12:17:14Z",
      "updated_at": "2021-09-02T12:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (e.g., SELECT median(one_metric</var>), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b' Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.80304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-09-01T18:10:10Z",
      "updated_at": "2021-08-03T00:48:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.27159,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how"
      },
      "id": "603e95e8e7b9d286642a07fa"
    },
    {
      "sections": [
        "NRQL query examples for mobile monitoring",
        "Mobile, MobileSession, and MobileCrash event query examples",
        "Interactions: Which interactions are most popular among my users?",
        "Location: Which regions of China have the most users?",
        "Device profile: How many users use the latest OS versions?",
        "App version: Have we seen an increase in session duration since yesterday's release?",
        "Performance: How much memory does my app use for sessions longer than 5 seconds?",
        "Crashes: What are my app's most common crashes?",
        "Crash rate: What is the crash rate for different versions of my app?",
        "MobileRequest event query examples",
        "Error rate by request domain",
        "Error rate for business-critical API",
        "Response time percentiles of important APIs",
        "Volume of network requests",
        "Slow response user impact",
        "Response time distribution by domain, carrier, ASN owner, country, etc.",
        "Percentile response time",
        "Requests per session",
        "MobileRequestError event query examples",
        "HTTP errors",
        "Network failures",
        "Error rate: Percentage of users impacted",
        "Errors by version",
        "Unique devices (by UUID)",
        "Historical HTTP error counts",
        "MobileHandledException event query examples",
        "App exceptions",
        "Top exception locations",
        "Most common interaction generating exceptions",
        "Most common exception message",
        "Most common method reporting exceptions",
        "Handled exception rate"
      ],
      "title": "NRQL query examples for mobile monitoring",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "2844422852b86681e69a3ef9333f2268deacbecb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-query-examples-mobile-monitoring/",
      "published_at": "2021-09-01T18:09:11Z",
      "updated_at": "2021-08-03T00:46:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways to query your data. This document will show you some example NRQL queries from mobile monitoring data. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event query examples Mobile queries allow you to understand and compare a wide variety of mobile data, including interactions, location, device profile, app version, crashes, and performance. These examples use queries made on the Mobile, MobileSession, and MobileCrash event types: Interactions: Which interactions are most popular among my users? SELECT uniqueCount(uuid) FROM Mobile SINCE 1 day ago FACET name Copy Location: Which regions of China have the most users? SELECT uniqueCount(uuid) FROM MobileSession WHERE countryCode='CN' FACET regionCode SINCE 7 days ago Copy Device profile: How many users use the latest OS versions? SELECT uniqueCount(uuid) FROM MobileSession FACET osVersion SINCE 7 days ago Copy App version: Have we seen an increase in session duration since yesterday's release? SELECT percentile(sessionDuration, 90) FROM MobileSession since 1 day ago compare with 2 days ago Copy Performance: How much memory does my app use for sessions longer than 5 seconds? SELECT histogram(memUsageMb) FROM MobileSession WHERE sessionDuration > 5 Copy Crashes: What are my app's most common crashes? SELECT count(*) FROM MobileCrash FACET crashException Copy Crash rate: What is the crash rate for different versions of my app? SELECT percentage(uniqueCount(sessionId), WHERE category = 'Crash') as `Crash rate` FROM MobileSession, MobileCrash facet appVersion since 90 days ago Copy MobileRequest event query examples This feature requires mobile monitoring agent version 5.14.0 or higher. MobileRequest data is enabled by default for: Android version 5.15.2 or higher iOS version 6.0.0 or higher For earlier versions, starting with Android version 5.14.0 or iOS version 5.14.0, you must enable the feature. Upgrade to the latest Android or iOS version, or add the required feature flag to your app. Below are some NRQL queries that address common use cases. Use the MobileRequest attributes to make your own NRQL queries. The last two examples use MobileRequestError events in addition to MobileRequest to get an error rate. Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate seen by our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Response time percentiles of important APIs For important requests in the 90th percentile, what is the response time by URL? SELECT percentile(responseTime, 90), latest(requestUrl) as 'Latest URL' from MobileRequest facet cases(where requestUrl like '%{YOUR_CORE_API}%' as 'Core API', where requestUrl like '%{YOUR_FEATURE_API}%' as 'New Feature API') Copy Volume of network requests How much network traffic from the apps are backend services receiving? SELECT count(*) FROM MobileRequest FACET requestDomain since 3 days ago Copy Slow response user impact What % of users are impacted by http response times greater than 3 seconds? SELECT filter(uniqueCount(MobileRequest.uuid), WHERE responseTime > 3) / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted' FROM MobileRequest, MobileSession since 1 day ago timeseries compare with 2 days ago Copy Response time distribution by domain, carrier, ASN owner, country, etc. What is the distribution of response time and request count across domain, country, carrier, or ASN owner? SELECT histogram(responseTime, 20, 20) FROM MobileRequest since 3 days ago facet asnOwner Copy Percentile response time What is the breakdown of response time by different percentiles? SELECT percentile(responseTime, 98) as '98 percentile (sec)', percentile(responseTime, 90) as '90 percentile (sec)', percentile(responseTime, 50) as '50 percentile (sec)' from MobileRequest since 3 days ago Copy Requests per session How do requests per session compare across different apps or subsequent builds of those apps? SELECT count(*)/uniqueCount(sessionId) from MobileRequest, MobileSession facet appName timeseries Copy MobileRequestError event query examples Below are some NRQL queries that address common use cases. Use the MobileRequestError attributes to make your own NRQL queries. HTTP errors Which queries are causing the most errors? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestUrl Copy Network failures What network failures are most common for my application? SELECT count(*) FROM MobileRequestError where errorType = 'NetworkFailure' facet networkError Copy Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate in our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Error rate: Percentage of users impacted How many users are experiencing errors as compared to my total user count? SELECT filter(uniqueCount(MobileRequestError.uuid), WHERE errorType = 'HTTPError') / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted by Errors' FROM MobileRequestError, MobileSession COMPARE WITH 7 days AGO Copy Errors by version Which version(s) of my app are causing the most errors? SELECT count(*) FROM MobileRequestError FACET appVersion Copy Unique devices (by UUID) Which unique devices (by UUID) are having the most issues with my application? SELECT count(*), latest(device), latest(carrier), latest(asnOwner), latest(countryCode) FROM MobileRequestError FACET deviceUuid limit 100 SINCE 1 days ago Copy Historical HTTP error counts What does my historical HTTP Error count look like (by domain)? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestDomain timeseries Copy MobileHandledException event query examples Below are some NRQL queries for common handled exception use cases. Use the MobileHandledException attributes to make your own NRQL queries. App exceptions Which apps have reported the most number of handled exceptions? SELECT count(*) FROM MobileHandledException FACET appName SINCE 3 days ago Copy Top exception locations What are most common exception locations for my application? How many exceptions do we have, and where do they occur? SELECT count(*) FROM MobileHandledException FACET exceptionLocation SINCE 3 days ago Copy Most common interaction generating exceptions Which interaction produces the most exceptions? SELECT count(*) FROM MobileHandledException FACET lastInteraction SINCE 3 days ago Copy Most common exception message What are the most common reported exception messages? SELECT count(*) FROM MobileHandledException FACET exceptionMessage SINCE 3 days ago Copy Most common method reporting exceptions What are the most common methods reporting exceptions? SELECT count(*) FROM MobileHandledException FACET exceptionLocationMethod SINCE 3 days ago Copy Handled exception rate How often are handled exceptions encountered by our users? SELECT percentage(uniqueCount(sessionId), WHERE exceptionLocation IS NOT NULL) FROM MobileSession,MobileHandledException SINCE 3 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.26999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "sections": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "There are several ways to <em>query</em> <em>your</em> <em>data</em>. This document will show you some example <em>NRQL</em> queries from mobile monitoring <em>data</em>. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event <em>query</em> examples Mobile queries"
      },
      "id": "60445a6128ccbc6b6a2c60ca"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/improvements-nrql-percentile": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-09-02T12:17:14Z",
      "updated_at": "2021-09-02T12:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (e.g., SELECT median(one_metric</var>), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b' Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.80286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-09-01T18:10:10Z",
      "updated_at": "2021-08-03T00:48:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.27158,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how"
      },
      "id": "603e95e8e7b9d286642a07fa"
    },
    {
      "sections": [
        "NRQL query examples for mobile monitoring",
        "Mobile, MobileSession, and MobileCrash event query examples",
        "Interactions: Which interactions are most popular among my users?",
        "Location: Which regions of China have the most users?",
        "Device profile: How many users use the latest OS versions?",
        "App version: Have we seen an increase in session duration since yesterday's release?",
        "Performance: How much memory does my app use for sessions longer than 5 seconds?",
        "Crashes: What are my app's most common crashes?",
        "Crash rate: What is the crash rate for different versions of my app?",
        "MobileRequest event query examples",
        "Error rate by request domain",
        "Error rate for business-critical API",
        "Response time percentiles of important APIs",
        "Volume of network requests",
        "Slow response user impact",
        "Response time distribution by domain, carrier, ASN owner, country, etc.",
        "Percentile response time",
        "Requests per session",
        "MobileRequestError event query examples",
        "HTTP errors",
        "Network failures",
        "Error rate: Percentage of users impacted",
        "Errors by version",
        "Unique devices (by UUID)",
        "Historical HTTP error counts",
        "MobileHandledException event query examples",
        "App exceptions",
        "Top exception locations",
        "Most common interaction generating exceptions",
        "Most common exception message",
        "Most common method reporting exceptions",
        "Handled exception rate"
      ],
      "title": "NRQL query examples for mobile monitoring",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "2844422852b86681e69a3ef9333f2268deacbecb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-query-examples-mobile-monitoring/",
      "published_at": "2021-09-01T18:09:11Z",
      "updated_at": "2021-08-03T00:46:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways to query your data. This document will show you some example NRQL queries from mobile monitoring data. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event query examples Mobile queries allow you to understand and compare a wide variety of mobile data, including interactions, location, device profile, app version, crashes, and performance. These examples use queries made on the Mobile, MobileSession, and MobileCrash event types: Interactions: Which interactions are most popular among my users? SELECT uniqueCount(uuid) FROM Mobile SINCE 1 day ago FACET name Copy Location: Which regions of China have the most users? SELECT uniqueCount(uuid) FROM MobileSession WHERE countryCode='CN' FACET regionCode SINCE 7 days ago Copy Device profile: How many users use the latest OS versions? SELECT uniqueCount(uuid) FROM MobileSession FACET osVersion SINCE 7 days ago Copy App version: Have we seen an increase in session duration since yesterday's release? SELECT percentile(sessionDuration, 90) FROM MobileSession since 1 day ago compare with 2 days ago Copy Performance: How much memory does my app use for sessions longer than 5 seconds? SELECT histogram(memUsageMb) FROM MobileSession WHERE sessionDuration > 5 Copy Crashes: What are my app's most common crashes? SELECT count(*) FROM MobileCrash FACET crashException Copy Crash rate: What is the crash rate for different versions of my app? SELECT percentage(uniqueCount(sessionId), WHERE category = 'Crash') as `Crash rate` FROM MobileSession, MobileCrash facet appVersion since 90 days ago Copy MobileRequest event query examples This feature requires mobile monitoring agent version 5.14.0 or higher. MobileRequest data is enabled by default for: Android version 5.15.2 or higher iOS version 6.0.0 or higher For earlier versions, starting with Android version 5.14.0 or iOS version 5.14.0, you must enable the feature. Upgrade to the latest Android or iOS version, or add the required feature flag to your app. Below are some NRQL queries that address common use cases. Use the MobileRequest attributes to make your own NRQL queries. The last two examples use MobileRequestError events in addition to MobileRequest to get an error rate. Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate seen by our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Response time percentiles of important APIs For important requests in the 90th percentile, what is the response time by URL? SELECT percentile(responseTime, 90), latest(requestUrl) as 'Latest URL' from MobileRequest facet cases(where requestUrl like '%{YOUR_CORE_API}%' as 'Core API', where requestUrl like '%{YOUR_FEATURE_API}%' as 'New Feature API') Copy Volume of network requests How much network traffic from the apps are backend services receiving? SELECT count(*) FROM MobileRequest FACET requestDomain since 3 days ago Copy Slow response user impact What % of users are impacted by http response times greater than 3 seconds? SELECT filter(uniqueCount(MobileRequest.uuid), WHERE responseTime > 3) / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted' FROM MobileRequest, MobileSession since 1 day ago timeseries compare with 2 days ago Copy Response time distribution by domain, carrier, ASN owner, country, etc. What is the distribution of response time and request count across domain, country, carrier, or ASN owner? SELECT histogram(responseTime, 20, 20) FROM MobileRequest since 3 days ago facet asnOwner Copy Percentile response time What is the breakdown of response time by different percentiles? SELECT percentile(responseTime, 98) as '98 percentile (sec)', percentile(responseTime, 90) as '90 percentile (sec)', percentile(responseTime, 50) as '50 percentile (sec)' from MobileRequest since 3 days ago Copy Requests per session How do requests per session compare across different apps or subsequent builds of those apps? SELECT count(*)/uniqueCount(sessionId) from MobileRequest, MobileSession facet appName timeseries Copy MobileRequestError event query examples Below are some NRQL queries that address common use cases. Use the MobileRequestError attributes to make your own NRQL queries. HTTP errors Which queries are causing the most errors? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestUrl Copy Network failures What network failures are most common for my application? SELECT count(*) FROM MobileRequestError where errorType = 'NetworkFailure' facet networkError Copy Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate in our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Error rate: Percentage of users impacted How many users are experiencing errors as compared to my total user count? SELECT filter(uniqueCount(MobileRequestError.uuid), WHERE errorType = 'HTTPError') / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted by Errors' FROM MobileRequestError, MobileSession COMPARE WITH 7 days AGO Copy Errors by version Which version(s) of my app are causing the most errors? SELECT count(*) FROM MobileRequestError FACET appVersion Copy Unique devices (by UUID) Which unique devices (by UUID) are having the most issues with my application? SELECT count(*), latest(device), latest(carrier), latest(asnOwner), latest(countryCode) FROM MobileRequestError FACET deviceUuid limit 100 SINCE 1 days ago Copy Historical HTTP error counts What does my historical HTTP Error count look like (by domain)? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestDomain timeseries Copy MobileHandledException event query examples Below are some NRQL queries for common handled exception use cases. Use the MobileHandledException attributes to make your own NRQL queries. App exceptions Which apps have reported the most number of handled exceptions? SELECT count(*) FROM MobileHandledException FACET appName SINCE 3 days ago Copy Top exception locations What are most common exception locations for my application? How many exceptions do we have, and where do they occur? SELECT count(*) FROM MobileHandledException FACET exceptionLocation SINCE 3 days ago Copy Most common interaction generating exceptions Which interaction produces the most exceptions? SELECT count(*) FROM MobileHandledException FACET lastInteraction SINCE 3 days ago Copy Most common exception message What are the most common reported exception messages? SELECT count(*) FROM MobileHandledException FACET exceptionMessage SINCE 3 days ago Copy Most common method reporting exceptions What are the most common methods reporting exceptions? SELECT count(*) FROM MobileHandledException FACET exceptionLocationMethod SINCE 3 days ago Copy Handled exception rate How often are handled exceptions encountered by our users? SELECT percentage(uniqueCount(sessionId), WHERE exceptionLocation IS NOT NULL) FROM MobileSession,MobileHandledException SINCE 3 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.26997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "sections": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "There are several ways to <em>query</em> <em>your</em> <em>data</em>. This document will show you some example <em>NRQL</em> queries from mobile monitoring <em>data</em>. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event <em>query</em> examples Mobile queries"
      },
      "id": "60445a6128ccbc6b6a2c60ca"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nested-aggregation-make-ordered-computations-single-query": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-09-02T12:17:14Z",
      "updated_at": "2021-09-02T12:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (e.g., SELECT median(one_metric</var>), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b' Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.80286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-09-01T18:10:10Z",
      "updated_at": "2021-08-03T00:48:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.27158,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how"
      },
      "id": "603e95e8e7b9d286642a07fa"
    },
    {
      "sections": [
        "NRQL query examples for mobile monitoring",
        "Mobile, MobileSession, and MobileCrash event query examples",
        "Interactions: Which interactions are most popular among my users?",
        "Location: Which regions of China have the most users?",
        "Device profile: How many users use the latest OS versions?",
        "App version: Have we seen an increase in session duration since yesterday's release?",
        "Performance: How much memory does my app use for sessions longer than 5 seconds?",
        "Crashes: What are my app's most common crashes?",
        "Crash rate: What is the crash rate for different versions of my app?",
        "MobileRequest event query examples",
        "Error rate by request domain",
        "Error rate for business-critical API",
        "Response time percentiles of important APIs",
        "Volume of network requests",
        "Slow response user impact",
        "Response time distribution by domain, carrier, ASN owner, country, etc.",
        "Percentile response time",
        "Requests per session",
        "MobileRequestError event query examples",
        "HTTP errors",
        "Network failures",
        "Error rate: Percentage of users impacted",
        "Errors by version",
        "Unique devices (by UUID)",
        "Historical HTTP error counts",
        "MobileHandledException event query examples",
        "App exceptions",
        "Top exception locations",
        "Most common interaction generating exceptions",
        "Most common exception message",
        "Most common method reporting exceptions",
        "Handled exception rate"
      ],
      "title": "NRQL query examples for mobile monitoring",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "2844422852b86681e69a3ef9333f2268deacbecb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-query-examples-mobile-monitoring/",
      "published_at": "2021-09-01T18:09:11Z",
      "updated_at": "2021-08-03T00:46:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways to query your data. This document will show you some example NRQL queries from mobile monitoring data. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event query examples Mobile queries allow you to understand and compare a wide variety of mobile data, including interactions, location, device profile, app version, crashes, and performance. These examples use queries made on the Mobile, MobileSession, and MobileCrash event types: Interactions: Which interactions are most popular among my users? SELECT uniqueCount(uuid) FROM Mobile SINCE 1 day ago FACET name Copy Location: Which regions of China have the most users? SELECT uniqueCount(uuid) FROM MobileSession WHERE countryCode='CN' FACET regionCode SINCE 7 days ago Copy Device profile: How many users use the latest OS versions? SELECT uniqueCount(uuid) FROM MobileSession FACET osVersion SINCE 7 days ago Copy App version: Have we seen an increase in session duration since yesterday's release? SELECT percentile(sessionDuration, 90) FROM MobileSession since 1 day ago compare with 2 days ago Copy Performance: How much memory does my app use for sessions longer than 5 seconds? SELECT histogram(memUsageMb) FROM MobileSession WHERE sessionDuration > 5 Copy Crashes: What are my app's most common crashes? SELECT count(*) FROM MobileCrash FACET crashException Copy Crash rate: What is the crash rate for different versions of my app? SELECT percentage(uniqueCount(sessionId), WHERE category = 'Crash') as `Crash rate` FROM MobileSession, MobileCrash facet appVersion since 90 days ago Copy MobileRequest event query examples This feature requires mobile monitoring agent version 5.14.0 or higher. MobileRequest data is enabled by default for: Android version 5.15.2 or higher iOS version 6.0.0 or higher For earlier versions, starting with Android version 5.14.0 or iOS version 5.14.0, you must enable the feature. Upgrade to the latest Android or iOS version, or add the required feature flag to your app. Below are some NRQL queries that address common use cases. Use the MobileRequest attributes to make your own NRQL queries. The last two examples use MobileRequestError events in addition to MobileRequest to get an error rate. Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate seen by our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Response time percentiles of important APIs For important requests in the 90th percentile, what is the response time by URL? SELECT percentile(responseTime, 90), latest(requestUrl) as 'Latest URL' from MobileRequest facet cases(where requestUrl like '%{YOUR_CORE_API}%' as 'Core API', where requestUrl like '%{YOUR_FEATURE_API}%' as 'New Feature API') Copy Volume of network requests How much network traffic from the apps are backend services receiving? SELECT count(*) FROM MobileRequest FACET requestDomain since 3 days ago Copy Slow response user impact What % of users are impacted by http response times greater than 3 seconds? SELECT filter(uniqueCount(MobileRequest.uuid), WHERE responseTime > 3) / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted' FROM MobileRequest, MobileSession since 1 day ago timeseries compare with 2 days ago Copy Response time distribution by domain, carrier, ASN owner, country, etc. What is the distribution of response time and request count across domain, country, carrier, or ASN owner? SELECT histogram(responseTime, 20, 20) FROM MobileRequest since 3 days ago facet asnOwner Copy Percentile response time What is the breakdown of response time by different percentiles? SELECT percentile(responseTime, 98) as '98 percentile (sec)', percentile(responseTime, 90) as '90 percentile (sec)', percentile(responseTime, 50) as '50 percentile (sec)' from MobileRequest since 3 days ago Copy Requests per session How do requests per session compare across different apps or subsequent builds of those apps? SELECT count(*)/uniqueCount(sessionId) from MobileRequest, MobileSession facet appName timeseries Copy MobileRequestError event query examples Below are some NRQL queries that address common use cases. Use the MobileRequestError attributes to make your own NRQL queries. HTTP errors Which queries are causing the most errors? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestUrl Copy Network failures What network failures are most common for my application? SELECT count(*) FROM MobileRequestError where errorType = 'NetworkFailure' facet networkError Copy Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate in our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Error rate: Percentage of users impacted How many users are experiencing errors as compared to my total user count? SELECT filter(uniqueCount(MobileRequestError.uuid), WHERE errorType = 'HTTPError') / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted by Errors' FROM MobileRequestError, MobileSession COMPARE WITH 7 days AGO Copy Errors by version Which version(s) of my app are causing the most errors? SELECT count(*) FROM MobileRequestError FACET appVersion Copy Unique devices (by UUID) Which unique devices (by UUID) are having the most issues with my application? SELECT count(*), latest(device), latest(carrier), latest(asnOwner), latest(countryCode) FROM MobileRequestError FACET deviceUuid limit 100 SINCE 1 days ago Copy Historical HTTP error counts What does my historical HTTP Error count look like (by domain)? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestDomain timeseries Copy MobileHandledException event query examples Below are some NRQL queries for common handled exception use cases. Use the MobileHandledException attributes to make your own NRQL queries. App exceptions Which apps have reported the most number of handled exceptions? SELECT count(*) FROM MobileHandledException FACET appName SINCE 3 days ago Copy Top exception locations What are most common exception locations for my application? How many exceptions do we have, and where do they occur? SELECT count(*) FROM MobileHandledException FACET exceptionLocation SINCE 3 days ago Copy Most common interaction generating exceptions Which interaction produces the most exceptions? SELECT count(*) FROM MobileHandledException FACET lastInteraction SINCE 3 days ago Copy Most common exception message What are the most common reported exception messages? SELECT count(*) FROM MobileHandledException FACET exceptionMessage SINCE 3 days ago Copy Most common method reporting exceptions What are the most common methods reporting exceptions? SELECT count(*) FROM MobileHandledException FACET exceptionLocationMethod SINCE 3 days ago Copy Handled exception rate How often are handled exceptions encountered by our users? SELECT percentage(uniqueCount(sessionId), WHERE exceptionLocation IS NOT NULL) FROM MobileSession,MobileHandledException SINCE 3 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.26997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "sections": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "There are several ways to <em>query</em> <em>your</em> <em>data</em>. This document will show you some example <em>NRQL</em> queries from mobile monitoring <em>data</em>. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event <em>query</em> examples Mobile queries"
      },
      "id": "60445a6128ccbc6b6a2c60ca"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-09-02T12:17:14Z",
      "updated_at": "2021-09-02T12:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (e.g., SELECT median(one_metric</var>), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b' Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.80267,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-09-01T18:10:10Z",
      "updated_at": "2021-08-03T00:48:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.27156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how"
      },
      "id": "603e95e8e7b9d286642a07fa"
    },
    {
      "sections": [
        "NRQL query examples for mobile monitoring",
        "Mobile, MobileSession, and MobileCrash event query examples",
        "Interactions: Which interactions are most popular among my users?",
        "Location: Which regions of China have the most users?",
        "Device profile: How many users use the latest OS versions?",
        "App version: Have we seen an increase in session duration since yesterday's release?",
        "Performance: How much memory does my app use for sessions longer than 5 seconds?",
        "Crashes: What are my app's most common crashes?",
        "Crash rate: What is the crash rate for different versions of my app?",
        "MobileRequest event query examples",
        "Error rate by request domain",
        "Error rate for business-critical API",
        "Response time percentiles of important APIs",
        "Volume of network requests",
        "Slow response user impact",
        "Response time distribution by domain, carrier, ASN owner, country, etc.",
        "Percentile response time",
        "Requests per session",
        "MobileRequestError event query examples",
        "HTTP errors",
        "Network failures",
        "Error rate: Percentage of users impacted",
        "Errors by version",
        "Unique devices (by UUID)",
        "Historical HTTP error counts",
        "MobileHandledException event query examples",
        "App exceptions",
        "Top exception locations",
        "Most common interaction generating exceptions",
        "Most common exception message",
        "Most common method reporting exceptions",
        "Handled exception rate"
      ],
      "title": "NRQL query examples for mobile monitoring",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "2844422852b86681e69a3ef9333f2268deacbecb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-query-examples-mobile-monitoring/",
      "published_at": "2021-09-01T18:09:11Z",
      "updated_at": "2021-08-03T00:46:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways to query your data. This document will show you some example NRQL queries from mobile monitoring data. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event query examples Mobile queries allow you to understand and compare a wide variety of mobile data, including interactions, location, device profile, app version, crashes, and performance. These examples use queries made on the Mobile, MobileSession, and MobileCrash event types: Interactions: Which interactions are most popular among my users? SELECT uniqueCount(uuid) FROM Mobile SINCE 1 day ago FACET name Copy Location: Which regions of China have the most users? SELECT uniqueCount(uuid) FROM MobileSession WHERE countryCode='CN' FACET regionCode SINCE 7 days ago Copy Device profile: How many users use the latest OS versions? SELECT uniqueCount(uuid) FROM MobileSession FACET osVersion SINCE 7 days ago Copy App version: Have we seen an increase in session duration since yesterday's release? SELECT percentile(sessionDuration, 90) FROM MobileSession since 1 day ago compare with 2 days ago Copy Performance: How much memory does my app use for sessions longer than 5 seconds? SELECT histogram(memUsageMb) FROM MobileSession WHERE sessionDuration > 5 Copy Crashes: What are my app's most common crashes? SELECT count(*) FROM MobileCrash FACET crashException Copy Crash rate: What is the crash rate for different versions of my app? SELECT percentage(uniqueCount(sessionId), WHERE category = 'Crash') as `Crash rate` FROM MobileSession, MobileCrash facet appVersion since 90 days ago Copy MobileRequest event query examples This feature requires mobile monitoring agent version 5.14.0 or higher. MobileRequest data is enabled by default for: Android version 5.15.2 or higher iOS version 6.0.0 or higher For earlier versions, starting with Android version 5.14.0 or iOS version 5.14.0, you must enable the feature. Upgrade to the latest Android or iOS version, or add the required feature flag to your app. Below are some NRQL queries that address common use cases. Use the MobileRequest attributes to make your own NRQL queries. The last two examples use MobileRequestError events in addition to MobileRequest to get an error rate. Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate seen by our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Response time percentiles of important APIs For important requests in the 90th percentile, what is the response time by URL? SELECT percentile(responseTime, 90), latest(requestUrl) as 'Latest URL' from MobileRequest facet cases(where requestUrl like '%{YOUR_CORE_API}%' as 'Core API', where requestUrl like '%{YOUR_FEATURE_API}%' as 'New Feature API') Copy Volume of network requests How much network traffic from the apps are backend services receiving? SELECT count(*) FROM MobileRequest FACET requestDomain since 3 days ago Copy Slow response user impact What % of users are impacted by http response times greater than 3 seconds? SELECT filter(uniqueCount(MobileRequest.uuid), WHERE responseTime > 3) / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted' FROM MobileRequest, MobileSession since 1 day ago timeseries compare with 2 days ago Copy Response time distribution by domain, carrier, ASN owner, country, etc. What is the distribution of response time and request count across domain, country, carrier, or ASN owner? SELECT histogram(responseTime, 20, 20) FROM MobileRequest since 3 days ago facet asnOwner Copy Percentile response time What is the breakdown of response time by different percentiles? SELECT percentile(responseTime, 98) as '98 percentile (sec)', percentile(responseTime, 90) as '90 percentile (sec)', percentile(responseTime, 50) as '50 percentile (sec)' from MobileRequest since 3 days ago Copy Requests per session How do requests per session compare across different apps or subsequent builds of those apps? SELECT count(*)/uniqueCount(sessionId) from MobileRequest, MobileSession facet appName timeseries Copy MobileRequestError event query examples Below are some NRQL queries that address common use cases. Use the MobileRequestError attributes to make your own NRQL queries. HTTP errors Which queries are causing the most errors? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestUrl Copy Network failures What network failures are most common for my application? SELECT count(*) FROM MobileRequestError where errorType = 'NetworkFailure' facet networkError Copy Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate in our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Error rate: Percentage of users impacted How many users are experiencing errors as compared to my total user count? SELECT filter(uniqueCount(MobileRequestError.uuid), WHERE errorType = 'HTTPError') / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted by Errors' FROM MobileRequestError, MobileSession COMPARE WITH 7 days AGO Copy Errors by version Which version(s) of my app are causing the most errors? SELECT count(*) FROM MobileRequestError FACET appVersion Copy Unique devices (by UUID) Which unique devices (by UUID) are having the most issues with my application? SELECT count(*), latest(device), latest(carrier), latest(asnOwner), latest(countryCode) FROM MobileRequestError FACET deviceUuid limit 100 SINCE 1 days ago Copy Historical HTTP error counts What does my historical HTTP Error count look like (by domain)? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestDomain timeseries Copy MobileHandledException event query examples Below are some NRQL queries for common handled exception use cases. Use the MobileHandledException attributes to make your own NRQL queries. App exceptions Which apps have reported the most number of handled exceptions? SELECT count(*) FROM MobileHandledException FACET appName SINCE 3 days ago Copy Top exception locations What are most common exception locations for my application? How many exceptions do we have, and where do they occur? SELECT count(*) FROM MobileHandledException FACET exceptionLocation SINCE 3 days ago Copy Most common interaction generating exceptions Which interaction produces the most exceptions? SELECT count(*) FROM MobileHandledException FACET lastInteraction SINCE 3 days ago Copy Most common exception message What are the most common reported exception messages? SELECT count(*) FROM MobileHandledException FACET exceptionMessage SINCE 3 days ago Copy Most common method reporting exceptions What are the most common methods reporting exceptions? SELECT count(*) FROM MobileHandledException FACET exceptionLocationMethod SINCE 3 days ago Copy Handled exception rate How often are handled exceptions encountered by our users? SELECT percentage(uniqueCount(sessionId), WHERE exceptionLocation IS NOT NULL) FROM MobileSession,MobileHandledException SINCE 3 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.26996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "sections": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "There are several ways to <em>query</em> <em>your</em> <em>data</em>. This document will show you some example <em>NRQL</em> queries from mobile monitoring <em>data</em>. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event <em>query</em> examples Mobile queries"
      },
      "id": "60445a6128ccbc6b6a2c60ca"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-query-examples-mobile-monitoring": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-09-02T12:17:14Z",
      "updated_at": "2021-09-02T12:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (e.g., SELECT median(one_metric</var>), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b' Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.80267,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-09-01T18:10:10Z",
      "updated_at": "2021-08-03T00:48:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.27156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how"
      },
      "id": "603e95e8e7b9d286642a07fa"
    },
    {
      "sections": [
        "App data NRQL query examples",
        "Unique users",
        "Unique user trends",
        "Pageview trends",
        "OS version",
        "Key account Apdex"
      ],
      "title": "App data NRQL query examples",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "54b651240956896f8bdc7d9c3fbb7b6096f455a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/app-data-nrql-query-examples/",
      "published_at": "2021-09-02T11:09:19Z",
      "updated_at": "2021-07-10T03:13:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL to query the application data collected by APM, browser monitoring, and mobile monitoring. You can then use this data to answer a variety of questions. Here are some basic examples. Unique users How many unique user sessions did you have in the last week? SELECT uniqueCount(session) FROM PageView SINCE 1 week ago Copy Unique user trends Were your unique user sessions up or down last week compared to the week before? SELECT uniqueCount(session) FROM PageView SINCE 1 week ago COMPARE WITH 1 week ago Copy Pageview trends How can I graph the number of unique users yesterday compared to the day before? SELECT count(*) FROM PageView SINCE 1 day ago COMPARE WITH 1 day ago TIMESERIES AUTO Copy OS version How many of your mobile users are on the latest OS version? SELECT uniqueCount(uuid) FROM MobileSession FACET osVersion SINCE 7 days ago Copy Key account Apdex What is the Apdex score for a particularly important customer? If you have defined some custom attributes, you can query to monitor how this customer experiences your app from a performance standpoint: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.68826,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "App <em>data</em> <em>NRQL</em> <em>query</em> examples",
        "sections": "App <em>data</em> <em>NRQL</em> <em>query</em> examples",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "You can use <em>NRQL</em> to <em>query</em> the application <em>data</em> collected by APM, browser monitoring, and mobile monitoring. You can then use this <em>data</em> to answer a variety of questions. Here are some basic examples. Unique users How many unique user sessions did you have in the last week? SELECT uniqueCount(session"
      },
      "id": "60445a0f64441f5a46378eec"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-segment-your-data-buckets": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-09-02T12:17:14Z",
      "updated_at": "2021-09-02T12:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (e.g., SELECT median(one_metric</var>), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b' Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.80255,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-09-01T18:10:10Z",
      "updated_at": "2021-08-03T00:48:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.27155,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how"
      },
      "id": "603e95e8e7b9d286642a07fa"
    },
    {
      "sections": [
        "NRQL query examples for mobile monitoring",
        "Mobile, MobileSession, and MobileCrash event query examples",
        "Interactions: Which interactions are most popular among my users?",
        "Location: Which regions of China have the most users?",
        "Device profile: How many users use the latest OS versions?",
        "App version: Have we seen an increase in session duration since yesterday's release?",
        "Performance: How much memory does my app use for sessions longer than 5 seconds?",
        "Crashes: What are my app's most common crashes?",
        "Crash rate: What is the crash rate for different versions of my app?",
        "MobileRequest event query examples",
        "Error rate by request domain",
        "Error rate for business-critical API",
        "Response time percentiles of important APIs",
        "Volume of network requests",
        "Slow response user impact",
        "Response time distribution by domain, carrier, ASN owner, country, etc.",
        "Percentile response time",
        "Requests per session",
        "MobileRequestError event query examples",
        "HTTP errors",
        "Network failures",
        "Error rate: Percentage of users impacted",
        "Errors by version",
        "Unique devices (by UUID)",
        "Historical HTTP error counts",
        "MobileHandledException event query examples",
        "App exceptions",
        "Top exception locations",
        "Most common interaction generating exceptions",
        "Most common exception message",
        "Most common method reporting exceptions",
        "Handled exception rate"
      ],
      "title": "NRQL query examples for mobile monitoring",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "2844422852b86681e69a3ef9333f2268deacbecb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-query-examples-mobile-monitoring/",
      "published_at": "2021-09-01T18:09:11Z",
      "updated_at": "2021-08-03T00:46:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways to query your data. This document will show you some example NRQL queries from mobile monitoring data. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event query examples Mobile queries allow you to understand and compare a wide variety of mobile data, including interactions, location, device profile, app version, crashes, and performance. These examples use queries made on the Mobile, MobileSession, and MobileCrash event types: Interactions: Which interactions are most popular among my users? SELECT uniqueCount(uuid) FROM Mobile SINCE 1 day ago FACET name Copy Location: Which regions of China have the most users? SELECT uniqueCount(uuid) FROM MobileSession WHERE countryCode='CN' FACET regionCode SINCE 7 days ago Copy Device profile: How many users use the latest OS versions? SELECT uniqueCount(uuid) FROM MobileSession FACET osVersion SINCE 7 days ago Copy App version: Have we seen an increase in session duration since yesterday's release? SELECT percentile(sessionDuration, 90) FROM MobileSession since 1 day ago compare with 2 days ago Copy Performance: How much memory does my app use for sessions longer than 5 seconds? SELECT histogram(memUsageMb) FROM MobileSession WHERE sessionDuration > 5 Copy Crashes: What are my app's most common crashes? SELECT count(*) FROM MobileCrash FACET crashException Copy Crash rate: What is the crash rate for different versions of my app? SELECT percentage(uniqueCount(sessionId), WHERE category = 'Crash') as `Crash rate` FROM MobileSession, MobileCrash facet appVersion since 90 days ago Copy MobileRequest event query examples This feature requires mobile monitoring agent version 5.14.0 or higher. MobileRequest data is enabled by default for: Android version 5.15.2 or higher iOS version 6.0.0 or higher For earlier versions, starting with Android version 5.14.0 or iOS version 5.14.0, you must enable the feature. Upgrade to the latest Android or iOS version, or add the required feature flag to your app. Below are some NRQL queries that address common use cases. Use the MobileRequest attributes to make your own NRQL queries. The last two examples use MobileRequestError events in addition to MobileRequest to get an error rate. Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate seen by our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Response time percentiles of important APIs For important requests in the 90th percentile, what is the response time by URL? SELECT percentile(responseTime, 90), latest(requestUrl) as 'Latest URL' from MobileRequest facet cases(where requestUrl like '%{YOUR_CORE_API}%' as 'Core API', where requestUrl like '%{YOUR_FEATURE_API}%' as 'New Feature API') Copy Volume of network requests How much network traffic from the apps are backend services receiving? SELECT count(*) FROM MobileRequest FACET requestDomain since 3 days ago Copy Slow response user impact What % of users are impacted by http response times greater than 3 seconds? SELECT filter(uniqueCount(MobileRequest.uuid), WHERE responseTime > 3) / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted' FROM MobileRequest, MobileSession since 1 day ago timeseries compare with 2 days ago Copy Response time distribution by domain, carrier, ASN owner, country, etc. What is the distribution of response time and request count across domain, country, carrier, or ASN owner? SELECT histogram(responseTime, 20, 20) FROM MobileRequest since 3 days ago facet asnOwner Copy Percentile response time What is the breakdown of response time by different percentiles? SELECT percentile(responseTime, 98) as '98 percentile (sec)', percentile(responseTime, 90) as '90 percentile (sec)', percentile(responseTime, 50) as '50 percentile (sec)' from MobileRequest since 3 days ago Copy Requests per session How do requests per session compare across different apps or subsequent builds of those apps? SELECT count(*)/uniqueCount(sessionId) from MobileRequest, MobileSession facet appName timeseries Copy MobileRequestError event query examples Below are some NRQL queries that address common use cases. Use the MobileRequestError attributes to make your own NRQL queries. HTTP errors Which queries are causing the most errors? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestUrl Copy Network failures What network failures are most common for my application? SELECT count(*) FROM MobileRequestError where errorType = 'NetworkFailure' facet networkError Copy Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate in our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Error rate: Percentage of users impacted How many users are experiencing errors as compared to my total user count? SELECT filter(uniqueCount(MobileRequestError.uuid), WHERE errorType = 'HTTPError') / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted by Errors' FROM MobileRequestError, MobileSession COMPARE WITH 7 days AGO Copy Errors by version Which version(s) of my app are causing the most errors? SELECT count(*) FROM MobileRequestError FACET appVersion Copy Unique devices (by UUID) Which unique devices (by UUID) are having the most issues with my application? SELECT count(*), latest(device), latest(carrier), latest(asnOwner), latest(countryCode) FROM MobileRequestError FACET deviceUuid limit 100 SINCE 1 days ago Copy Historical HTTP error counts What does my historical HTTP Error count look like (by domain)? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestDomain timeseries Copy MobileHandledException event query examples Below are some NRQL queries for common handled exception use cases. Use the MobileHandledException attributes to make your own NRQL queries. App exceptions Which apps have reported the most number of handled exceptions? SELECT count(*) FROM MobileHandledException FACET appName SINCE 3 days ago Copy Top exception locations What are most common exception locations for my application? How many exceptions do we have, and where do they occur? SELECT count(*) FROM MobileHandledException FACET exceptionLocation SINCE 3 days ago Copy Most common interaction generating exceptions Which interaction produces the most exceptions? SELECT count(*) FROM MobileHandledException FACET lastInteraction SINCE 3 days ago Copy Most common exception message What are the most common reported exception messages? SELECT count(*) FROM MobileHandledException FACET exceptionMessage SINCE 3 days ago Copy Most common method reporting exceptions What are the most common methods reporting exceptions? SELECT count(*) FROM MobileHandledException FACET exceptionLocationMethod SINCE 3 days ago Copy Handled exception rate How often are handled exceptions encountered by our users? SELECT percentage(uniqueCount(sessionId), WHERE exceptionLocation IS NOT NULL) FROM MobileSession,MobileHandledException SINCE 3 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.26996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "sections": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "There are several ways to <em>query</em> <em>your</em> <em>data</em>. This document will show you some example <em>NRQL</em> queries from mobile monitoring <em>data</em>. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event <em>query</em> examples Mobile queries"
      },
      "id": "60445a6128ccbc6b6a2c60ca"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-09-02T12:17:14Z",
      "updated_at": "2021-09-02T12:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (e.g., SELECT median(one_metric</var>), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b' Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.80237,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL query examples for mobile monitoring",
        "Mobile, MobileSession, and MobileCrash event query examples",
        "Interactions: Which interactions are most popular among my users?",
        "Location: Which regions of China have the most users?",
        "Device profile: How many users use the latest OS versions?",
        "App version: Have we seen an increase in session duration since yesterday's release?",
        "Performance: How much memory does my app use for sessions longer than 5 seconds?",
        "Crashes: What are my app's most common crashes?",
        "Crash rate: What is the crash rate for different versions of my app?",
        "MobileRequest event query examples",
        "Error rate by request domain",
        "Error rate for business-critical API",
        "Response time percentiles of important APIs",
        "Volume of network requests",
        "Slow response user impact",
        "Response time distribution by domain, carrier, ASN owner, country, etc.",
        "Percentile response time",
        "Requests per session",
        "MobileRequestError event query examples",
        "HTTP errors",
        "Network failures",
        "Error rate: Percentage of users impacted",
        "Errors by version",
        "Unique devices (by UUID)",
        "Historical HTTP error counts",
        "MobileHandledException event query examples",
        "App exceptions",
        "Top exception locations",
        "Most common interaction generating exceptions",
        "Most common exception message",
        "Most common method reporting exceptions",
        "Handled exception rate"
      ],
      "title": "NRQL query examples for mobile monitoring",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "2844422852b86681e69a3ef9333f2268deacbecb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-query-examples-mobile-monitoring/",
      "published_at": "2021-09-01T18:09:11Z",
      "updated_at": "2021-08-03T00:46:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways to query your data. This document will show you some example NRQL queries from mobile monitoring data. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event query examples Mobile queries allow you to understand and compare a wide variety of mobile data, including interactions, location, device profile, app version, crashes, and performance. These examples use queries made on the Mobile, MobileSession, and MobileCrash event types: Interactions: Which interactions are most popular among my users? SELECT uniqueCount(uuid) FROM Mobile SINCE 1 day ago FACET name Copy Location: Which regions of China have the most users? SELECT uniqueCount(uuid) FROM MobileSession WHERE countryCode='CN' FACET regionCode SINCE 7 days ago Copy Device profile: How many users use the latest OS versions? SELECT uniqueCount(uuid) FROM MobileSession FACET osVersion SINCE 7 days ago Copy App version: Have we seen an increase in session duration since yesterday's release? SELECT percentile(sessionDuration, 90) FROM MobileSession since 1 day ago compare with 2 days ago Copy Performance: How much memory does my app use for sessions longer than 5 seconds? SELECT histogram(memUsageMb) FROM MobileSession WHERE sessionDuration > 5 Copy Crashes: What are my app's most common crashes? SELECT count(*) FROM MobileCrash FACET crashException Copy Crash rate: What is the crash rate for different versions of my app? SELECT percentage(uniqueCount(sessionId), WHERE category = 'Crash') as `Crash rate` FROM MobileSession, MobileCrash facet appVersion since 90 days ago Copy MobileRequest event query examples This feature requires mobile monitoring agent version 5.14.0 or higher. MobileRequest data is enabled by default for: Android version 5.15.2 or higher iOS version 6.0.0 or higher For earlier versions, starting with Android version 5.14.0 or iOS version 5.14.0, you must enable the feature. Upgrade to the latest Android or iOS version, or add the required feature flag to your app. Below are some NRQL queries that address common use cases. Use the MobileRequest attributes to make your own NRQL queries. The last two examples use MobileRequestError events in addition to MobileRequest to get an error rate. Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate seen by our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Response time percentiles of important APIs For important requests in the 90th percentile, what is the response time by URL? SELECT percentile(responseTime, 90), latest(requestUrl) as 'Latest URL' from MobileRequest facet cases(where requestUrl like '%{YOUR_CORE_API}%' as 'Core API', where requestUrl like '%{YOUR_FEATURE_API}%' as 'New Feature API') Copy Volume of network requests How much network traffic from the apps are backend services receiving? SELECT count(*) FROM MobileRequest FACET requestDomain since 3 days ago Copy Slow response user impact What % of users are impacted by http response times greater than 3 seconds? SELECT filter(uniqueCount(MobileRequest.uuid), WHERE responseTime > 3) / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted' FROM MobileRequest, MobileSession since 1 day ago timeseries compare with 2 days ago Copy Response time distribution by domain, carrier, ASN owner, country, etc. What is the distribution of response time and request count across domain, country, carrier, or ASN owner? SELECT histogram(responseTime, 20, 20) FROM MobileRequest since 3 days ago facet asnOwner Copy Percentile response time What is the breakdown of response time by different percentiles? SELECT percentile(responseTime, 98) as '98 percentile (sec)', percentile(responseTime, 90) as '90 percentile (sec)', percentile(responseTime, 50) as '50 percentile (sec)' from MobileRequest since 3 days ago Copy Requests per session How do requests per session compare across different apps or subsequent builds of those apps? SELECT count(*)/uniqueCount(sessionId) from MobileRequest, MobileSession facet appName timeseries Copy MobileRequestError event query examples Below are some NRQL queries that address common use cases. Use the MobileRequestError attributes to make your own NRQL queries. HTTP errors Which queries are causing the most errors? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestUrl Copy Network failures What network failures are most common for my application? SELECT count(*) FROM MobileRequestError where errorType = 'NetworkFailure' facet networkError Copy Error rate by request domain Which domains are prone to failure and error? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestDomain Copy Error rate for business-critical API What is the error rate in our mobile apps for the most business-critical API? SELECT percentage(count(*), where errorType = 'NetworkFailure' OR errorType = 'HTTPError') as 'Error Rate %', count(*) as '# of Requests', filter(count(*), where errorType='NetworkFailure' OR errorType='HTTPError' as '# of Errors') FROM MobileRequestError, MobileRequest facet requestPath where requestPath = '{MY_API_PATH}' Copy Error rate: Percentage of users impacted How many users are experiencing errors as compared to my total user count? SELECT filter(uniqueCount(MobileRequestError.uuid), WHERE errorType = 'HTTPError') / uniqueCount(MobileSession.uuid) * 100 as '% Users Impacted by Errors' FROM MobileRequestError, MobileSession COMPARE WITH 7 days AGO Copy Errors by version Which version(s) of my app are causing the most errors? SELECT count(*) FROM MobileRequestError FACET appVersion Copy Unique devices (by UUID) Which unique devices (by UUID) are having the most issues with my application? SELECT count(*), latest(device), latest(carrier), latest(asnOwner), latest(countryCode) FROM MobileRequestError FACET deviceUuid limit 100 SINCE 1 days ago Copy Historical HTTP error counts What does my historical HTTP Error count look like (by domain)? SELECT count(*) FROM MobileRequestError where errorType = 'HTTPError' FACET requestDomain timeseries Copy MobileHandledException event query examples Below are some NRQL queries for common handled exception use cases. Use the MobileHandledException attributes to make your own NRQL queries. App exceptions Which apps have reported the most number of handled exceptions? SELECT count(*) FROM MobileHandledException FACET appName SINCE 3 days ago Copy Top exception locations What are most common exception locations for my application? How many exceptions do we have, and where do they occur? SELECT count(*) FROM MobileHandledException FACET exceptionLocation SINCE 3 days ago Copy Most common interaction generating exceptions Which interaction produces the most exceptions? SELECT count(*) FROM MobileHandledException FACET lastInteraction SINCE 3 days ago Copy Most common exception message What are the most common reported exception messages? SELECT count(*) FROM MobileHandledException FACET exceptionMessage SINCE 3 days ago Copy Most common method reporting exceptions What are the most common methods reporting exceptions? SELECT count(*) FROM MobileHandledException FACET exceptionLocationMethod SINCE 3 days ago Copy Handled exception rate How often are handled exceptions encountered by our users? SELECT percentage(uniqueCount(sessionId), WHERE exceptionLocation IS NOT NULL) FROM MobileSession,MobileHandledException SINCE 3 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.26993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "sections": "<em>NRQL</em> <em>query</em> examples for mobile monitoring",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "There are several ways to <em>query</em> <em>your</em> <em>data</em>. This document will show you some example <em>NRQL</em> queries from mobile monitoring <em>data</em>. To see descriptions of the mobile-reported events and attributes available, see Mobile events. Mobile, MobileSession, and MobileCrash event <em>query</em> examples Mobile queries"
      },
      "id": "60445a6128ccbc6b6a2c60ca"
    },
    {
      "sections": [
        "App data NRQL query examples",
        "Unique users",
        "Unique user trends",
        "Pageview trends",
        "OS version",
        "Key account Apdex"
      ],
      "title": "App data NRQL query examples",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "54b651240956896f8bdc7d9c3fbb7b6096f455a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/app-data-nrql-query-examples/",
      "published_at": "2021-09-02T11:09:19Z",
      "updated_at": "2021-07-10T03:13:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL to query the application data collected by APM, browser monitoring, and mobile monitoring. You can then use this data to answer a variety of questions. Here are some basic examples. Unique users How many unique user sessions did you have in the last week? SELECT uniqueCount(session) FROM PageView SINCE 1 week ago Copy Unique user trends Were your unique user sessions up or down last week compared to the week before? SELECT uniqueCount(session) FROM PageView SINCE 1 week ago COMPARE WITH 1 week ago Copy Pageview trends How can I graph the number of unique users yesterday compared to the day before? SELECT count(*) FROM PageView SINCE 1 day ago COMPARE WITH 1 day ago TIMESERIES AUTO Copy OS version How many of your mobile users are on the latest OS version? SELECT uniqueCount(uuid) FROM MobileSession FACET osVersion SINCE 7 days ago Copy Key account Apdex What is the Apdex score for a particularly important customer? If you have defined some custom attributes, you can query to monitor how this customer experiences your app from a performance standpoint: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.68825,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "App <em>data</em> <em>NRQL</em> <em>query</em> examples",
        "sections": "App <em>data</em> <em>NRQL</em> <em>query</em> examples",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "You can use <em>NRQL</em> to <em>query</em> the application <em>data</em> collected by APM, browser monitoring, and mobile monitoring. You can then use this <em>data</em> to answer a variety of questions. Here are some basic examples. Unique users How many unique user sessions did you have in the last week? SELECT uniqueCount(session"
      },
      "id": "60445a0f64441f5a46378eec"
    }
  ],
  "/docs/security/index": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 80.699615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 80.69645,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em>",
        "body": " the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware <em>security</em> module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 80.69333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/covid-19": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.91098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90294,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89502,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.91086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.8949,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-01": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.91086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.8949,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-02": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.91075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90271,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89479,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-03": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.91075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90271,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89479,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-04": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.91064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90259,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89468,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-05": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.91064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90259,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89468,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-06": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.91052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90248,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89456,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-01": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.91052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90248,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89456,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-02": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.9104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90237,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-03": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.9104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90237,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-04": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.9104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90237,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-05": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.9103,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90225,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-06": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.9103,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90225,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-07": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.91019,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90215,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89423,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-08": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.91019,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90215,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89423,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-09": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.91006,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.8941,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-10": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.91006,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.8941,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-11": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-12": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-01": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-02": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90985,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.9018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89389,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-03": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90985,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.9018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89389,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-04": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.9017,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89377,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-05": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.9017,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89377,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr20-01": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.9017,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89377,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr20-02": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.9096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90158,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89365,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-01": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.9096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90158,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89365,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-heartbleed-vulnerability": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/solarwinds-orion": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.9094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90135,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89343,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/security-privacy/compliance/data-encryption": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.50583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Services in Scope by <em>compliance</em> program",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " <em>compliance</em> programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our <em>compliance</em> program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 304.41187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 304.4001,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/security-privacy/compliance/fedramp-compliant-endpoints": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.50568,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Services in Scope by <em>compliance</em> program",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " <em>compliance</em> programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our <em>compliance</em> program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 304.41168,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "Data encryption",
        "Encryption in transit",
        "Disk encryption",
        "Account-level encryption"
      ],
      "title": "Data encryption",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c5e00e8b0148c49664de0e5f3e8a2e142ac0aeed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/data-encryption/",
      "published_at": "2021-09-02T16:35:53Z",
      "updated_at": "2021-07-02T01:22:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether your data is in transit to New Relic or at rest in our storage, we apply strong encryption measures to help prevent unauthorized access, threats, or theft. This includes FIPS 140-2 compliance as well as security accreditation for the Federal Risk and Authorization Management Program (FedRAMP). New Relic is authorized for Moderate Impact SaaS Services (FedRAMP Authorized Moderate) for accounts that meet specific criteria. As a cloud service provider, we are committed to ensuring our compliance with FedRAMP's requirements for the confidentiality, integrity, and availability of your data. This document describes our data encryption methods, including who gets it, what data is encrypted, and how it works. For more information, see our security documentation and Security website, or contact your account representative. Encryption in transit All New Relic customers benefit from the security provided with data encryption in transit. TLS is required for all domains. Encryption in transit Comments Who gets it Data encryption in transit is automatically included in all New Relic subscriptions. What data is encrypted Encryption in transit applies to our agents and APIs. This also applies to any third-party telemetry sources that use TLS with New Relic, such as Prometheus OpenMetrics and other integrations. How it works Uses industry-standard transport layer security (TLS). Our preferred protocol for all domains is TLS 1.2. For more information about data transmission, firewalls, hosting, and storage, see our data security documentation. Disk encryption New Relic's disk-based encryption provides additional security while your data is at rest (FIPS 140-2 compliant). For more information, see the documentation about our Telemetry Data Platform and managing data retention. Disk-level encryption at rest Comments Who gets it Free for all New Relic customers where data is stored in Amazon AWS. What data is encrypted This encryption protects the physical disk where New Relic retains your data, including the following: Log management data Dimensional metrics data As we implement encryption at rest for additional telemetry types, your data will be encrypted automatically with no additional steps required by you. How it works New Relic uses Amazon AWS non-volatile, memory express SSD instance store volumes for disk-level data encryption at rest. The data on each instance storage device is encrypted using an XTS-AES-256 block cipher implemented in a hardware module on the instance. Encryption keys are generated using the hardware module and are unique to each instance storage device. All encryption keys are destroyed when the instance stops or terminates, and they cannot be recovered. As additional security measures: Disk-level encryption cannot be disabled. External encryption keys cannot be provided. Account-level encryption New Relic's account-level encryption at rest allows approved New Relic customers to benefit from even higher levels of security (FIPS 140-2 and FedRAMP Moderate compliant). Account-level encryption at rest Comments Who gets it Account-level data encryption depends on your New Relic subscription and your account hierarchy. For example, if your data is encrypted at the parent account level, your child account data also is automatically encrypted at rest. Available for: Government agencies Regulated industries, such as financial institutions and healthcare Other organizations that have heightened data protection needs or require compliance with PCI, HIPAA, or FedRAMP Account-level data encryption is available for approved customers. For more information, or to request account-level encryption, contact your New Relic account representative. Approved customers must send their data to New Relic's FedRAMP compliant endpoints. What data is encrypted Account-level encryption includes: Log management data Dimensional metrics used by Telemetry SDKs, Metric API, some integrations Events Distributed traces Backups for all data with account-level encryption How it works Master key: > Key management is performed outside New Relic's database with a FIPS 140-2 certified library using AES-GCM with 256-bit keys. The FIPS-certified Key Management System (KMS) rotates annually for each per-environment master key. The master key is generated inside a hardware security module (HSM) that is not exposed or stored externally. Data encryption key: Data files are encrypted with an account-specific data encryption key (DEK) generated on our hosts and rotated daily. The data encryption key is sent to the KMS to be encrypted (wrapped) by the master key, and the wrapped data encryption key is stored along with the data file. Process: Before reading a file, a host must first send the wrapped data encryption key to the KMS to be decrypted. To improve performance, an unwrapped data encryption key is cached temporarily on the host. For more information, see our documentation about key management for encryption at rest.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.22818,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Whether your data is in transit to New Relic or at rest in our storage, we apply strong encryption measures to help prevent unauthorized access, threats, or theft. This includes FIPS 140-2 <em>compliance</em> as well as <em>security</em> accreditation for the Federal Risk and Authorization Management Program"
      },
      "id": "6045241f196a676785960f4d"
    }
  ],
  "/docs/security/security-privacy/compliance/hipaa-readiness-new-relic": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 303.5016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Services in Scope by <em>compliance</em> program",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " <em>compliance</em> programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our <em>compliance</em> program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.85675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.84528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/security-privacy/compliance/key-management-encryption-rest": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 310.50568,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Services in Scope by <em>compliance</em> program",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " <em>compliance</em> programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our <em>compliance</em> program scope, you assume the responsibility to review, understand, and risk-manage your <em>security</em> controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them."
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 304.3999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Data encryption",
        "Encryption in transit",
        "Disk encryption",
        "Account-level encryption"
      ],
      "title": "Data encryption",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c5e00e8b0148c49664de0e5f3e8a2e142ac0aeed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/data-encryption/",
      "published_at": "2021-09-02T16:35:53Z",
      "updated_at": "2021-07-02T01:22:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether your data is in transit to New Relic or at rest in our storage, we apply strong encryption measures to help prevent unauthorized access, threats, or theft. This includes FIPS 140-2 compliance as well as security accreditation for the Federal Risk and Authorization Management Program (FedRAMP). New Relic is authorized for Moderate Impact SaaS Services (FedRAMP Authorized Moderate) for accounts that meet specific criteria. As a cloud service provider, we are committed to ensuring our compliance with FedRAMP's requirements for the confidentiality, integrity, and availability of your data. This document describes our data encryption methods, including who gets it, what data is encrypted, and how it works. For more information, see our security documentation and Security website, or contact your account representative. Encryption in transit All New Relic customers benefit from the security provided with data encryption in transit. TLS is required for all domains. Encryption in transit Comments Who gets it Data encryption in transit is automatically included in all New Relic subscriptions. What data is encrypted Encryption in transit applies to our agents and APIs. This also applies to any third-party telemetry sources that use TLS with New Relic, such as Prometheus OpenMetrics and other integrations. How it works Uses industry-standard transport layer security (TLS). Our preferred protocol for all domains is TLS 1.2. For more information about data transmission, firewalls, hosting, and storage, see our data security documentation. Disk encryption New Relic's disk-based encryption provides additional security while your data is at rest (FIPS 140-2 compliant). For more information, see the documentation about our Telemetry Data Platform and managing data retention. Disk-level encryption at rest Comments Who gets it Free for all New Relic customers where data is stored in Amazon AWS. What data is encrypted This encryption protects the physical disk where New Relic retains your data, including the following: Log management data Dimensional metrics data As we implement encryption at rest for additional telemetry types, your data will be encrypted automatically with no additional steps required by you. How it works New Relic uses Amazon AWS non-volatile, memory express SSD instance store volumes for disk-level data encryption at rest. The data on each instance storage device is encrypted using an XTS-AES-256 block cipher implemented in a hardware module on the instance. Encryption keys are generated using the hardware module and are unique to each instance storage device. All encryption keys are destroyed when the instance stops or terminates, and they cannot be recovered. As additional security measures: Disk-level encryption cannot be disabled. External encryption keys cannot be provided. Account-level encryption New Relic's account-level encryption at rest allows approved New Relic customers to benefit from even higher levels of security (FIPS 140-2 and FedRAMP Moderate compliant). Account-level encryption at rest Comments Who gets it Account-level data encryption depends on your New Relic subscription and your account hierarchy. For example, if your data is encrypted at the parent account level, your child account data also is automatically encrypted at rest. Available for: Government agencies Regulated industries, such as financial institutions and healthcare Other organizations that have heightened data protection needs or require compliance with PCI, HIPAA, or FedRAMP Account-level data encryption is available for approved customers. For more information, or to request account-level encryption, contact your New Relic account representative. Approved customers must send their data to New Relic's FedRAMP compliant endpoints. What data is encrypted Account-level encryption includes: Log management data Dimensional metrics used by Telemetry SDKs, Metric API, some integrations Events Distributed traces Backups for all data with account-level encryption How it works Master key: > Key management is performed outside New Relic's database with a FIPS 140-2 certified library using AES-GCM with 256-bit keys. The FIPS-certified Key Management System (KMS) rotates annually for each per-environment master key. The master key is generated inside a hardware security module (HSM) that is not exposed or stored externally. Data encryption key: Data files are encrypted with an account-specific data encryption key (DEK) generated on our hosts and rotated daily. The data encryption key is sent to the KMS to be encrypted (wrapped) by the master key, and the wrapped data encryption key is stored along with the data file. Process: Before reading a file, a host must first send the wrapped data encryption key to the KMS to be decrypted. To improve performance, an unwrapped data encryption key is cached temporarily on the host. For more information, see our documentation about key management for encryption at rest.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.22818,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Whether your data is in transit to New Relic or at rest in our storage, we apply strong encryption measures to help prevent unauthorized access, threats, or theft. This includes FIPS 140-2 <em>compliance</em> as well as <em>security</em> accreditation for the Federal Risk and Authorization Management Program"
      },
      "id": "6045241f196a676785960f4d"
    }
  ],
  "/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services": [
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 304.4115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 304.39972,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Data encryption",
        "Encryption in transit",
        "Disk encryption",
        "Account-level encryption"
      ],
      "title": "Data encryption",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c5e00e8b0148c49664de0e5f3e8a2e142ac0aeed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/data-encryption/",
      "published_at": "2021-09-02T16:35:53Z",
      "updated_at": "2021-07-02T01:22:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether your data is in transit to New Relic or at rest in our storage, we apply strong encryption measures to help prevent unauthorized access, threats, or theft. This includes FIPS 140-2 compliance as well as security accreditation for the Federal Risk and Authorization Management Program (FedRAMP). New Relic is authorized for Moderate Impact SaaS Services (FedRAMP Authorized Moderate) for accounts that meet specific criteria. As a cloud service provider, we are committed to ensuring our compliance with FedRAMP's requirements for the confidentiality, integrity, and availability of your data. This document describes our data encryption methods, including who gets it, what data is encrypted, and how it works. For more information, see our security documentation and Security website, or contact your account representative. Encryption in transit All New Relic customers benefit from the security provided with data encryption in transit. TLS is required for all domains. Encryption in transit Comments Who gets it Data encryption in transit is automatically included in all New Relic subscriptions. What data is encrypted Encryption in transit applies to our agents and APIs. This also applies to any third-party telemetry sources that use TLS with New Relic, such as Prometheus OpenMetrics and other integrations. How it works Uses industry-standard transport layer security (TLS). Our preferred protocol for all domains is TLS 1.2. For more information about data transmission, firewalls, hosting, and storage, see our data security documentation. Disk encryption New Relic's disk-based encryption provides additional security while your data is at rest (FIPS 140-2 compliant). For more information, see the documentation about our Telemetry Data Platform and managing data retention. Disk-level encryption at rest Comments Who gets it Free for all New Relic customers where data is stored in Amazon AWS. What data is encrypted This encryption protects the physical disk where New Relic retains your data, including the following: Log management data Dimensional metrics data As we implement encryption at rest for additional telemetry types, your data will be encrypted automatically with no additional steps required by you. How it works New Relic uses Amazon AWS non-volatile, memory express SSD instance store volumes for disk-level data encryption at rest. The data on each instance storage device is encrypted using an XTS-AES-256 block cipher implemented in a hardware module on the instance. Encryption keys are generated using the hardware module and are unique to each instance storage device. All encryption keys are destroyed when the instance stops or terminates, and they cannot be recovered. As additional security measures: Disk-level encryption cannot be disabled. External encryption keys cannot be provided. Account-level encryption New Relic's account-level encryption at rest allows approved New Relic customers to benefit from even higher levels of security (FIPS 140-2 and FedRAMP Moderate compliant). Account-level encryption at rest Comments Who gets it Account-level data encryption depends on your New Relic subscription and your account hierarchy. For example, if your data is encrypted at the parent account level, your child account data also is automatically encrypted at rest. Available for: Government agencies Regulated industries, such as financial institutions and healthcare Other organizations that have heightened data protection needs or require compliance with PCI, HIPAA, or FedRAMP Account-level data encryption is available for approved customers. For more information, or to request account-level encryption, contact your New Relic account representative. Approved customers must send their data to New Relic's FedRAMP compliant endpoints. What data is encrypted Account-level encryption includes: Log management data Dimensional metrics used by Telemetry SDKs, Metric API, some integrations Events Distributed traces Backups for all data with account-level encryption How it works Master key: > Key management is performed outside New Relic's database with a FIPS 140-2 certified library using AES-GCM with 256-bit keys. The FIPS-certified Key Management System (KMS) rotates annually for each per-environment master key. The master key is generated inside a hardware security module (HSM) that is not exposed or stored externally. Data encryption key: Data files are encrypted with an account-specific data encryption key (DEK) generated on our hosts and rotated daily. The data encryption key is sent to the KMS to be encrypted (wrapped) by the master key, and the wrapped data encryption key is stored along with the data file. Process: Before reading a file, a host must first send the wrapped data encryption key to the KMS to be decrypted. To improve performance, an unwrapped data encryption key is cached temporarily on the host. For more information, see our documentation about key management for encryption at rest.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.22818,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "Whether your data is in transit to New Relic or at rest in our storage, we apply strong encryption measures to help prevent unauthorized access, threats, or theft. This includes FIPS 140-2 <em>compliance</em> as well as <em>security</em> accreditation for the Federal Risk and Authorization Management Program"
      },
      "id": "6045241f196a676785960f4d"
    }
  ],
  "/docs/security/security-privacy/data-privacy/data-privacy-new-relic": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ": Customer must send its <em>data</em> only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic&#x27;s time frames for supported regulatory frameworks and annual audits include"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90112,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects <em>data</em> from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.8932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Overview of <em>data</em> sources",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our <em>data</em> encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/security-privacy/data-privacy/new-relic-personal-data-requests": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ": Customer must send its <em>data</em> only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic&#x27;s time frames for supported regulatory frameworks and annual audits include"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects <em>data</em> from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.8931,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Overview of <em>data</em> sources",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our <em>data</em> encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/security-privacy/data-privacy/security-controls-privacy": [
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ": Customer must send its <em>data</em> only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic&#x27;s time frames for supported regulatory frameworks and annual audits include"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "For customers with heightened regulatory or <em>privacy</em> needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects <em>data</em> from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It&#x27;s"
      },
      "id": "603e944f196a6762d0a83dd1"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.8931,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Overview of <em>data</em> sources",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our <em>data</em> encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/security/security-privacy/information-security/report-security-vulnerabilities-hackerone": [
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.90524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides <em>information</em> on FedRAMP-compliant endpoints in New Relic. For more <em>information</em> about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This list is current. Last updated 31 August 2021. This document describes New Relic&#x27;s products and services as they relate to regulatory framework compliance status. For more <em>information</em>, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " process for <em>security</em>-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of <em>Information</em> at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact."
      },
      "id": "603e944f196a6762d0a83dd1"
    }
  ],
  "/docs/security/security-privacy/information-security/security-bulletins": [
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.90514,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides <em>information</em> on FedRAMP-compliant endpoints in New Relic. For more <em>information</em> about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This list is current. Last updated 31 August 2021. This document describes New Relic&#x27;s products and services as they relate to regulatory framework compliance status. For more <em>information</em>, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90091,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " process for <em>security</em>-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of <em>Information</em> at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact."
      },
      "id": "603e944f196a6762d0a83dd1"
    }
  ],
  "/docs/security/security-privacy/information-security/software-development-lifecycle": [
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-09-02T16:35:51Z",
      "updated_at": "2021-09-02T16:35:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.90514,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This document provides <em>information</em> on FedRAMP-compliant endpoints in New Relic. For more <em>information</em> about our <em>security</em> accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Services in Scope by compliance program",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-09-02T16:38:13Z",
      "updated_at": "2021-09-02T16:38:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 31 August 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Services in Scope by compliance program The following table describes New Relic's Services in Scope of New Relic's assurance programs. A check indicates that this service in scope of the most recent assessment and current reports. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate HITRUST CSF Alerts APM AWS Metric Streams Browser monitoring Errors inbox Incident Intelligence (Applied Intelligence) Infrastructure agent (and associated on-host integrations) Cloud integrations (AWS, Azure, and GCP) Insights Logs (with exception of log patterns) Log patterns Metric API Mobile agents Network Performance Monitoring Pixie: Community Cloud for Pixie Community Cloud for Pixie has completed a SOC 2 Type 1 audit. Pixie: Auto-telemetry with Pixie Plugins Proactive Detection (Applied Intelligence) Programmability: New Relic One apps Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "This list is current. Last updated 31 August 2021. This document describes New Relic&#x27;s products and services as they relate to regulatory framework compliance status. For more <em>information</em>, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "sections": [
        "Key management for encryption at rest",
        "Encryption and decryption process",
        "Key rotation",
        "Key handling",
        "FedRAMP authorization"
      ],
      "title": "Key management for encryption at rest",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "c87b09a6dc7ef44c8e1471d0d840dc034be11b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/key-management-encryption-rest/",
      "published_at": "2021-09-02T16:37:02Z",
      "updated_at": "2021-09-02T16:37:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For customers with heightened regulatory or privacy needs, New Relic offers account-based, FIPS-compliant encryption-at-rest capabilities with unique keys per account. This protects data from inadvertent or intentional exposure, even in the event an attacker has access to the file system. It's important to maintain both a high level of protection and also optimal performance and long-term storage and retrieval of data. To do this, New Relic uses a two-tier system consisting of a data encryption key (DEK) and a master key, each with separate usage, storage, and rotation policies. For an overview of how we handle your data in transit and at rest, including details about the key management process for data encryption, see data encryption documentation. Encryption and decryption process When encryption at rest is enabled for an account, each new file is encrypted (AES-GCM with 256 bit keys) with a data encryption key that is unique to the account and the server writing the data. Each DEK is generated locally using a FIPS 140-2 validated cryptographic module on the server. Each account’s DEK is rotated every 24 hours or when it has been used to encrypt 64 GB of data. It can also be rotated manually, as-needed. The DEK that is used to encrypt a file is subsequently encrypted with the Master Key and appended in this wrapped format onto the encrypted data file. The key is encrypted remotely on our key management service (KMS), which is provided by AWS. In order to read a file, the process is reversed: First, the NRDB host on which the data resides extracts the wrapped DEK from the file and sends it to the KMS to be decrypted (unwrapped). Finally, the host decrypts the data file and processes it. Key rotation To prevent ciphertext attacks, a new data encryption key is generated for each account when the existing DEK has been used to encrypt 64 GB of data or every 24 hours if the data threshold is not met before then. The master key is used only to encrypt DEKs, so a ciphertext attack against it is improbable. In compliance with FIPS guidelines, the KMS automatically rotates the master key once a year. Each New Relic region contains a single master key, which is never transmitted out of the KMS. Key handling New Relic servers generate each DEK locally, and the plain text DEK is never written to disk. If an attacker gained access to process memory, they could retrieve the unencrypted DEK for that server and time period, but they would be unable to read data from any other time periods. The Master key is generated, stored, and used within a FIPS 140-2 validated hardware security module (HSM) on the KMS. Neither New Relic nor AWS employees can retrieve the plain text of the master key. Secure generation, management, backup, storage, and destruction are all handled and guaranteed by the KMS. Administrator access to key management functions is controlled and audited using AWS permissions and CloudTrail. FedRAMP authorization In addition to our usual review process for security-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of Information at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.90091,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Encryption <em>and</em> decryption process",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " process for <em>security</em>-critical components, New Relic’s encryption system has been reviewed by a third party and found to meet all requirements of NIST SC-28(1) Protection of <em>Information</em> at Rest, SC-12(3) Cryptographic Key Establishment and Management, and SC-13 Cryptographic Protection. It is approved as part of our authorization for FedRAMP Moderate impact."
      },
      "id": "603e944f196a6762d0a83dd1"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/account-linking": [
    {
      "sections": [
        "New Relic One pricing and billing",
        "Important",
        "How the New Relic One pricing plan works",
        "Billing and usage in the UI",
        "Billing calculation details",
        "Data usage calculation",
        "Incident Intelligence events",
        "Determine event source",
        "Stop reporting events",
        "Full user count billing details",
        "Data retention",
        "Billing periods",
        "Usage plan details",
        "Query and alert on usage data",
        "Free tier",
        "Non-profit use of New Relic",
        "Cancel or downgrade"
      ],
      "title": "New Relic One pricing and billing ",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "03d43f14ae24579c81b601571242aef540833c8c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing/",
      "published_at": "2021-09-01T21:58:46Z",
      "updated_at": "2021-09-01T21:58:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of how New Relic One pricing works, and how to view and manage billing. Important This document explains the New Relic One pricing plan. If you’re on our original pricing plan, see Original pricing. Not sure which you're on? See Overview of pricing. How the New Relic One pricing plan works Starting July 30, 2020, all of our new customers are on a pricing plan that we call New Relic One pricing. Customers on our original pricing plan are able to transition to this pricing. For New Relic One pricing, billing is based on these factors: The amount of data ingested. 100 GBs per month is free. $0.25 per GB ingested above that. The number of provisioned full users, defined as users with access to Full Stack Observability features. Basic users are free. The cost of each full user depends on your edition: Standard, Pro, or Enterprise. Standard edition includes one full user for free, and a max of five. Pro and Enterprise give access to more account and user management features, more support, longer data retention, and other features. For Applied Intelligence, our intelligent alert/detection system: the number of incident events above the free 1000 per month. (Note that our alerting functionality is available for free and doesn't count towards this limit.) For a summary of what's included for free, see Free edition. For an overview of pricing, see our Pricing page. Keep reading for details about New Relic One pricing and billing. Billing and usage in the UI For how to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. Billing calculation details For accounts on New Relic One pricing, some high-level billing information is displayed in the UI. Here are some more details about how billing works: Data usage calculation One pricing factor is your ingested data. In this context, “ingested” refers to the data actually saved to your account after we apply various data trimming and data transformation rules. In other words, it’s not the size of the raw data sent to New Relic, but the size of the data that actually ends up stored. To view and manage your usage, go to the usage UI. Other calculation details: In the context of our pricing plan, a GB is defined as 1 billion bytes. Monthly data ingested is rounded down to the nearest integer. For example, if your account uses 100.9 GBs during a month, that’s counted as 100 GBs. For more on how data is ingested, see Manage data ingest. For how to query usage, see Query and alert on usage. Incident Intelligence events One billing factor is how many incident events your organization sends to Incident Intelligence for correlation and analysis. If your organization is on New Relic One pricing, Incident Intelligence comes with a certain number of free incident events per month. (Our original pricing plan doesn't have a free tier.) You can track usage and cost in two places in the UI: In the usage UI From the Incident Intelligence system settings UI page: From one.newrelic.com, click Alerts & AI, then click Incident Intelligence, and then click System settings. Determine event source When you set up Incident Intelligence data sources, the incident events ingested by those sources are what count towards your total. To see the sources affecting your billing, go to the Sources page: From one.newrelic.com, click Alerts & AI, click Incident Intelligence, and then click Sources. Stop reporting events Go to the Incident Intelligence Sources UI page and disconnect all the sources you don’t want. If all sources are removed, no data is sent to Incident Intelligence. Full user count billing details For accounts with New Relic One pricing, the monthly count of provisioned full users is one billing factor. To give an example: if you're on the Pro pricing edition and your organization has 100 full users during the month of January, you'd be billed for 100 full users for that month. A full user counts as a billable user the moment they're added to a New Relic organization (provisioned), whether or not that user has logged into or used New Relic yet. A user's user type is meant to be long-term setting determined by a user's expected New Relic duties and responsibilities. Because user type is a billing factor, we have restrictions around how often a full user can be downgraded to a basic user: a full user can downgrade to a basic user a maximum of two times in a rolling 12-month period. If a full user has been changed to a basic user two times in that 12-month period, that user won't be able to return to being a basic user until the start of the next 12-month period. To learn reasons for assigning one user type or another, see Tips on assigning user type. Here are more user-related billing details and caveats: You can see your full user count in the UI. We de-duplicate users based on email address. If there are multiple users in an organization that have the same email address, those user records count as a single user for billing purposes. The count of full users is prorated based on the start of a New Relic subscription, or based on when a user is created as a full user or converted to a full user. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. For organizations on our original account/user model that have a parent/child account structure, the count of billable users in the UI may differ from the users you can see. For more on this, see User count discrepancy. The Standard edition of the New Relic One pricing plan includes one free full user. For organizations on our original user model, because the organization-related settings aren't as robust as on our newer model, a user may be set as a basic user in one account and as a full user in another account. In such cases, the full user status takes precedence and that user is considered a full user. For how to query usage data, see Query and alert on usage. For more on user capabilities, see Users and roles. Data retention See Data retention. Billing periods For pay-as-you-go customers, billing occurs at the end of the month (UTC), and you can see this tracked in the UI. When you input your credit card and start to be charged, your end-of-month bill will take into account all activity (billable data usage and users) that occurred since the beginning of that month. For example: if you input your credit card in the middle of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month bill. For how to query user-related usage, see Query and alert on usage. Usage plan details There are two New Relic One pricing usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel at any time. For details, see Usage plans. Annual pool of funds: This plan applies to some customers who have subscribed for a year or more. For details, see Usage plans. For some frequently asked questions, see Pricing FAQs. Query and alert on usage data To create detailed queries of your usage, and get notifications when you are close to hitting certain usage levels, see Query usage data. Free tier If your organization is on New Relic One pricing and on the Standard pricing edition for Full Stack Observability, you can use New Relic free, forever, if you stay under the free allowed limits. Here's a summary of what Standard edition gets access to for free: A single account (Pro and Enterprise Full Stack Observability editions can have multiple accounts per organization). Up to 100 GBs of ingested data per month. One full user, and unlimited basic users. Access to alerts and Applied Intelligence (up to 1,000 Incident Intelligence events per month). To upgrade to Pro or Enterprise, or to learn more about pricing, see New Relic pricing. Non-profit use of New Relic If you’re a non-profit and want to use New Relic at special pricing, see our Non-profit eligibility docs. Cancel or downgrade See Downgrade account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.94495,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> One pricing <em>and</em> billing ",
        "sections": "<em>New</em> <em>Relic</em> One pricing <em>and</em> billing",
        "tags": "<em>Accounts</em> <em>and</em> billing",
        "body": " to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of <em>your</em> usage data and set up alerts. Billing calculation details For <em>accounts</em> on <em>New</em> <em>Relic</em> One pricing, some high-level billing information is displayed"
      },
      "id": "6043f69a64441f7b26378eda"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-aws-lambda-monitoring/",
      "sections": [
        "Enable monitoring for AWS Lambda"
      ],
      "published_at": "2021-09-02T16:42:38Z",
      "title": "Enable monitoring for AWS Lambda",
      "updated_at": "2021-08-26T04:49:50Z",
      "type": "docs",
      "external_id": "8a60acf499837668684b93945d3ce973d95fe347",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several steps to enabling Lambda monitoring: Link your AWS account. Optional: configure CloudWatch Log collection: if in Step 1, you used the newrelic-lambda CLI, that automatically installs the CloudWatch logs collector by default and you can skip this step. Instrument an example function. Instrument your functions. Optional: Set up alerts and custom events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.35721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable monitoring for <em>AWS</em> Lambda",
        "sections": "Enable monitoring for <em>AWS</em> Lambda",
        "body": "There are several steps to enabling Lambda monitoring: <em>Link</em> <em>your</em> <em>AWS</em> <em>account</em>. Optional: configure CloudWatch Log collection: if in <em>Step</em> <em>1</em>, you used the newrelic-lambda CLI, that automatically installs the CloudWatch logs collector by default and you can skip this <em>step</em>. Instrument an example function. Instrument <em>your</em> functions. Optional: Set up alerts and custom events."
      },
      "id": "61271d6e196a677c0b00b320"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy/",
      "sections": [
        "Legacy manual instrumentation for Lambda monitoring",
        "Go",
        "Zip and upload recommendations",
        "Java",
        "Tip",
        ".NET Core",
        "Async handler function",
        "Inheriting from APIGatewayProxyFunction",
        "Important",
        "Using the SQS Wrapper",
        "Using the SNS Wrapper",
        "Node.js",
        "Python"
      ],
      "published_at": "2021-09-02T16:43:44Z",
      "title": "Legacy manual instrumentation for Lambda monitoring",
      "updated_at": "2021-09-02T16:43:44Z",
      "type": "docs",
      "external_id": "694e22b2ce401a96d200ab2e12a08850532b3e5a",
      "document_type": "page",
      "popularity": 1,
      "body": "On this page, you will learn how to manually instrument your lambda function. It's organized by runtime language. Go To instrument your Go-language Lambda: Download our Go agent package and place it in the same directory as your function. Install the agent: go get -u github.com/newrelic/go-agent/v3/newrelic. Install the nrlambda integration go get -u github.com/newrelic/go-agent/v3/integrations/nrlambda. In your Lambda code, import our components, create an application, and update how you start your Lambda. See our GitHub repo for an example of an instrumented Lambda. Optional: Add custom events that will be associated with your Lambda invocation by using the RecordCustomEvent API. For example: func handler(ctx context.Context) { if txn := newrelic.FromContext(ctx); nil != txn { txn.Application().RecordCustomEvent(\"MyEvent\", map[string]interface{}{ \"zip\": \"zap\", }) } fmt.Println(\"hello world!\") } Copy Build and zip your Lambda function and upload it to AWS. Zip and upload recommendations Here are suggestions for zipping and uploading the Lambda: Build the binary for execution on Linux. This produces a binary file called main. You can use: $ GOOS=linux go build -o main Copy Zip the binary into a deployment package using: $ zip deployment.zip main Copy Upload the zip file to AWS using either the AWS Lambda console or the AWS CLI. Name the handler main (to match the name given during the binary build). The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this is the account ID for the root/parent account. Optional: To configure logging, see Go agent logging. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Java Monitoring for AWS Lambda in Java doesn't use our APM Java agent. Instead, it uses these two OpenTracing dependencies: AWS Lambda OpenTracing Java SDK: OpenTracing instrumentation for AWS Lambda RequestHandler and RequestStreamHandler. Our AWS Lambda OpenTracing Tracer: An OpenTracing Tracer implementation designed to monitor AWS Lambda. It generates spans, error events, transaction events, error traces, and provides distributed tracing support. Tip Supported OpenTracing Versions OpenTracing 0.31.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:1.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:1.0.0 OpenTracing 0.32.0, 0.33.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:2.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:2.1.0 To instrument your Java Lambda: In your project’s build.gradle file, include our OpenTracing AWS Lambda Tracer and the AWS Lambda OpenTracing SDK dependencies: dependencies { compile(\"com.newrelic.opentracing:java-aws-lambda:2.1.0\") compile(\"com.newrelic.opentracing:newrelic-java-lambda:2.1.1\") compile(\"io.opentracing:opentracing-util:0.33.0\") } Copy Implement the AWS Lambda RequestHandler interface as shown in the Java Lambda example and override the doHandleRequest method. In the doHandleRequest method, call the LambdaTracing.instrument(...) API to create a root span to trace the lambda function's execution. This is also where you will define your business logic for the lambda function. Register a LambdaTracer.INSTANCE as the OpenTracing Global tracer, as shown in the Java Lambda example. Create a ZIP deployment package and upload it to AWS Lambda. Or deploy it via other means. In the AWS Lambda console, set the handler. For the example Java Lambda, the handler would be com.handler.example.MyLambdaHandler::handleRequest. Because handleRequest is assumed, you could also use com.handler.example.MyLambdaHandler. The following AWS console environment variables are required if you want your Lambda function to be included in distributed tracing. This is recommended. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_PRIMARY_APPLICATION_ID. This is also your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this must be the account ID for the root/parent account. Optional: In the Lambda console, enable debug logging by adding this environment variable: NEW_RELIC_DEBUG is true. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Please see the AWS Lambda distributed tracing example for a complete project that illustrates common use cases such as: Distributed tracing between Lambda functions Manual span creation (aka custom instrumentation) Tracing external calls Adding custom attributes (aka Tags) to spans .NET Core Our monitoring of .NET Core-based AWS Lambda functions doesn't use our standard .NET Core APM agent. Instead, it uses a NuGet package. To instrument your .NET Core Lambda: In your Lambda Functions project, install the NewRelic.OpenTracing.AmazonLambda.Tracer NuGet package. Note: NewRelic.OpenTracing.AmazonLambda.Tracer depends on version 1.2.0+ of Amazon.Lambda.APIGatewayEvent NuGet package. If the environment already uses a lower version of Amazon.Lambda.APIGatewayEvent, the New Relic package may produce errors such as System.MissingMethodException . Import the NuGet package and OpenTracing utils: using OpenTracing.Util; using NewRelic.OpenTracing.AmazonLambda; Copy Instrument your function, as shown in this example: public class Function { static Function() { // Register The NewRelic Lambda Tracer Instance GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public object FunctionWrapper(ILambdaContext context) { // Instantiate NewRelic TracingWrapper and pass your FunctionHandler as // an argument return new TracingRequestHandler().LambdaWrapper(FunctionHandler, context); } /// <summary> /// A simple function that takes a string and does a ToUpper /// </summary> /// <param name=\"input\"></param> /// <param name=\"context\"></param> /// <returns></returns> public object FunctionHandler(ILambdaContext context) { ... } } Copy Tip The arguments passed to FunctionWrapper must match the signature of FunctionHandler. If your handler function returns a Task, the Lambda wrapper will block on the return task until it completes, so that it can measure the duration and capture exceptions, if any are present. In addition, you may also inherit from the APIGatewayProxyFunction. For an example, see below: Async handler function public async Task<int> FunctionHandlerAsync(ILambdaContext lambdaContext) { return await new TracingRequestHandler().LambdaWrapper( ActualFunctionHandlerAsync, lambdaContext); } public async Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(ILambdaContext lambdaContext) { // Function can make other async operations here ... } Copy Inheriting from APIGatewayProxyFunction public class LambdaFunction : APIGatewayProxyFunction { static LambdaFunction() { // Register The NewRelic Lambda Tracer Instance OpenTracing.Util.GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public override Task<APIGatewayProxyResponse> FunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { Task<APIGatewayProxyResponse> task = new TracingRequestHandler().LambdaWrapper(ActualFunctionHandlerAsync, request, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { return base.FunctionHandlerAsync(request, lambdaContext); } } Copy Optional for SQS and SNS: Starting in version 1.0 of our .NET Lambda Tracer, distributed tracing support has been added for SQS and SNS. To enable distributed tracing for SQS or SNS you will need to complete the items in this step as well as setup the environment variables in the step that follows this one. Important Enabling distributed tracing support for SQS and SNS will disable automatic instrumentation for both of SQS and SNS and require the use of these wrappers to instrument them. Set the NEW_RELIC_USE_DT_WRAPPER environment variable to true. To instrument SQS and SNS calls you will need to use the provided wrappers. Using the SQS Wrapper The SQS wrapper supports wrapping the following methods: Amazon.SQS.AmazonSQSClient.SendMessageAsync(...) Amazon.SQS.AmazonSQSClient.SendMessageBatchAsync(...) Examples // SQS Client AmazonSQSClient client = new AmazonSQSClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // SendMessageRequest SendMessageRequest sendRequest = new SendMessageRequest(\"QUEUE_URI_STRING\", \"An SQS Message\"); Task<SendMessageResponse> responseOne = SQSWrapper.WrapRequest(client.SendMessageAsync, sendRequest); // String-based Task<SendMessageResponse> responseTwo = SQSWrapper.WrapRequest(client.SendMessageAsync, \"QUEUE_URI_STRING\", \"Another SQS Message\"); // SendMessageBatchRequest List<SendMessageBatchRequestEntry> batchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id1\", \"First SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id2\", \"Second SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id3\", \"Third SQS Message\")); SendMessageBatchRequest sendBatchRequest = new SendMessageBatchRequest(QUEUE_URI, batchEntries); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, sendBatchRequest); // SendMessageBatchRequestEntry List List<SendMessageBatchRequestEntry> moreBatchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id4\", \"Fourth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id5\", \"Fifth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id6\", \"Sixth SQS Message\")); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, moreBatchEntries); Copy Using the SNS Wrapper The SNS wrapper supports wrapping the following methods: Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient.PublishAsync(...) Examples // SNS Client AmazonSimpleNotificationServiceClient client = new Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // PublishRequest - Phone Number PublishRequest phonePublishRequest = new PublishRequest(); phonePublishRequest.PhoneNumber = +1XXX5555100; phonePublishRequest.Message = \"An SNS Message for phones\"; Task<PublishResponse> phoneResponse = SNSWrapper.WrapRequest(client.PublishAsync, phonePublishRequest); // PublishRequest - ARN PublishRequest publishRequest = new PublishRequest(\"TOPIC_ARN\", \"An SNS Message\"); Task<PublishResponse> publishResponse = SNSWrapper.WrapRequest(client.PublishAsync, publishRequest); // String-based without subject Task<PublishResponse> ResponseOne = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Another SNS Message\"); // String-based with subject Task<PublishResponse> ResponseTwo = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Yet Another SNS Message\", \"A Subject\"); Copy The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS Lambda console: NEW_RELIC_ACCOUNT_ID: The account ID the Lambda is reporting to. NEW_RELIC_TRUSTED_ACCOUNT_KEY: This is also the account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Ensure that the wrapper function (FunctionWrapper in above example) is set up as the function handler. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Node.js To instrument your Node.js Lambda: Download our Node.js agent package and place it in the same directory as your function, ensuring the agent is installed as a dependency in the node_modules directory. Use the Node Package Manager: npm install newrelic --save Copy Install our AWS SDK module alongside the Node.js agent: npm install @newrelic/aws-sdk --save Copy In your Lambda code, require the agent module and the AWS SDK at the top of the file, and wrap the handler function. For example: const newrelic = require('newrelic'); require('@newrelic/aws-sdk'); // Other module loads go under the two require statements above module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { // This is your handler function code console.log('Lambda executed'); callback(); }); Copy Optional: You can also add custom events to your Lambda using the recordCustomEvent API. For example: module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { newrelic.recordCustomEvent(‘MyEventType’, {foo: ‘bar’}); console.log('Lambda executed'); callback(); }); Copy Zip your Lambda function and the Node.js agent folder together. Requirements and recommendations: The New Relic files outside the New Relic agent folder don't need to be included. If your Lambda function file name is, for example, lambda_function.node, we recommend naming your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set these environment variables: NEW_RELIC_NO_CONFIG_FILE. Set to true if not using a configuration file. NEW_RELIC_APP_NAME: Your application name. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Optional: To run the agent in serverless mode outside of AWS in a local environment, set the environment variable NEW_RELIC_SERVERLESS_MODE_ENABLED to true. (When executing this in an AWS Lambda environment, the agent will automatically run in serverless mode. Do not use this variable if you're running in AWS.) Optional: To enable logging in serverless mode, set these environment variables: Set NEW_RELIC_LOG_ENABLED to true. Set NEW_RELIC_LOG to stdout for output to CloudWatch, or set to any writeable file location. The log level is set to info by default. See other log levels. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Python To instrument your Python Lambda: Download our Python agent package and place it in the same directory as your function. To do this, use pip: pip install -t . newrelic Copy Important If you use Homebrew, you may get this error: DistutilsOptionError: must supply either home or prefix/exec-prefix -- not both. For details, see the Homebrew GitHub post. In your Lambda code, import the Python agent module and decorate the handler function using the New Relic decorator. The New Relic package must be imported first in your code. Here's an example: import newrelic.agent newrelic.agent.initialize() @newrelic.agent.lambda_handler() def handler(event, context): ... Copy Optional: You can also add custom events to your Lambda using the record_custom_event API. Here's an example: @newrelic.agent.lambda_handler() def handler(event, context): newrelic.agent.record_custom_event('CustomEvent', {'foo': 'bar'}) … Copy Zip your lambda_function.py and newrelic/ folder together using these guidelines: The New Relic files outside the newrelic/ folder don't need to be included. If your Lambda function file name is, for example, lambda_function.py, name your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set this environment variable: NEW_RELIC_SERVERLESS_MODE_ENABLED. Set to true The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED. Set to true. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Optional: To configure logging, use the NEW_RELIC_LOG and NEW_RELIC_LOG_LEVEL environment variables in the AWS Console. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. The New Relic decorator gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, configure CloudWatch to send those logs to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.63115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Zip <em>and</em> upload recommendations",
        "body": " to function but they are required if you want <em>your</em> Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the <em>AWS</em> console: <em>NEW_RELIC_ACCOUNT</em>_ID. <em>Your</em> <em>account</em> ID. <em>NEW_RELIC_TRUSTED_ACCOUNT</em>_KEY. This is also <em>your</em> <em>account</em> ID. If <em>your</em>"
      },
      "id": "603ebbcb64441f800a4e8850"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/configure-serverless-monitoring-aws-lambda": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-09-01T21:29:27Z",
      "updated_at": "2021-09-01T21:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.303314,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Step</em> 3: <em>Configure</em> the agent for Infinite Tracing",
        "tags": "Enable and <em>configure</em>",
        "body": " for your services yet, or if you want to instrument <em>additional</em> services. Tip You&#x27;ll need a New Relic account to set up distributed tracing. If you don&#x27;t already have one, you can quickly create a free account. <em>Step</em> 1. Identify services Figure out which services you want to instrument so they each send"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Install New Relic Java agent for Docker",
        "Get the Java agent",
        "Download using curl",
        "Download using Invoke-WebRequest (PowerShell)",
        "Download from the New Relic UI",
        "Set up the installation directory",
        "Modify startup scripts",
        "Set agent configurations",
        "Application name",
        "Tip",
        "License key",
        "Logs",
        "Environment (optional)",
        "Important",
        "Enabled (optional)",
        "Additional Tomcat Dockerfile examples",
        "Tomcat with environment and Java system properties",
        "How to start an application with the Java agent",
        "Next steps"
      ],
      "title": "Install New Relic Java agent for Docker",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "Additional installation"
      ],
      "external_id": "4de0ccd173c9851b045cfa036089e2f703b4a0f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/java-agent/additional-installation/install-new-relic-java-agent-docker/",
      "published_at": "2021-09-01T19:37:38Z",
      "updated_at": "2021-08-27T14:01:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains a basic installation of the APM agent for Java applications in a Docker container. We discuss required configurations and also explore some optional configurations, including: How to use identical New Relic configuration files for each container, regardless of the environment where the containers are used How to use the Docker layer when every agent in every environment needs slightly different configuration data How to disable the New Relic agent in some environments and enable it in others Although we don't discuss advanced options here, you can install the Java agent in Docker volumes and use your Docker container image in other software such as Swarm, ECS, AKS, EKS, OpenShift, and Kubernetes. Our Docker examples refer to Tomcat, so if you are using another application server, refer to your vendor’s documentation. Get the Java agent Download newrelic-java.zip using curl, Invoke-WebRequest (PowerShell), or the New Relic UI: Download using curl Complete the following: Start a command-line session. Change to a temporary directory where you can download the zip file. Execute this curl command: curl -O https://download.newrelic.com/newrelic/java-agent/newrelic-agent/current/newrelic-java.zip Copy Unzip newrelic-java.zip Download using Invoke-WebRequest (PowerShell) Complete the following: Start a PowerShell session. Change to a temporary directory where you can download the zip file. Execute this PowerShell command: Invoke-WebRequest -Uri https://download.newrelic.com/newrelic/java-agent/newrelic-agent/current/newrelic-java.zip -OutFile newrelic-java.zip Copy Unzip newrelic-java.zip: Expand-Archive -Path newrelic-java.zip -DestinationPath DESTINATION_PATH Copy Download from the New Relic UI From one.newrelic.com, click Add more data and then search for \"Java\". Select the Java app monitoring option and complete the process. Set up the installation directory You can unzip the newrelic-java.zip file wherever it is convenient for you. In the subsequent sections we assume you extracted it in the current working directory, which puts the files we need in ./newrelic. Modify startup scripts The startup script that contains the command to start your application server must include Java’s built-in argument -javaagent. We recommend that you set this argument with the JAVA_OPTS environment variable. The value of that argument must contain the location where you ADD the Java APM agent’s jar file to the image. For example, with Tomcat, use commands like these in the Dockerfile: RUN mkdir -p /usr/local/tomcat/newrelic ADD ./newrelic/newrelic.jar /usr/local/tomcat/newrelic/newrelic.jar ENV JAVA_OPTS=\"$JAVA_OPTS -javaagent:/usr/local/tomcat/newrelic/newrelic.jar\" Copy Set agent configurations By default, agent behavior is controlled by configuration entries in newrelic.yml, which is typically located in the same directory as the agent. This section explains how to override these newrelic.yml configurations by using environment variables or Java system properties in the Dockerfile. Before we look at some specific configurations, here’s how to load newrelic.yml using the Dockerfile: ADD ./newrelic/newrelic.yml /usr/local/tomcat/newrelic/newrelic.yml Copy For a basic Docker installation, complete these configurations: Application name License key Logs Environment (optional) Enabled (optional) Application name The application name is a configuration you set to identify your application in New Relic. Tip You can reuse an application name for multiple apps serving the same role so that all the data from those apps rolls up into the same logical application in New Relic. For more detail about additional grouping options, see Use multiple names for an app. Replace MY_APP_NAME with your application name in one of these Dockerfile commands: Option Command Environment variable ENV NEW_RELIC_APP_NAME=\"MY_APP_NAME\" Copy Java system property ENV JAVA_OPTS=\"$JAVA_OPTS -Dnewrelic.config.app_name='MY_APP_NAME'\" Copy After you boot the container, your application name appears in New Relic. License key This configuration is required for you to report data to your New Relic account. To copy your license key: Go to the API keys UI and get a license key. In one of these Dockerfile commands, replace MY_LICENSE_KEY with your license key: Option Command Environment variable ENV NEW_RELIC_LICENSE_KEY=\"MY_LICENSE_KEY\" Copy Java system property ENV JAVA_OPTS=\"$JAVA_OPTS -Dnewrelic.config.license_key='MY_LICENSE_KEY'\" Copy Logs By default, logs are written into the logs directory relative to the location of newrelic.jar. Make sure that the user account that starts your application server also has the right to perform tasks such as: Creating the logs directory. Creating and appending to the log files in that directory. Here’s a Dockerfile example where tomcat is the user who starts Tomcat: RUN mkdir -p /usr/local/tomcat/newrelic/logs RUN chown -R tomcat:tomcat /usr/local/tomcat/newrelic/logs Copy You can also send the logs to STDOUT by adding one of the following to the Dockerfile: Option Command Environment Variable ENV NEW_RELIC_LOG_FILE_NAME=STDOUT Copy Java system property ENV JAVA_OPTS=-Dnewrelic.config.log_file_name=STDOUT Copy Environment (optional) You can pass either a Java property or an environment variable to determine which of the environment-specific stanzas the agent uses in newrelic.yml. Use this approach if you prefer to have the newrelic.yml file control environment-specific configurations instead of passing all the configurations via Docker. Here’s a Dockerfile example of passing the newrelic.environment Java system property via Docker to use the custom value dev in the environment stanza of newrelic.yml: Using the shell form of the CMD instruction, include a reference to a new environment variable you choose (for example, ENV): CMD java -Dnewrelic.environment=$ENV -jar myjar.jar Copy In your docker run command line, include an argument to set the environment variable in the container: docker run -it -e \"ENV=dev\" myDockerImage Copy Important If you don’t specify a value for newrelic.environment, the agent assumes it is running in your production environment and uses the values from the main body of the configuration file. Enabled (optional) This configuration controls whether the agent is enabled. Let’s say you want the same Docker image for every installation. However, you don’t want to run the New Relic agent every time an engineer spins up a test app because you don’t want to run up your instance count. This problem can be solved using the newrelic.environment Java system property. In the main body of newrelic.yml, disable the Java agent by setting enabled: false. In specific environment stanzas of newrelic.yml, set enabled: true. Then, you can run specific agents by specifying the environment at runtime. Additional Tomcat Dockerfile examples Tomcat with environment and Java system properties FROM tomcat:9 # Add the newrelic.jar and -javaagent parameters RUN mkdir -p /usr/local/tomcat/newrelic ADD ./newrelic/newrelic.jar /usr/local/tomcat/newrelic/ ENV JAVA_OPTS=\"$JAVA_OPTS -javaagent:/usr/local/tomcat/newrelic/newrelic.jar\" # Add the configuration file ADD ./newrelic/newrelic.yml /usr/local/tomcat/newrelic/ # An example of setting a system property config ENV JAVA_OPTS=\"$JAVA_OPTS -Dnewrelic.config.app_name='My Application'\" # An example of setting an Environment variable config ENV NEW_RELIC_LICENSE_KEY=\"license_key\" # Config to include the agent logs in Docker's stdout logging ENV JAVA_OPTS=\"$JAVA_OPTS -Dnewrelic.config.log_file_name=STDOUT\" EXPOSE 8080 CMD [\"catalina.sh\", \"run\"] Copy How to start an application with the Java agent FROM openjdk:8 ADD my-application.jar /app ADD newrelic.jar /app ADD newrelic.yml /app ENV NEW_RELIC_APP_NAME=\"My Application\" ENV NEW_RELIC_LICENSE_KEY=\"license_key\" ENV NEW_RELIC_LOG_FILE_NAME=\"STDOUT\" ENTRYPOINT [\"java\",\"-javaagent:/app/newrelic.jar\",\"-jar\",\"/app/my-application.jar\"] Copy Next steps Now that you have a basic agent installation in Docker, here are some additional steps to consider: Review other configurations for the agent. Read a detailed Explorers Hub post about Docker and New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 93.8035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Set agent <em>configurations</em>",
        "tags": "<em>Additional</em> installation",
        "body": "This document explains a basic installation of the APM agent for Java applications in a Docker container. We discuss required configurations and also explore some optional configurations, including: How to use identical New Relic <em>configuration</em> files for each container, regardless of the environment"
      },
      "id": "603ea3dc28ccbc8889eba765"
    },
    {
      "sections": [
        "Java: Configure logs in context",
        "Set up your Java app",
        "Dropwizard 1.3 or higher",
        "java.util.logging",
        "java.util.logging classpath additions",
        "Log4j 1.x",
        "Log4j 2.x",
        "Logback version 1.2.0 or higher",
        "Spring and Springboot",
        "View logs in UI",
        "What's next?"
      ],
      "title": "Java: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "59255e4b759113c33c56c041bc7376f06de7fe45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/java-configure-logs-context-all/",
      "published_at": "2021-09-01T18:18:57Z",
      "updated_at": "2021-09-01T04:08:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Java agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Java app To enable logs in context for APM apps monitored by Java: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Java agent version. Use Java agent version 5.6.0 or higher for logs in context. Enable the JVM argument -javaagent, and enable distributed tracing. Configure logs in context for Java to enrich your log data, using any of the following extensions as applicable. If you use Spring or Spring Boot and aren't sure which extension you need, see our Spring documentation. Dropwizard 1.3 or higher We offer a Dropwizard extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with the DropWizard extension: Make sure you have the Dropwizard 1.3 or higher package installed and working on your application. Use the original Dropwizard appenders and logging factory installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Dropwizard 1.3 extension as applicable: Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:dropwizard:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>dropwizard</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your Dropwizard .yaml configuration file with a newrelic-json layout, replacing the currently used type: console or type: file with either type: newrelic-console or type: newrelic-file as appropriate. For example: logging: appenders: - type: newrelic-console # Add the two lines below if you don't have a layout specified on the appender. # If you have a layout, remove all parameters to the layout and set the type. layout: type: newrelic-json Copy The New Relic Dropwizard extension also supports a log-format layout type that uses the standard Dropwizard logging. For testing purposes, you can change the type of the layout with a one-line change: logging: appenders: - type: newrelic-file # This format will be ignored by the newrelic-json layout, but used by the log-format layout. logFormat: \"%date{ISO8601} %c %-5p: %m trace.id=%mdc{trace.id} span.id=%mdc{span.id}%n\" layout: # type: newrelic-json type: log-format Copy java.util.logging We offer a java.util.logging extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the java.util.logging extension: Make sure you have the java.util.logging package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the java.util.logging extension as applicable. If you can't edit these files, you can instead add the jars directly to the application classpath. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:jul:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>jul</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Check if your logging file's handlers property is set to something other than NewRelicMemoryHandler. Look for a line listing the root logger's handlers, like this: handlers = java.util.logging.FileHandler Copy Update your logging properties file to set the root logger's handler to NewRelicMemoryHandler so it intercepts messages destined for another handler: handlers = com.newrelic.logging.jul.NewRelicMemoryHandler Copy Configure the NewRelicMemoryHandler by setting the target to the handler that was previously assigned to the root logger, so it captures data New Relic needs on the thread the log message is coming from: com.newrelic.logging.jul.NewRelicMemoryHandler.target = java.util.logging.FileHandler Copy Use a NewRelicFormatter for the final handler. Update your logging properties file to set the formatter property like the following example. Make sure the handler where you set the formatter is the target handler from the previous step (java.util.logging.FileHandler in this example). java.util.logging.FileHandler.formatter = com.newrelic.logging.jul. NewRelicFormatter Copy The New Relic log format is JSON with telemetry metadata we use to correlate transactions and logs together. Currently we do not support any customization of that format. Once complete, JSON is logged instead of text. The JSON should be formatted as single objects, one per line, and should contain fields like log.level and thread.name. The trace.id, which is required for logs in context, should only have a value for log messages that occur within a transaction. java.util.logging classpath additions The most direct way to get the logs-in-context extensions is to add these dependencies to Maven's pom.xml or Gradle's build.gradle. This allows the packaging tools to pick up the correct dependencies. If you can't edit these files, you can instead add the jars directly to the application classpath for your logging framework's configuration. Before you modify the classpath: Enable the JVM argument -javaagent on your app's Java agent. Verify which logging framework the application is using. Make sure you are able to change your logging framework's configuration. Add the following three jars to the classpath if they aren't already present. Generally, we recommend taking the latest versions published on Maven Central. Group ID com.newrelic.logging and Artifact ID: Select the artifact named after your application's logging framework in Maven. Group ID com.fasterxml.jackson.core and Artifact ID: Use jackson-core. Group ID com.newrelic.agent.java and Artifact ID: Use newrelic-api. Log4j 1.x We offer a Log4j 1.x extension extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 1.x extension, you must configure the Log4j extension in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Make sure you have the Log4j 1.x package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 1.x extension as applicable. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/>: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension: <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Log4j 2.x We offer a Log4j 2.x extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 2.x extension: Make sure you have the Log4j 2.x or Logs4j 2 binding package installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 2.x extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you're using a properties file, add packages=com.newrelic.logging.log4j2. Add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you're using a properties file, only change the layout.type: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, skip this step. If you added a new appender, add <AppenderRef/> within <Root> to use this appender. Use the ref attribute to refer to appender name you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you're using a properties file and added a new appender, add: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Logback version 1.2.0 or higher We offer a Logback extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with Logback: Make sure you have Logback version 1.2.0 or higher and the New Relic Java agent version 5.6.0 or higher installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Logback extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing <encoder> element. If you're logging to the console (stdout/stderr), look for ConsoleAppender and replace: <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you're logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the first appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. Then list any other appenders after the NewRelicAsyncAppender in the <root> list. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Here are examples of an updated logging .xml file for the Logback extension. You can also see a working example in GitHub. Single console appender example Example configuration file after adding in the logging extension information: <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two console appenders example This example sends New Relic logging to a file, but still sends standard logging to the console: <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Spring and Springboot We offer extensions for current versions of Spring and Spring Boot. If you already know the logging library, you can skip directly to that documentation: java.util.logging log4j 1 log4j 2 logback The extensions support default configurations only on Spring Boot 2.0 and higher. With Spring Boot: Here are tips to determine which logging library you have: If you have spring-boot-starter-log4j2 in your dependencies, you're using log4j 2.x. Refer to the Spring Boot log4j 2.x documentation for basic configuration, and the New Relic log4j 2 extension for customizing your configuration. If you're using Spring Boot but not the starter-log4j2, you're using logback by default. Refer to Spring Boot logback documentation for basic configuration, and the New Relic logback extension for customizing your configuration. With Spring (but not Spring Boot): Spring 5 or higher: Spring implements a bridge to other logging libraries that will automatically find them. However, those individual libraries must be configured and explicitly included in your project dependencies. To identify your logging dependency, consult your Gradle, Maven, or other build tool's dependency tree. Then follow the procedures to configure logs in context for your Java app with that extension. Spring 4 or lower: Spring version 4 and lower uses Apache Commons Logging for its bridge. Refer to the Spring documentation for information on configuring its bridge. View logs in UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 85.8006,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: <em>Configure</em> logs in context",
        "sections": "Java: <em>Configure</em> logs in context",
        "tags": "<em>Configure</em> logs in context",
        "body": " your logging <em>configuration</em> xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic&#x27;s log forwarder, add the following section. Change &quot;LOG_FILE&quot; to the name of the appender you updated in the previous <em>step</em>. &lt;appender name=&quot;ASYNC&quot; class"
      },
      "id": "612efca3e7b9d2f718b6f223"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-aws-lambda-monitoring": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/configure-serverless-monitoring-aws-lambda/",
      "sections": [
        "Step 5: Additional configuration",
        "Set up alerts",
        "Add custom events"
      ],
      "published_at": "2021-09-02T16:42:37Z",
      "title": "Step 5: Additional configuration",
      "updated_at": "2021-08-27T08:19:45Z",
      "type": "docs",
      "external_id": "7ccc0cbc8f96ad38d90cfa4e6c12b53f8ebfcbb4",
      "document_type": "page",
      "popularity": 1,
      "body": "After you enable serverless monitoring for AWS Lambda, you can add additional configuration to fine-tune your data. Set up alerts Our alerts let you get notifications on anything you can monitor with New Relic, including APM metrics, key transactions, NRQL queries, and more. For details about setting up alerts on Lambda functions, see monitoring for AWS Lambda: Configuring alerts Add custom events Besides the data we provide by default, you can also set up your own events or attributes. For details about these language-specific settings, see Configuring custom attributes and events in AWS Lambda.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1815.5607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "After you <em>enable</em> serverless <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, you can add additional configuration to fine-tune your data. Set up alerts Our alerts let you get notifications on anything you can <em>monitor</em> with New Relic, including APM metrics, key transactions, NRQL queries, and more. For details about"
      },
      "id": "603e94df196a676d7ea83ddc"
    },
    {
      "sections": [
        "Troubleshoot enabling serverless monitoring of AWS Lambda",
        "Problem",
        "Solution",
        "Recommended: Attach your CloudWatch logs to the ticket",
        "Important"
      ],
      "title": "Troubleshoot enabling serverless monitoring of AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Troubleshooting"
      ],
      "external_id": "73f864add78be5efb2429485506dc5a679a9820e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/troubleshooting/troubleshoot-enabling-serverless-monitoring-aws-lambda/",
      "published_at": "2021-09-02T16:47:47Z",
      "updated_at": "2021-03-16T18:38:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You’re attempting to enable serverless monitoring for AWS Lambda and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the AWS integration step wasn't completed. Not seeing data on Troubleshooting category UI pages. If you aren't seeing data on the Distributed tracing, Errors, and Invocations UI tabs, this means the APM agent instrumentation step wasn't completed. Besides these basic enablement problems, there are some additional problems that may cause an issue: CloudWatch error \"HTTP error 401: unauthorized.\" This is due to an incorrect API Key. The --nr-api-keyargument in the Configure AWS enable step takes your user key, which is different from the REST API key. Custom metrics are missing. Lambda monitoring is not compatible with our custom metrics. Use custom attributes to add metadata. Invocations missing. To see invocation breakdown details, distributed tracing must be enabled as part of the Lambda instrumentation step. Distributed tracing is required so that span details can be displayed in the invocation details pane. You've completed the installation, integration, and instrumentation steps correctly, and your function is sending logs to CloudWatch but you're not seeing traces for specific dependencies (or any traces) in the UI. This may result from the order of layer merging (if you're using our Lambda layers) or from the order of import (if you're instrumenting manually): If you're instrumenting with layers: make sure in your function configuration that the New Relic layer is merged before other layers (though if your function uses webpack, the New Relic layer should be merged after the webpack layer). If you're instrumenting a Node function manually, make sure that your function imports newrelic and @newrelic/aws-sdk before it imports any dependencies you expect to monitor. If none of these solutions help you, contact our support team. The following information will help you when you talk to support technicians: Has the Lambda function appeared in the UI before? If so, what is the name of the function? If some data for the Lambda function is appearing in the UI, what specific data is appearing? What APM language agent are you using to instrument the function? Recommended: Attach your CloudWatch logs to the ticket To provide our support team with logging information when opening a ticket: Invoke the function in AWS Lambda. Click on the logs link after your function runs. This will take you to the CloudWatch logs in AWS. On the left-hand sidebar in AWS, under Logs, click on Insights. Select your function and also the newrelic-log-ingestion stream. Apply an appropriate Time Filter, and a log entry limit (the default of 20 may not be enough). Under Actions select Copy query results (ASCII). Paste the copied text into a new text file, then save and upload the text file to the ticket. Important The NR_LAMBDA_MONITORING payload contains all the information the agent attempts to send up, including metrics, events, some AWS account metadata, invocations and errors data. Note that some of that data (for example, our legacy metrics) will not make it to our UI because our ingest pipeline does not consume them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 728.29584,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot <em>enabling</em> serverless <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "sections": "Troubleshoot <em>enabling</em> serverless <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "body": "Problem You’re attempting to <em>enable</em> serverless <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the <em>AWS</em> integration step wasn&#x27;t"
      },
      "id": "603ea6bb64441f85284e889b"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "ab6a129f8c50643b9af1c135863572d1ab595e30",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-09-01T23:36:23Z",
      "updated_at": "2021-03-16T05:36:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 463.28003,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Connect <em>AWS</em> GovCloud to New Relic",
        "sections": "Connect <em>AWS</em> GovCloud to New Relic",
        "body": ". For instructions, see <em>Enable</em> <em>Lambda</em> <em>monitoring</em>. <em>AWS</em> integrations supported in GovCloud: ALB&#x2F;NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM <em>Lambda</em> RDS Redshift Route53 S3 SNS SQS Step Functions Connect <em>AWS</em> GovCloud to New Relic To start"
      },
      "id": "603e85bc196a675469a83dcd"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy": [
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-09-02T16:45:40Z",
      "updated_at": "2021-09-02T16:45:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.64978,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements of AWS <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility and requirements of AWS <em>Lambda</em> <em>monitoring</em>",
        "tags": "AWS <em>Lambda</em> <em>monitoring</em>",
        "body": "Before enabling serverless <em>monitoring</em> for AWS <em>Lambda</em>, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS <em>Lambda</em> language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "sections": [
        "Step 4: Instrument your own Lambda functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "published_at": "2021-09-02T16:43:44Z",
      "title": "Step 4: Instrument your own Lambda functions",
      "updated_at": "2021-08-27T07:52:48Z",
      "type": "docs",
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "document_type": "page",
      "popularity": 1,
      "body": "This is one step of enabling New Relic's AWS Lambda monitoring. Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.80371,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Step 4: <em>Instrument</em> your own <em>Lambda</em> functions",
        "sections": "Step 4: <em>Instrument</em> your own <em>Lambda</em> functions",
        "body": " filter from your function&#x27;s CloudWatch Log Group to invoke the newrelic-log-ingestion <em>lambda</em> function. See below. <em>Manual</em> process: Stream CloudWatch logs to New Relic <em>Lambda</em> Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are <em>monitoring</em>. Select"
      },
      "id": "605aa8a064441f453b868bb9"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "sections": [
        "Step 3: Instrument a Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "published_at": "2021-09-02T16:43:44Z",
      "title": "Step 3: Instrument a Lambda function",
      "updated_at": "2021-08-27T08:19:45Z",
      "type": "docs",
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "document_type": "page",
      "popularity": 1,
      "body": "This is one step of enabling New Relic's AWS Lambda monitoring. New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate distributed tracing into a non-trivial serverless application in our distributed tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.3412,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Step 3: <em>Instrument</em> a <em>Lambda</em> function",
        "sections": "Step 3: <em>Instrument</em> a <em>Lambda</em> function",
        "body": "This is one step of enabling New Relic&#x27;s AWS <em>Lambda</em> <em>monitoring</em>. New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your"
      },
      "id": "605aa85628ccbcc6d13ae663"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy/",
      "sections": [
        "Legacy manual instrumentation for Lambda monitoring",
        "Go",
        "Zip and upload recommendations",
        "Java",
        "Tip",
        ".NET Core",
        "Async handler function",
        "Inheriting from APIGatewayProxyFunction",
        "Important",
        "Using the SQS Wrapper",
        "Using the SNS Wrapper",
        "Node.js",
        "Python"
      ],
      "published_at": "2021-09-02T16:43:44Z",
      "title": "Legacy manual instrumentation for Lambda monitoring",
      "updated_at": "2021-09-02T16:43:44Z",
      "type": "docs",
      "external_id": "694e22b2ce401a96d200ab2e12a08850532b3e5a",
      "document_type": "page",
      "popularity": 1,
      "body": "On this page, you will learn how to manually instrument your lambda function. It's organized by runtime language. Go To instrument your Go-language Lambda: Download our Go agent package and place it in the same directory as your function. Install the agent: go get -u github.com/newrelic/go-agent/v3/newrelic. Install the nrlambda integration go get -u github.com/newrelic/go-agent/v3/integrations/nrlambda. In your Lambda code, import our components, create an application, and update how you start your Lambda. See our GitHub repo for an example of an instrumented Lambda. Optional: Add custom events that will be associated with your Lambda invocation by using the RecordCustomEvent API. For example: func handler(ctx context.Context) { if txn := newrelic.FromContext(ctx); nil != txn { txn.Application().RecordCustomEvent(\"MyEvent\", map[string]interface{}{ \"zip\": \"zap\", }) } fmt.Println(\"hello world!\") } Copy Build and zip your Lambda function and upload it to AWS. Zip and upload recommendations Here are suggestions for zipping and uploading the Lambda: Build the binary for execution on Linux. This produces a binary file called main. You can use: $ GOOS=linux go build -o main Copy Zip the binary into a deployment package using: $ zip deployment.zip main Copy Upload the zip file to AWS using either the AWS Lambda console or the AWS CLI. Name the handler main (to match the name given during the binary build). The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this is the account ID for the root/parent account. Optional: To configure logging, see Go agent logging. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Java Monitoring for AWS Lambda in Java doesn't use our APM Java agent. Instead, it uses these two OpenTracing dependencies: AWS Lambda OpenTracing Java SDK: OpenTracing instrumentation for AWS Lambda RequestHandler and RequestStreamHandler. Our AWS Lambda OpenTracing Tracer: An OpenTracing Tracer implementation designed to monitor AWS Lambda. It generates spans, error events, transaction events, error traces, and provides distributed tracing support. Tip Supported OpenTracing Versions OpenTracing 0.31.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:1.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:1.0.0 OpenTracing 0.32.0, 0.33.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:2.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:2.1.0 To instrument your Java Lambda: In your project’s build.gradle file, include our OpenTracing AWS Lambda Tracer and the AWS Lambda OpenTracing SDK dependencies: dependencies { compile(\"com.newrelic.opentracing:java-aws-lambda:2.1.0\") compile(\"com.newrelic.opentracing:newrelic-java-lambda:2.1.1\") compile(\"io.opentracing:opentracing-util:0.33.0\") } Copy Implement the AWS Lambda RequestHandler interface as shown in the Java Lambda example and override the doHandleRequest method. In the doHandleRequest method, call the LambdaTracing.instrument(...) API to create a root span to trace the lambda function's execution. This is also where you will define your business logic for the lambda function. Register a LambdaTracer.INSTANCE as the OpenTracing Global tracer, as shown in the Java Lambda example. Create a ZIP deployment package and upload it to AWS Lambda. Or deploy it via other means. In the AWS Lambda console, set the handler. For the example Java Lambda, the handler would be com.handler.example.MyLambdaHandler::handleRequest. Because handleRequest is assumed, you could also use com.handler.example.MyLambdaHandler. The following AWS console environment variables are required if you want your Lambda function to be included in distributed tracing. This is recommended. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_PRIMARY_APPLICATION_ID. This is also your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this must be the account ID for the root/parent account. Optional: In the Lambda console, enable debug logging by adding this environment variable: NEW_RELIC_DEBUG is true. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Please see the AWS Lambda distributed tracing example for a complete project that illustrates common use cases such as: Distributed tracing between Lambda functions Manual span creation (aka custom instrumentation) Tracing external calls Adding custom attributes (aka Tags) to spans .NET Core Our monitoring of .NET Core-based AWS Lambda functions doesn't use our standard .NET Core APM agent. Instead, it uses a NuGet package. To instrument your .NET Core Lambda: In your Lambda Functions project, install the NewRelic.OpenTracing.AmazonLambda.Tracer NuGet package. Note: NewRelic.OpenTracing.AmazonLambda.Tracer depends on version 1.2.0+ of Amazon.Lambda.APIGatewayEvent NuGet package. If the environment already uses a lower version of Amazon.Lambda.APIGatewayEvent, the New Relic package may produce errors such as System.MissingMethodException . Import the NuGet package and OpenTracing utils: using OpenTracing.Util; using NewRelic.OpenTracing.AmazonLambda; Copy Instrument your function, as shown in this example: public class Function { static Function() { // Register The NewRelic Lambda Tracer Instance GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public object FunctionWrapper(ILambdaContext context) { // Instantiate NewRelic TracingWrapper and pass your FunctionHandler as // an argument return new TracingRequestHandler().LambdaWrapper(FunctionHandler, context); } /// <summary> /// A simple function that takes a string and does a ToUpper /// </summary> /// <param name=\"input\"></param> /// <param name=\"context\"></param> /// <returns></returns> public object FunctionHandler(ILambdaContext context) { ... } } Copy Tip The arguments passed to FunctionWrapper must match the signature of FunctionHandler. If your handler function returns a Task, the Lambda wrapper will block on the return task until it completes, so that it can measure the duration and capture exceptions, if any are present. In addition, you may also inherit from the APIGatewayProxyFunction. For an example, see below: Async handler function public async Task<int> FunctionHandlerAsync(ILambdaContext lambdaContext) { return await new TracingRequestHandler().LambdaWrapper( ActualFunctionHandlerAsync, lambdaContext); } public async Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(ILambdaContext lambdaContext) { // Function can make other async operations here ... } Copy Inheriting from APIGatewayProxyFunction public class LambdaFunction : APIGatewayProxyFunction { static LambdaFunction() { // Register The NewRelic Lambda Tracer Instance OpenTracing.Util.GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public override Task<APIGatewayProxyResponse> FunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { Task<APIGatewayProxyResponse> task = new TracingRequestHandler().LambdaWrapper(ActualFunctionHandlerAsync, request, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { return base.FunctionHandlerAsync(request, lambdaContext); } } Copy Optional for SQS and SNS: Starting in version 1.0 of our .NET Lambda Tracer, distributed tracing support has been added for SQS and SNS. To enable distributed tracing for SQS or SNS you will need to complete the items in this step as well as setup the environment variables in the step that follows this one. Important Enabling distributed tracing support for SQS and SNS will disable automatic instrumentation for both of SQS and SNS and require the use of these wrappers to instrument them. Set the NEW_RELIC_USE_DT_WRAPPER environment variable to true. To instrument SQS and SNS calls you will need to use the provided wrappers. Using the SQS Wrapper The SQS wrapper supports wrapping the following methods: Amazon.SQS.AmazonSQSClient.SendMessageAsync(...) Amazon.SQS.AmazonSQSClient.SendMessageBatchAsync(...) Examples // SQS Client AmazonSQSClient client = new AmazonSQSClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // SendMessageRequest SendMessageRequest sendRequest = new SendMessageRequest(\"QUEUE_URI_STRING\", \"An SQS Message\"); Task<SendMessageResponse> responseOne = SQSWrapper.WrapRequest(client.SendMessageAsync, sendRequest); // String-based Task<SendMessageResponse> responseTwo = SQSWrapper.WrapRequest(client.SendMessageAsync, \"QUEUE_URI_STRING\", \"Another SQS Message\"); // SendMessageBatchRequest List<SendMessageBatchRequestEntry> batchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id1\", \"First SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id2\", \"Second SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id3\", \"Third SQS Message\")); SendMessageBatchRequest sendBatchRequest = new SendMessageBatchRequest(QUEUE_URI, batchEntries); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, sendBatchRequest); // SendMessageBatchRequestEntry List List<SendMessageBatchRequestEntry> moreBatchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id4\", \"Fourth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id5\", \"Fifth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id6\", \"Sixth SQS Message\")); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, moreBatchEntries); Copy Using the SNS Wrapper The SNS wrapper supports wrapping the following methods: Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient.PublishAsync(...) Examples // SNS Client AmazonSimpleNotificationServiceClient client = new Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // PublishRequest - Phone Number PublishRequest phonePublishRequest = new PublishRequest(); phonePublishRequest.PhoneNumber = +1XXX5555100; phonePublishRequest.Message = \"An SNS Message for phones\"; Task<PublishResponse> phoneResponse = SNSWrapper.WrapRequest(client.PublishAsync, phonePublishRequest); // PublishRequest - ARN PublishRequest publishRequest = new PublishRequest(\"TOPIC_ARN\", \"An SNS Message\"); Task<PublishResponse> publishResponse = SNSWrapper.WrapRequest(client.PublishAsync, publishRequest); // String-based without subject Task<PublishResponse> ResponseOne = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Another SNS Message\"); // String-based with subject Task<PublishResponse> ResponseTwo = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Yet Another SNS Message\", \"A Subject\"); Copy The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS Lambda console: NEW_RELIC_ACCOUNT_ID: The account ID the Lambda is reporting to. NEW_RELIC_TRUSTED_ACCOUNT_KEY: This is also the account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Ensure that the wrapper function (FunctionWrapper in above example) is set up as the function handler. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Node.js To instrument your Node.js Lambda: Download our Node.js agent package and place it in the same directory as your function, ensuring the agent is installed as a dependency in the node_modules directory. Use the Node Package Manager: npm install newrelic --save Copy Install our AWS SDK module alongside the Node.js agent: npm install @newrelic/aws-sdk --save Copy In your Lambda code, require the agent module and the AWS SDK at the top of the file, and wrap the handler function. For example: const newrelic = require('newrelic'); require('@newrelic/aws-sdk'); // Other module loads go under the two require statements above module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { // This is your handler function code console.log('Lambda executed'); callback(); }); Copy Optional: You can also add custom events to your Lambda using the recordCustomEvent API. For example: module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { newrelic.recordCustomEvent(‘MyEventType’, {foo: ‘bar’}); console.log('Lambda executed'); callback(); }); Copy Zip your Lambda function and the Node.js agent folder together. Requirements and recommendations: The New Relic files outside the New Relic agent folder don't need to be included. If your Lambda function file name is, for example, lambda_function.node, we recommend naming your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set these environment variables: NEW_RELIC_NO_CONFIG_FILE. Set to true if not using a configuration file. NEW_RELIC_APP_NAME: Your application name. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Optional: To run the agent in serverless mode outside of AWS in a local environment, set the environment variable NEW_RELIC_SERVERLESS_MODE_ENABLED to true. (When executing this in an AWS Lambda environment, the agent will automatically run in serverless mode. Do not use this variable if you're running in AWS.) Optional: To enable logging in serverless mode, set these environment variables: Set NEW_RELIC_LOG_ENABLED to true. Set NEW_RELIC_LOG to stdout for output to CloudWatch, or set to any writeable file location. The log level is set to info by default. See other log levels. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Python To instrument your Python Lambda: Download our Python agent package and place it in the same directory as your function. To do this, use pip: pip install -t . newrelic Copy Important If you use Homebrew, you may get this error: DistutilsOptionError: must supply either home or prefix/exec-prefix -- not both. For details, see the Homebrew GitHub post. In your Lambda code, import the Python agent module and decorate the handler function using the New Relic decorator. The New Relic package must be imported first in your code. Here's an example: import newrelic.agent newrelic.agent.initialize() @newrelic.agent.lambda_handler() def handler(event, context): ... Copy Optional: You can also add custom events to your Lambda using the record_custom_event API. Here's an example: @newrelic.agent.lambda_handler() def handler(event, context): newrelic.agent.record_custom_event('CustomEvent', {'foo': 'bar'}) … Copy Zip your lambda_function.py and newrelic/ folder together using these guidelines: The New Relic files outside the newrelic/ folder don't need to be included. If your Lambda function file name is, for example, lambda_function.py, name your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set this environment variable: NEW_RELIC_SERVERLESS_MODE_ENABLED. Set to true The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED. Set to true. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Optional: To configure logging, use the NEW_RELIC_LOG and NEW_RELIC_LOG_LEVEL environment variables in the AWS Console. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. The New Relic decorator gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, configure CloudWatch to send those logs to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.98364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Legacy manual <em>instrumentation</em> for <em>Lambda</em> monitoring",
        "sections": "Legacy manual <em>instrumentation</em> for <em>Lambda</em> monitoring",
        "body": "On this page, you will learn how to manually <em>instrument</em> your <em>lambda</em> <em>function</em>. It&#x27;s organized by runtime language. Go To <em>instrument</em> your Go-language <em>Lambda</em>: Download our Go agent package and place it in the same directory as your <em>function</em>. Install the agent: go get -u github.com&#x2F;newrelic&#x2F;go-agent&#x2F;v<em>3</em>"
      },
      "id": "603ebbcb64441f800a4e8850"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-aws-lambda-monitoring/",
      "sections": [
        "Enable monitoring for AWS Lambda"
      ],
      "published_at": "2021-09-02T16:42:38Z",
      "title": "Enable monitoring for AWS Lambda",
      "updated_at": "2021-08-26T04:49:50Z",
      "type": "docs",
      "external_id": "8a60acf499837668684b93945d3ce973d95fe347",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several steps to enabling Lambda monitoring: Link your AWS account. Optional: configure CloudWatch Log collection: if in Step 1, you used the newrelic-lambda CLI, that automatically installs the CloudWatch logs collector by default and you can skip this step. Instrument an example function. Instrument your functions. Optional: Set up alerts and custom events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.00693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable monitoring for <em>AWS</em> <em>Lambda</em>",
        "sections": "Enable monitoring for <em>AWS</em> <em>Lambda</em>",
        "body": "There are several steps to enabling <em>Lambda</em> monitoring: Link your AWS account. Optional: configure CloudWatch Log collection: if in <em>Step</em> 1, you used the newrelic-<em>lambda</em> CLI, that automatically installs the CloudWatch logs collector by default and you can skip this <em>step</em>. <em>Instrument</em> an example <em>function</em>. <em>Instrument</em> your functions. Optional: Set up alerts and custom events."
      },
      "id": "61271d6e196a677c0b00b320"
    },
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-09-02T16:45:40Z",
      "updated_at": "2021-09-02T16:45:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.48235,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility <em>and</em> requirements of <em>AWS</em> <em>Lambda</em> monitoring",
        "sections": "Compatibility <em>and</em> requirements of <em>AWS</em> <em>Lambda</em> monitoring",
        "tags": "<em>AWS</em> <em>Lambda</em> monitoring",
        "body": "Before enabling serverless monitoring for AWS <em>Lambda</em>, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS <em>Lambda</em> language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python<em>3</em>.7, python<em>3</em>.8, python<em>3</em>.9 Go: provided, provided.al2 Java: java8.al2"
      },
      "id": "603e98bd64441ff7454e8885"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy/",
      "sections": [
        "Legacy manual instrumentation for Lambda monitoring",
        "Go",
        "Zip and upload recommendations",
        "Java",
        "Tip",
        ".NET Core",
        "Async handler function",
        "Inheriting from APIGatewayProxyFunction",
        "Important",
        "Using the SQS Wrapper",
        "Using the SNS Wrapper",
        "Node.js",
        "Python"
      ],
      "published_at": "2021-09-02T16:43:44Z",
      "title": "Legacy manual instrumentation for Lambda monitoring",
      "updated_at": "2021-09-02T16:43:44Z",
      "type": "docs",
      "external_id": "694e22b2ce401a96d200ab2e12a08850532b3e5a",
      "document_type": "page",
      "popularity": 1,
      "body": "On this page, you will learn how to manually instrument your lambda function. It's organized by runtime language. Go To instrument your Go-language Lambda: Download our Go agent package and place it in the same directory as your function. Install the agent: go get -u github.com/newrelic/go-agent/v3/newrelic. Install the nrlambda integration go get -u github.com/newrelic/go-agent/v3/integrations/nrlambda. In your Lambda code, import our components, create an application, and update how you start your Lambda. See our GitHub repo for an example of an instrumented Lambda. Optional: Add custom events that will be associated with your Lambda invocation by using the RecordCustomEvent API. For example: func handler(ctx context.Context) { if txn := newrelic.FromContext(ctx); nil != txn { txn.Application().RecordCustomEvent(\"MyEvent\", map[string]interface{}{ \"zip\": \"zap\", }) } fmt.Println(\"hello world!\") } Copy Build and zip your Lambda function and upload it to AWS. Zip and upload recommendations Here are suggestions for zipping and uploading the Lambda: Build the binary for execution on Linux. This produces a binary file called main. You can use: $ GOOS=linux go build -o main Copy Zip the binary into a deployment package using: $ zip deployment.zip main Copy Upload the zip file to AWS using either the AWS Lambda console or the AWS CLI. Name the handler main (to match the name given during the binary build). The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this is the account ID for the root/parent account. Optional: To configure logging, see Go agent logging. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Java Monitoring for AWS Lambda in Java doesn't use our APM Java agent. Instead, it uses these two OpenTracing dependencies: AWS Lambda OpenTracing Java SDK: OpenTracing instrumentation for AWS Lambda RequestHandler and RequestStreamHandler. Our AWS Lambda OpenTracing Tracer: An OpenTracing Tracer implementation designed to monitor AWS Lambda. It generates spans, error events, transaction events, error traces, and provides distributed tracing support. Tip Supported OpenTracing Versions OpenTracing 0.31.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:1.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:1.0.0 OpenTracing 0.32.0, 0.33.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:2.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:2.1.0 To instrument your Java Lambda: In your project’s build.gradle file, include our OpenTracing AWS Lambda Tracer and the AWS Lambda OpenTracing SDK dependencies: dependencies { compile(\"com.newrelic.opentracing:java-aws-lambda:2.1.0\") compile(\"com.newrelic.opentracing:newrelic-java-lambda:2.1.1\") compile(\"io.opentracing:opentracing-util:0.33.0\") } Copy Implement the AWS Lambda RequestHandler interface as shown in the Java Lambda example and override the doHandleRequest method. In the doHandleRequest method, call the LambdaTracing.instrument(...) API to create a root span to trace the lambda function's execution. This is also where you will define your business logic for the lambda function. Register a LambdaTracer.INSTANCE as the OpenTracing Global tracer, as shown in the Java Lambda example. Create a ZIP deployment package and upload it to AWS Lambda. Or deploy it via other means. In the AWS Lambda console, set the handler. For the example Java Lambda, the handler would be com.handler.example.MyLambdaHandler::handleRequest. Because handleRequest is assumed, you could also use com.handler.example.MyLambdaHandler. The following AWS console environment variables are required if you want your Lambda function to be included in distributed tracing. This is recommended. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_PRIMARY_APPLICATION_ID. This is also your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this must be the account ID for the root/parent account. Optional: In the Lambda console, enable debug logging by adding this environment variable: NEW_RELIC_DEBUG is true. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Please see the AWS Lambda distributed tracing example for a complete project that illustrates common use cases such as: Distributed tracing between Lambda functions Manual span creation (aka custom instrumentation) Tracing external calls Adding custom attributes (aka Tags) to spans .NET Core Our monitoring of .NET Core-based AWS Lambda functions doesn't use our standard .NET Core APM agent. Instead, it uses a NuGet package. To instrument your .NET Core Lambda: In your Lambda Functions project, install the NewRelic.OpenTracing.AmazonLambda.Tracer NuGet package. Note: NewRelic.OpenTracing.AmazonLambda.Tracer depends on version 1.2.0+ of Amazon.Lambda.APIGatewayEvent NuGet package. If the environment already uses a lower version of Amazon.Lambda.APIGatewayEvent, the New Relic package may produce errors such as System.MissingMethodException . Import the NuGet package and OpenTracing utils: using OpenTracing.Util; using NewRelic.OpenTracing.AmazonLambda; Copy Instrument your function, as shown in this example: public class Function { static Function() { // Register The NewRelic Lambda Tracer Instance GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public object FunctionWrapper(ILambdaContext context) { // Instantiate NewRelic TracingWrapper and pass your FunctionHandler as // an argument return new TracingRequestHandler().LambdaWrapper(FunctionHandler, context); } /// <summary> /// A simple function that takes a string and does a ToUpper /// </summary> /// <param name=\"input\"></param> /// <param name=\"context\"></param> /// <returns></returns> public object FunctionHandler(ILambdaContext context) { ... } } Copy Tip The arguments passed to FunctionWrapper must match the signature of FunctionHandler. If your handler function returns a Task, the Lambda wrapper will block on the return task until it completes, so that it can measure the duration and capture exceptions, if any are present. In addition, you may also inherit from the APIGatewayProxyFunction. For an example, see below: Async handler function public async Task<int> FunctionHandlerAsync(ILambdaContext lambdaContext) { return await new TracingRequestHandler().LambdaWrapper( ActualFunctionHandlerAsync, lambdaContext); } public async Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(ILambdaContext lambdaContext) { // Function can make other async operations here ... } Copy Inheriting from APIGatewayProxyFunction public class LambdaFunction : APIGatewayProxyFunction { static LambdaFunction() { // Register The NewRelic Lambda Tracer Instance OpenTracing.Util.GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public override Task<APIGatewayProxyResponse> FunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { Task<APIGatewayProxyResponse> task = new TracingRequestHandler().LambdaWrapper(ActualFunctionHandlerAsync, request, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { return base.FunctionHandlerAsync(request, lambdaContext); } } Copy Optional for SQS and SNS: Starting in version 1.0 of our .NET Lambda Tracer, distributed tracing support has been added for SQS and SNS. To enable distributed tracing for SQS or SNS you will need to complete the items in this step as well as setup the environment variables in the step that follows this one. Important Enabling distributed tracing support for SQS and SNS will disable automatic instrumentation for both of SQS and SNS and require the use of these wrappers to instrument them. Set the NEW_RELIC_USE_DT_WRAPPER environment variable to true. To instrument SQS and SNS calls you will need to use the provided wrappers. Using the SQS Wrapper The SQS wrapper supports wrapping the following methods: Amazon.SQS.AmazonSQSClient.SendMessageAsync(...) Amazon.SQS.AmazonSQSClient.SendMessageBatchAsync(...) Examples // SQS Client AmazonSQSClient client = new AmazonSQSClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // SendMessageRequest SendMessageRequest sendRequest = new SendMessageRequest(\"QUEUE_URI_STRING\", \"An SQS Message\"); Task<SendMessageResponse> responseOne = SQSWrapper.WrapRequest(client.SendMessageAsync, sendRequest); // String-based Task<SendMessageResponse> responseTwo = SQSWrapper.WrapRequest(client.SendMessageAsync, \"QUEUE_URI_STRING\", \"Another SQS Message\"); // SendMessageBatchRequest List<SendMessageBatchRequestEntry> batchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id1\", \"First SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id2\", \"Second SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id3\", \"Third SQS Message\")); SendMessageBatchRequest sendBatchRequest = new SendMessageBatchRequest(QUEUE_URI, batchEntries); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, sendBatchRequest); // SendMessageBatchRequestEntry List List<SendMessageBatchRequestEntry> moreBatchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id4\", \"Fourth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id5\", \"Fifth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id6\", \"Sixth SQS Message\")); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, moreBatchEntries); Copy Using the SNS Wrapper The SNS wrapper supports wrapping the following methods: Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient.PublishAsync(...) Examples // SNS Client AmazonSimpleNotificationServiceClient client = new Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // PublishRequest - Phone Number PublishRequest phonePublishRequest = new PublishRequest(); phonePublishRequest.PhoneNumber = +1XXX5555100; phonePublishRequest.Message = \"An SNS Message for phones\"; Task<PublishResponse> phoneResponse = SNSWrapper.WrapRequest(client.PublishAsync, phonePublishRequest); // PublishRequest - ARN PublishRequest publishRequest = new PublishRequest(\"TOPIC_ARN\", \"An SNS Message\"); Task<PublishResponse> publishResponse = SNSWrapper.WrapRequest(client.PublishAsync, publishRequest); // String-based without subject Task<PublishResponse> ResponseOne = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Another SNS Message\"); // String-based with subject Task<PublishResponse> ResponseTwo = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Yet Another SNS Message\", \"A Subject\"); Copy The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS Lambda console: NEW_RELIC_ACCOUNT_ID: The account ID the Lambda is reporting to. NEW_RELIC_TRUSTED_ACCOUNT_KEY: This is also the account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Ensure that the wrapper function (FunctionWrapper in above example) is set up as the function handler. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Node.js To instrument your Node.js Lambda: Download our Node.js agent package and place it in the same directory as your function, ensuring the agent is installed as a dependency in the node_modules directory. Use the Node Package Manager: npm install newrelic --save Copy Install our AWS SDK module alongside the Node.js agent: npm install @newrelic/aws-sdk --save Copy In your Lambda code, require the agent module and the AWS SDK at the top of the file, and wrap the handler function. For example: const newrelic = require('newrelic'); require('@newrelic/aws-sdk'); // Other module loads go under the two require statements above module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { // This is your handler function code console.log('Lambda executed'); callback(); }); Copy Optional: You can also add custom events to your Lambda using the recordCustomEvent API. For example: module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { newrelic.recordCustomEvent(‘MyEventType’, {foo: ‘bar’}); console.log('Lambda executed'); callback(); }); Copy Zip your Lambda function and the Node.js agent folder together. Requirements and recommendations: The New Relic files outside the New Relic agent folder don't need to be included. If your Lambda function file name is, for example, lambda_function.node, we recommend naming your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set these environment variables: NEW_RELIC_NO_CONFIG_FILE. Set to true if not using a configuration file. NEW_RELIC_APP_NAME: Your application name. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Optional: To run the agent in serverless mode outside of AWS in a local environment, set the environment variable NEW_RELIC_SERVERLESS_MODE_ENABLED to true. (When executing this in an AWS Lambda environment, the agent will automatically run in serverless mode. Do not use this variable if you're running in AWS.) Optional: To enable logging in serverless mode, set these environment variables: Set NEW_RELIC_LOG_ENABLED to true. Set NEW_RELIC_LOG to stdout for output to CloudWatch, or set to any writeable file location. The log level is set to info by default. See other log levels. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Python To instrument your Python Lambda: Download our Python agent package and place it in the same directory as your function. To do this, use pip: pip install -t . newrelic Copy Important If you use Homebrew, you may get this error: DistutilsOptionError: must supply either home or prefix/exec-prefix -- not both. For details, see the Homebrew GitHub post. In your Lambda code, import the Python agent module and decorate the handler function using the New Relic decorator. The New Relic package must be imported first in your code. Here's an example: import newrelic.agent newrelic.agent.initialize() @newrelic.agent.lambda_handler() def handler(event, context): ... Copy Optional: You can also add custom events to your Lambda using the record_custom_event API. Here's an example: @newrelic.agent.lambda_handler() def handler(event, context): newrelic.agent.record_custom_event('CustomEvent', {'foo': 'bar'}) … Copy Zip your lambda_function.py and newrelic/ folder together using these guidelines: The New Relic files outside the newrelic/ folder don't need to be included. If your Lambda function file name is, for example, lambda_function.py, name your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set this environment variable: NEW_RELIC_SERVERLESS_MODE_ENABLED. Set to true The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED. Set to true. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Optional: To configure logging, use the NEW_RELIC_LOG and NEW_RELIC_LOG_LEVEL environment variables in the AWS Console. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. The New Relic decorator gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, configure CloudWatch to send those logs to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.77676,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Legacy manual <em>instrumentation</em> for <em>Lambda</em> monitoring",
        "sections": "Legacy manual <em>instrumentation</em> for <em>Lambda</em> monitoring",
        "body": "On this page, you will learn how to manually <em>instrument</em> <em>your</em> <em>lambda</em> <em>function</em>. It&#x27;s organized by runtime language. Go To <em>instrument</em> <em>your</em> Go-language <em>Lambda</em>: Download our Go agent package and place it in the same directory as <em>your</em> <em>function</em>. Install the agent: go get -u github.com&#x2F;newrelic&#x2F;go-agent&#x2F;v3"
      },
      "id": "603ebbcb64441f800a4e8850"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "sections": [
        "Step 3: Instrument a Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "published_at": "2021-09-02T16:43:44Z",
      "title": "Step 3: Instrument a Lambda function",
      "updated_at": "2021-08-27T08:19:45Z",
      "type": "docs",
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "document_type": "page",
      "popularity": 1,
      "body": "This is one step of enabling New Relic's AWS Lambda monitoring. New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate distributed tracing into a non-trivial serverless application in our distributed tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.74864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Step</em> 3: <em>Instrument</em> a <em>Lambda</em> <em>function</em>",
        "sections": "<em>Step</em> 3: <em>Instrument</em> a <em>Lambda</em> <em>function</em>",
        "body": "This is one <em>step</em> of enabling New Relic&#x27;s AWS <em>Lambda</em> monitoring. New Relic provides working minimal examples as a starting point for instrumenting <em>your</em> <em>own</em> serverless <em>functions</em>, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for <em>your</em>"
      },
      "id": "605aa85628ccbcc6d13ae663"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-aws-lambda-monitoring/",
      "sections": [
        "Enable monitoring for AWS Lambda"
      ],
      "published_at": "2021-09-02T16:42:38Z",
      "title": "Enable monitoring for AWS Lambda",
      "updated_at": "2021-08-26T04:49:50Z",
      "type": "docs",
      "external_id": "8a60acf499837668684b93945d3ce973d95fe347",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several steps to enabling Lambda monitoring: Link your AWS account. Optional: configure CloudWatch Log collection: if in Step 1, you used the newrelic-lambda CLI, that automatically installs the CloudWatch logs collector by default and you can skip this step. Instrument an example function. Instrument your functions. Optional: Set up alerts and custom events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.33395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable monitoring for AWS <em>Lambda</em>",
        "sections": "Enable monitoring for AWS <em>Lambda</em>",
        "body": "There are several steps to enabling <em>Lambda</em> monitoring: Link <em>your</em> AWS account. Optional: configure CloudWatch Log collection: if in <em>Step</em> 1, you used the newrelic-<em>lambda</em> CLI, that automatically installs the CloudWatch logs collector by default and you can skip this <em>step</em>. <em>Instrument</em> an example <em>function</em>. <em>Instrument</em> <em>your</em> <em>functions</em>. Optional: Set up alerts and custom events."
      },
      "id": "61271d6e196a677c0b00b320"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/set-up-cloudwatch-logs": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy/",
      "sections": [
        "Legacy manual instrumentation for Lambda monitoring",
        "Go",
        "Zip and upload recommendations",
        "Java",
        "Tip",
        ".NET Core",
        "Async handler function",
        "Inheriting from APIGatewayProxyFunction",
        "Important",
        "Using the SQS Wrapper",
        "Using the SNS Wrapper",
        "Node.js",
        "Python"
      ],
      "published_at": "2021-09-02T16:43:44Z",
      "title": "Legacy manual instrumentation for Lambda monitoring",
      "updated_at": "2021-09-02T16:43:44Z",
      "type": "docs",
      "external_id": "694e22b2ce401a96d200ab2e12a08850532b3e5a",
      "document_type": "page",
      "popularity": 1,
      "body": "On this page, you will learn how to manually instrument your lambda function. It's organized by runtime language. Go To instrument your Go-language Lambda: Download our Go agent package and place it in the same directory as your function. Install the agent: go get -u github.com/newrelic/go-agent/v3/newrelic. Install the nrlambda integration go get -u github.com/newrelic/go-agent/v3/integrations/nrlambda. In your Lambda code, import our components, create an application, and update how you start your Lambda. See our GitHub repo for an example of an instrumented Lambda. Optional: Add custom events that will be associated with your Lambda invocation by using the RecordCustomEvent API. For example: func handler(ctx context.Context) { if txn := newrelic.FromContext(ctx); nil != txn { txn.Application().RecordCustomEvent(\"MyEvent\", map[string]interface{}{ \"zip\": \"zap\", }) } fmt.Println(\"hello world!\") } Copy Build and zip your Lambda function and upload it to AWS. Zip and upload recommendations Here are suggestions for zipping and uploading the Lambda: Build the binary for execution on Linux. This produces a binary file called main. You can use: $ GOOS=linux go build -o main Copy Zip the binary into a deployment package using: $ zip deployment.zip main Copy Upload the zip file to AWS using either the AWS Lambda console or the AWS CLI. Name the handler main (to match the name given during the binary build). The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this is the account ID for the root/parent account. Optional: To configure logging, see Go agent logging. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Java Monitoring for AWS Lambda in Java doesn't use our APM Java agent. Instead, it uses these two OpenTracing dependencies: AWS Lambda OpenTracing Java SDK: OpenTracing instrumentation for AWS Lambda RequestHandler and RequestStreamHandler. Our AWS Lambda OpenTracing Tracer: An OpenTracing Tracer implementation designed to monitor AWS Lambda. It generates spans, error events, transaction events, error traces, and provides distributed tracing support. Tip Supported OpenTracing Versions OpenTracing 0.31.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:1.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:1.0.0 OpenTracing 0.32.0, 0.33.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:2.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:2.1.0 To instrument your Java Lambda: In your project’s build.gradle file, include our OpenTracing AWS Lambda Tracer and the AWS Lambda OpenTracing SDK dependencies: dependencies { compile(\"com.newrelic.opentracing:java-aws-lambda:2.1.0\") compile(\"com.newrelic.opentracing:newrelic-java-lambda:2.1.1\") compile(\"io.opentracing:opentracing-util:0.33.0\") } Copy Implement the AWS Lambda RequestHandler interface as shown in the Java Lambda example and override the doHandleRequest method. In the doHandleRequest method, call the LambdaTracing.instrument(...) API to create a root span to trace the lambda function's execution. This is also where you will define your business logic for the lambda function. Register a LambdaTracer.INSTANCE as the OpenTracing Global tracer, as shown in the Java Lambda example. Create a ZIP deployment package and upload it to AWS Lambda. Or deploy it via other means. In the AWS Lambda console, set the handler. For the example Java Lambda, the handler would be com.handler.example.MyLambdaHandler::handleRequest. Because handleRequest is assumed, you could also use com.handler.example.MyLambdaHandler. The following AWS console environment variables are required if you want your Lambda function to be included in distributed tracing. This is recommended. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_PRIMARY_APPLICATION_ID. This is also your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this must be the account ID for the root/parent account. Optional: In the Lambda console, enable debug logging by adding this environment variable: NEW_RELIC_DEBUG is true. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Please see the AWS Lambda distributed tracing example for a complete project that illustrates common use cases such as: Distributed tracing between Lambda functions Manual span creation (aka custom instrumentation) Tracing external calls Adding custom attributes (aka Tags) to spans .NET Core Our monitoring of .NET Core-based AWS Lambda functions doesn't use our standard .NET Core APM agent. Instead, it uses a NuGet package. To instrument your .NET Core Lambda: In your Lambda Functions project, install the NewRelic.OpenTracing.AmazonLambda.Tracer NuGet package. Note: NewRelic.OpenTracing.AmazonLambda.Tracer depends on version 1.2.0+ of Amazon.Lambda.APIGatewayEvent NuGet package. If the environment already uses a lower version of Amazon.Lambda.APIGatewayEvent, the New Relic package may produce errors such as System.MissingMethodException . Import the NuGet package and OpenTracing utils: using OpenTracing.Util; using NewRelic.OpenTracing.AmazonLambda; Copy Instrument your function, as shown in this example: public class Function { static Function() { // Register The NewRelic Lambda Tracer Instance GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public object FunctionWrapper(ILambdaContext context) { // Instantiate NewRelic TracingWrapper and pass your FunctionHandler as // an argument return new TracingRequestHandler().LambdaWrapper(FunctionHandler, context); } /// <summary> /// A simple function that takes a string and does a ToUpper /// </summary> /// <param name=\"input\"></param> /// <param name=\"context\"></param> /// <returns></returns> public object FunctionHandler(ILambdaContext context) { ... } } Copy Tip The arguments passed to FunctionWrapper must match the signature of FunctionHandler. If your handler function returns a Task, the Lambda wrapper will block on the return task until it completes, so that it can measure the duration and capture exceptions, if any are present. In addition, you may also inherit from the APIGatewayProxyFunction. For an example, see below: Async handler function public async Task<int> FunctionHandlerAsync(ILambdaContext lambdaContext) { return await new TracingRequestHandler().LambdaWrapper( ActualFunctionHandlerAsync, lambdaContext); } public async Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(ILambdaContext lambdaContext) { // Function can make other async operations here ... } Copy Inheriting from APIGatewayProxyFunction public class LambdaFunction : APIGatewayProxyFunction { static LambdaFunction() { // Register The NewRelic Lambda Tracer Instance OpenTracing.Util.GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public override Task<APIGatewayProxyResponse> FunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { Task<APIGatewayProxyResponse> task = new TracingRequestHandler().LambdaWrapper(ActualFunctionHandlerAsync, request, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { return base.FunctionHandlerAsync(request, lambdaContext); } } Copy Optional for SQS and SNS: Starting in version 1.0 of our .NET Lambda Tracer, distributed tracing support has been added for SQS and SNS. To enable distributed tracing for SQS or SNS you will need to complete the items in this step as well as setup the environment variables in the step that follows this one. Important Enabling distributed tracing support for SQS and SNS will disable automatic instrumentation for both of SQS and SNS and require the use of these wrappers to instrument them. Set the NEW_RELIC_USE_DT_WRAPPER environment variable to true. To instrument SQS and SNS calls you will need to use the provided wrappers. Using the SQS Wrapper The SQS wrapper supports wrapping the following methods: Amazon.SQS.AmazonSQSClient.SendMessageAsync(...) Amazon.SQS.AmazonSQSClient.SendMessageBatchAsync(...) Examples // SQS Client AmazonSQSClient client = new AmazonSQSClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // SendMessageRequest SendMessageRequest sendRequest = new SendMessageRequest(\"QUEUE_URI_STRING\", \"An SQS Message\"); Task<SendMessageResponse> responseOne = SQSWrapper.WrapRequest(client.SendMessageAsync, sendRequest); // String-based Task<SendMessageResponse> responseTwo = SQSWrapper.WrapRequest(client.SendMessageAsync, \"QUEUE_URI_STRING\", \"Another SQS Message\"); // SendMessageBatchRequest List<SendMessageBatchRequestEntry> batchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id1\", \"First SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id2\", \"Second SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id3\", \"Third SQS Message\")); SendMessageBatchRequest sendBatchRequest = new SendMessageBatchRequest(QUEUE_URI, batchEntries); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, sendBatchRequest); // SendMessageBatchRequestEntry List List<SendMessageBatchRequestEntry> moreBatchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id4\", \"Fourth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id5\", \"Fifth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id6\", \"Sixth SQS Message\")); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, moreBatchEntries); Copy Using the SNS Wrapper The SNS wrapper supports wrapping the following methods: Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient.PublishAsync(...) Examples // SNS Client AmazonSimpleNotificationServiceClient client = new Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // PublishRequest - Phone Number PublishRequest phonePublishRequest = new PublishRequest(); phonePublishRequest.PhoneNumber = +1XXX5555100; phonePublishRequest.Message = \"An SNS Message for phones\"; Task<PublishResponse> phoneResponse = SNSWrapper.WrapRequest(client.PublishAsync, phonePublishRequest); // PublishRequest - ARN PublishRequest publishRequest = new PublishRequest(\"TOPIC_ARN\", \"An SNS Message\"); Task<PublishResponse> publishResponse = SNSWrapper.WrapRequest(client.PublishAsync, publishRequest); // String-based without subject Task<PublishResponse> ResponseOne = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Another SNS Message\"); // String-based with subject Task<PublishResponse> ResponseTwo = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Yet Another SNS Message\", \"A Subject\"); Copy The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS Lambda console: NEW_RELIC_ACCOUNT_ID: The account ID the Lambda is reporting to. NEW_RELIC_TRUSTED_ACCOUNT_KEY: This is also the account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Ensure that the wrapper function (FunctionWrapper in above example) is set up as the function handler. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Node.js To instrument your Node.js Lambda: Download our Node.js agent package and place it in the same directory as your function, ensuring the agent is installed as a dependency in the node_modules directory. Use the Node Package Manager: npm install newrelic --save Copy Install our AWS SDK module alongside the Node.js agent: npm install @newrelic/aws-sdk --save Copy In your Lambda code, require the agent module and the AWS SDK at the top of the file, and wrap the handler function. For example: const newrelic = require('newrelic'); require('@newrelic/aws-sdk'); // Other module loads go under the two require statements above module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { // This is your handler function code console.log('Lambda executed'); callback(); }); Copy Optional: You can also add custom events to your Lambda using the recordCustomEvent API. For example: module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { newrelic.recordCustomEvent(‘MyEventType’, {foo: ‘bar’}); console.log('Lambda executed'); callback(); }); Copy Zip your Lambda function and the Node.js agent folder together. Requirements and recommendations: The New Relic files outside the New Relic agent folder don't need to be included. If your Lambda function file name is, for example, lambda_function.node, we recommend naming your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set these environment variables: NEW_RELIC_NO_CONFIG_FILE. Set to true if not using a configuration file. NEW_RELIC_APP_NAME: Your application name. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Optional: To run the agent in serverless mode outside of AWS in a local environment, set the environment variable NEW_RELIC_SERVERLESS_MODE_ENABLED to true. (When executing this in an AWS Lambda environment, the agent will automatically run in serverless mode. Do not use this variable if you're running in AWS.) Optional: To enable logging in serverless mode, set these environment variables: Set NEW_RELIC_LOG_ENABLED to true. Set NEW_RELIC_LOG to stdout for output to CloudWatch, or set to any writeable file location. The log level is set to info by default. See other log levels. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Python To instrument your Python Lambda: Download our Python agent package and place it in the same directory as your function. To do this, use pip: pip install -t . newrelic Copy Important If you use Homebrew, you may get this error: DistutilsOptionError: must supply either home or prefix/exec-prefix -- not both. For details, see the Homebrew GitHub post. In your Lambda code, import the Python agent module and decorate the handler function using the New Relic decorator. The New Relic package must be imported first in your code. Here's an example: import newrelic.agent newrelic.agent.initialize() @newrelic.agent.lambda_handler() def handler(event, context): ... Copy Optional: You can also add custom events to your Lambda using the record_custom_event API. Here's an example: @newrelic.agent.lambda_handler() def handler(event, context): newrelic.agent.record_custom_event('CustomEvent', {'foo': 'bar'}) … Copy Zip your lambda_function.py and newrelic/ folder together using these guidelines: The New Relic files outside the newrelic/ folder don't need to be included. If your Lambda function file name is, for example, lambda_function.py, name your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set this environment variable: NEW_RELIC_SERVERLESS_MODE_ENABLED. Set to true The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED. Set to true. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Optional: To configure logging, use the NEW_RELIC_LOG and NEW_RELIC_LOG_LEVEL environment variables in the AWS Console. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. The New Relic decorator gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, configure CloudWatch to send those logs to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 477.8505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Zip and <em>upload</em> recommendations",
        "body": ", this needs to be the account ID for the root&#x2F;parent account. <em>Optional</em>: To configure logging, use the NEW_RELIC_<em>LOG</em> and NEW_RELIC_<em>LOG</em>_LEVEL environment variables in the <em>AWS</em> Console. Invoke the Lambda at least once. This creates a <em>CloudWatch</em> <em>log</em> group, which must be present for the next <em>step</em> to work"
      },
      "id": "603ebbcb64441f800a4e8850"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-aws-lambda-monitoring/",
      "sections": [
        "Enable monitoring for AWS Lambda"
      ],
      "published_at": "2021-09-02T16:42:38Z",
      "title": "Enable monitoring for AWS Lambda",
      "updated_at": "2021-08-26T04:49:50Z",
      "type": "docs",
      "external_id": "8a60acf499837668684b93945d3ce973d95fe347",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several steps to enabling Lambda monitoring: Link your AWS account. Optional: configure CloudWatch Log collection: if in Step 1, you used the newrelic-lambda CLI, that automatically installs the CloudWatch logs collector by default and you can skip this step. Instrument an example function. Instrument your functions. Optional: Set up alerts and custom events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 462.1508,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable monitoring for <em>AWS</em> Lambda",
        "sections": "Enable monitoring for <em>AWS</em> Lambda",
        "body": "There are several steps to enabling Lambda monitoring: Link your <em>AWS</em> account. <em>Optional</em>: configure <em>CloudWatch</em> <em>Log</em> <em>collection</em>: if in <em>Step</em> 1, you used the newrelic-lambda CLI, that automatically installs the <em>CloudWatch</em> logs collector by default and you can skip this <em>step</em>. Instrument an example function. Instrument your functions. <em>Optional</em>: <em>Set</em> <em>up</em> alerts and custom events."
      },
      "id": "61271d6e196a677c0b00b320"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/update-serverless-monitoring-aws-lambda/",
      "sections": [
        "Update Lambda monitoring",
        "Important",
        "Update our Lambda integration via CLI",
        "Update layers via CLI",
        "Update a manual Serverless application repository install",
        "Enabling log management",
        "Caution"
      ],
      "published_at": "2021-09-02T16:45:41Z",
      "title": "Update Lambda monitoring",
      "updated_at": "2021-08-27T08:21:04Z",
      "type": "docs",
      "external_id": "7075499bcc9b1ff1e346a705ab414adcca54fd09",
      "document_type": "page",
      "popularity": 1,
      "body": "After enabling our monitoring for AWS Lambda, you should occasionally update our Lambda function that's used to report AWS log data: newrelic-log-ingestion. There are two ways to do this: Update via CLI: Use this if you enabled our Lambda monitoring using our CLI tool. Update via AWS Serverless Application Repository: Use this if you enabled using the manual procedure. Important These update procedures apply to our serverless monitoring for AWS Lambda, and not to our infrastructure monitoring for AWS Lambda integration. Update our Lambda integration via CLI This section describes how to update if your Lambda monitoring was enabled using our recommended CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region identifier (for example, us-west-2). newrelic-lambda integrations update \\ --aws-region YOUR_REGION Copy If you do not have our logs enabled, you'll also need to update your Amazon CloudWatch log subscription filters with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --aws-region YOUR_REGION Copy Update layers via CLI This section describes how to update your function's Layer if you installed it with our CLI tool. Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy Pass the --upgrade flag to the install command: newrelic-lambda layers install \\ --function installed \\ --nr-account-id NR_ACCOUNT_ID \\ --upgrade Copy Update a manual Serverless application repository install If you manually installed the ingest function from the AWS Serverless Application Repository (and didn't use the CLI), update using this procedure: Run the following, replacing YOUR_REGION with your region (for example, us-west-2). aws serverlessrepo create-cloud-formation-change-set \\ --application-id arn:aws:serverlessrepo:us-east-1:463657938898:applications/NewRelic-log-ingestion \\ --stack-name NewRelic-log-ingestion \\ --capabilities CAPABILITY_RESOURCE_POLICY \\ --region YOUR_REGION Copy This command outputs several fields, one of which is the ChangeSetId: an ARN for the change set that you just created. Copy that ARN. Use the ARN in this command, which executes the change set: aws cloudformation execute-change-set --change-set-name YOUR_CHANGE_SET_ARN Copy Enabling log management If you currently don't have New Relic's log management enabled, but would like to: Make sure you have the latest version of the CLI: pip install --upgrade newrelic-lambda-cli Copy For each region in which you've installed the newrelic-log-ingestion function, run the following command, replacing YOUR_REGION with your region (for example, us-west-2). newrelic-lambda integrations update \\ --enable-logs \\ --aws-region YOUR_REGION Copy Then do either of the following: Update your Amazon CloudWatch log subscription filters for each region with the following command: newrelic-lambda subscriptions install \\ --function installed \\ --filter-pattern \"\" \\ --aws-region YOUR_REGION Copy Or, you can send function logs to New Relic directly, bypassing CloudWatch and the newrelic-log-ingestion Lambda. To do this, set the environment variable NEW_RELIC_EXTENSION_SEND_FUNCTION_LOGS=true in your Lambda function configuration. After that, be sure to remove any existing New Relic log subscriptions for that function using this command: newrelic-lambda subscriptions uninstall \\ --function FUNCTION_NAME \\ --aws-region YOUR_REGION Copy If the log subscription is present while the extension is sending logs, logs will be sent twice, resulting in duplicate log records in New Relic. Optionally, if you'd like to avoid Amazon's charges for CloudWatch Log ingestion, you can also modify your function's execution role so that it doesn't grant the CloudWatch Log permissions. This will prevent your function from logging to CloudWatch. Caution CloudWatch Logs ingest fees can be considerable, but this step should be taken with caution. Make sure your New Relic log ingestion integration is working well and meeting your needs before disabling CloudWatch logs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 346.33035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Update</em> Lambda monitoring",
        "sections": "<em>Update</em> Lambda monitoring",
        "body": " with your region identifier (for example, us-west-<em>2</em>). newrelic-lambda integrations update \\ --<em>aws</em>-region YOUR_REGION Copy If you do not have our logs enabled, you&#x27;ll also need to update your Amazon <em>CloudWatch</em> <em>log</em> subscription filters with the following command: newrelic-lambda subscriptions install"
      },
      "id": "6045248c28ccbc98a82c606b"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/update-serverless-monitoring-aws-lambda": [
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-09-02T16:45:40Z",
      "updated_at": "2021-09-02T16:45:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.470825,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements of AWS <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility and requirements of AWS <em>Lambda</em> <em>monitoring</em>",
        "tags": "AWS <em>Lambda</em> <em>monitoring</em>",
        "body": "Before enabling serverless <em>monitoring</em> for AWS <em>Lambda</em>, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS <em>Lambda</em> language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy/",
      "sections": [
        "Legacy manual instrumentation for Lambda monitoring",
        "Go",
        "Zip and upload recommendations",
        "Java",
        "Tip",
        ".NET Core",
        "Async handler function",
        "Inheriting from APIGatewayProxyFunction",
        "Important",
        "Using the SQS Wrapper",
        "Using the SNS Wrapper",
        "Node.js",
        "Python"
      ],
      "published_at": "2021-09-02T16:43:44Z",
      "title": "Legacy manual instrumentation for Lambda monitoring",
      "updated_at": "2021-09-02T16:43:44Z",
      "type": "docs",
      "external_id": "694e22b2ce401a96d200ab2e12a08850532b3e5a",
      "document_type": "page",
      "popularity": 1,
      "body": "On this page, you will learn how to manually instrument your lambda function. It's organized by runtime language. Go To instrument your Go-language Lambda: Download our Go agent package and place it in the same directory as your function. Install the agent: go get -u github.com/newrelic/go-agent/v3/newrelic. Install the nrlambda integration go get -u github.com/newrelic/go-agent/v3/integrations/nrlambda. In your Lambda code, import our components, create an application, and update how you start your Lambda. See our GitHub repo for an example of an instrumented Lambda. Optional: Add custom events that will be associated with your Lambda invocation by using the RecordCustomEvent API. For example: func handler(ctx context.Context) { if txn := newrelic.FromContext(ctx); nil != txn { txn.Application().RecordCustomEvent(\"MyEvent\", map[string]interface{}{ \"zip\": \"zap\", }) } fmt.Println(\"hello world!\") } Copy Build and zip your Lambda function and upload it to AWS. Zip and upload recommendations Here are suggestions for zipping and uploading the Lambda: Build the binary for execution on Linux. This produces a binary file called main. You can use: $ GOOS=linux go build -o main Copy Zip the binary into a deployment package using: $ zip deployment.zip main Copy Upload the zip file to AWS using either the AWS Lambda console or the AWS CLI. Name the handler main (to match the name given during the binary build). The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this is the account ID for the root/parent account. Optional: To configure logging, see Go agent logging. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Java Monitoring for AWS Lambda in Java doesn't use our APM Java agent. Instead, it uses these two OpenTracing dependencies: AWS Lambda OpenTracing Java SDK: OpenTracing instrumentation for AWS Lambda RequestHandler and RequestStreamHandler. Our AWS Lambda OpenTracing Tracer: An OpenTracing Tracer implementation designed to monitor AWS Lambda. It generates spans, error events, transaction events, error traces, and provides distributed tracing support. Tip Supported OpenTracing Versions OpenTracing 0.31.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:1.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:1.0.0 OpenTracing 0.32.0, 0.33.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:2.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:2.1.0 To instrument your Java Lambda: In your project’s build.gradle file, include our OpenTracing AWS Lambda Tracer and the AWS Lambda OpenTracing SDK dependencies: dependencies { compile(\"com.newrelic.opentracing:java-aws-lambda:2.1.0\") compile(\"com.newrelic.opentracing:newrelic-java-lambda:2.1.1\") compile(\"io.opentracing:opentracing-util:0.33.0\") } Copy Implement the AWS Lambda RequestHandler interface as shown in the Java Lambda example and override the doHandleRequest method. In the doHandleRequest method, call the LambdaTracing.instrument(...) API to create a root span to trace the lambda function's execution. This is also where you will define your business logic for the lambda function. Register a LambdaTracer.INSTANCE as the OpenTracing Global tracer, as shown in the Java Lambda example. Create a ZIP deployment package and upload it to AWS Lambda. Or deploy it via other means. In the AWS Lambda console, set the handler. For the example Java Lambda, the handler would be com.handler.example.MyLambdaHandler::handleRequest. Because handleRequest is assumed, you could also use com.handler.example.MyLambdaHandler. The following AWS console environment variables are required if you want your Lambda function to be included in distributed tracing. This is recommended. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_PRIMARY_APPLICATION_ID. This is also your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this must be the account ID for the root/parent account. Optional: In the Lambda console, enable debug logging by adding this environment variable: NEW_RELIC_DEBUG is true. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Please see the AWS Lambda distributed tracing example for a complete project that illustrates common use cases such as: Distributed tracing between Lambda functions Manual span creation (aka custom instrumentation) Tracing external calls Adding custom attributes (aka Tags) to spans .NET Core Our monitoring of .NET Core-based AWS Lambda functions doesn't use our standard .NET Core APM agent. Instead, it uses a NuGet package. To instrument your .NET Core Lambda: In your Lambda Functions project, install the NewRelic.OpenTracing.AmazonLambda.Tracer NuGet package. Note: NewRelic.OpenTracing.AmazonLambda.Tracer depends on version 1.2.0+ of Amazon.Lambda.APIGatewayEvent NuGet package. If the environment already uses a lower version of Amazon.Lambda.APIGatewayEvent, the New Relic package may produce errors such as System.MissingMethodException . Import the NuGet package and OpenTracing utils: using OpenTracing.Util; using NewRelic.OpenTracing.AmazonLambda; Copy Instrument your function, as shown in this example: public class Function { static Function() { // Register The NewRelic Lambda Tracer Instance GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public object FunctionWrapper(ILambdaContext context) { // Instantiate NewRelic TracingWrapper and pass your FunctionHandler as // an argument return new TracingRequestHandler().LambdaWrapper(FunctionHandler, context); } /// <summary> /// A simple function that takes a string and does a ToUpper /// </summary> /// <param name=\"input\"></param> /// <param name=\"context\"></param> /// <returns></returns> public object FunctionHandler(ILambdaContext context) { ... } } Copy Tip The arguments passed to FunctionWrapper must match the signature of FunctionHandler. If your handler function returns a Task, the Lambda wrapper will block on the return task until it completes, so that it can measure the duration and capture exceptions, if any are present. In addition, you may also inherit from the APIGatewayProxyFunction. For an example, see below: Async handler function public async Task<int> FunctionHandlerAsync(ILambdaContext lambdaContext) { return await new TracingRequestHandler().LambdaWrapper( ActualFunctionHandlerAsync, lambdaContext); } public async Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(ILambdaContext lambdaContext) { // Function can make other async operations here ... } Copy Inheriting from APIGatewayProxyFunction public class LambdaFunction : APIGatewayProxyFunction { static LambdaFunction() { // Register The NewRelic Lambda Tracer Instance OpenTracing.Util.GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public override Task<APIGatewayProxyResponse> FunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { Task<APIGatewayProxyResponse> task = new TracingRequestHandler().LambdaWrapper(ActualFunctionHandlerAsync, request, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { return base.FunctionHandlerAsync(request, lambdaContext); } } Copy Optional for SQS and SNS: Starting in version 1.0 of our .NET Lambda Tracer, distributed tracing support has been added for SQS and SNS. To enable distributed tracing for SQS or SNS you will need to complete the items in this step as well as setup the environment variables in the step that follows this one. Important Enabling distributed tracing support for SQS and SNS will disable automatic instrumentation for both of SQS and SNS and require the use of these wrappers to instrument them. Set the NEW_RELIC_USE_DT_WRAPPER environment variable to true. To instrument SQS and SNS calls you will need to use the provided wrappers. Using the SQS Wrapper The SQS wrapper supports wrapping the following methods: Amazon.SQS.AmazonSQSClient.SendMessageAsync(...) Amazon.SQS.AmazonSQSClient.SendMessageBatchAsync(...) Examples // SQS Client AmazonSQSClient client = new AmazonSQSClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // SendMessageRequest SendMessageRequest sendRequest = new SendMessageRequest(\"QUEUE_URI_STRING\", \"An SQS Message\"); Task<SendMessageResponse> responseOne = SQSWrapper.WrapRequest(client.SendMessageAsync, sendRequest); // String-based Task<SendMessageResponse> responseTwo = SQSWrapper.WrapRequest(client.SendMessageAsync, \"QUEUE_URI_STRING\", \"Another SQS Message\"); // SendMessageBatchRequest List<SendMessageBatchRequestEntry> batchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id1\", \"First SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id2\", \"Second SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id3\", \"Third SQS Message\")); SendMessageBatchRequest sendBatchRequest = new SendMessageBatchRequest(QUEUE_URI, batchEntries); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, sendBatchRequest); // SendMessageBatchRequestEntry List List<SendMessageBatchRequestEntry> moreBatchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id4\", \"Fourth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id5\", \"Fifth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id6\", \"Sixth SQS Message\")); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, moreBatchEntries); Copy Using the SNS Wrapper The SNS wrapper supports wrapping the following methods: Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient.PublishAsync(...) Examples // SNS Client AmazonSimpleNotificationServiceClient client = new Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // PublishRequest - Phone Number PublishRequest phonePublishRequest = new PublishRequest(); phonePublishRequest.PhoneNumber = +1XXX5555100; phonePublishRequest.Message = \"An SNS Message for phones\"; Task<PublishResponse> phoneResponse = SNSWrapper.WrapRequest(client.PublishAsync, phonePublishRequest); // PublishRequest - ARN PublishRequest publishRequest = new PublishRequest(\"TOPIC_ARN\", \"An SNS Message\"); Task<PublishResponse> publishResponse = SNSWrapper.WrapRequest(client.PublishAsync, publishRequest); // String-based without subject Task<PublishResponse> ResponseOne = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Another SNS Message\"); // String-based with subject Task<PublishResponse> ResponseTwo = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Yet Another SNS Message\", \"A Subject\"); Copy The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS Lambda console: NEW_RELIC_ACCOUNT_ID: The account ID the Lambda is reporting to. NEW_RELIC_TRUSTED_ACCOUNT_KEY: This is also the account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Ensure that the wrapper function (FunctionWrapper in above example) is set up as the function handler. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Node.js To instrument your Node.js Lambda: Download our Node.js agent package and place it in the same directory as your function, ensuring the agent is installed as a dependency in the node_modules directory. Use the Node Package Manager: npm install newrelic --save Copy Install our AWS SDK module alongside the Node.js agent: npm install @newrelic/aws-sdk --save Copy In your Lambda code, require the agent module and the AWS SDK at the top of the file, and wrap the handler function. For example: const newrelic = require('newrelic'); require('@newrelic/aws-sdk'); // Other module loads go under the two require statements above module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { // This is your handler function code console.log('Lambda executed'); callback(); }); Copy Optional: You can also add custom events to your Lambda using the recordCustomEvent API. For example: module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { newrelic.recordCustomEvent(‘MyEventType’, {foo: ‘bar’}); console.log('Lambda executed'); callback(); }); Copy Zip your Lambda function and the Node.js agent folder together. Requirements and recommendations: The New Relic files outside the New Relic agent folder don't need to be included. If your Lambda function file name is, for example, lambda_function.node, we recommend naming your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set these environment variables: NEW_RELIC_NO_CONFIG_FILE. Set to true if not using a configuration file. NEW_RELIC_APP_NAME: Your application name. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Optional: To run the agent in serverless mode outside of AWS in a local environment, set the environment variable NEW_RELIC_SERVERLESS_MODE_ENABLED to true. (When executing this in an AWS Lambda environment, the agent will automatically run in serverless mode. Do not use this variable if you're running in AWS.) Optional: To enable logging in serverless mode, set these environment variables: Set NEW_RELIC_LOG_ENABLED to true. Set NEW_RELIC_LOG to stdout for output to CloudWatch, or set to any writeable file location. The log level is set to info by default. See other log levels. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Python To instrument your Python Lambda: Download our Python agent package and place it in the same directory as your function. To do this, use pip: pip install -t . newrelic Copy Important If you use Homebrew, you may get this error: DistutilsOptionError: must supply either home or prefix/exec-prefix -- not both. For details, see the Homebrew GitHub post. In your Lambda code, import the Python agent module and decorate the handler function using the New Relic decorator. The New Relic package must be imported first in your code. Here's an example: import newrelic.agent newrelic.agent.initialize() @newrelic.agent.lambda_handler() def handler(event, context): ... Copy Optional: You can also add custom events to your Lambda using the record_custom_event API. Here's an example: @newrelic.agent.lambda_handler() def handler(event, context): newrelic.agent.record_custom_event('CustomEvent', {'foo': 'bar'}) … Copy Zip your lambda_function.py and newrelic/ folder together using these guidelines: The New Relic files outside the newrelic/ folder don't need to be included. If your Lambda function file name is, for example, lambda_function.py, name your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set this environment variable: NEW_RELIC_SERVERLESS_MODE_ENABLED. Set to true The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED. Set to true. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Optional: To configure logging, use the NEW_RELIC_LOG and NEW_RELIC_LOG_LEVEL environment variables in the AWS Console. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. The New Relic decorator gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, configure CloudWatch to send those logs to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.08534,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Legacy manual instrumentation for <em>Lambda</em> <em>monitoring</em>",
        "sections": "Legacy manual instrumentation for <em>Lambda</em> <em>monitoring</em>",
        "body": "&#x2F;newrelic. Install the nrlambda integration go get -u github.com&#x2F;newrelic&#x2F;go-agent&#x2F;v3&#x2F;integrations&#x2F;nrlambda. In your <em>Lambda</em> code, import our components, create an application, and <em>update</em> how you start your <em>Lambda</em>. See our GitHub repo for an example of an instrumented <em>Lambda</em>. Optional: Add custom"
      },
      "id": "603ebbcb64441f800a4e8850"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "sections": [
        "Step 4: Instrument your own Lambda functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "published_at": "2021-09-02T16:43:44Z",
      "title": "Step 4: Instrument your own Lambda functions",
      "updated_at": "2021-08-27T07:52:48Z",
      "type": "docs",
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "document_type": "page",
      "popularity": 1,
      "body": "This is one step of enabling New Relic's AWS Lambda monitoring. Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions and choose Stream to AWS Lambda. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.86286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Step 4: Instrument your own <em>Lambda</em> functions",
        "sections": "Step 4: Instrument your own <em>Lambda</em> functions",
        "body": "This is one step of enabling New Relic&#x27;s AWS <em>Lambda</em> <em>monitoring</em>. Important Because there are several steps to integration, it&#x27;s important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different"
      },
      "id": "605aa8a064441f453b868bb9"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/architecture": [
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-09-02T16:45:40Z",
      "updated_at": "2021-09-02T16:45:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.77597,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Before enabling <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, make sure you meet the requirements and learn about <em>AWS</em> charges resulting from its use. Recommended <em>AWS</em> <em>Lambda</em> language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "sections": [
        "Monitoring AWS Lambda with Serverless monitoring",
        "Why it matters",
        "Access and requirements",
        "Next steps: Enable and use Lambda monitoring"
      ],
      "title": "Monitoring AWS Lambda with Serverless monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "5d1d86ec786398b3190ed1a6e152373e0547dc57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring/",
      "published_at": "2021-09-02T16:45:40Z",
      "updated_at": "2021-07-27T18:00:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer in-depth performance monitoring for your serverless AWS Lambda functions. Read on to learn about the feature, how it works, and its requirements. This Lambda monitoring feature is not the same as the Lambda monitoring integration, which only uses CloudWatch data. Serverless Lambda monitoring is more extensive and uses both CloudWatch data and code-level instrumentation to deliver more in-depth monitoring. Why it matters Do you need to rapidly instrument monitoring and observability to your serverless functions without resorting to code changes? Our Lambda layer provides unified visibility into the most detailed behaviors of your Lambda functions so you can understand what's going on in your serverless applications. Use all this information to troubleshoot your systems and optimize your functions so they can function faster and deliver with confidence on serverless architectures. Spend less time instrumenting, and more time building. Lambda monitoring gives you: Every invocation of your Lambda functions, including performance data like detailed duration, cold starts, exceptions, and tracebacks. AWS Lambda event source information, which provides context and attributes about events that triggered each AWS Lambda invocation, such as API Gateway, ALB SNS, SQS, DynamoDB, and more. Visibility into your entire ecosystem with distributed tracing: see the path of requests that led to your Lambda, and see Lambda spans in your other distributed traces. Logs in context, which provides full invocation and function level logs right along side the metrics, attributes, and trace data. Inventoried tags and metadata. We retrieve information from your AWS entities, giving you the ability to filter and facet down to the team, or specific metadata attributes on the function configuration or invocation itself. Easy ability to query your data with an automatic facet builder, which instantly facets your dashboards and charts by attribute or function to explore custom data, without having to write queries. Lambda data is displayed in its own dedicated UI in New Relic One. Access and requirements See Compatibility and requirements of AWS Lambda monitoring. Next steps: Enable and use Lambda monitoring To get started using our Lambda monitoring, see the installation and enablement instructions. You can also set up alerts or add your own custom events or attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.6796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "sections": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "We offer in-depth performance <em>monitoring</em> for your <em>serverless</em> <em>AWS</em> <em>Lambda</em> functions. Read on to learn about the feature, how it works, and its requirements. This <em>Lambda</em> <em>monitoring</em> feature is not the same as the <em>Lambda</em> <em>monitoring</em> integration, which only uses CloudWatch data. <em>Serverless</em> <em>Lambda</em>"
      },
      "id": "603eb08b28ccbc8b90eba75c"
    },
    {
      "sections": [
        "Troubleshoot enabling serverless monitoring of AWS Lambda",
        "Problem",
        "Solution",
        "Recommended: Attach your CloudWatch logs to the ticket",
        "Important"
      ],
      "title": "Troubleshoot enabling serverless monitoring of AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Troubleshooting"
      ],
      "external_id": "73f864add78be5efb2429485506dc5a679a9820e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/troubleshooting/troubleshoot-enabling-serverless-monitoring-aws-lambda/",
      "published_at": "2021-09-02T16:47:47Z",
      "updated_at": "2021-03-16T18:38:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You’re attempting to enable serverless monitoring for AWS Lambda and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the AWS integration step wasn't completed. Not seeing data on Troubleshooting category UI pages. If you aren't seeing data on the Distributed tracing, Errors, and Invocations UI tabs, this means the APM agent instrumentation step wasn't completed. Besides these basic enablement problems, there are some additional problems that may cause an issue: CloudWatch error \"HTTP error 401: unauthorized.\" This is due to an incorrect API Key. The --nr-api-keyargument in the Configure AWS enable step takes your user key, which is different from the REST API key. Custom metrics are missing. Lambda monitoring is not compatible with our custom metrics. Use custom attributes to add metadata. Invocations missing. To see invocation breakdown details, distributed tracing must be enabled as part of the Lambda instrumentation step. Distributed tracing is required so that span details can be displayed in the invocation details pane. You've completed the installation, integration, and instrumentation steps correctly, and your function is sending logs to CloudWatch but you're not seeing traces for specific dependencies (or any traces) in the UI. This may result from the order of layer merging (if you're using our Lambda layers) or from the order of import (if you're instrumenting manually): If you're instrumenting with layers: make sure in your function configuration that the New Relic layer is merged before other layers (though if your function uses webpack, the New Relic layer should be merged after the webpack layer). If you're instrumenting a Node function manually, make sure that your function imports newrelic and @newrelic/aws-sdk before it imports any dependencies you expect to monitor. If none of these solutions help you, contact our support team. The following information will help you when you talk to support technicians: Has the Lambda function appeared in the UI before? If so, what is the name of the function? If some data for the Lambda function is appearing in the UI, what specific data is appearing? What APM language agent are you using to instrument the function? Recommended: Attach your CloudWatch logs to the ticket To provide our support team with logging information when opening a ticket: Invoke the function in AWS Lambda. Click on the logs link after your function runs. This will take you to the CloudWatch logs in AWS. On the left-hand sidebar in AWS, under Logs, click on Insights. Select your function and also the newrelic-log-ingestion stream. Apply an appropriate Time Filter, and a log entry limit (the default of 20 may not be enough). Under Actions select Copy query results (ASCII). Paste the copied text into a new text file, then save and upload the text file to the ticket. Important The NR_LAMBDA_MONITORING payload contains all the information the agent attempts to send up, including metrics, events, some AWS account metadata, invocations and errors data. Note that some of that data (for example, our legacy metrics) will not make it to our UI because our ingest pipeline does not consume them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.50333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot enabling <em>serverless</em> <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "sections": "Troubleshoot enabling <em>serverless</em> <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Problem You’re attempting to enable <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the <em>AWS</em> integration step wasn&#x27;t"
      },
      "id": "603ea6bb64441f85284e889b"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring": [
    {
      "sections": [
        "Monitoring AWS Lambda with Serverless monitoring",
        "Why it matters",
        "Access and requirements",
        "Next steps: Enable and use Lambda monitoring"
      ],
      "title": "Monitoring AWS Lambda with Serverless monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "5d1d86ec786398b3190ed1a6e152373e0547dc57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring/",
      "published_at": "2021-09-02T16:45:40Z",
      "updated_at": "2021-07-27T18:00:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer in-depth performance monitoring for your serverless AWS Lambda functions. Read on to learn about the feature, how it works, and its requirements. This Lambda monitoring feature is not the same as the Lambda monitoring integration, which only uses CloudWatch data. Serverless Lambda monitoring is more extensive and uses both CloudWatch data and code-level instrumentation to deliver more in-depth monitoring. Why it matters Do you need to rapidly instrument monitoring and observability to your serverless functions without resorting to code changes? Our Lambda layer provides unified visibility into the most detailed behaviors of your Lambda functions so you can understand what's going on in your serverless applications. Use all this information to troubleshoot your systems and optimize your functions so they can function faster and deliver with confidence on serverless architectures. Spend less time instrumenting, and more time building. Lambda monitoring gives you: Every invocation of your Lambda functions, including performance data like detailed duration, cold starts, exceptions, and tracebacks. AWS Lambda event source information, which provides context and attributes about events that triggered each AWS Lambda invocation, such as API Gateway, ALB SNS, SQS, DynamoDB, and more. Visibility into your entire ecosystem with distributed tracing: see the path of requests that led to your Lambda, and see Lambda spans in your other distributed traces. Logs in context, which provides full invocation and function level logs right along side the metrics, attributes, and trace data. Inventoried tags and metadata. We retrieve information from your AWS entities, giving you the ability to filter and facet down to the team, or specific metadata attributes on the function configuration or invocation itself. Easy ability to query your data with an automatic facet builder, which instantly facets your dashboards and charts by attribute or function to explore custom data, without having to write queries. Lambda data is displayed in its own dedicated UI in New Relic One. Access and requirements See Compatibility and requirements of AWS Lambda monitoring. Next steps: Enable and use Lambda monitoring To get started using our Lambda monitoring, see the installation and enablement instructions. You can also set up alerts or add your own custom events or attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.03934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "sections": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " and requirements See Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>. Next steps: Enable and use <em>Lambda</em> <em>monitoring</em> To <em>get</em> <em>started</em> using our <em>Lambda</em> <em>monitoring</em>, see the installation and enablement instructions. You can also set up alerts or add your own custom events or attributes."
      },
      "id": "603eb08b28ccbc8b90eba75c"
    },
    {
      "sections": [
        "Troubleshoot enabling serverless monitoring of AWS Lambda",
        "Problem",
        "Solution",
        "Recommended: Attach your CloudWatch logs to the ticket",
        "Important"
      ],
      "title": "Troubleshoot enabling serverless monitoring of AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Troubleshooting"
      ],
      "external_id": "73f864add78be5efb2429485506dc5a679a9820e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/troubleshooting/troubleshoot-enabling-serverless-monitoring-aws-lambda/",
      "published_at": "2021-09-02T16:47:47Z",
      "updated_at": "2021-03-16T18:38:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You’re attempting to enable serverless monitoring for AWS Lambda and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the AWS integration step wasn't completed. Not seeing data on Troubleshooting category UI pages. If you aren't seeing data on the Distributed tracing, Errors, and Invocations UI tabs, this means the APM agent instrumentation step wasn't completed. Besides these basic enablement problems, there are some additional problems that may cause an issue: CloudWatch error \"HTTP error 401: unauthorized.\" This is due to an incorrect API Key. The --nr-api-keyargument in the Configure AWS enable step takes your user key, which is different from the REST API key. Custom metrics are missing. Lambda monitoring is not compatible with our custom metrics. Use custom attributes to add metadata. Invocations missing. To see invocation breakdown details, distributed tracing must be enabled as part of the Lambda instrumentation step. Distributed tracing is required so that span details can be displayed in the invocation details pane. You've completed the installation, integration, and instrumentation steps correctly, and your function is sending logs to CloudWatch but you're not seeing traces for specific dependencies (or any traces) in the UI. This may result from the order of layer merging (if you're using our Lambda layers) or from the order of import (if you're instrumenting manually): If you're instrumenting with layers: make sure in your function configuration that the New Relic layer is merged before other layers (though if your function uses webpack, the New Relic layer should be merged after the webpack layer). If you're instrumenting a Node function manually, make sure that your function imports newrelic and @newrelic/aws-sdk before it imports any dependencies you expect to monitor. If none of these solutions help you, contact our support team. The following information will help you when you talk to support technicians: Has the Lambda function appeared in the UI before? If so, what is the name of the function? If some data for the Lambda function is appearing in the UI, what specific data is appearing? What APM language agent are you using to instrument the function? Recommended: Attach your CloudWatch logs to the ticket To provide our support team with logging information when opening a ticket: Invoke the function in AWS Lambda. Click on the logs link after your function runs. This will take you to the CloudWatch logs in AWS. On the left-hand sidebar in AWS, under Logs, click on Insights. Select your function and also the newrelic-log-ingestion stream. Apply an appropriate Time Filter, and a log entry limit (the default of 20 may not be enough). Under Actions select Copy query results (ASCII). Paste the copied text into a new text file, then save and upload the text file to the ticket. Important The NR_LAMBDA_MONITORING payload contains all the information the agent attempts to send up, including metrics, events, some AWS account metadata, invocations and errors data. Note that some of that data (for example, our legacy metrics) will not make it to our UI because our ingest pipeline does not consume them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.88217,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot enabling <em>serverless</em> <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "sections": "Troubleshoot enabling <em>serverless</em> <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Problem You’re attempting to enable <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the <em>AWS</em> integration step wasn&#x27;t"
      },
      "id": "603ea6bb64441f85284e889b"
    },
    {
      "sections": [
        "Understand the Lambda monitoring UI",
        "View your data",
        "Important",
        "UI pages",
        "Understand chart data",
        "For more help"
      ],
      "title": "Understand the Lambda monitoring UI",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "UI and data"
      ],
      "external_id": "45a6a881de05bcb4814f7f25f2bfa1632257a7f1",
      "image": "https://docs.newrelic.com/static/17e88e0171bc6b4358292daf4ddf7cf4/c1b63/new-relic-lambda-entities-screenshot_0.png",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/ui-data/understand-lambda-monitoring-ui/",
      "published_at": "2021-09-02T16:46:42Z",
      "updated_at": "2021-03-30T19:47:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Serverless monitoring for AWS Lambda offers in-depth performance monitoring for your Lambda functions. This document explains how to: Find your Lambda data in the UI Understand the UI components Understand your chart data How to create custom charts View your data one.newrelic.com> Explorer > Amazon Web Services > Lambda functions: Click Lambda functions to see charts and details. To view your Lambda data in New Relic: Go to one.newrelic.com, click Explorer. In the left nav under Amazon Web Services, click Lambda functions. For more about our UI, see Intro to New Relic One. Important If you can't find your Lambda data: Ensure you've followed the instructions for enabling Lambda monitoring. Note that this feature is different from our infrastructure monitoring Lambda integration. UI pages Here are descriptions of the UI pages available for our Lambda monitoring: UI page Functionality Summary The Summary page displays charts that give you a quick view into the most important performance data. If available, this will feature data gathered from APM agent instrumentation. CloudWatch metrics The CloudWatch metrics page displays Lambda data that comes from AWS CloudWatch. Charts include: invocation counts, duration, throttles, and error counts. Distributed tracing The Distributed tracing page shows distributed traces that include the monitored Lambda function. For details about this feature, see Distributed tracing. Errors The Errors page displays errors (AwsLambdaInvocationError events). You can filter by error rate, error percentage, or error class. You can drill down into errors and see attributes and, if available, stack traces. Invocations The Invocations page lets you filter your invocations by attribute, and view duration, throughput, external calls, and invocation breakdowns. About invocation breakdowns: Some invocations will generate a breakdown if distributed tracing is enabled during instrumentation. Breakdowns are sampled; approximately 10% of invocations generate a breakdown. This sampling rate may be higher, depending on upstream sampling decisions. Logs The Logs page displays recent log messages from your Lambda function. For details about this feature, see Logs. Understand chart data Lambda data charts are generated by running NRQL queries of Lambda-related event data. Reasons to view a chart's NRQL query include: To better understand what a chart is displaying To get ideas on how to create a custom NRQL query and chart Related documentation: Learn how to view a chart's query. Learn about Lambda data storage and structure. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.52324,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand the <em>Lambda</em> <em>monitoring</em> UI",
        "sections": "Understand the <em>Lambda</em> <em>monitoring</em> UI",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "<em>Serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> offers in-depth performance <em>monitoring</em> for your <em>Lambda</em> functions. This document explains how to: Find your <em>Lambda</em> data in the UI Understand the UI components Understand your chart data How to create custom charts View your data one.newrelic.com&gt; Explorer"
      },
      "id": "603eb10f196a67c65da83da2"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring": [
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-09-02T16:45:40Z",
      "updated_at": "2021-09-02T16:45:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 345.26917,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Before enabling <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, make sure you meet the requirements and learn about <em>AWS</em> charges resulting from its use. Recommended <em>AWS</em> <em>Lambda</em> language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "sections": [
        "Troubleshoot enabling serverless monitoring of AWS Lambda",
        "Problem",
        "Solution",
        "Recommended: Attach your CloudWatch logs to the ticket",
        "Important"
      ],
      "title": "Troubleshoot enabling serverless monitoring of AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Troubleshooting"
      ],
      "external_id": "73f864add78be5efb2429485506dc5a679a9820e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/troubleshooting/troubleshoot-enabling-serverless-monitoring-aws-lambda/",
      "published_at": "2021-09-02T16:47:47Z",
      "updated_at": "2021-03-16T18:38:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You’re attempting to enable serverless monitoring for AWS Lambda and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the AWS integration step wasn't completed. Not seeing data on Troubleshooting category UI pages. If you aren't seeing data on the Distributed tracing, Errors, and Invocations UI tabs, this means the APM agent instrumentation step wasn't completed. Besides these basic enablement problems, there are some additional problems that may cause an issue: CloudWatch error \"HTTP error 401: unauthorized.\" This is due to an incorrect API Key. The --nr-api-keyargument in the Configure AWS enable step takes your user key, which is different from the REST API key. Custom metrics are missing. Lambda monitoring is not compatible with our custom metrics. Use custom attributes to add metadata. Invocations missing. To see invocation breakdown details, distributed tracing must be enabled as part of the Lambda instrumentation step. Distributed tracing is required so that span details can be displayed in the invocation details pane. You've completed the installation, integration, and instrumentation steps correctly, and your function is sending logs to CloudWatch but you're not seeing traces for specific dependencies (or any traces) in the UI. This may result from the order of layer merging (if you're using our Lambda layers) or from the order of import (if you're instrumenting manually): If you're instrumenting with layers: make sure in your function configuration that the New Relic layer is merged before other layers (though if your function uses webpack, the New Relic layer should be merged after the webpack layer). If you're instrumenting a Node function manually, make sure that your function imports newrelic and @newrelic/aws-sdk before it imports any dependencies you expect to monitor. If none of these solutions help you, contact our support team. The following information will help you when you talk to support technicians: Has the Lambda function appeared in the UI before? If so, what is the name of the function? If some data for the Lambda function is appearing in the UI, what specific data is appearing? What APM language agent are you using to instrument the function? Recommended: Attach your CloudWatch logs to the ticket To provide our support team with logging information when opening a ticket: Invoke the function in AWS Lambda. Click on the logs link after your function runs. This will take you to the CloudWatch logs in AWS. On the left-hand sidebar in AWS, under Logs, click on Insights. Select your function and also the newrelic-log-ingestion stream. Apply an appropriate Time Filter, and a log entry limit (the default of 20 may not be enough). Under Actions select Copy query results (ASCII). Paste the copied text into a new text file, then save and upload the text file to the ticket. Important The NR_LAMBDA_MONITORING payload contains all the information the agent attempts to send up, including metrics, events, some AWS account metadata, invocations and errors data. Note that some of that data (for example, our legacy metrics) will not make it to our UI because our ingest pipeline does not consume them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.88217,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot enabling <em>serverless</em> <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "sections": "Troubleshoot enabling <em>serverless</em> <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Problem You’re attempting to enable <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the <em>AWS</em> integration step wasn&#x27;t"
      },
      "id": "603ea6bb64441f85284e889b"
    },
    {
      "sections": [
        "Understand the Lambda monitoring UI",
        "View your data",
        "Important",
        "UI pages",
        "Understand chart data",
        "For more help"
      ],
      "title": "Understand the Lambda monitoring UI",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "UI and data"
      ],
      "external_id": "45a6a881de05bcb4814f7f25f2bfa1632257a7f1",
      "image": "https://docs.newrelic.com/static/17e88e0171bc6b4358292daf4ddf7cf4/c1b63/new-relic-lambda-entities-screenshot_0.png",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/ui-data/understand-lambda-monitoring-ui/",
      "published_at": "2021-09-02T16:46:42Z",
      "updated_at": "2021-03-30T19:47:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Serverless monitoring for AWS Lambda offers in-depth performance monitoring for your Lambda functions. This document explains how to: Find your Lambda data in the UI Understand the UI components Understand your chart data How to create custom charts View your data one.newrelic.com> Explorer > Amazon Web Services > Lambda functions: Click Lambda functions to see charts and details. To view your Lambda data in New Relic: Go to one.newrelic.com, click Explorer. In the left nav under Amazon Web Services, click Lambda functions. For more about our UI, see Intro to New Relic One. Important If you can't find your Lambda data: Ensure you've followed the instructions for enabling Lambda monitoring. Note that this feature is different from our infrastructure monitoring Lambda integration. UI pages Here are descriptions of the UI pages available for our Lambda monitoring: UI page Functionality Summary The Summary page displays charts that give you a quick view into the most important performance data. If available, this will feature data gathered from APM agent instrumentation. CloudWatch metrics The CloudWatch metrics page displays Lambda data that comes from AWS CloudWatch. Charts include: invocation counts, duration, throttles, and error counts. Distributed tracing The Distributed tracing page shows distributed traces that include the monitored Lambda function. For details about this feature, see Distributed tracing. Errors The Errors page displays errors (AwsLambdaInvocationError events). You can filter by error rate, error percentage, or error class. You can drill down into errors and see attributes and, if available, stack traces. Invocations The Invocations page lets you filter your invocations by attribute, and view duration, throughput, external calls, and invocation breakdowns. About invocation breakdowns: Some invocations will generate a breakdown if distributed tracing is enabled during instrumentation. Breakdowns are sampled; approximately 10% of invocations generate a breakdown. This sampling rate may be higher, depending on upstream sampling decisions. Logs The Logs page displays recent log messages from your Lambda function. For details about this feature, see Logs. Understand chart data Lambda data charts are generated by running NRQL queries of Lambda-related event data. Reasons to view a chart's NRQL query include: To better understand what a chart is displaying To get ideas on how to create a custom NRQL query and chart Related documentation: Learn how to view a chart's query. Learn about Lambda data storage and structure. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.52324,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand the <em>Lambda</em> <em>monitoring</em> UI",
        "sections": "Understand the <em>Lambda</em> <em>monitoring</em> UI",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "<em>Serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> offers in-depth performance <em>monitoring</em> for your <em>Lambda</em> functions. This document explains how to: Find your <em>Lambda</em> data in the UI Understand the UI components Understand your chart data How to create custom charts View your data one.newrelic.com&gt; Explorer"
      },
      "id": "603eb10f196a67c65da83da2"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/troubleshooting/troubleshoot-enabling-serverless-monitoring-aws-lambda": [
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-09-02T16:45:40Z",
      "updated_at": "2021-09-02T16:45:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.77563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Before enabling <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, make sure you meet the requirements and learn about <em>AWS</em> charges resulting from its use. Recommended <em>AWS</em> <em>Lambda</em> language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "sections": [
        "Monitoring AWS Lambda with Serverless monitoring",
        "Why it matters",
        "Access and requirements",
        "Next steps: Enable and use Lambda monitoring"
      ],
      "title": "Monitoring AWS Lambda with Serverless monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "5d1d86ec786398b3190ed1a6e152373e0547dc57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring/",
      "published_at": "2021-09-02T16:45:40Z",
      "updated_at": "2021-07-27T18:00:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer in-depth performance monitoring for your serverless AWS Lambda functions. Read on to learn about the feature, how it works, and its requirements. This Lambda monitoring feature is not the same as the Lambda monitoring integration, which only uses CloudWatch data. Serverless Lambda monitoring is more extensive and uses both CloudWatch data and code-level instrumentation to deliver more in-depth monitoring. Why it matters Do you need to rapidly instrument monitoring and observability to your serverless functions without resorting to code changes? Our Lambda layer provides unified visibility into the most detailed behaviors of your Lambda functions so you can understand what's going on in your serverless applications. Use all this information to troubleshoot your systems and optimize your functions so they can function faster and deliver with confidence on serverless architectures. Spend less time instrumenting, and more time building. Lambda monitoring gives you: Every invocation of your Lambda functions, including performance data like detailed duration, cold starts, exceptions, and tracebacks. AWS Lambda event source information, which provides context and attributes about events that triggered each AWS Lambda invocation, such as API Gateway, ALB SNS, SQS, DynamoDB, and more. Visibility into your entire ecosystem with distributed tracing: see the path of requests that led to your Lambda, and see Lambda spans in your other distributed traces. Logs in context, which provides full invocation and function level logs right along side the metrics, attributes, and trace data. Inventoried tags and metadata. We retrieve information from your AWS entities, giving you the ability to filter and facet down to the team, or specific metadata attributes on the function configuration or invocation itself. Easy ability to query your data with an automatic facet builder, which instantly facets your dashboards and charts by attribute or function to explore custom data, without having to write queries. Lambda data is displayed in its own dedicated UI in New Relic One. Access and requirements See Compatibility and requirements of AWS Lambda monitoring. Next steps: Enable and use Lambda monitoring To get started using our Lambda monitoring, see the installation and enablement instructions. You can also set up alerts or add your own custom events or attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.67957,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "sections": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "We offer in-depth performance <em>monitoring</em> for your <em>serverless</em> <em>AWS</em> <em>Lambda</em> functions. Read on to learn about the feature, how it works, and its requirements. This <em>Lambda</em> <em>monitoring</em> feature is not the same as the <em>Lambda</em> <em>monitoring</em> integration, which only uses CloudWatch data. <em>Serverless</em> <em>Lambda</em>"
      },
      "id": "603eb08b28ccbc8b90eba75c"
    },
    {
      "sections": [
        "Understand the Lambda monitoring UI",
        "View your data",
        "Important",
        "UI pages",
        "Understand chart data",
        "For more help"
      ],
      "title": "Understand the Lambda monitoring UI",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "UI and data"
      ],
      "external_id": "45a6a881de05bcb4814f7f25f2bfa1632257a7f1",
      "image": "https://docs.newrelic.com/static/17e88e0171bc6b4358292daf4ddf7cf4/c1b63/new-relic-lambda-entities-screenshot_0.png",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/ui-data/understand-lambda-monitoring-ui/",
      "published_at": "2021-09-02T16:46:42Z",
      "updated_at": "2021-03-30T19:47:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Serverless monitoring for AWS Lambda offers in-depth performance monitoring for your Lambda functions. This document explains how to: Find your Lambda data in the UI Understand the UI components Understand your chart data How to create custom charts View your data one.newrelic.com> Explorer > Amazon Web Services > Lambda functions: Click Lambda functions to see charts and details. To view your Lambda data in New Relic: Go to one.newrelic.com, click Explorer. In the left nav under Amazon Web Services, click Lambda functions. For more about our UI, see Intro to New Relic One. Important If you can't find your Lambda data: Ensure you've followed the instructions for enabling Lambda monitoring. Note that this feature is different from our infrastructure monitoring Lambda integration. UI pages Here are descriptions of the UI pages available for our Lambda monitoring: UI page Functionality Summary The Summary page displays charts that give you a quick view into the most important performance data. If available, this will feature data gathered from APM agent instrumentation. CloudWatch metrics The CloudWatch metrics page displays Lambda data that comes from AWS CloudWatch. Charts include: invocation counts, duration, throttles, and error counts. Distributed tracing The Distributed tracing page shows distributed traces that include the monitored Lambda function. For details about this feature, see Distributed tracing. Errors The Errors page displays errors (AwsLambdaInvocationError events). You can filter by error rate, error percentage, or error class. You can drill down into errors and see attributes and, if available, stack traces. Invocations The Invocations page lets you filter your invocations by attribute, and view duration, throughput, external calls, and invocation breakdowns. About invocation breakdowns: Some invocations will generate a breakdown if distributed tracing is enabled during instrumentation. Breakdowns are sampled; approximately 10% of invocations generate a breakdown. This sampling rate may be higher, depending on upstream sampling decisions. Logs The Logs page displays recent log messages from your Lambda function. For details about this feature, see Logs. Understand chart data Lambda data charts are generated by running NRQL queries of Lambda-related event data. Reasons to view a chart's NRQL query include: To better understand what a chart is displaying To get ideas on how to create a custom NRQL query and chart Related documentation: Learn how to view a chart's query. Learn about Lambda data storage and structure. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.88911,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand the <em>Lambda</em> <em>monitoring</em> UI",
        "sections": "Understand the <em>Lambda</em> <em>monitoring</em> UI",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "<em>Serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> offers in-depth performance <em>monitoring</em> for your <em>Lambda</em> functions. This document explains how to: Find your <em>Lambda</em> data in the UI Understand the UI components Understand your chart data How to create custom charts View your data one.newrelic.com&gt; Explorer"
      },
      "id": "603eb10f196a67c65da83da2"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/ui-data/understand-lambda-data-structure": [
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-09-02T16:45:40Z",
      "updated_at": "2021-09-02T16:45:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.77563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility <em>and</em> requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility <em>and</em> requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " SDK is not used, <em>Lambda</em> <em>data</em> will appear as external service calls in the <em>UI</em>, with minimal detail. In other words, we rely on the <em>AWS</em> SDK to facilitate instrumentation of your <em>function</em>. For the following services, only the &quot;target&quot; (<em>Lambda</em> <em>function</em> name, SNS topic ARN, DynamoDB table name, etc"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "sections": [
        "Understand the Lambda monitoring UI",
        "View your data",
        "Important",
        "UI pages",
        "Understand chart data",
        "For more help"
      ],
      "title": "Understand the Lambda monitoring UI",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "UI and data"
      ],
      "external_id": "45a6a881de05bcb4814f7f25f2bfa1632257a7f1",
      "image": "https://docs.newrelic.com/static/17e88e0171bc6b4358292daf4ddf7cf4/c1b63/new-relic-lambda-entities-screenshot_0.png",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/ui-data/understand-lambda-monitoring-ui/",
      "published_at": "2021-09-02T16:46:42Z",
      "updated_at": "2021-03-30T19:47:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Serverless monitoring for AWS Lambda offers in-depth performance monitoring for your Lambda functions. This document explains how to: Find your Lambda data in the UI Understand the UI components Understand your chart data How to create custom charts View your data one.newrelic.com> Explorer > Amazon Web Services > Lambda functions: Click Lambda functions to see charts and details. To view your Lambda data in New Relic: Go to one.newrelic.com, click Explorer. In the left nav under Amazon Web Services, click Lambda functions. For more about our UI, see Intro to New Relic One. Important If you can't find your Lambda data: Ensure you've followed the instructions for enabling Lambda monitoring. Note that this feature is different from our infrastructure monitoring Lambda integration. UI pages Here are descriptions of the UI pages available for our Lambda monitoring: UI page Functionality Summary The Summary page displays charts that give you a quick view into the most important performance data. If available, this will feature data gathered from APM agent instrumentation. CloudWatch metrics The CloudWatch metrics page displays Lambda data that comes from AWS CloudWatch. Charts include: invocation counts, duration, throttles, and error counts. Distributed tracing The Distributed tracing page shows distributed traces that include the monitored Lambda function. For details about this feature, see Distributed tracing. Errors The Errors page displays errors (AwsLambdaInvocationError events). You can filter by error rate, error percentage, or error class. You can drill down into errors and see attributes and, if available, stack traces. Invocations The Invocations page lets you filter your invocations by attribute, and view duration, throughput, external calls, and invocation breakdowns. About invocation breakdowns: Some invocations will generate a breakdown if distributed tracing is enabled during instrumentation. Breakdowns are sampled; approximately 10% of invocations generate a breakdown. This sampling rate may be higher, depending on upstream sampling decisions. Logs The Logs page displays recent log messages from your Lambda function. For details about this feature, see Logs. Understand chart data Lambda data charts are generated by running NRQL queries of Lambda-related event data. Reasons to view a chart's NRQL query include: To better understand what a chart is displaying To get ideas on how to create a custom NRQL query and chart Related documentation: Learn how to view a chart's query. Learn about Lambda data storage and structure. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.44844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand the <em>Lambda</em> <em>monitoring</em> <em>UI</em>",
        "sections": "Understand the <em>Lambda</em> <em>monitoring</em> <em>UI</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "<em>Serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> offers in-depth performance <em>monitoring</em> for your <em>Lambda</em> functions. This document explains how to: Find your <em>Lambda</em> <em>data</em> in the <em>UI</em> Understand the <em>UI</em> components Understand your chart <em>data</em> How to create custom charts View your <em>data</em> one.newrelic.com&gt; Explorer"
      },
      "id": "603eb10f196a67c65da83da2"
    },
    {
      "sections": [
        "Monitoring AWS Lambda with Serverless monitoring",
        "Why it matters",
        "Access and requirements",
        "Next steps: Enable and use Lambda monitoring"
      ],
      "title": "Monitoring AWS Lambda with Serverless monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "5d1d86ec786398b3190ed1a6e152373e0547dc57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring/",
      "published_at": "2021-09-02T16:45:40Z",
      "updated_at": "2021-07-27T18:00:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer in-depth performance monitoring for your serverless AWS Lambda functions. Read on to learn about the feature, how it works, and its requirements. This Lambda monitoring feature is not the same as the Lambda monitoring integration, which only uses CloudWatch data. Serverless Lambda monitoring is more extensive and uses both CloudWatch data and code-level instrumentation to deliver more in-depth monitoring. Why it matters Do you need to rapidly instrument monitoring and observability to your serverless functions without resorting to code changes? Our Lambda layer provides unified visibility into the most detailed behaviors of your Lambda functions so you can understand what's going on in your serverless applications. Use all this information to troubleshoot your systems and optimize your functions so they can function faster and deliver with confidence on serverless architectures. Spend less time instrumenting, and more time building. Lambda monitoring gives you: Every invocation of your Lambda functions, including performance data like detailed duration, cold starts, exceptions, and tracebacks. AWS Lambda event source information, which provides context and attributes about events that triggered each AWS Lambda invocation, such as API Gateway, ALB SNS, SQS, DynamoDB, and more. Visibility into your entire ecosystem with distributed tracing: see the path of requests that led to your Lambda, and see Lambda spans in your other distributed traces. Logs in context, which provides full invocation and function level logs right along side the metrics, attributes, and trace data. Inventoried tags and metadata. We retrieve information from your AWS entities, giving you the ability to filter and facet down to the team, or specific metadata attributes on the function configuration or invocation itself. Easy ability to query your data with an automatic facet builder, which instantly facets your dashboards and charts by attribute or function to explore custom data, without having to write queries. Lambda data is displayed in its own dedicated UI in New Relic One. Access and requirements See Compatibility and requirements of AWS Lambda monitoring. Next steps: Enable and use Lambda monitoring To get started using our Lambda monitoring, see the installation and enablement instructions. You can also set up alerts or add your own custom events or attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.67957,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "sections": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "We offer in-depth performance <em>monitoring</em> for your <em>serverless</em> <em>AWS</em> <em>Lambda</em> functions. Read on to learn about the feature, how it works, and its requirements. This <em>Lambda</em> <em>monitoring</em> feature is not the same as the <em>Lambda</em> <em>monitoring</em> integration, which only uses CloudWatch <em>data</em>. <em>Serverless</em> <em>Lambda</em>"
      },
      "id": "603eb08b28ccbc8b90eba75c"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/ui-data/understand-lambda-monitoring-ui": [
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-09-02T16:45:40Z",
      "updated_at": "2021-09-02T16:45:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.77563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility <em>and</em> requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility <em>and</em> requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " SDK is not used, <em>Lambda</em> <em>data</em> will appear as external service calls in the <em>UI</em>, with minimal detail. In other words, we rely on the <em>AWS</em> SDK to facilitate instrumentation of your <em>function</em>. For the following services, only the &quot;target&quot; (<em>Lambda</em> <em>function</em> name, SNS topic ARN, DynamoDB table name, etc"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "sections": [
        "Understand the Lambda data structure",
        "Sources of Lambda data",
        "Event definitions and attributes"
      ],
      "title": "Understand the Lambda data structure",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "UI and data"
      ],
      "external_id": "07406ff52f251eb6195f76d730e30615828cb734",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/ui-data/understand-lambda-data-structure/",
      "published_at": "2021-09-02T16:46:42Z",
      "updated_at": "2021-03-16T18:11:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our serverless monitoring for AWS Lambda offers in-depth performance monitoring for your Lambda functions. This document will explain the source, structure, and storage of your Lambda data. Sources of Lambda data Our Lambda monitoring data comes from these two sources: Our APM agent instrumentation (or similar customer-created instrumentation) AWS CloudWatch metrics For details on how this data is configured and how it flows to New Relic, see the enablement procedures. The data displayed in the UI is a combination of these data sources. For example, the Overview page displays data reported by instrumentation, while the Metrics page displays CloudWatch data. Event definitions and attributes Lambda data is stored in our database (NRDB) as events (data objects with associated attributes). Lambda data is attached to the following event types. Select an event name to see its attributes. AwsLambdaInvocation event: Captures overall timing and associated metadata. A Lambda invocation generates a single AwsLambdaInvocation event. AwsLambdaInvocationError event: If an error occurs during a Lambda, this event will be generated. Span: This includes detail about a segment of a Lambda function. Spans are used for distributed tracing. Distributed tracing relies on data sampling; 10% of invocations are sampled to generate spans. Custom event types: With some agent APIs, custom events can be created and associated with a particular Lambda invocation, and then queried with NRQL. For more about limits on event storage, see Access and requirements.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.51071,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand the <em>Lambda</em> <em>data</em> structure",
        "sections": "Understand the <em>Lambda</em> <em>data</em> structure",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Our <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> offers in-depth performance <em>monitoring</em> for your <em>Lambda</em> functions. This document will explain the source, structure, and storage of your <em>Lambda</em> <em>data</em>. Sources of <em>Lambda</em> <em>data</em> Our <em>Lambda</em> <em>monitoring</em> <em>data</em> comes from these two sources: Our APM agent instrumentation"
      },
      "id": "603eb0c8e7b9d24b202a0820"
    },
    {
      "sections": [
        "Monitoring AWS Lambda with Serverless monitoring",
        "Why it matters",
        "Access and requirements",
        "Next steps: Enable and use Lambda monitoring"
      ],
      "title": "Monitoring AWS Lambda with Serverless monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "5d1d86ec786398b3190ed1a6e152373e0547dc57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring/",
      "published_at": "2021-09-02T16:45:40Z",
      "updated_at": "2021-07-27T18:00:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer in-depth performance monitoring for your serverless AWS Lambda functions. Read on to learn about the feature, how it works, and its requirements. This Lambda monitoring feature is not the same as the Lambda monitoring integration, which only uses CloudWatch data. Serverless Lambda monitoring is more extensive and uses both CloudWatch data and code-level instrumentation to deliver more in-depth monitoring. Why it matters Do you need to rapidly instrument monitoring and observability to your serverless functions without resorting to code changes? Our Lambda layer provides unified visibility into the most detailed behaviors of your Lambda functions so you can understand what's going on in your serverless applications. Use all this information to troubleshoot your systems and optimize your functions so they can function faster and deliver with confidence on serverless architectures. Spend less time instrumenting, and more time building. Lambda monitoring gives you: Every invocation of your Lambda functions, including performance data like detailed duration, cold starts, exceptions, and tracebacks. AWS Lambda event source information, which provides context and attributes about events that triggered each AWS Lambda invocation, such as API Gateway, ALB SNS, SQS, DynamoDB, and more. Visibility into your entire ecosystem with distributed tracing: see the path of requests that led to your Lambda, and see Lambda spans in your other distributed traces. Logs in context, which provides full invocation and function level logs right along side the metrics, attributes, and trace data. Inventoried tags and metadata. We retrieve information from your AWS entities, giving you the ability to filter and facet down to the team, or specific metadata attributes on the function configuration or invocation itself. Easy ability to query your data with an automatic facet builder, which instantly facets your dashboards and charts by attribute or function to explore custom data, without having to write queries. Lambda data is displayed in its own dedicated UI in New Relic One. Access and requirements See Compatibility and requirements of AWS Lambda monitoring. Next steps: Enable and use Lambda monitoring To get started using our Lambda monitoring, see the installation and enablement instructions. You can also set up alerts or add your own custom events or attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.67957,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "sections": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "We offer in-depth performance <em>monitoring</em> for your <em>serverless</em> <em>AWS</em> <em>Lambda</em> functions. Read on to learn about the feature, how it works, and its requirements. This <em>Lambda</em> <em>monitoring</em> feature is not the same as the <em>Lambda</em> <em>monitoring</em> integration, which only uses CloudWatch <em>data</em>. <em>Serverless</em> <em>Lambda</em>"
      },
      "id": "603eb08b28ccbc8b90eba75c"
    }
  ],
  "/docs/serverless-function-monitoring/index": [
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-09-02T16:45:40Z",
      "updated_at": "2021-09-02T16:45:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 565.9122,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements of AWS Lambda <em>monitoring</em>",
        "sections": "Compatibility and requirements of AWS Lambda <em>monitoring</em>",
        "tags": "<em>Serverless</em> function <em>monitoring</em>",
        "body": "Before enabling <em>serverless</em> <em>monitoring</em> for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/configure-serverless-monitoring-aws-lambda/",
      "sections": [
        "Step 5: Additional configuration",
        "Set up alerts",
        "Add custom events"
      ],
      "published_at": "2021-09-02T16:42:37Z",
      "title": "Step 5: Additional configuration",
      "updated_at": "2021-08-27T08:19:45Z",
      "type": "docs",
      "external_id": "7ccc0cbc8f96ad38d90cfa4e6c12b53f8ebfcbb4",
      "document_type": "page",
      "popularity": 1,
      "body": "After you enable serverless monitoring for AWS Lambda, you can add additional configuration to fine-tune your data. Set up alerts Our alerts let you get notifications on anything you can monitor with New Relic, including APM metrics, key transactions, NRQL queries, and more. For details about setting up alerts on Lambda functions, see monitoring for AWS Lambda: Configuring alerts Add custom events Besides the data we provide by default, you can also set up your own events or attributes. For details about these language-specific settings, see Configuring custom attributes and events in AWS Lambda.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 420.36652,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "After you enable <em>serverless</em> <em>monitoring</em> for AWS Lambda, you can add additional configuration to fine-tune your data. Set up alerts Our alerts let you get notifications on anything you can <em>monitor</em> with New Relic, including APM metrics, key transactions, NRQL queries, and more. For details about"
      },
      "id": "603e94df196a676d7ea83ddc"
    },
    {
      "sections": [
        "Get started with Full-Stack Observability",
        "You’re in control because you understand your system",
        "All the answers in one place",
        "Start anywhere"
      ],
      "title": "Get started with Full-Stack Observability",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "e7fc0bf91fa26b38a11933b6570c8b1e483a1ff9",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability/",
      "published_at": "2021-09-05T01:43:25Z",
      "updated_at": "2021-08-27T06:57:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Full-Stack Observability is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. You’re in control because you understand your system New Relic helps you cut through the layers of complexity surrounding your systems by bringing together and connecting data from any instrumented source and environment, without having to jump between tools. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. New Relic provides answers to essential questions in one place. All the answers in one place As a full user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Full-Stack Observability curated experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find the signal. Start anywhere Being fully-connected, New Relic allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. Use the Explorer in New Relic One to access and observe the full stack of your software, see performance data and alerting status at a glance, and check relationships. We provide you with a simple, yet powerful visual tool to monitor all your entities, that is, anything we can identify that reports data. In the New Relic ecosystem, entities include basic components like applications, hosts, containers, or database services, but it can also refer to custom groupings of such elements. You can also create your own entities. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces. You want to instrument Start with Keep exploring Front-end applications Mobile applications User behavior and flows New Relic Explorer Browser monitoring Mobile monitoring Synthetic monitoring Single page monitoring Scripted browsers Containerized minions Workloads Backend applications Serverless applications New Relic Explorer Application monitoring Serverless monitoring Learning about Apdex Distributed tracing Logs in context APM data to infrastructure Workloads Infrastructure hosts and services (on-premise, cloud, orchestrated) Container environments and orchestration tools (Kubernetes, ECS, etc.) Infrastructure monitoring Infrastructure integrations Kubernetes integration Docker integration ECS integration Log forwarding APM data to infrastructure Custom integrations Kubernetes cluster explorer Infrastructure alerts Workloads",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 325.60913,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ", and traces. You want to instrument Start with Keep exploring Front-end applications Mobile applications User behavior and flows New Relic Explorer Browser <em>monitoring</em> Mobile <em>monitoring</em> Synthetic <em>monitoring</em> Single page <em>monitoring</em> Scripted browsers Containerized minions Workloads Backend applications <em>Serverless</em>"
      },
      "id": "603e891528ccbce6d9eba765"
    }
  ],
  "/docs/style-guide/article-templates/agent-api-guide-template": [
    {
      "sections": [
        "Add to data dictionary",
        "Data dictionary structure",
        "Add a new data type",
        "Add attributes",
        "Attribute style guidelines",
        "Using units of measurement"
      ],
      "title": "Add to data dictionary",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "32b8cab502883cc3443e54c86a0bd4021cc5a10f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/data-dictionary-style-guidelines/",
      "published_at": "2021-09-01T21:49:54Z",
      "updated_at": "2021-07-22T06:26:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use the data dictionary to provide information about data types (for example, Transaction, Metric, Log) and attached attributes. This is exposed in the New Relic query experience, on hovering over the data types and attributes. And we also expose the dictionary to the public. This doc contains info on how to add data to the dictionary. Note that currently we don't have infrastructure integration data in the dictionary. We also have very few attributes for the Metric data type, just a few basic default ones, despite there being many potential attributes attached to that data type depending on what the data source is. Data dictionary structure The data in the data dictionary is structured like this: Data types: sometimes called \"events\" for historical reasons, these are the NRDB data objects, like Transaction, Metric, Log, Span, etc. Attributes: these are key:value pairs attached to data types. One attribute can have multiple data types listed for it. For example, appName is on multiple data types. Data source: The New Relic product from which the data originates. With the current implementation, a data type must have a single data source assigned. This isn't ideal, as theoretically a data type can come from multiple sources. Add a new data type To add a new data type: Make a new folder in this directory, alongside the other directories: /docs-website/tree/develop/src/data-dictionary/events Copy Duplicate a data type file (for example, this Metric data type), place it in the new folder, and fill it out with the new info. For how to add attributes on a new data type, keep reading. Add attributes To add attributes: Our goal is to avoid adding redundant attributes entries, so you should first check to see if there's an existing attribute that has the same name and same general definition as the one you're trying to add. If it exists, edit that file to include the new data type (under events:). If an existing attribute is fairly close in definition but not exact, try to edit the definition so it works for all associated data types. If there is no existing attribute, create a new one. The easiest way is to copy an existing attribute file, edit all relevant fields to be accurate, and place it in the folder of the data type it's attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see Style. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute style guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes on this: Feel free to use sentence fragments. Feel free to edit definitions submitted from internal teams as sometimes their definitions will be overly long or have unneeded links. Some attributes are only present in some situations (for example, when a specific APM agent is used, or when a specific config option is true). We should avoid documenting most of these, with the idea that most customers will only care about the data because it's being reported for them, and won't care about the things that factor into the reasons why it wouldn't be reported. If it's thought that the addition would help customers who already have the data reporting understand the data better, you can include it. Write so it reads well as plain text. Details on this: Note that the docs site data dictionary has our usual docs styles available, but the query UI definitions have no styling available. This means that you should write definitions so that they are understandable without any styling, as plain text. You can often avoid any need for styling (for example, data types like Transaction are easy to understand as plain text, as are most phrasings that use attribute names or values. When plain text makes something too ambiguous and you need some styling, use back ticks to indicate attributes or values (for example, a definition like: Reported when ` category ` is ` http ` ). Using this also sets us up for success if we implement styling in the UI definitions in the future. We should avoid links because those aren't visible in the query UI; the query UI only displays plain text. However, every attribute entry in the query UI does display a 'See attribute in docs' link that links to the complete and normally formatted docs site entry. This means that we can use links provided that they will display in an easy to understand way in the query UI. For example, here's an example of an attribute that would read clearly in plain text despite not having a link. We should avoid using a link format like \"For more information, see Create an alert condition\", because it wouldn't read well in plain text, and would choose something like \"For more information, see our alert condition docs.\" Using units of measurement Attribute entries have an optional unit of measurement field in the front matter. For example, here the front matter for an attribute with a percent unit of measurement: --- name: cpuPercent type: attribute units: percentage (%) events: - ProcessSample --- Copy What unit of measurement to select for an attribute is sometimes obvious, like if the attribute value is measured in milliseconds (units: milliseconds (ms)) or seconds (units: seconds (s)) or a percentage (units: percentage (%)). We also have several units of measurement that are not obvious, like count, enum, rate, and ID. (Technically, these aren't actually \"units of measurement\" and are more just conceptual data types but we're doing it this way as a workaround so you can ignore the fact that units of measurement isn't actually accurate.) The main reason we want to specify this information is that this will control what kinds of queries or charts can be created or auto-suggested by New Relic. For example, the New Relic UI wouldn't want to auto-suggest a chart graphing the average of ID values because that wouldn't make any sense. So attributes with accurate units, such as data types, will help product provide more practical help/suggestions to customers in future. Here are some tips for the non-obvious unit types: count: This is a count of something, though not a count of time-based units. For a number to be a count, it must (a) only be capable of increasing during a given time/sampling period, and (b) have a theoretically uncapped range. This wouldn't be used for a count of time units; if it was a count of seconds, for example, you would just use 'seconds' as the unit of measurement. A couple of examples of a count: databaseCallCount threadConcurrency enum: enum is short for enumerated list. In other words, it is a specific range of numbers that represent other non-numeric elements. For example, an attribute that had HTTP error codes (404, 505, etc.) as possible values would be an enum. A range of numbers that represent color codes would be another example of an enum. (Theoretically, an enum can represent lists without numeric values but we have no need to categorize strings so we only care about numeric-value lists.) Example: httpResponsecode. rate: Use this for any rate (for example, count per second). These are typically for averaged rates over small units of time, like second or millisecond. We previously have used the unit of time for these attributes (for example, using seconds as the unit of measurement for a count per second rate), but now we want to use rate for these. This is necessary because the types of displays used for rates would be different than the types of displays used for a simpler duration/count measurement. Example: MySQL integration attribute db.innodb.dataReadBytesPerSecond, which has the definition \"Rate at which data is read from InnoDB tables in bytes per second.\" id: Use ID for any identification number attribute. Example: appId.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.7939,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Attribute <em>style</em> <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ". For more on that, see <em>Style</em>. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute <em>style</em> guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes"
      },
      "id": "6050b4da64441f84f1532199"
    },
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "46997b8327630e068987c09788cb6e5115896517",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/delete-document/",
      "published_at": "2021-09-01T21:35:11Z",
      "updated_at": "2021-09-01T21:35:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 253.80307,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "60422009e7b9d21bd22a07d4"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.86542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "604220ec196a670d0ba83dd4"
    }
  ],
  "/docs/style-guide/article-templates/agent-release-notes-template-123": [
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "f2930bdf571bc3615529ba58b5527d80c4d6b164",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-ruby/",
      "published_at": "2021-09-01T22:53:15Z",
      "updated_at": "2021-08-30T20:56:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, no additional configuration is required. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1.816241,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "id": "612d460128ccbc17bf56a863",
      "highlight": {}
    },
    {
      "sections": [
        "Introduction to infrastructure integrations",
        "Types of infrastructure integrations",
        "Cloud integrations",
        "On-host integrations",
        "Install instructions",
        "Features",
        "Types of integration data"
      ],
      "title": "Introduction to infrastructure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "98b6a0d19418b67c315b3757a1acc905b2fc53bf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/infrastructure-integrations/get-started/introduction-infrastructure-integrations/",
      "published_at": "2021-09-01T18:11:16Z",
      "updated_at": "2021-08-27T04:53:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers various integrations for reporting data to our platform. One category of integrations is our Infrastructure integrations. Types of infrastructure integrations New Relic has two main categories of infrastructure integrations: cloud and on-host. Cloud integrations Cloud integrations collect data from cloud services and accounts. There's no installation process for cloud integrations, you simply connect your New Relic account to your cloud provider account. Integrations Description Amazon Web Services (AWS) cloud-based integrations Connect your Amazon Web Services (AWS) account to monitor and report data to New Relic. See the list of AWS integrations. Microsoft Azure cloud-based integrations Connect your Microsoft Azure account to monitor and report data to New Relic. See the list of Azure integrations. Google Cloud Platform (GCP) cloud-based integrations Connect your Google Cloud Platform (GCP) account to monitor and report data to New Relic. See the list of GCP integrations. On-host integrations On-host integrations are infrastructure monitoring integrations that can be run directly on your host or server: Integrations Description Kubernetes integration Connect your account to gain visibility of your Kubernetes environment, explore your clusters, and manage alerts. On-host integrations Monitor and report data from many popular services, including NGINX, MySQL, Redis, Apache, RabbitMQ, and many more. Build your own To create your own lightweight integration, use our Flex integration tool. Install instructions To enable cloud integrations or install on-host integrations, see: Cloud integrations: AWS procedures, Azure procedures, Google Cloud Platform procedures Kubernetes: Kubernetes procedures On-host integrations: See an integration's documentation for install procedures Features After an infrastructure integration is activated, you can: Filter and analyze the metrics and configuration data in our Infrastructure UI. Query your data and create custom charts and dashboards. Create alert conditions to monitor problems with your services' performance. For cloud integrations, configure data collection settings. Types of integration data Infrastructure integrations generate some basic types of data that you can use in New Relic. Integration data Description Metrics Numeric measurement data. Examples: Number of requests in a queue Number of hits on a database per minute Percentage of CPU being used Cloud-based and on-host integrations include pre-built dashboards that display important metrics. Inventory Live system state and configuration information. Examples: Host name AWS region or availability zone Port being used Changes in inventory generate events in New Relic, so you can easily figure out when performance issues were caused by a change in the system. Events Important activity on a system. Examples: Service starting Version update New table being created Changes to inventory are a type of event. Attributes Key-value pairs generated by some integrations. Examples: Certain inventory data Additional data attached to events Any data that is not considered metrics or inventory Depending on the integration, other types of information may be reported as attributes. Our integrations are data agnostic; they have no knowledge of whether reported data contains personal information. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1.6414398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "id": "60450a39e7b9d2de845799cd",
      "highlight": {}
    },
    {
      "sections": [
        "Kubernetes integration: Recommended alert policy",
        "Recommended alert conditions",
        "Node allocatable CPU utilization % is too high",
        "Node allocatable memory utilization % is too high",
        "Node pods allocatable utilization % is too high"
      ],
      "title": "Kubernetes integration: Recommended alert policy",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "a1420c0b9ac0dedab27b91360da8d0f48930f419",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/kubernetes-integration-recommended-alert-policy/",
      "published_at": "2021-09-01T18:12:09Z",
      "updated_at": "2021-08-26T21:58:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When deploying the Kubernetes integration for the first time, we deploy a default set of alert conditions to your account, the predefined alert policy, a basis for alert conditions on your Kubernetes cluster. While we try to tackle the most common use cases across all the environments, there's a number of additional alerts you can set up to extend the default policy. What follows are some recommendations. Recommended alert conditions Node allocatable CPU utilization % is too high Setting Value Event type K8sNodeSample SELECT value (cpuUsedCores/cpuLimitCores)*100 Warning threshold > 90% for at least 5 minutes Critical threshold > 95% for at least 5 mins Node allocatable memory utilization % is too high Setting Value Event type K8sNodeSample SELECT value (memoryUsedBytes/memoryLimitBytes)/100 Warning threshold > 85% for at least 5 minutes Critical threshold > 95% for at least 5 mins You need to set a memory limit in your container specs for memoryLimitBytes to report data. Node pods allocatable utilization % is too high Setting Value Event type K8sPodSample SELECT value isScheduled Warning threshold Critical threshold isScheduled = 0 for at least 7 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1.6308148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "id": "603e80dce7b9d21ed62a07ce",
      "highlight": {}
    }
  ],
  "/docs/style-guide/article-templates/api-tutorial-template": [
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "46997b8327630e068987c09788cb6e5115896517",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/delete-document/",
      "published_at": "2021-09-01T21:35:11Z",
      "updated_at": "2021-09-01T21:35:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.92194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "60422009e7b9d21bd22a07d4"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.9654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "604220ec196a670d0ba83dd4"
    },
    {
      "sections": [
        "apiStyleGuidelines (Example agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Tip",
        "Parameters",
        "Return values",
        "Examples",
        "URL guidelines",
        "Title guidelines",
        "Short title guidelines",
        "Syntax guidelines",
        "Important"
      ],
      "title": "apiStyleGuidelines (Example agent API)",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "API writing guidelines"
      ],
      "external_id": "41eee9dfacd933b49935d7bd4d32cb76476c29ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/apistyleguidelines-example-agent-api/",
      "published_at": "2021-09-01T21:49:05Z",
      "updated_at": "2021-03-10T23:41:36Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.apiStyleGuidelines(data type $parameter_name[, integer $optional_param]) newrelic.apiStyleGuidelines(data type $parameter_name, array $different_param, string $third_param) Copy Briefly describe the call. Ideally, one line or less on the \"View all methods\" page. Requirements Agent version 1.2.3.4 or higher. Additional requirements on their own line (do not use bullets). Do not use any callouts. If there are no special requirements, write: Compatible with all agent versions. Description Describe the behavior of the call with as much detail as possible. Do not describe what individual parameters do except in broad strokes; details of parameters and call variants belong under the Parameters heading. Similarly, do not describe return values. When cross-referencing another API call, format its name with code blocks, and include parentheses () like this: anotherCoolMethod(). Tip You can include callouts, but use discretion. These pages are already visually busy. Parameters If there are no parameters, leave this section blank. If there is only one call variant, do not include a syntax block in this section. Parameter Description newrelic.apiStyleGuidelines(data type $parameter_name[, integer $optional_param]) Copy $parameter_name data type Required. Brief description of parameter. $optional_param integer Optional. Brief description of parameter. newrelic.apiStyleGuidelines(data type $parameter_name, array $different_param) Copy $parameter_name data type Required. Brief description of parameter. $different_param array Required. Brief description of parameter. $third_param string Required. Brief description of parameter. Return values What does this call return, and in what circumstances? Are there any things we expect customers to do with that return value? If the call does not return anything, leave this section blank. Examples This section documents rules for oddballs that aren't self-documenting. The rest of the examples are embedded within the page itself. In general, this page is intended for style reference. For examples of how to write good API method pages, check out our existing API docs, such as the PHP API. URL guidelines For the doc's URL: Manually edit the URL slug to remove the agent name. Where the API call does not already include separators (as in newrelic_awesome_call), separate the bits with hyphens -. For example: https://docs.newrelic.com/docs/new-relic-only/advanced-style-guide/writing-guidelines/api-style-guidelines Copy Title guidelines For the doc's title: Include the method name and the agent name in parentheses. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do not include parentheses () in the call itself. For example: apiStyleGuidelines (Example agent API) Copy Short title guidelines For the doc's short title: Include only the method name. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do not include parentheses (). Adjust if necessary to fit on a single line in the category's sidebar. For example: apiStyleGuidelines Copy Syntax guidelines Important The Python and iOS agents use their own guidelines. For those guidelines, see the existing methods in those languages. Document each variant of a call on its own line. Do not use any formatting except italicizing the data type. Wrap optional parameters (including the comma separator) in square brackets []. Indicate the variable portion by prefacing it with a dollar sign $. If the call must be prefixed with newrelic. or similar, include that in the syntax. Optional: Include the return value, if that seems important for your particular agent. If you do, follow language conventions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.20831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>apiStyleGuidelines</em> (Example agent <em>API</em>)",
        "sections": "URL <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ":&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;new-relic-only&#x2F;advanced-<em>style</em>-<em>guide</em>&#x2F;<em>writing</em>-<em>guidelines</em>&#x2F;<em>api</em>-<em>style</em>-<em>guidelines</em> Copy Title <em>guidelines</em> For the doc&#x27;s title: Include the method name and the agent name in parentheses. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do"
      },
      "id": "60441b8d28ccbc0ab22c60b3"
    }
  ],
  "/docs/style-guide/article-templates/apistyleguidelines-example-agent-api": [
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "46997b8327630e068987c09788cb6e5115896517",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/delete-document/",
      "published_at": "2021-09-01T21:35:11Z",
      "updated_at": "2021-09-01T21:35:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.92194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "60422009e7b9d21bd22a07d4"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.9654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "604220ec196a670d0ba83dd4"
    },
    {
      "sections": [
        "API tutorial template",
        "Introduction (this heading will not be visible)",
        "Optional: Provide an overview for complex processes",
        "Provide a procedure to accomplish the task",
        "Tip",
        "Step 1. Do something...",
        "If needed: Step 2. Do something else...",
        "If needed: Step 3. Do something else...",
        "Last step. Verify that the task was completed...",
        "Optional: Do something else with the API",
        "Optional: Large example code block",
        "Code block example",
        "Optional: Troubleshooting"
      ],
      "title": "API tutorial template  ",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "API writing guidelines"
      ],
      "external_id": "a3fb036bc32f2dbc39c252acc9306e5ae0d5b7bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/api-tutorial-template/",
      "published_at": "2021-09-01T21:48:01Z",
      "updated_at": "2021-03-10T23:40:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is a template for an API tutorial document: Please skim the entire template first to understand the expected structure for this type of doc. Then, clone this doc using the Clone content link in the Page tools box. Delete all content up to Introduction (this heading won't be visible). For the doc title (the field at top of page): Doc should be named in a practical, use-case-focused way. Example: Add custom attributes to transactions Introduction (this heading will not be visible) Provide a brief explanation of what this document will teach customers, and why it is valuable for customers to know how to do that. Focus on the value the API provides to the customers and mention specific, common use cases. Any relevant notes about support/compatability should go here, too. Here's an example from the Java API asynchronous tutorial doc: New Relic for Java includes an API to instrument asynchronous activity. For supported frameworks, the Java agent usually instruments async work automatically. However, the async API can be useful for adding more detail to your data. This document provides examples of using tokens and segments to instrument your app. Optional: Provide an overview for complex processes This is an optional section for complicated tutorials that involve either using several methods in one procedure or that have different alternate steps you can take to achieve similar results. This section can link to lower-down sections to allow users to skip around as needed. For simple tutorials, this section isn't necessary. For an example, see this section of the Java async tutorial. Provide a procedure to accomplish the task Tell the user how to accomplish the task, and link to the methods necessary to accomplish that task. As much as possible, we're looking to describe tasks in \"procedures\" (procedure is tech writer jargon for a series of numbered steps). This may be tough to do for fairly open-ended/variable tasks, but it will usually be possible to chunk the content at a fairly high-level to make it into a procedure. Along the way, explain what the importance of the procedure step is, and how one might verify that the step was done correctly. For code samples, avoid using large chunks of code. Instead, use smaller pieces of code and give context for how they are being used. (If you think a large app code example would be helpful, place that later in the doc in the Example section.) Tip For an example of an open-ended task segmented into procedural chunks, see the Asynchronous doc section Connecting async threads. For another example, see this TomCat GAE Flex procedure. Base your procedure on the simple structure below. Tech writers will edit your content to match our style and formatting requirements: Step 1. Do something... Methods and example code to implement the first step. For each step, if applicable, indicate the significance of that step (why it's important) and how the user might verify that the step was done correctly (for example, something showing up in UI, or running a verification test of some sort). If needed: Step 2. Do something else... Methods and example code to implement step 2. If needed: Step 3. Do something else... Methods and example code to implement step 3. Last step. Verify that the task was completed... Explain how a user would know they'd completed the task correctly. In particular, how would the user find the new change or data in the New Relic UI. What NR products and pages would the change be noticed on? If new data shows up in Insights, what event types can it be found under? Optional: Do something else with the API Same as above. Make as many headings and separate procedures as needed. Optional: Large example code block If you think a large app code example would be useful, place here. Within any code block, explain all New Relic functions/methods, not just the main methods. Instead of in-line comments, consider using highlighted sections underneath the code block to give additional context. Here's an example: Code block example The following code example shows a segment starting in the storeItem method to measure how long the Lambda statement is waiting in the thread pool. To stop timing the segment, you must call either .end() or .ignore(). If you don't want to report the segment as part of its parent transaction, call .ignore(). Otherwise, to report the segment as part of its parent transaction, call .end(). private void storeItem(long id) { Segment segment = NewRelic.getAgent().getTransaction(). startSegment(\"storeItem\") ; segment. reportAsExternal (DatastoreParameters .product(\"H2\") .collection(null) .operation(\"insert\") .instance(\"localhost\", 8080) .databaseName(\"test\") .build()); // fire and forget DB_POOL.submit(() -> { segment.end(); insertData(id); }); } Copy The agent API calls in this sample are: startSegment(...): Begins the segment that will time the code. For more on this method, see the Javadoc. reportAsExternal(DatastoreParameters()): Associates the time with a datastore external call This will show up in New Relic APM with datastore data. For more information, see reportAsExternal API. segment.end(): Stops timing this segment. For more on this method, see the Javadoc. Optional: Troubleshooting Optional area for any common errors or troubleshooting tips.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.20824,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>API</em> tutorial template  ",
        "sections": "<em>API</em> tutorial template",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " to describe tasks in &quot;procedures&quot; (procedure is <em>tech</em> <em>writer</em> jargon for a series of numbered steps). This may be tough to do for fairly open-ended&#x2F;variable tasks, but it will usually be possible to chunk the content at a fairly high-level to make it into a procedure. Along the way, explain what"
      },
      "id": "60441b4a64441f7766378f09"
    }
  ],
  "/docs/style-guide/article-templates/basic-doc-template": [
    {
      "sections": [
        "Add to data dictionary",
        "Data dictionary structure",
        "Add a new data type",
        "Add attributes",
        "Attribute style guidelines",
        "Using units of measurement"
      ],
      "title": "Add to data dictionary",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "32b8cab502883cc3443e54c86a0bd4021cc5a10f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/data-dictionary-style-guidelines/",
      "published_at": "2021-09-01T21:49:54Z",
      "updated_at": "2021-07-22T06:26:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use the data dictionary to provide information about data types (for example, Transaction, Metric, Log) and attached attributes. This is exposed in the New Relic query experience, on hovering over the data types and attributes. And we also expose the dictionary to the public. This doc contains info on how to add data to the dictionary. Note that currently we don't have infrastructure integration data in the dictionary. We also have very few attributes for the Metric data type, just a few basic default ones, despite there being many potential attributes attached to that data type depending on what the data source is. Data dictionary structure The data in the data dictionary is structured like this: Data types: sometimes called \"events\" for historical reasons, these are the NRDB data objects, like Transaction, Metric, Log, Span, etc. Attributes: these are key:value pairs attached to data types. One attribute can have multiple data types listed for it. For example, appName is on multiple data types. Data source: The New Relic product from which the data originates. With the current implementation, a data type must have a single data source assigned. This isn't ideal, as theoretically a data type can come from multiple sources. Add a new data type To add a new data type: Make a new folder in this directory, alongside the other directories: /docs-website/tree/develop/src/data-dictionary/events Copy Duplicate a data type file (for example, this Metric data type), place it in the new folder, and fill it out with the new info. For how to add attributes on a new data type, keep reading. Add attributes To add attributes: Our goal is to avoid adding redundant attributes entries, so you should first check to see if there's an existing attribute that has the same name and same general definition as the one you're trying to add. If it exists, edit that file to include the new data type (under events:). If an existing attribute is fairly close in definition but not exact, try to edit the definition so it works for all associated data types. If there is no existing attribute, create a new one. The easiest way is to copy an existing attribute file, edit all relevant fields to be accurate, and place it in the folder of the data type it's attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see Style. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute style guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes on this: Feel free to use sentence fragments. Feel free to edit definitions submitted from internal teams as sometimes their definitions will be overly long or have unneeded links. Some attributes are only present in some situations (for example, when a specific APM agent is used, or when a specific config option is true). We should avoid documenting most of these, with the idea that most customers will only care about the data because it's being reported for them, and won't care about the things that factor into the reasons why it wouldn't be reported. If it's thought that the addition would help customers who already have the data reporting understand the data better, you can include it. Write so it reads well as plain text. Details on this: Note that the docs site data dictionary has our usual docs styles available, but the query UI definitions have no styling available. This means that you should write definitions so that they are understandable without any styling, as plain text. You can often avoid any need for styling (for example, data types like Transaction are easy to understand as plain text, as are most phrasings that use attribute names or values. When plain text makes something too ambiguous and you need some styling, use back ticks to indicate attributes or values (for example, a definition like: Reported when ` category ` is ` http ` ). Using this also sets us up for success if we implement styling in the UI definitions in the future. We should avoid links because those aren't visible in the query UI; the query UI only displays plain text. However, every attribute entry in the query UI does display a 'See attribute in docs' link that links to the complete and normally formatted docs site entry. This means that we can use links provided that they will display in an easy to understand way in the query UI. For example, here's an example of an attribute that would read clearly in plain text despite not having a link. We should avoid using a link format like \"For more information, see Create an alert condition\", because it wouldn't read well in plain text, and would choose something like \"For more information, see our alert condition docs.\" Using units of measurement Attribute entries have an optional unit of measurement field in the front matter. For example, here the front matter for an attribute with a percent unit of measurement: --- name: cpuPercent type: attribute units: percentage (%) events: - ProcessSample --- Copy What unit of measurement to select for an attribute is sometimes obvious, like if the attribute value is measured in milliseconds (units: milliseconds (ms)) or seconds (units: seconds (s)) or a percentage (units: percentage (%)). We also have several units of measurement that are not obvious, like count, enum, rate, and ID. (Technically, these aren't actually \"units of measurement\" and are more just conceptual data types but we're doing it this way as a workaround so you can ignore the fact that units of measurement isn't actually accurate.) The main reason we want to specify this information is that this will control what kinds of queries or charts can be created or auto-suggested by New Relic. For example, the New Relic UI wouldn't want to auto-suggest a chart graphing the average of ID values because that wouldn't make any sense. So attributes with accurate units, such as data types, will help product provide more practical help/suggestions to customers in future. Here are some tips for the non-obvious unit types: count: This is a count of something, though not a count of time-based units. For a number to be a count, it must (a) only be capable of increasing during a given time/sampling period, and (b) have a theoretically uncapped range. This wouldn't be used for a count of time units; if it was a count of seconds, for example, you would just use 'seconds' as the unit of measurement. A couple of examples of a count: databaseCallCount threadConcurrency enum: enum is short for enumerated list. In other words, it is a specific range of numbers that represent other non-numeric elements. For example, an attribute that had HTTP error codes (404, 505, etc.) as possible values would be an enum. A range of numbers that represent color codes would be another example of an enum. (Theoretically, an enum can represent lists without numeric values but we have no need to categorize strings so we only care about numeric-value lists.) Example: httpResponsecode. rate: Use this for any rate (for example, count per second). These are typically for averaged rates over small units of time, like second or millisecond. We previously have used the unit of time for these attributes (for example, using seconds as the unit of measurement for a count per second rate), but now we want to use rate for these. This is necessary because the types of displays used for rates would be different than the types of displays used for a simpler duration/count measurement. Example: MySQL integration attribute db.innodb.dataReadBytesPerSecond, which has the definition \"Rate at which data is read from InnoDB tables in bytes per second.\" id: Use ID for any identification number attribute. Example: appId.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.7939,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Attribute <em>style</em> <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ". For more on that, see <em>Style</em>. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute <em>style</em> guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes"
      },
      "id": "6050b4da64441f84f1532199"
    },
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "46997b8327630e068987c09788cb6e5115896517",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/delete-document/",
      "published_at": "2021-09-01T21:35:11Z",
      "updated_at": "2021-09-01T21:35:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 253.80281,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "60422009e7b9d21bd22a07d4"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.86517,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "604220ec196a670d0ba83dd4"
    }
  ],
  "/docs/style-guide/article-templates/create-release-notes": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-09-01T22:03:08Z",
      "updated_at": "2021-08-20T14:51:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark Watermarks are customizible text backgrounds that indicate something special about a page. They look like large, faded text behind the doc's content. We used to insert watermarks in beta docs, but now we insert a custom callout. Here are some other examples of watermarks: Legacy, Deprecated, and NR ONLY). Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 586.02075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " <em>notes</em> This format includes specific fields for <em>release</em> <em>notes</em>. Users rely on <em>release</em> <em>notes</em> to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see <em>Create</em> <em>release</em> <em>notes</em>. What&#x27;s New posts This format includes specific fields"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/get-started/introduction-style-guide/",
      "sections": [
        "Introduction to the style guide",
        "Organize your doc to make it easier to read",
        "Use action-oriented titles",
        "Start the document with an introductory paragraph",
        "Keep documents short",
        "Use the New Relic voice",
        "Change doc titles and anchors",
        "Create and edit categories",
        "Start writing and editing docs"
      ],
      "published_at": "2021-09-01T21:50:48Z",
      "title": "Introduction to the style guide",
      "updated_at": "2021-04-12T11:26:22Z",
      "type": "docs",
      "external_id": "b0bfbe0b3791c4feb00fe86a41e49312cd9e82cd",
      "document_type": "page",
      "popularity": 1,
      "body": "We've written these guidelines to make it easier for you to contribute to our docs, as well as to give you some insight into how we think about good technical writing. We, the Tech Docs team, rely on your expertise to keep New Relic's documentation updated and useful. Thank you for your willingness to share your knowledge! Our style guide focuses on style and usage that's particular to our site. Our site follows American English conventions. For topics that aren't covered, please refer to the Microsoft Writing Style Guide (for guidelines on technical terminology) or the Chicago Manual of Style (for general writing and editing guidelines). Organize your doc to make it easier to read Consider these organization guidelines when thinking about the order of information in a doc. By following these guidelines, you'll make it easier for readers to skim and find what they need. How to organize information Comments Separate what and why from how. Define any necessary prerequisites, policies, or background information (the what and the why) before you step through the how (step-by-step procedures). Examples: Explain what the feature is and why it matters before telling readers how to use it. Describe any limitations with user permissions or subscription levels that would prevent them from using the feature. If the feature is available for any user or subscription level, don't bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting a procedure that they have everything they need. Front-load directions with context. Make sure readers know where they need to be, before telling them what to do. In general, use (select an app) to describe what users select from the product index. Examples: Go to one.newrelic.com > Explorer > (select an app or service). Select (account dropdown) > User preferences. On the command line, type gitk. Also, structure steps by front-loading context from the user's point of view. For example, instead of \"Go to x to do y,\" structure the step as \"To do y, go to x.\" Separate requirements from options. Example: Type the Email you use to sign in and to receive information from New Relic. Optional: Type additional user emails, separated by commas. Follow the \"five to nine\" guideline. Depending on the topic, organize the information so there is a maximum of five to nine chunks of information. For example, readers may start to get lost or overwhelmed after about five h2 sections or seven steps into a procedure. If you have more than nine h2 sections or steps, you might need to create an additional doc or procedure. Other organization tools to consider: Levels of headings Lists Collapsers Callouts Tables Code examples For more help section Use action-oriented titles Wherever possible, give your document or h2 heading a task- or action-oriented title. Focus on what users are trying to accomplish or the problem they're trying to solve. Use present-tense verbs, rather than \"-ing\" verbs. Quality Title example Bad The query history Okay View query history Good Query history: Create and edit NRQL queries Start the document with an introductory paragraph Unless the document is less than a single screen in length, begin with a brief paragraph that introduces the topic or summarizes the important points. Not sure where to start? Try writing all the content for your document first, and then add the introduction to the top to summarize your key points. Or use the introduction to expand on the text in your metaDescription in the metadata. Keep documents short The amount of content needed can help you decide whether you need one or more documents for the topic. If all of the document's contents apply directly to the title, then everything belongs in the same document. If several related sections could be logically split into individual documents, and the overall length of your document is more than about two screenfuls, split those sections into other documents. Be sure to include links to the related contents. If a large document needs to be broken into multiple smaller documents, consider whether they might be best grouped together in their own sub-category. Use the New Relic voice We strive for a voice that's approachable, expert, and visionary. Check out our voice guidelines for how to write content with these qualities. And keep in mind these essential writing tips that apply to any type of documentation. Guidelines Comments Be clear and direct. Remember to: Use present tense. Use active voice; avoid passive voice. Tell users what to do, not what they \"should\" do. If absolutely necessary, tell users what not to do in situations where unexpected results may occur. Whenever possible, provide an alternative suggestion when telling users what not to do. Example: Using active voice with an alternative suggestion for what not to do Do not use your config file to change this setting, because this could affect other processes. Instead, go to one.newrelic.com > APM > (select an app or service) > Settings > Application. Write to aid localization and translation. Do not use euphemisms, idioms, jargon, or slang. Use the same terms and wording consistently. If you need to include an abbreviation or acronym, spell it out the first time it appears in the document. Always take a moment to ask yourself whether people will really understand the terms you are using in the way you're using them. Change doc titles and anchors Because changes to doc titles, anchors, and redirects can break links to other docs, please create an issue to request these types of changes and we'll help you out with that. Create and edit categories Because changes to categories can affect large groups of docs at once, please create an issue to request these types of changes and we'll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see Create and edit content. To learn how to create and publish release notes, see Create release notes. To make it even easier to start a new doc, use templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 374.1057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Create</em> and edit categories",
        "body": " large groups of docs at once, please <em>create</em> an issue to request these types of changes and we&#x27;ll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see <em>Create</em> and edit content. To learn how to <em>create</em> and publish <em>release</em> <em>notes</em>, see <em>Create</em> <em>release</em> <em>notes</em>. To make it even easier to start a new doc, use templates."
      },
      "id": "60415293e7b9d262f32a07d7"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.77287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "This document describes how to change the title of a document and how to <em>create</em>, edit, and delete redirects. Procedures are the same for both standard docs (&quot;basic pages&quot;) and <em>release</em> <em>notes</em>. Caution Changing titles or updating redirects can <em>create</em> issues with finding content. If you need to change"
      },
      "id": "604220ec196a670d0ba83dd4"
    }
  ],
  "/docs/style-guide/article-templates/data-dictionary-style-guidelines": [
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "46997b8327630e068987c09788cb6e5115896517",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/delete-document/",
      "published_at": "2021-09-01T21:35:11Z",
      "updated_at": "2021-09-01T21:35:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 253.80269,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "60422009e7b9d21bd22a07d4"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.86505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "604220ec196a670d0ba83dd4"
    },
    {
      "sections": [
        "Agent API guide template",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Instrument asynchronous work",
        "Instrument calls to external services",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "{Add sections specific to the particular agent, such as Java’s “Obtain references to New Relic entities”}"
      ],
      "title": "Agent API guide template",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "cb11b9872d72d3b98e136e9e9209c7d6f409c38d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/agent-api-guide-template/",
      "published_at": "2021-09-01T21:48:01Z",
      "updated_at": "2021-07-09T00:05:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Introduction: This section will introduce the agent and the API in general terms. Talk about when a user would want the API, and alternatives to using the API (for example, instrumentation via XML file). Mention that the API is often unnecessary if your framework has “out of the box” support. Link to the root of your API reference, whether that is on-site or off-site. Warn the user that they need to be on the most recent agent version. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or “instruments”) the parent method in these transactions to measure your app’s overall performance, and collects transaction traces from long-running transactions for additional detail. For more information about transactions, see transaction and transaction trace. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Start timing a method New Relic is not instrumenting automatically... Create a new transaction. See [ link to reference or tutorial doc for startTransaction() equivalent] Stop timing a method after its work is completed... Stop a transaction. See [ link to reference or tutorial doc for stopTransaction() equivalent] Prevent a transaction from reporting to New Relic... Ignore the transaction. See [ link to reference or tutorial doc for ignoreTransaction() equivalent] Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don’t have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method... See [ link to reference doc or tutorial doc for createTracer() equivalent]. Enhance the metadata of a transaction Sometimes, the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example, the default name might not be helpful (perhaps it is causing a metric grouping issue), or you want to add custom attributes to your transactions so you can filter them in Insights. Use these methods when you want to change how New Relic instruments a transaction that’s already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction... See [ link to reference doc or tutorial doc for setTransactionName() equivalent]. Add metadata (such as your customer’s account name or subscription level) to your transactions... Use custom attributes. See [ link to reference doc or tutorial doc for addCustomParameter() equivalent]. Mark a transaction as a background job... See [ link to reference doc or tutorial doc for backgroundJob() equivalent]. Mark a transaction as a web transaction... See [ link to reference doc or tutorial doc for setRequestAndResponse() equivalent]. Prevent a transaction from affecting your [ Apdex score]... See [ link to reference doc for ignoreApdex() equivalent]. Instrument asynchronous work For supported frameworks, the agent usually detects async work and instruments it correctly. However, if your app uses another framework, or the default async instrumentation is inaccurate, you can explicitly connect async work using tokens and segments. If you want to... Do this... Trace an async method that New Relic is already instrumenting... See [ link to tutorial doc]. Trace an async method that New Relic is not instrumenting... See [ link to tutorial doc]. Instrument calls to external services Use these methods to collect data about your app’s connections to other apps or databases: If you want to... Do this... Time a call to an external resource (such as an external service, database server, or message queue)... Mark them as external after tracing them with [ link to reference doc or tutorial doc for startTransaction() equivalent]. See [ link to reference doc or tutorial doc for reportAsExternal() equivalent]. Connect activity to another app instrumented by a New Relic agent... Use cross application tracing. See [ link to reference doc or tutorial doc for addOutboundRequestHeaders() equivalent] Time a custom transport channel, such as a proprietary RPC transport... See [ link to appropriate API methods or tutorial doc] Collect or ignore errors Usually, the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically... See [ link to reference doc or tutorial doc for noticeError() equivalent]. Prevent the agent from reporting an error at all... Mark the error as ignored. See [ link to config doc or tutorial doc for ignore_classes equivalent]. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic... Mark the error as expected. See [ link to config doc or tutorial doc for expected_classes equivalent]. Send custom event and metric data from your app New Relic APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in New Relic Insights... Create a custom event. See [ link to appropriate section of https://docs.newrelic.com/docs/insights/insights-data-sources/custom-dat... ] Tag your events with metadata to filter and facet them in Insights or error analytics... Add custom attributes. See [ link to reference or tutorial doc for addCustomAttribute() equivalent] Report custom performance data once a minute... Create a custom metric. See [ link to reference or tutorial doc for recordMetric() equivalent] { Add sections specific to the particular agent, such as Java’s “Obtain references to New Relic entities”}",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.84766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Agent API <em>guide</em> <em>template</em>",
        "sections": "Agent API <em>guide</em> <em>template</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "60441b8d196a67c4c6960f5e"
    }
  ],
  "/docs/style-guide/article-templates/graphql-api-tutorial-template": [
    {
      "sections": [
        "Add to data dictionary",
        "Data dictionary structure",
        "Add a new data type",
        "Add attributes",
        "Attribute style guidelines",
        "Using units of measurement"
      ],
      "title": "Add to data dictionary",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "32b8cab502883cc3443e54c86a0bd4021cc5a10f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/data-dictionary-style-guidelines/",
      "published_at": "2021-09-01T21:49:54Z",
      "updated_at": "2021-07-22T06:26:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use the data dictionary to provide information about data types (for example, Transaction, Metric, Log) and attached attributes. This is exposed in the New Relic query experience, on hovering over the data types and attributes. And we also expose the dictionary to the public. This doc contains info on how to add data to the dictionary. Note that currently we don't have infrastructure integration data in the dictionary. We also have very few attributes for the Metric data type, just a few basic default ones, despite there being many potential attributes attached to that data type depending on what the data source is. Data dictionary structure The data in the data dictionary is structured like this: Data types: sometimes called \"events\" for historical reasons, these are the NRDB data objects, like Transaction, Metric, Log, Span, etc. Attributes: these are key:value pairs attached to data types. One attribute can have multiple data types listed for it. For example, appName is on multiple data types. Data source: The New Relic product from which the data originates. With the current implementation, a data type must have a single data source assigned. This isn't ideal, as theoretically a data type can come from multiple sources. Add a new data type To add a new data type: Make a new folder in this directory, alongside the other directories: /docs-website/tree/develop/src/data-dictionary/events Copy Duplicate a data type file (for example, this Metric data type), place it in the new folder, and fill it out with the new info. For how to add attributes on a new data type, keep reading. Add attributes To add attributes: Our goal is to avoid adding redundant attributes entries, so you should first check to see if there's an existing attribute that has the same name and same general definition as the one you're trying to add. If it exists, edit that file to include the new data type (under events:). If an existing attribute is fairly close in definition but not exact, try to edit the definition so it works for all associated data types. If there is no existing attribute, create a new one. The easiest way is to copy an existing attribute file, edit all relevant fields to be accurate, and place it in the folder of the data type it's attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see Style. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute style guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes on this: Feel free to use sentence fragments. Feel free to edit definitions submitted from internal teams as sometimes their definitions will be overly long or have unneeded links. Some attributes are only present in some situations (for example, when a specific APM agent is used, or when a specific config option is true). We should avoid documenting most of these, with the idea that most customers will only care about the data because it's being reported for them, and won't care about the things that factor into the reasons why it wouldn't be reported. If it's thought that the addition would help customers who already have the data reporting understand the data better, you can include it. Write so it reads well as plain text. Details on this: Note that the docs site data dictionary has our usual docs styles available, but the query UI definitions have no styling available. This means that you should write definitions so that they are understandable without any styling, as plain text. You can often avoid any need for styling (for example, data types like Transaction are easy to understand as plain text, as are most phrasings that use attribute names or values. When plain text makes something too ambiguous and you need some styling, use back ticks to indicate attributes or values (for example, a definition like: Reported when ` category ` is ` http ` ). Using this also sets us up for success if we implement styling in the UI definitions in the future. We should avoid links because those aren't visible in the query UI; the query UI only displays plain text. However, every attribute entry in the query UI does display a 'See attribute in docs' link that links to the complete and normally formatted docs site entry. This means that we can use links provided that they will display in an easy to understand way in the query UI. For example, here's an example of an attribute that would read clearly in plain text despite not having a link. We should avoid using a link format like \"For more information, see Create an alert condition\", because it wouldn't read well in plain text, and would choose something like \"For more information, see our alert condition docs.\" Using units of measurement Attribute entries have an optional unit of measurement field in the front matter. For example, here the front matter for an attribute with a percent unit of measurement: --- name: cpuPercent type: attribute units: percentage (%) events: - ProcessSample --- Copy What unit of measurement to select for an attribute is sometimes obvious, like if the attribute value is measured in milliseconds (units: milliseconds (ms)) or seconds (units: seconds (s)) or a percentage (units: percentage (%)). We also have several units of measurement that are not obvious, like count, enum, rate, and ID. (Technically, these aren't actually \"units of measurement\" and are more just conceptual data types but we're doing it this way as a workaround so you can ignore the fact that units of measurement isn't actually accurate.) The main reason we want to specify this information is that this will control what kinds of queries or charts can be created or auto-suggested by New Relic. For example, the New Relic UI wouldn't want to auto-suggest a chart graphing the average of ID values because that wouldn't make any sense. So attributes with accurate units, such as data types, will help product provide more practical help/suggestions to customers in future. Here are some tips for the non-obvious unit types: count: This is a count of something, though not a count of time-based units. For a number to be a count, it must (a) only be capable of increasing during a given time/sampling period, and (b) have a theoretically uncapped range. This wouldn't be used for a count of time units; if it was a count of seconds, for example, you would just use 'seconds' as the unit of measurement. A couple of examples of a count: databaseCallCount threadConcurrency enum: enum is short for enumerated list. In other words, it is a specific range of numbers that represent other non-numeric elements. For example, an attribute that had HTTP error codes (404, 505, etc.) as possible values would be an enum. A range of numbers that represent color codes would be another example of an enum. (Theoretically, an enum can represent lists without numeric values but we have no need to categorize strings so we only care about numeric-value lists.) Example: httpResponsecode. rate: Use this for any rate (for example, count per second). These are typically for averaged rates over small units of time, like second or millisecond. We previously have used the unit of time for these attributes (for example, using seconds as the unit of measurement for a count per second rate), but now we want to use rate for these. This is necessary because the types of displays used for rates would be different than the types of displays used for a simpler duration/count measurement. Example: MySQL integration attribute db.innodb.dataReadBytesPerSecond, which has the definition \"Rate at which data is read from InnoDB tables in bytes per second.\" id: Use ID for any identification number attribute. Example: appId.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.79388,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Attribute <em>style</em> <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ". For more on that, see <em>Style</em>. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute <em>style</em> guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes"
      },
      "id": "6050b4da64441f84f1532199"
    },
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "46997b8327630e068987c09788cb6e5115896517",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/delete-document/",
      "published_at": "2021-09-01T21:35:11Z",
      "updated_at": "2021-09-01T21:35:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 253.80269,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "60422009e7b9d21bd22a07d4"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.86505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "604220ec196a670d0ba83dd4"
    }
  ],
  "/docs/style-guide/article-templates/landing-page-template": [
    {
      "sections": [
        "Update the home page",
        "Update a link's URL",
        "Add a new tile to the home page",
        "Add a new section to the home page"
      ],
      "title": "Update the home page",
      "type": "docs",
      "tags": [
        "home page",
        "landing pages"
      ],
      "external_id": "d637697a72493d8dbe0c9538e5b35f13f62d7474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/edit-homepage/",
      "published_at": "2021-09-01T19:07:14Z",
      "updated_at": "2021-04-11T08:27:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can't just hit the edit button docs.newrelic.com to make edits to the home page. The page that opens is index.js, the file that manages the parts of the home page, but not the content. It's rare that you'll need to make changes to this file. Most home page changes will be to add a new tile or section to the page, or update links. These types of changes are handled in two files: src/data/homepage.yml - contains home page section titles, section descriptions, and the URLs for tiles. src/i18n/translations/en/translation.json - contains tile info, including the title and short description of tiles. Update a link's URL Change or add new links using homepage.yml. In homepage.yml, search for the link you want to change. Edit the URL, save, commit, and PR the change. Add a new tile to the home page You'll make changes to both homepage.yml and translations.json On the translations.json doc, find the spot where you want to add the new tile (which section, and in what order you want it to appear), and add a new entry with this format: \"t#\": { \"title\": \"tile name\", \"description\": \"Short description.\" }, Copy Make sure you update the number on the tile. If you want to insert it in the middle of a group, update all the subsequent tile numbers as well. Save the file. Open homepage.yml, find the spot where the new tile will be, and add a new line with the relative link for the new tile. For example, - /docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster Save and check that your new tile builds properly on a local build. Commit, push, PR when you're ready. Add a new section to the home page On the translations.json page, add a new section modeled in the spot where you want the new section to appear. Include at least one title. For example, here's the TDP entry, with one tile: \"tdp\": { \"title\": \"Telemetry Data Platform\", \"description\": \"Ingest, visualize, and alert on all your telemetry data in one place.\", \"t1\": { \"title\": \"Introduction to Telemetry Data Platform\", \"description\": \"How to manage all your monitoring in one place.\" }, Copy When you're done creating the info, save the file. In the homepage.yml page, find the corresponding location for the new section, and add the short name you provided in the translation.json file, title, description, and tile URLs. For example, here's the corresponding TDP section on homepage.yml. tdp: title: Telemetry Data Platform description: Ingest, visualize, and alert on all your telemetry data in one place. tiles: - /docs/data-ingest-apis/get-data-new-relic/getting-started/get-started-telemetry-data-platform Copy Save, build locally, commit, PR.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.50253,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update the home <em>page</em>",
        "sections": "Update the home <em>page</em>",
        "tags": "<em>landing</em> <em>pages</em>",
        "body": "You can&#x27;t just hit the edit button docs.newrelic.com to make edits to the home <em>page</em>. The <em>page</em> that opens is index.js, the file that manages the parts of the home <em>page</em>, but not the content. It&#x27;s rare that you&#x27;ll need to make changes to this file. Most home <em>page</em> changes will be to add a new tile"
      },
      "id": "6072b300e7b9d231b2a5c663"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-09-01T22:03:08Z",
      "updated_at": "2021-08-20T14:51:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark Watermarks are customizible text backgrounds that indicate something special about a page. They look like large, faded text behind the doc's content. We used to insert watermarks in beta docs, but now we insert a custom callout. Here are some other examples of watermarks: Legacy, Deprecated, and NR ONLY). Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.02261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Page</em> <em>templates</em>",
        "body": "Our Docs site is made up of different content types and templates. Most of the time, the default <em>page</em> content type and the basic <em>template</em> will have everything you&#x27;ll need. Read on for more information about our <em>page</em> types. Docs meta content (frontmatter) Thr top of every doc begins with a set"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "image": "https://docs.newrelic.com/static/e8d42feaa627a4f1abd362c85a07596d/c1b63/example-doc-in-folder.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/understand-edit-docs-site-structure/",
      "sections": [
        "Understand and edit docs site structure (nav file, sidebar, categories)",
        "Terms",
        "Understand how the docs site structure works",
        "How is the displayed structure related to the actual folders?",
        "What determines a doc's URL?",
        "What does a nav file do?",
        "Where is the docs site structure exposed?",
        "What determines a doc's sidebar?",
        "When you click a sidebar category, what determines how that category view displays?",
        "Nav file format",
        "Tip",
        "Procedures",
        "Add a new category",
        "Add a new nav file",
        "Add a new category to a nav file",
        "Add a doc to sidebar/nav-file",
        "Add doc in multiple sidebar locations",
        "Move docs to other categories",
        "Move docs using nav file",
        "Move docs between folders",
        "Move or delete a folder",
        "Create a \"dummy\" sub-category of docs that don't live in that category",
        "Make a sidebar category heading clickable",
        "Troubleshoot category views not working correctly"
      ],
      "published_at": "2021-09-01T21:52:39Z",
      "title": "Understand and edit docs site structure (nav file, sidebar, categories)",
      "updated_at": "2021-09-01T04:18:46Z",
      "type": "docs",
      "external_id": "5498c89c5d5497ac899f70f86bb8bf0cda4bc840",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc contains information and procedures pertaining to the structure of the docs site, including: the nav files, the sidebar, docs category (index) views, and more. For succinct instructions, see Procedures, but it is highly recommended you understand the general concepts of how the docs site structure works if you will be doing larger docs site projects. Terms When talking about the docs site structure, sometimes people use different words for the same things. Below is a list of terms that can help us communicate about the docs site structure: Nav files: In the github docs site, there are yaml files under the nav folder that are used to determine the docs site structure that we display. This structure is exposed in the docs site left sidebar and when you view docs category views (also known as index views, like this one). Folder: We sometimes use \"folders\" to refer to the actual docs site folder structure (those folders and files in the content section). This is a way to differentiate between the actual folder structure and the displayed structure that's set using the nav files. Sidebar: On public-facing docs, the sidebar is what is visible on the left hand side, showing the structure of that category of docs. The sidebar and index view are both determined by the structure set in the nav file. Category or subcategory: we use these words a bit interchangeably to refer to the various levels of docs site categories. For example, this view shows a list of docs in a specific category, as does this higher level category view. Index: In this context, an \"index\" is sometimes used to refer to a view of a certain category of docs (like this one). \"Index\" and \"category\" can be used a bit interchangably, but the gist is that the \"index\" term refers to a docs category being displayed in a page load. (Note that this is a different, more general use of the term than the index.mdx files that are used to build landing pages.) Understand how the docs site structure works This section will explain some of the logic behind how the docs site structure is determined and how the structure we display to the public relates to the actual docs folder structure. How is the displayed structure related to the actual folders? The actual docs folder structure (the folders and mdx files in the content folder) is entirely separate from the docs site structure that we display (e.g., the structure shown in the sidebar and category views like this one). The displayed structure of the docs site is determined solely by the nav files (the yaml-format files in the nav folder). It's important to understand the above point. The divergence of the docs folder structure and the displayed docs site structure is necessary: we need a way to control the displayed site structure, which is used for the sidebar and category views, without requiring us to keep the folder structure and folder names and doc file names completely parallel and matching. Because these two things are so separate, it means we have some fairly complex behind-the-scenes logic to get them to work together. And this means that there can be fairly unintuitive aspects of how that logic works. We do have procedures for common use cases, but it will help you a lot to understand the specifics below of how the displayed structure is generated. What determines a doc's URL? Where a doc file (mdx file) is located in the content folder, and the associated folder and file names, are the only factors that govern that doc's URL. For example, consider the following doc file automated-user-provisioning-single-sign.mdx: This doc's URL is solely based on its folder location and the names of the folders. In this case, its URL is: docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign Copy This has important implications, including: When you move a doc from one folder to another, its URL changes, and this means that you will have to add a redirect to that doc of its original URL. If you rename an mdx file name or a folder name, that changes its URL, so that means you would have to add a redirect to that doc for its original URL. What does a nav file do? The nav files are quite simple. A nav file controls these things: The docs structure (the various levels of docs) for that category of docs. The category headers, set by title (e.g., \"On-host integrations list\") and path (e.g., \"/docs/integrations/on-host-integrations\"). The doc information, set by title (e.g., \"NGINX integration\") and path (the doc's URL). A category and a doc in a nav file have the same elements: a title and a `path. What separates a category from a doc is that: A category contains docs in the level below it. If a category has a path (which isn't required but should be present for most docs), the path points to a content docs folder that has at least one doc in it. For more on nav file format, see Nav file format Where is the docs site structure exposed? The structure set in the nav files is exposed in two places: The left sidebar of a doc that shows the structure of that category. When a category header in the sidebar is clicked, it shows a view of that docs site category. Doc category views, also sometimes called index views: for example, this view, which shows a particular section of docs. What determines a doc's sidebar? As stated above, the sidebar is just one way that the docs site structure governed by the nav files is exposed. When a doc is loaded, the docs site searches for that URL in the nav files. If it finds a match, it displays that nav file in the sidebar with that doc highlighted. If it finds that doc in more than one nav file, it attempts to find the right nav file by choosing the nav that matches the top level category in the doc URL. For example, if a doc with a relative URL /docs/accounts/accounts-billing/account-setup/create-your-new-relic-account was in two nav files, the docs site code would search to see if one of the nav files has docs/accounts as its first path field. If it finds a match, it uses that nav file. For an example of a doc that is placed in two different nav files, in this category view click the Manage data doc and see how, when it loads, it displays the sidebar for the nav file that better matches its URL. When you click a sidebar category, what determines how that category view displays? When you click on a docs category header in the sidebar and a docs category view loads (like this one), what governs what is displayed there? Here is how this process works: A category header in the sidebar has an associated URL, which is set in the nav file. In the example nav file snippet below, the Get started category view has a path set to /docs/apis/intro-apis. This is what governs the sidebar heading title of \"Get started\" and tells it the URL to use. - title: APIs path: /docs/apis pages: - title: Get started path: /docs/apis/intro-apis pages: - title: New Relic APIs path: /docs/apis/intro-apis/introduction-new-relic-apis - title: API keys path: /docs/apis/intro-apis/new-relic-api-keys Copy If the associated folder of that path has an index mdx file (representing a landing page, like this one), the docs site displays that landing page. If there is no landing page, we check to see if that path matches an actual folder that has at least one mdx file. In other words, if we instead put in a completely arbitrary URL path for a category path, like docs/random-category/random-category-2, it would not work. It requires an existing folder with at least one doc in there. Other aspects to consider: Note that a category doesn't need a path link in the nav file; that is just what tells it to create a link and a URL for that view. If a category in a nav file lacks a path, it won't have a link or associated URL for it (for an example, see the \"New Relic University\" category in this section). Having a category without an associated link/URL can be an acceptable choice if you are creating a category of docs that don't reside in that section and you simply want to give a helpful category view in the sidebar. Note that every URL based on actual folder structure can create a theoretical URL. For example, here's a URL based on an actual folder containing one doc. But because there is no path in a nav file corresponding to that URL, it doesn't display anything. Nav file format Below is a snippet of the agents.yml nav file. Note that the file has indentation that corresponds to the level of the navigation hierarchy. When making changes or creating a new nav file, be sure to use the existing spacing format. yml title: Agents path: /docs/agents pages: - title: Manage APM agents path: /docs/agents/manage-apm-agents pages: - title: Agent data path: /docs/agents/manage-apm-agents/agent-data pages: - title: Real time streaming path: /docs/agents/manage-apm-agents/agent-data/real-time-streaming - title: Custom instrumentation path: /docs/agents/manage-apm-agents/agent-data/custom-instrumentation - title: Agent attributes path: /docs/agents/manage-apm-agents/agent-data/agent-attributes - title: Custom events path: /docs/agents/manage-apm-agents/agent-data/collect-custom-events - title: Custom metrics path: /docs/agents/manage-apm-agents/agent-data/collect-custom-metrics - title: Manage errors path: /docs/agents/manage-apm-agents/agent-data/manage-errors-apm-collect-ignore-or-mark-expected - title: Link Kubernetes path: /docs/agents/manage-apm-agents/agent-data/link-your-applications-kubernetes - title: App naming pages: - title: Name your application path: /docs/agents/manage-apm-agents/app-naming/name-your-application - title: Use multiple names for an app path: /docs/agents/manage-apm-agents/app-naming/use-multiple-names-app Copy Tip Navigation nesting is currently limited to a maximum of six levels deep. Please reach out to the engineering team if that is not enough. Here are important elements of the nav file: Key Required? Description title yes The text shown in the navigation, either of a doc or a category. path yes The URL path to the doc or the category view. Do not use trailing slashes. For docs categories in the nav file, the path is required to create an index view. Without the path, a docs category won't be clickable as a link and won't display a view of those docs. Learn more about index views. rootNav no rootNav controls whether a nav file will be displayed or hidden on the docs site home page. It is enabled by default. If you want to hide a category from the home page (as we do for our style guide docs, for example), you would set this to false, as shown below: title: Style guide path: /docs/style-guide rootNav: false Copy children no This is hardly ever used. It indicates a sub-navigation node. Procedures Below are instructions for several common procedures. It may help you to review the terms we use before starting a procedure. Procedures include: Add a new category Add a doc to sidebar/nav-file Move docs between folders or categories Move or delete folders Create a \"dummy\" category for docs that don’t live in that area Make a category heading clickable Troubleshoot messed up category views Add a new category We'll explain two procedures: adding a subcategory of docs in an existing nav file, and adding an entirely new nav file. Add a new nav file Adding an entirely new nav file should be rare, and something we only do occasionally during large overhauls of site structure. To add an entirely new nav file: Copy an existing file nav file, or create a new nav file. Customize the new nav file with the categories and docs you want, using the structure of existing nav files as a template. For more on structure, see nav format. Tip You need at least one level of nesting inside the nav file. Without that, doc titles in the auto-generated category views will render as H2 headings. For example, src/content/level-one/level-two/doc will work, but src/content/level-one/doc will produce strange formatting. If you don't want your new nav to appear on the main landing page, add rootNav: false to your .yml file. (For an example of this, see src/nav/style-guide.yml.) Add a new category to a nav file To add a new category to a nav file: In an existing nav file, add a new category, represented by its title and path. If you're adding a path for that category (recommended), it must use the URL of an existing folder with at least one mdx file in it. Add the docs you want in that section. Ensure your new content matches the indenting of the surrounding nav file. To learn more about how this works, see: How a doc's sidebar is determined How a doc category view is determined If a category view isn't clickable, see Make category view clickable. Add a doc to sidebar/nav-file Once you create a doc, you need to place it in one or more nav files. To do this: In the nav file location where you want to locate it, add the title (its short title displayed in the sidebar and category views) and the path, which is the doc's URL. Ensure that you've emulated the indenting based on the surrounding nav file content or other nav files. Add doc in multiple sidebar locations To add a doc in more than one sidebar location, simply add that doc (its title and path) wherever you want it to be in the nav file. For more on how the sidebar is determined for docs in multiple nav files, see Sidebar. You can add a doc URL in multiple nav file locations. Move docs to other categories Because the nav file and the actual folder structure aren't connected, there are two different ways to \"move docs\": Move a doc in the nav files: preferred and most common procedure. Move a doc between folders: less frequent, mainly when doing larger projects where we want to do a significant overhaul of the docs structure and want to ensure the folder structure doesn't become too divergent from the nav file structure. Move docs using nav file You would move a doc in the nav file when you want to change its location in the displayed docs site structure (i.e., the sidebar and docs category views). To move a doc from one place to another in the nav file: In the first nav file, copy the two rows representing that doc's entry (the title and path lines) and paste that content into the place you want it to live in the new nav file. In the new nav file section, make sure that new content is aligned properly with the surrounding nav file content. See [#nav-format] for more about nav file structure. Move docs between folders Note that moving docs between the folders should be relatively rare. The main reasons to do this are when the folder structure and nav file structure are becoming very different, which can be bad for a couple reasons: Too much divergence can create issues with category view displays or sidebar actions. Too much divergence can make finding and editing docs harder, so there can be value to keeping things fairly up to date and parallel. When you move a doc between folders or rename a doc, that changes its URL. Similarly, if you rename a folder, that changes the URL of all docs in that area. To move a doc between folders: Get the current URL of the doc you want to move and add that URL to its own list of redirects. Tips: One way to do this in VSCode is to right click the file and click \"Get relative path\". If you are moving many files, ask the team about ways to programmatically add redirects. Remove the trailing slash. Move the doc to the new folder. Update nav files with the new URL. This is easily overlooked but having the correct doc URL in the nav file, and not a redirect, is important. Note that a doc URL may be in more than one nav file so searching the site for that URL can help. Move or delete a folder Sometimes when we are doing a larger restructuring project, we may want to move or delete the actual folders instead of simply editing the nav files. If you are moving an entire folder or multiple folders to another folder, docs and all: Simply move these folders using your preferred method (e.g., using drag and drop) to the new location. Next, because that move changes all the URLs of the docs and categories, you'll need to add redirects: For adding redirects for docs, see the procedures for moving a doc between folders. For category redirects: For the section of the nav file affected by your folder editing, gather all the category URLs (path fields) that relate to the moved or deleted folders. We don't need to redirect all folder-related URL paths: we only need to redirect the nav file paths because those represent the paths that we actually link to in the docs (in other words: we aren't using folder-based URLs if they don't have a nav file path). Add those category path URLs as redirects in specific docs or, if that won't work, in the taxonomy-redirects file. We should aim to add category redirects in specific docs and the reason for this is that the taxonomy-redirects file is hard to use and because it's a better customer experience to land on a doc versus a category if possible. In most cases, you'll be able to find a fitting doc to redirect to but if only a category view makes sense, use the taxonomy redirects file. For larger projects, this can be tough work, so you'll want to check out the build and make sure all the sidebar links and category headers are working as expected. For deleting folders, you'll want to essentially follow the same steps as above: either moving or deleting the docs in those folders first, gathering the affected category path URLs and adding them as redirects, adn then deleting the empty folders. Create a \"dummy\" sub-category of docs that don't live in that category Sometimes you want to create a category of docs that is there to help expose a related doc or set of docs. For example, in this view, we have added a category for 'New Relic University' even though that's not a doc that lives in that section; in this case, it's not even a doc on our site. In the example above, this 'New Relic University' category header is in regular text and not a link, and that's because it doesn't have a path set for it in the nav file. This also means that in the sidebar, this category header is not a clickable link and simply functions as a collapser/expander. This is acceptable if you don't mind it but below we explain how you can get a clickable category if you need it. To create a so-called \"dummy\" category: Add the category structure you want in the nav file. If you're okay not having a clickable category header, your new category doesn't require a path. If you want a clickable category header, you will need to use or create a folder that matches the new category path and that has at least one mdx file in it (details). In the nav file, add the title and path information for the docs you want in that new category. Test your new category to ensure it is working correctly. Make a sidebar category heading clickable If there's a sidebar category that's only acting as an expander/collapser and doesn't have a link, that's because it either a) doesn't have a path set in the nav file, or b) that path goes to a folder that doesn't have a doc in it. For more on this, see the instructions regarding clickable headers in the \"dummy\" category section. Troubleshoot category views not working correctly If a docs category view is not working correctly, review how category views are formed. If this does happen, get another opinion from another tech writer to make sure you're not missing something, as we should rarely have problems. One reason that a category view might not work is specifically for path URLs that are also landing pages. In this case, if that path is used in more than one location in the same nav file, the docs site can be confused about which category view to use. We may fix this with a coding fix but in meantime: consider pointing to other URLs and not that path, so that there's only one use of that path per nav file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.58472,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " displayed in a <em>page</em> load. (Note that this is a different, more general use of the term than the index.mdx files that are used to build <em>landing</em> pages.) Understand how the docs site structure works This section will explain some of the logic behind how the docs site structure is determined and how"
      },
      "id": "612eff27e7b9d25b16b6f24c"
    }
  ],
  "/docs/style-guide/article-templates/troubleshooting-docs-guide": [
    {
      "sections": [
        "Add to data dictionary",
        "Data dictionary structure",
        "Add a new data type",
        "Add attributes",
        "Attribute style guidelines",
        "Using units of measurement"
      ],
      "title": "Add to data dictionary",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "32b8cab502883cc3443e54c86a0bd4021cc5a10f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/data-dictionary-style-guidelines/",
      "published_at": "2021-09-01T21:49:54Z",
      "updated_at": "2021-07-22T06:26:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use the data dictionary to provide information about data types (for example, Transaction, Metric, Log) and attached attributes. This is exposed in the New Relic query experience, on hovering over the data types and attributes. And we also expose the dictionary to the public. This doc contains info on how to add data to the dictionary. Note that currently we don't have infrastructure integration data in the dictionary. We also have very few attributes for the Metric data type, just a few basic default ones, despite there being many potential attributes attached to that data type depending on what the data source is. Data dictionary structure The data in the data dictionary is structured like this: Data types: sometimes called \"events\" for historical reasons, these are the NRDB data objects, like Transaction, Metric, Log, Span, etc. Attributes: these are key:value pairs attached to data types. One attribute can have multiple data types listed for it. For example, appName is on multiple data types. Data source: The New Relic product from which the data originates. With the current implementation, a data type must have a single data source assigned. This isn't ideal, as theoretically a data type can come from multiple sources. Add a new data type To add a new data type: Make a new folder in this directory, alongside the other directories: /docs-website/tree/develop/src/data-dictionary/events Copy Duplicate a data type file (for example, this Metric data type), place it in the new folder, and fill it out with the new info. For how to add attributes on a new data type, keep reading. Add attributes To add attributes: Our goal is to avoid adding redundant attributes entries, so you should first check to see if there's an existing attribute that has the same name and same general definition as the one you're trying to add. If it exists, edit that file to include the new data type (under events:). If an existing attribute is fairly close in definition but not exact, try to edit the definition so it works for all associated data types. If there is no existing attribute, create a new one. The easiest way is to copy an existing attribute file, edit all relevant fields to be accurate, and place it in the folder of the data type it's attached to (for example, Transaction). When writing an attribute, try to keep it as concise as possible, and avoid using links. For more on that, see Style. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute style guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes on this: Feel free to use sentence fragments. Feel free to edit definitions submitted from internal teams as sometimes their definitions will be overly long or have unneeded links. Some attributes are only present in some situations (for example, when a specific APM agent is used, or when a specific config option is true). We should avoid documenting most of these, with the idea that most customers will only care about the data because it's being reported for them, and won't care about the things that factor into the reasons why it wouldn't be reported. If it's thought that the addition would help customers who already have the data reporting understand the data better, you can include it. Write so it reads well as plain text. Details on this: Note that the docs site data dictionary has our usual docs styles available, but the query UI definitions have no styling available. This means that you should write definitions so that they are understandable without any styling, as plain text. You can often avoid any need for styling (for example, data types like Transaction are easy to understand as plain text, as are most phrasings that use attribute names or values. When plain text makes something too ambiguous and you need some styling, use back ticks to indicate attributes or values (for example, a definition like: Reported when ` category ` is ` http ` ). Using this also sets us up for success if we implement styling in the UI definitions in the future. We should avoid links because those aren't visible in the query UI; the query UI only displays plain text. However, every attribute entry in the query UI does display a 'See attribute in docs' link that links to the complete and normally formatted docs site entry. This means that we can use links provided that they will display in an easy to understand way in the query UI. For example, here's an example of an attribute that would read clearly in plain text despite not having a link. We should avoid using a link format like \"For more information, see Create an alert condition\", because it wouldn't read well in plain text, and would choose something like \"For more information, see our alert condition docs.\" Using units of measurement Attribute entries have an optional unit of measurement field in the front matter. For example, here the front matter for an attribute with a percent unit of measurement: --- name: cpuPercent type: attribute units: percentage (%) events: - ProcessSample --- Copy What unit of measurement to select for an attribute is sometimes obvious, like if the attribute value is measured in milliseconds (units: milliseconds (ms)) or seconds (units: seconds (s)) or a percentage (units: percentage (%)). We also have several units of measurement that are not obvious, like count, enum, rate, and ID. (Technically, these aren't actually \"units of measurement\" and are more just conceptual data types but we're doing it this way as a workaround so you can ignore the fact that units of measurement isn't actually accurate.) The main reason we want to specify this information is that this will control what kinds of queries or charts can be created or auto-suggested by New Relic. For example, the New Relic UI wouldn't want to auto-suggest a chart graphing the average of ID values because that wouldn't make any sense. So attributes with accurate units, such as data types, will help product provide more practical help/suggestions to customers in future. Here are some tips for the non-obvious unit types: count: This is a count of something, though not a count of time-based units. For a number to be a count, it must (a) only be capable of increasing during a given time/sampling period, and (b) have a theoretically uncapped range. This wouldn't be used for a count of time units; if it was a count of seconds, for example, you would just use 'seconds' as the unit of measurement. A couple of examples of a count: databaseCallCount threadConcurrency enum: enum is short for enumerated list. In other words, it is a specific range of numbers that represent other non-numeric elements. For example, an attribute that had HTTP error codes (404, 505, etc.) as possible values would be an enum. A range of numbers that represent color codes would be another example of an enum. (Theoretically, an enum can represent lists without numeric values but we have no need to categorize strings so we only care about numeric-value lists.) Example: httpResponsecode. rate: Use this for any rate (for example, count per second). These are typically for averaged rates over small units of time, like second or millisecond. We previously have used the unit of time for these attributes (for example, using seconds as the unit of measurement for a count per second rate), but now we want to use rate for these. This is necessary because the types of displays used for rates would be different than the types of displays used for a simpler duration/count measurement. Example: MySQL integration attribute db.innodb.dataReadBytesPerSecond, which has the definition \"Rate at which data is read from InnoDB tables in bytes per second.\" id: Use ID for any identification number attribute. Example: appId.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.79388,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Attribute <em>style</em> <em>guidelines</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": ". For more on that, see <em>Style</em>. If the attribute has one of the units of measurement we use (like units: percentage (%)), add that to the front matter. For info on units, see Units. Attribute <em>style</em> guidelines When adding or editing attributes, some things to keep in mind: Aim for concise descriptions. Notes"
      },
      "id": "6050b4da64441f84f1532199"
    },
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "46997b8327630e068987c09788cb6e5115896517",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/delete-document/",
      "published_at": "2021-09-01T21:35:11Z",
      "updated_at": "2021-09-01T21:35:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 253.80255,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "60422009e7b9d21bd22a07d4"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.86491,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "604220ec196a670d0ba83dd4"
    }
  ],
  "/docs/style-guide/get-started/introduction-style-guide": [
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "Child account",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "customer vs. user",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-09-01T21:56:16Z",
      "updated_at": "2021-09-01T21:56:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements Child account A parent account contains one or more child accounts. Child accounts were previously referred to as \"sub-accounts\". click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also [mouse over] #mouse-over). collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. customer vs. user When possible, use the second person you to form a sense of connection with the reader. For times when you need a descriptive third-person noun, keep the following guidelines in mind: customer and user are both appropriate depending on context. customer makes more sense when talking about billing, or about a group of people or a business entity. For example, one customer may have one or more individual users who interact with New Relic through the customer's account(s). user makes more sense as a general term for an individual user, or when talking about users as an object in the account model. For example, when discussing account models, it's important to be specific about what constitutes a single person identity in our system. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account We previously used \"master account\" and \"sub-account\" but now we use parent account and child account. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account New Relic organizations can have a parent/child account structure. This is more important for our original account/user model but still plays a role for some behind-the-scenes features on our New Relic One account/user model. Learn more about account structure. Parent accounts were previously referred to as master accounts, and there are still some uses of this in the codebase. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of browser monitoring docs. Often abbreviated as RUM, this is a generic industry term for browser monitoring. New Relic refers to this as page load timing or browser monitoring. Use this term only for SEO or clarification, not to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.642,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>introduction</em>",
        "tags": "Basic <em>style</em> <em>guide</em>",
        "body": "You can use this dictionary to <em>guide</em> your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft <em>Style</em> <em>Guide</em>, but we&#x27;ll use Chicago Manual of <em>Style</em> in a pinch. We also follow American English"
      },
      "id": "60421ec1196a676986a83d87"
    },
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution (callout-caution)",
        "Caution",
        "Important (callout-important)",
        "Important",
        "Tip (callout-tip)",
        "Tip",
        "User-related permissions",
        "Pricing (callout-pricing) Do not use.",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c8337fb61ea2576fe138fe4540929e67d501ce2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/callouts/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-20T14:36:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts Here's an example of the callout format: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy On our Docs site, we use these callout classes: Caution (callout-caution) Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use the callout-caution class. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important (callout-important) Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use the callout-important class. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip (callout-tip) Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use the callout-tip class. At a traffic light, a Tip would be a green light. Tip If you have integrated your New Relic account with a ticketing system such as Lighthouse, Pivotal Tracker, or Atlassian JIRA, you can use the note to file a ticket or story. User-related permissions For recommended wording, see User-related language and styles. Pricing (callout-pricing) Do not use. Pricing callouts let you know that you may need a specific subscription level in order to access the product or feature. Pricing callouts use the callout-pricing class. Typically, pricing callouts appear in the intro of a doc. See the example below for standard verbiage in the callout. With the new pricing model, these are rarely used. Tip Access to this feature depends on your subscription level. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, no watermark is needed–just a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the Docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.22205,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "Basic <em>style</em> <em>guide</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    },
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "46997b8327630e068987c09788cb6e5115896517",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/delete-document/",
      "published_at": "2021-09-01T21:35:11Z",
      "updated_at": "2021-09-01T21:35:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.73413,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "Tech writer <em>style</em> <em>guide</em>"
      },
      "id": "60422009e7b9d21bd22a07d4"
    }
  ],
  "/docs/style-guide/processes-procedures/delete-document": [
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 425.03995,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. <em>Procedures</em> are the same for both standard docs (&quot;basic pages&quot;) and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change"
      },
      "id": "604220ec196a670d0ba83dd4"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-09-01T22:03:08Z",
      "updated_at": "2021-08-20T14:51:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark Watermarks are customizible text backgrounds that indicate something special about a page. They look like large, faded text behind the doc's content. We used to insert watermarks in beta docs, but now we insert a custom callout. Here are some other examples of watermarks: Legacy, Deprecated, and NR ONLY). Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.3628,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " for product announcements. What&#x27;s New posts are created by PMM for larger announcements. They&#x27;re available in the docs site, but they&#x27;re also visible in the New Relic One UI. For more information, see What&#x27;s New <em>style</em> guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs <em>guide</em>."
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-09-01T22:03:08Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.10266,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures you would use the docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures&#x2F;images directory. If the images directory does"
      },
      "id": "604220ec196a67105da83dc2"
    }
  ],
  "/docs/style-guide/processes-procedures/docs-site-edit-checklist": [
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "46997b8327630e068987c09788cb6e5115896517",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/delete-document/",
      "published_at": "2021-09-01T21:35:11Z",
      "updated_at": "2021-09-01T21:35:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 426.61603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "60422009e7b9d21bd22a07d4"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 425.03995,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. <em>Procedures</em> are the same for both standard docs (&quot;basic pages&quot;) and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change"
      },
      "id": "604220ec196a670d0ba83dd4"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-09-01T22:03:08Z",
      "updated_at": "2021-08-20T14:51:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark Watermarks are customizible text backgrounds that indicate something special about a page. They look like large, faded text behind the doc's content. We used to insert watermarks in beta docs, but now we insert a custom callout. Here are some other examples of watermarks: Legacy, Deprecated, and NR ONLY). Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.3628,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " for product announcements. What&#x27;s New posts are created by PMM for larger announcements. They&#x27;re available in the docs site, but they&#x27;re also visible in the New Relic One UI. For more information, see What&#x27;s New <em>style</em> guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs <em>guide</em>."
      },
      "id": "6042220e64441f28b64e8843"
    }
  ],
  "/docs/style-guide/processes-procedures/edit-homepage": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-09-01T22:03:08Z",
      "updated_at": "2021-08-20T14:51:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark Watermarks are customizible text backgrounds that indicate something special about a page. They look like large, faded text behind the doc's content. We used to insert watermarks in beta docs, but now we insert a custom callout. Here are some other examples of watermarks: Legacy, Deprecated, and NR ONLY). Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 99.28689,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Page</em> templates",
        "body": " via the data dictionary service. For more information, see Work with attribute definition content type. <em>Landing</em> <em>pages</em> This format is for a more user-friendly and readable <em>landing</em> <em>page</em>, which replaces the standard taxonomy list views. For more information, see Working with <em>landing</em> <em>pages</em>. Release"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "image": "https://docs.newrelic.com/static/e8d42feaa627a4f1abd362c85a07596d/c1b63/example-doc-in-folder.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/understand-edit-docs-site-structure/",
      "sections": [
        "Understand and edit docs site structure (nav file, sidebar, categories)",
        "Terms",
        "Understand how the docs site structure works",
        "How is the displayed structure related to the actual folders?",
        "What determines a doc's URL?",
        "What does a nav file do?",
        "Where is the docs site structure exposed?",
        "What determines a doc's sidebar?",
        "When you click a sidebar category, what determines how that category view displays?",
        "Nav file format",
        "Tip",
        "Procedures",
        "Add a new category",
        "Add a new nav file",
        "Add a new category to a nav file",
        "Add a doc to sidebar/nav-file",
        "Add doc in multiple sidebar locations",
        "Move docs to other categories",
        "Move docs using nav file",
        "Move docs between folders",
        "Move or delete a folder",
        "Create a \"dummy\" sub-category of docs that don't live in that category",
        "Make a sidebar category heading clickable",
        "Troubleshoot category views not working correctly"
      ],
      "published_at": "2021-09-01T21:52:39Z",
      "title": "Understand and edit docs site structure (nav file, sidebar, categories)",
      "updated_at": "2021-09-01T04:18:46Z",
      "type": "docs",
      "external_id": "5498c89c5d5497ac899f70f86bb8bf0cda4bc840",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc contains information and procedures pertaining to the structure of the docs site, including: the nav files, the sidebar, docs category (index) views, and more. For succinct instructions, see Procedures, but it is highly recommended you understand the general concepts of how the docs site structure works if you will be doing larger docs site projects. Terms When talking about the docs site structure, sometimes people use different words for the same things. Below is a list of terms that can help us communicate about the docs site structure: Nav files: In the github docs site, there are yaml files under the nav folder that are used to determine the docs site structure that we display. This structure is exposed in the docs site left sidebar and when you view docs category views (also known as index views, like this one). Folder: We sometimes use \"folders\" to refer to the actual docs site folder structure (those folders and files in the content section). This is a way to differentiate between the actual folder structure and the displayed structure that's set using the nav files. Sidebar: On public-facing docs, the sidebar is what is visible on the left hand side, showing the structure of that category of docs. The sidebar and index view are both determined by the structure set in the nav file. Category or subcategory: we use these words a bit interchangeably to refer to the various levels of docs site categories. For example, this view shows a list of docs in a specific category, as does this higher level category view. Index: In this context, an \"index\" is sometimes used to refer to a view of a certain category of docs (like this one). \"Index\" and \"category\" can be used a bit interchangably, but the gist is that the \"index\" term refers to a docs category being displayed in a page load. (Note that this is a different, more general use of the term than the index.mdx files that are used to build landing pages.) Understand how the docs site structure works This section will explain some of the logic behind how the docs site structure is determined and how the structure we display to the public relates to the actual docs folder structure. How is the displayed structure related to the actual folders? The actual docs folder structure (the folders and mdx files in the content folder) is entirely separate from the docs site structure that we display (e.g., the structure shown in the sidebar and category views like this one). The displayed structure of the docs site is determined solely by the nav files (the yaml-format files in the nav folder). It's important to understand the above point. The divergence of the docs folder structure and the displayed docs site structure is necessary: we need a way to control the displayed site structure, which is used for the sidebar and category views, without requiring us to keep the folder structure and folder names and doc file names completely parallel and matching. Because these two things are so separate, it means we have some fairly complex behind-the-scenes logic to get them to work together. And this means that there can be fairly unintuitive aspects of how that logic works. We do have procedures for common use cases, but it will help you a lot to understand the specifics below of how the displayed structure is generated. What determines a doc's URL? Where a doc file (mdx file) is located in the content folder, and the associated folder and file names, are the only factors that govern that doc's URL. For example, consider the following doc file automated-user-provisioning-single-sign.mdx: This doc's URL is solely based on its folder location and the names of the folders. In this case, its URL is: docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign Copy This has important implications, including: When you move a doc from one folder to another, its URL changes, and this means that you will have to add a redirect to that doc of its original URL. If you rename an mdx file name or a folder name, that changes its URL, so that means you would have to add a redirect to that doc for its original URL. What does a nav file do? The nav files are quite simple. A nav file controls these things: The docs structure (the various levels of docs) for that category of docs. The category headers, set by title (e.g., \"On-host integrations list\") and path (e.g., \"/docs/integrations/on-host-integrations\"). The doc information, set by title (e.g., \"NGINX integration\") and path (the doc's URL). A category and a doc in a nav file have the same elements: a title and a `path. What separates a category from a doc is that: A category contains docs in the level below it. If a category has a path (which isn't required but should be present for most docs), the path points to a content docs folder that has at least one doc in it. For more on nav file format, see Nav file format Where is the docs site structure exposed? The structure set in the nav files is exposed in two places: The left sidebar of a doc that shows the structure of that category. When a category header in the sidebar is clicked, it shows a view of that docs site category. Doc category views, also sometimes called index views: for example, this view, which shows a particular section of docs. What determines a doc's sidebar? As stated above, the sidebar is just one way that the docs site structure governed by the nav files is exposed. When a doc is loaded, the docs site searches for that URL in the nav files. If it finds a match, it displays that nav file in the sidebar with that doc highlighted. If it finds that doc in more than one nav file, it attempts to find the right nav file by choosing the nav that matches the top level category in the doc URL. For example, if a doc with a relative URL /docs/accounts/accounts-billing/account-setup/create-your-new-relic-account was in two nav files, the docs site code would search to see if one of the nav files has docs/accounts as its first path field. If it finds a match, it uses that nav file. For an example of a doc that is placed in two different nav files, in this category view click the Manage data doc and see how, when it loads, it displays the sidebar for the nav file that better matches its URL. When you click a sidebar category, what determines how that category view displays? When you click on a docs category header in the sidebar and a docs category view loads (like this one), what governs what is displayed there? Here is how this process works: A category header in the sidebar has an associated URL, which is set in the nav file. In the example nav file snippet below, the Get started category view has a path set to /docs/apis/intro-apis. This is what governs the sidebar heading title of \"Get started\" and tells it the URL to use. - title: APIs path: /docs/apis pages: - title: Get started path: /docs/apis/intro-apis pages: - title: New Relic APIs path: /docs/apis/intro-apis/introduction-new-relic-apis - title: API keys path: /docs/apis/intro-apis/new-relic-api-keys Copy If the associated folder of that path has an index mdx file (representing a landing page, like this one), the docs site displays that landing page. If there is no landing page, we check to see if that path matches an actual folder that has at least one mdx file. In other words, if we instead put in a completely arbitrary URL path for a category path, like docs/random-category/random-category-2, it would not work. It requires an existing folder with at least one doc in there. Other aspects to consider: Note that a category doesn't need a path link in the nav file; that is just what tells it to create a link and a URL for that view. If a category in a nav file lacks a path, it won't have a link or associated URL for it (for an example, see the \"New Relic University\" category in this section). Having a category without an associated link/URL can be an acceptable choice if you are creating a category of docs that don't reside in that section and you simply want to give a helpful category view in the sidebar. Note that every URL based on actual folder structure can create a theoretical URL. For example, here's a URL based on an actual folder containing one doc. But because there is no path in a nav file corresponding to that URL, it doesn't display anything. Nav file format Below is a snippet of the agents.yml nav file. Note that the file has indentation that corresponds to the level of the navigation hierarchy. When making changes or creating a new nav file, be sure to use the existing spacing format. yml title: Agents path: /docs/agents pages: - title: Manage APM agents path: /docs/agents/manage-apm-agents pages: - title: Agent data path: /docs/agents/manage-apm-agents/agent-data pages: - title: Real time streaming path: /docs/agents/manage-apm-agents/agent-data/real-time-streaming - title: Custom instrumentation path: /docs/agents/manage-apm-agents/agent-data/custom-instrumentation - title: Agent attributes path: /docs/agents/manage-apm-agents/agent-data/agent-attributes - title: Custom events path: /docs/agents/manage-apm-agents/agent-data/collect-custom-events - title: Custom metrics path: /docs/agents/manage-apm-agents/agent-data/collect-custom-metrics - title: Manage errors path: /docs/agents/manage-apm-agents/agent-data/manage-errors-apm-collect-ignore-or-mark-expected - title: Link Kubernetes path: /docs/agents/manage-apm-agents/agent-data/link-your-applications-kubernetes - title: App naming pages: - title: Name your application path: /docs/agents/manage-apm-agents/app-naming/name-your-application - title: Use multiple names for an app path: /docs/agents/manage-apm-agents/app-naming/use-multiple-names-app Copy Tip Navigation nesting is currently limited to a maximum of six levels deep. Please reach out to the engineering team if that is not enough. Here are important elements of the nav file: Key Required? Description title yes The text shown in the navigation, either of a doc or a category. path yes The URL path to the doc or the category view. Do not use trailing slashes. For docs categories in the nav file, the path is required to create an index view. Without the path, a docs category won't be clickable as a link and won't display a view of those docs. Learn more about index views. rootNav no rootNav controls whether a nav file will be displayed or hidden on the docs site home page. It is enabled by default. If you want to hide a category from the home page (as we do for our style guide docs, for example), you would set this to false, as shown below: title: Style guide path: /docs/style-guide rootNav: false Copy children no This is hardly ever used. It indicates a sub-navigation node. Procedures Below are instructions for several common procedures. It may help you to review the terms we use before starting a procedure. Procedures include: Add a new category Add a doc to sidebar/nav-file Move docs between folders or categories Move or delete folders Create a \"dummy\" category for docs that don’t live in that area Make a category heading clickable Troubleshoot messed up category views Add a new category We'll explain two procedures: adding a subcategory of docs in an existing nav file, and adding an entirely new nav file. Add a new nav file Adding an entirely new nav file should be rare, and something we only do occasionally during large overhauls of site structure. To add an entirely new nav file: Copy an existing file nav file, or create a new nav file. Customize the new nav file with the categories and docs you want, using the structure of existing nav files as a template. For more on structure, see nav format. Tip You need at least one level of nesting inside the nav file. Without that, doc titles in the auto-generated category views will render as H2 headings. For example, src/content/level-one/level-two/doc will work, but src/content/level-one/doc will produce strange formatting. If you don't want your new nav to appear on the main landing page, add rootNav: false to your .yml file. (For an example of this, see src/nav/style-guide.yml.) Add a new category to a nav file To add a new category to a nav file: In an existing nav file, add a new category, represented by its title and path. If you're adding a path for that category (recommended), it must use the URL of an existing folder with at least one mdx file in it. Add the docs you want in that section. Ensure your new content matches the indenting of the surrounding nav file. To learn more about how this works, see: How a doc's sidebar is determined How a doc category view is determined If a category view isn't clickable, see Make category view clickable. Add a doc to sidebar/nav-file Once you create a doc, you need to place it in one or more nav files. To do this: In the nav file location where you want to locate it, add the title (its short title displayed in the sidebar and category views) and the path, which is the doc's URL. Ensure that you've emulated the indenting based on the surrounding nav file content or other nav files. Add doc in multiple sidebar locations To add a doc in more than one sidebar location, simply add that doc (its title and path) wherever you want it to be in the nav file. For more on how the sidebar is determined for docs in multiple nav files, see Sidebar. You can add a doc URL in multiple nav file locations. Move docs to other categories Because the nav file and the actual folder structure aren't connected, there are two different ways to \"move docs\": Move a doc in the nav files: preferred and most common procedure. Move a doc between folders: less frequent, mainly when doing larger projects where we want to do a significant overhaul of the docs structure and want to ensure the folder structure doesn't become too divergent from the nav file structure. Move docs using nav file You would move a doc in the nav file when you want to change its location in the displayed docs site structure (i.e., the sidebar and docs category views). To move a doc from one place to another in the nav file: In the first nav file, copy the two rows representing that doc's entry (the title and path lines) and paste that content into the place you want it to live in the new nav file. In the new nav file section, make sure that new content is aligned properly with the surrounding nav file content. See [#nav-format] for more about nav file structure. Move docs between folders Note that moving docs between the folders should be relatively rare. The main reasons to do this are when the folder structure and nav file structure are becoming very different, which can be bad for a couple reasons: Too much divergence can create issues with category view displays or sidebar actions. Too much divergence can make finding and editing docs harder, so there can be value to keeping things fairly up to date and parallel. When you move a doc between folders or rename a doc, that changes its URL. Similarly, if you rename a folder, that changes the URL of all docs in that area. To move a doc between folders: Get the current URL of the doc you want to move and add that URL to its own list of redirects. Tips: One way to do this in VSCode is to right click the file and click \"Get relative path\". If you are moving many files, ask the team about ways to programmatically add redirects. Remove the trailing slash. Move the doc to the new folder. Update nav files with the new URL. This is easily overlooked but having the correct doc URL in the nav file, and not a redirect, is important. Note that a doc URL may be in more than one nav file so searching the site for that URL can help. Move or delete a folder Sometimes when we are doing a larger restructuring project, we may want to move or delete the actual folders instead of simply editing the nav files. If you are moving an entire folder or multiple folders to another folder, docs and all: Simply move these folders using your preferred method (e.g., using drag and drop) to the new location. Next, because that move changes all the URLs of the docs and categories, you'll need to add redirects: For adding redirects for docs, see the procedures for moving a doc between folders. For category redirects: For the section of the nav file affected by your folder editing, gather all the category URLs (path fields) that relate to the moved or deleted folders. We don't need to redirect all folder-related URL paths: we only need to redirect the nav file paths because those represent the paths that we actually link to in the docs (in other words: we aren't using folder-based URLs if they don't have a nav file path). Add those category path URLs as redirects in specific docs or, if that won't work, in the taxonomy-redirects file. We should aim to add category redirects in specific docs and the reason for this is that the taxonomy-redirects file is hard to use and because it's a better customer experience to land on a doc versus a category if possible. In most cases, you'll be able to find a fitting doc to redirect to but if only a category view makes sense, use the taxonomy redirects file. For larger projects, this can be tough work, so you'll want to check out the build and make sure all the sidebar links and category headers are working as expected. For deleting folders, you'll want to essentially follow the same steps as above: either moving or deleting the docs in those folders first, gathering the affected category path URLs and adding them as redirects, adn then deleting the empty folders. Create a \"dummy\" sub-category of docs that don't live in that category Sometimes you want to create a category of docs that is there to help expose a related doc or set of docs. For example, in this view, we have added a category for 'New Relic University' even though that's not a doc that lives in that section; in this case, it's not even a doc on our site. In the example above, this 'New Relic University' category header is in regular text and not a link, and that's because it doesn't have a path set for it in the nav file. This also means that in the sidebar, this category header is not a clickable link and simply functions as a collapser/expander. This is acceptable if you don't mind it but below we explain how you can get a clickable category if you need it. To create a so-called \"dummy\" category: Add the category structure you want in the nav file. If you're okay not having a clickable category header, your new category doesn't require a path. If you want a clickable category header, you will need to use or create a folder that matches the new category path and that has at least one mdx file in it (details). In the nav file, add the title and path information for the docs you want in that new category. Test your new category to ensure it is working correctly. Make a sidebar category heading clickable If there's a sidebar category that's only acting as an expander/collapser and doesn't have a link, that's because it either a) doesn't have a path set in the nav file, or b) that path goes to a folder that doesn't have a doc in it. For more on this, see the instructions regarding clickable headers in the \"dummy\" category section. Troubleshoot category views not working correctly If a docs category view is not working correctly, review how category views are formed. If this does happen, get another opinion from another tech writer to make sure you're not missing something, as we should rarely have problems. One reason that a category view might not work is specifically for path URLs that are also landing pages. In this case, if that path is used in more than one location in the same nav file, the docs site can be confused about which category view to use. We may fix this with a coding fix but in meantime: consider pointing to other URLs and not that path, so that there's only one use of that path per nav file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 67.52375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " displayed in a <em>page</em> load. (Note that this is a different, more general use of the term than the index.mdx files that are used to build <em>landing</em> <em>pages</em>.) Understand how the docs site structure works This section will explain some of the logic behind how the docs site structure is determined and how"
      },
      "id": "612eff27e7b9d25b16b6f24c"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/landing-page-template/",
      "sections": [
        "Landing page template",
        "Important",
        "Front matter",
        "Tip",
        "Introduction section",
        "Tiles",
        "Button for viewing all docs in the category",
        "Code sample"
      ],
      "published_at": "2021-09-01T21:49:55Z",
      "title": "Landing page template",
      "updated_at": "2021-04-12T11:25:05Z",
      "type": "docs",
      "external_id": "c40093f49b3daaa82483e1f82228c53a3b12ad6c",
      "document_type": "page",
      "popularity": 1,
      "body": "Landing pages are a specialized type of page that serve as the starting pages for various New Relic products. For example, you'll see landing pages for Application monitoring (APM) and Browser monitoring. Important This landing page information does not apply to the docs home page. If you need to create a new landing page, you can either copy an existing landing page, or you can modify the sample landing page shown at the bottom. The next sections look at what you need to include for each landing page. Front matter When you insert the front matter, be sure to designate the type as landingPage. Here's an example: --- title: New Relic APM type: landingPage --- Copy Tip In the front matter, the following are optional: tags, translate, and redirects. So, you can leave them out if they don't have any values. Introduction section Following the front matter, the first content section is a two-column introduction (also called the hero section). This includes the following: A <LandingPageHero> component wrapping all the introductory content. A <HeroContent> component wrapping the text portion of the introduction (the content in the left column). An image or video (appears in the right column). A caption (optional), which is wrapped by the <figcaption> component. Here's an example of the hero section that shows you where to insert your content: <LandingPageHero> <HeroContent> INSERT_PARAGRAPHS_FOR_YOUR_INTRODUCTION </HeroContent> ![INSERT_ALT-TEXT_HERE](./images/INSERT_IMAGE_FILE_NAME.png \"INSERT_THE_IMAGE_TITLE_HERE\") <figcaption> INSERT_OPTIONAL_CAPTION_USING_SAME_INDENTATION_AS_IMAGE </figcaption> </LandingPageHero> Copy Tiles Tiles are a series of boxes after the introduction. They contain the main subject areas for your product. You should just list these in order you want them to appear, and the cascading style sheet will render them across the page. Here's an example of a tile: <LandingPageTileGrid> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE.\" href=\"/docs/INSERT_THE_DIRECTORY_PATH_TO_THE_TARGET_LANDING_PAGE_INDEX.HTML\" icon=\"fe-INSERT_THE_ICON_NAME\" > INSERT_TILE_CONTENT_HERE... </LandingPageTile> ... Copy For each tile, do the following: Insert a value for title that explains the purpose of the category. Insert a value for href that links to the target landing page. If the target landing page is index.html, you can just include the directory path with no filename since index.html is the default (it doesn't cause any problems if you include index.html). Insert a value for icon by prefixing the icon name with fe- (Feather icons), logo- (third-party logos), or nr- (New Relic logos). For example, here is the format for a feather icon: fe-alert-triangle). Tip For more details about icons, see Embed images. Between the LandingPageTile tags, insert text, such as a bullet list with links to product documentation. Button for viewing all docs in the category After your tiles, you should have a single button that offers to take users to all the documentation for that category. The table of contents page that gets linked here is always at the same path as the landing page, but with /table-of-contents appended to it. These table of contents pages get built automatically for every landing page. For example, if this landing page was located at /docs/apm, this link should be /docs/apm/table-of-contents. Here's an example: <ButtonLink role=\"button\" to=\"INSERT_LINK_TO_DIRECTORY_WITH_ALL_THESE_DOCS/table-of-contents\" variant=\"normal\" > View all INSERT_YOUR_CATEGORY_HERE docs </ButtonLink> Copy Code sample Here's a sample landing page you could modify to suit your needs: --- title: INSERT_YOUR_TITLE_HERE type: landingPage --- <LandingPageHero> <HeroContent> INSERT_PARAGRAPHS_FOR_YOUR_INTRODUCTION </HeroContent> ![INSERT_ALT-TEXT_HERE](./images/INSERT_IMAGE_FILE_NAME.png \"INSERT_THE_IMAGE_TITLE_HERE\") <figcaption> INSERT_OPTIONAL_CAPTION_USING_SAME_INDENTATION_AS_IMAGE </figcaption> </LandingPageHero> <LandingPageTileGrid> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * [INSERT_LINK_NAME](INSERT_LINK_URL) Aliquam auctor mattis nisl ut iaculis. * [INSERT_LINK_NAME](INSERT_LINK_URL) Suspendisse pharetra elit sit amet risus euismod, a consectetur tortor vulputate. </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) to lectus diam, ornare vitae dui suscipit, laoreet ultrices lacus. * Mauris tempor massa ac augue mattis, nec pharetra quam mollis [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) rhoncus tortor vitae libero laoreet feugiat. * Donec dui elit, fermentum vel faucibus sed, rhoncus in felis [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) uspendisse pharetra elit sit amet risus euismod. * Pellentesque finibus magna vitae hendrerit gravida [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) Etiam imperdiet felis eu ipsum consequat tristique. * Etiam imperdiet felis eu ipsum consequat tristique [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> <LandingPageTile title=\"INSERT_YOUR_BOX_TITLE_HERE\" icon=\"fe-INSERT_ICON_NAME_HERE\" > * Use [INSERT_LINK_NAME](INSERT_LINK_URL) Quisque hendrerit, dolor sed sodales aliquet. * Vestibulum varius lectus ac velit euismod [INSERT_LINK_NAME](INSERT_LINK_URL). </LandingPageTile> </LandingPageTileGrid> <ButtonLink role=\"button\" to=\"INSERT_LINK_TO_DIRECTORY_WITH_ALL_THESE_DOCS/table-of-contents\" variant=\"normal\" > View all INSERT_YOUR_CATEGORY_HERE docs </ButtonLink> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 61.100815,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Landing</em> <em>page</em> template",
        "sections": "<em>Landing</em> <em>page</em> template",
        "body": "<em>Landing</em> <em>pages</em> are a specialized type of <em>page</em> that serve as the starting <em>pages</em> for various New Relic products. For example, you&#x27;ll see <em>landing</em> <em>pages</em> for Application monitoring (APM) and Browser monitoring. Important This <em>landing</em> <em>page</em> information does not apply to the docs <em>home</em> <em>page</em>. If you need"
      },
      "id": "6042212a28ccbc283feba79d"
    }
  ],
  "/docs/style-guide/processes-procedures/embed-images": [
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "46997b8327630e068987c09788cb6e5115896517",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/delete-document/",
      "published_at": "2021-09-01T21:35:11Z",
      "updated_at": "2021-09-01T21:35:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 426.6158,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "60422009e7b9d21bd22a07d4"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 425.03973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. <em>Procedures</em> are the same for both standard docs (&quot;basic pages&quot;) and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change"
      },
      "id": "604220ec196a670d0ba83dd4"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-09-01T22:03:08Z",
      "updated_at": "2021-08-20T14:51:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark Watermarks are customizible text backgrounds that indicate something special about a page. They look like large, faded text behind the doc's content. We used to insert watermarks in beta docs, but now we insert a custom callout. Here are some other examples of watermarks: Legacy, Deprecated, and NR ONLY). Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.36273,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " for product announcements. What&#x27;s New posts are created by PMM for larger announcements. They&#x27;re available in the docs site, but they&#x27;re also visible in the New Relic One UI. For more information, see What&#x27;s New <em>style</em> guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs <em>guide</em>."
      },
      "id": "6042220e64441f28b64e8843"
    }
  ],
  "/docs/style-guide/processes-procedures/embed-videos": [
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "46997b8327630e068987c09788cb6e5115896517",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/delete-document/",
      "published_at": "2021-09-01T21:35:11Z",
      "updated_at": "2021-09-01T21:35:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 426.6156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "60422009e7b9d21bd22a07d4"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 425.03955,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. <em>Procedures</em> are the same for both standard docs (&quot;basic pages&quot;) and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change"
      },
      "id": "604220ec196a670d0ba83dd4"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-09-01T22:03:08Z",
      "updated_at": "2021-08-20T14:51:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark Watermarks are customizible text backgrounds that indicate something special about a page. They look like large, faded text behind the doc's content. We used to insert watermarks in beta docs, but now we insert a custom callout. Here are some other examples of watermarks: Legacy, Deprecated, and NR ONLY). Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.3627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " for product announcements. What&#x27;s New posts are created by PMM for larger announcements. They&#x27;re available in the docs site, but they&#x27;re also visible in the New Relic One UI. For more information, see What&#x27;s New <em>style</em> guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs <em>guide</em>."
      },
      "id": "6042220e64441f28b64e8843"
    }
  ],
  "/docs/style-guide/processes-procedures/rename-or-redirect-document": [
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "46997b8327630e068987c09788cb6e5115896517",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/delete-document/",
      "published_at": "2021-09-01T21:35:11Z",
      "updated_at": "2021-09-01T21:35:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 426.6156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "60422009e7b9d21bd22a07d4"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-09-01T22:03:08Z",
      "updated_at": "2021-08-20T14:51:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark Watermarks are customizible text backgrounds that indicate something special about a page. They look like large, faded text behind the doc's content. We used to insert watermarks in beta docs, but now we insert a custom callout. Here are some other examples of watermarks: Legacy, Deprecated, and NR ONLY). Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.3627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " for product announcements. What&#x27;s New posts are created by PMM for larger announcements. They&#x27;re available in the docs site, but they&#x27;re also visible in the New Relic One UI. For more information, see What&#x27;s New <em>style</em> guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs <em>guide</em>."
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-09-01T22:03:08Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.10266,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures you would use the docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures&#x2F;images directory. If the images directory does"
      },
      "id": "604220ec196a67105da83dc2"
    }
  ],
  "/docs/style-guide/processes-procedures/understand-edit-docs-site-structure": [
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.10585,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rename or redirect a <em>document</em>",
        "sections": "Rename or redirect a <em>document</em>",
        "tags": "Processes <em>and</em> procedures",
        "body": " a document title, change the title being used in the title field in the frontmatter at the top of the <em>doc</em>. If you want to update a title in the <em>sidebar</em>, change the title for that <em>doc</em> in the <em>nav</em> <em>file</em>. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser"
      },
      "id": "604220ec196a670d0ba83dd4"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-09-01T22:03:08Z",
      "updated_at": "2021-08-20T14:51:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark Watermarks are customizible text backgrounds that indicate something special about a page. They look like large, faded text behind the doc's content. We used to insert watermarks in beta docs, but now we insert a custom callout. Here are some other examples of watermarks: Legacy, Deprecated, and NR ONLY). Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.79762,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "<em>Docs</em> meta content (frontmatter)",
        "tags": "Processes <em>and</em> procedures",
        "body": " not capitalize any other word in the title unless it&#x27;s a proper noun, such as a specific product name, or it follows a colon (:). If you&#x27;re looking for ideas on how to choose a title, browse the titles of similar <em>docs</em>. The title used in the <em>sidebar</em> (left navigation pane) is set in the <em>nav</em> <em>file</em>. type"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/tech-writer-workflow/",
      "sections": [
        "Tech Writer workflow",
        "Resources",
        "Edit in the UI vs local build",
        "Work on a branch, not a fork",
        "Set up your local environment",
        "Run the site locally",
        "Prerequisites",
        "Build the site",
        "Edit a doc",
        "Commit your changes",
        "Publish your commits",
        "Open your pull request",
        "Preview a doc",
        "Revise and publish a doc",
        "Revert merging"
      ],
      "published_at": "2021-09-01T21:57:08Z",
      "title": "Tech Writer workflow",
      "updated_at": "2021-08-27T04:54:57Z",
      "type": "docs",
      "external_id": "074905b02af0ab6eb53640c1c80e83296a8a0b02",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the UI vs local build Need to edit a doc? Use this table to decide where to work! Use the UI for: Use the local build for: Adding content to one doc: Rewriting sentences, or 1-2 lines Editing small amounts of content: updating URLs, deleting typos, etc. Brand new docs Rewrites of more than 1 or 2 lines Any updates to doc frontmatter Title changes Taxonomy changes Metadescription updates Redirects Updating images Editing multiple docs at once Continue reading for instructions on how to edit a doc locally. Work on a branch, not a fork Some teams work on branches, some teams work on forks; the docs team works in branches. As long as a branch has been pushed upstream, this allows us to work collaboratively and ensure that no work is ever lost when someone goes on vacation. To create a branch on the docs-website repo: Open GitHub Desktop Click on Current branch: xxx Click on New Branch You will be prompted to name your new branch. Descriptive names are best. It's a great way to quickly clue people in to what your work is all about. For example, if you are working on What’s New pages, you might name the branch Whats-new-updates. When you create a new branch, don't forget to add the Jira issue's key (DOC-1234) to the branch name and the PR title. Set up your local environment Running the site locally makes testing and previewing large changes much easier. Here's how to get setup: Install GitHub Desktop Sign in to GitHub Desktop. On Macs, click on GitHub Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Navigate to the Docs Site repository on GitHub.com. Click the green Code button and then select Open with GitHub Desktop. Choose the location where you want the repo, and this will clone the entire repository to your local machine at the designated path. You can ensure the repo was cloned by navigating to your local GitHub folder (the default is ~/Documents/github). Once you have cloned the repo, you don't need to clone it again in the future. Run the site locally Build the site locally using the terminal to preview changes before opening a Pull Request. While it's highly recommended to build the site locally, this is technically an optional step. The site will automatically reflect any local changes once build. Node and Yarn are tools used to build the site on your local machine. Prerequisites Install Node Install Yarn npm install -g yarn Build the site In your terminal, go to your cloned repo, docs-website. For example: cd ~/Documents/github/docs-website Run yarn with the following commands: yarn && yarn start The site will take a few minutes to build. Make yourself some tea or coffee. Once it's built, you can access your preview site in your browser by navigating to http://localhost:8000/ Edit a doc Once your local environment and branch are set up, you're ready to edit a doc. Check out the style guide for writing guidelines. First, ensure your Current Branch in GitHub Desktop is set to the correct branch, not Develop. Navigate to the doc you want to edit in Finder. If I wanted to edit a Python agent doc, I would navigate to: ~/Documents/github/docs-website/src/content/docs/agents/python-agent/hosting-services/python-agent-stackato.mdx Edit the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help with formatting markdown Save the file with your edits, then follow the same process for any other docs you wish to edit. Commit your changes Once your edits are done, you can commit them. This stages your changes, which you will later push upstream to Github. By pushing your changes, everyone will have access to your branch and commits. Navigate to GitHub Desktop. The left column should have a record of all the edits you have made to docs. In the bottom left corner, name your commit and add a good description of your edits. It should be descriptive enough to ensure that someone can understand all the changes made by simply scanning this description. Click Commit to [yourbranchname] Publish your commits Once you have committed your changes, you're almost ready to open your Pull Request. First, you need to ensure your branch is pushed upstream. On GitHub desktop, click the blue Publish Branch button if available. If you don't see the Publish Branch, click the blue Push Origin button. This will push all your commits upstream and make them available to everyone else through the GitHub repository. Open your pull request Now that your commits are available to everyone, you need to notify people that your changes are ready to be merged into the develop branch. To do this, you open a pull request: On GitHub Desktop, click the blue Create Pull Request button. This will open GitHub in your browser, and prompt you to fill in your pull request. Ensure you're merging from your branch into either the main or develop branch. If you scroll down, you can review all your commits to ensure they reflect all your changes. Just like your commit description, your pull request description should be detailed and give the full context of your changes. Feel free to add any additional context here (issue or Jira number, SMEs, etc.) To request a review from another Tech Writer: in GitHub open the PR, navigate to the Conversation section, and then select or type in a reviewer name in the Reviewer section. Add any relevant labels to your PR. If you do not add from_tw, the PR will not be automatically assigned to another writer for review. Once you're satisfied with your pull request, click the green Create pull request button. You can either publish the changes directly by approving the pull request yourself, or you can request for another Tech Writer to peer edit it. At the bottom of the pull request page, you will see a Checks section. These checks ensure your PR doesn't break the build process of the site. Ensure all checks marked required pass before merging. Once the pull request has passed the checks and it has been approved by another tech writer (or you are confident the changes are ready to be published), click the green Merge pull request button. This will merge your branch and commits into the repository and will begin the build process. If you don't add the from_tw label when you first create a PR, it will not automatically assign a reviewer. If you forget to add the label before opening the PR: Add the from_tw label. Turn the PR into a draft PR. Select the PR is ready for review button at the bottom of the page to reopen the PR. The PR should now have a reviewer. Preview a doc There are two main ways to preview branches you’ve already published and run commits on: Local: Quicker, but requires a semi-substantial amount of setup and familiarity with a terminal. Gatsby Cloud: Full preview of the live site with no overhead, and a very convenient way to share a preview of your draft with a SME. Gatsby Cloud will comment on your PR with a link to a preview version of the site once the build is ready. Building the site generally takes about 15 minutes, but can sometimes take longer if there are a lot of changes. Revise and publish a doc If you’re notified that a reviewer has submitted a review to your file, go to your PR and review the changes. You might see them in the diff view, if they’re part of a review with comments; otherwise, they might appear as copy edits in the file. Respond to any comments in the file. Either reply with follow up discussion, or click Resolve conversation. When you’ve resolved all the comments, and all of the automatic checks have passed, you can merge the pull request. Merging the pull request sets in motion the automated build process and your changes will be published shortly. Note: You will only be able to merge when the Merge pull request button is green. If it’s not green, review for any comments you missed, or other messages that indicate why GitHub is blocking you from merging. Revert merging Remember that you can almost always undo things. If you merge a PR, and then find that you shouldn’t have, you can unmerge with the Revert button. On the Pull requests tab in GitHub, click Closed on the tally bar to see all the issues and PRs that have alredy been merged. Locate the PR you merged, and locate the Revert button. Click Revert. That creates a new PR, which needs to be merged. If you want to reopen it, you need to follow the link back to the original PR and either revert that or reopen it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.77747,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Edit</em> a <em>doc</em>",
        "body": "This document will guide you through the entire workflow for editing the New Relic documentation <em>site</em> as a New Relic Tech <em>Docs</em> Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop <em>Edit</em> in the UI vs local build Need to <em>edit</em> a <em>doc</em>? Use"
      },
      "id": "60c6a91764441f404d91f8c6"
    }
  ],
  "/docs/style-guide/processes-procedures/use-content-types-text-formats": [
    {
      "sections": [
        "Delete a document",
        "Caution"
      ],
      "title": "Delete a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "46997b8327630e068987c09788cb6e5115896517",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/delete-document/",
      "published_at": "2021-09-01T21:35:11Z",
      "updated_at": "2021-09-01T21:35:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution When you delete a document, its content and its redirects will still be available in the GitHub commit history. In general, if you're not on the New Relic Docs team, please don't delete any docs. Instead, file an issue and someone on our team will help you out. If you are certain you want to delete a document, do this: Locate the mdx file of the doc you want to delete. Take care of redirects: Find the most relevant doc to redirect readers to. Add the deleted doc's URL as a redirect. Copy any existing redirects from the deleted doc and add them to the new doc. Delete the doc's title and path from the appropriate nav file. Delete the doc mdx file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 426.61542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>"
      },
      "id": "60422009e7b9d21bd22a07d4"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 425.0393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. <em>Procedures</em> are the same for both standard docs (&quot;basic pages&quot;) and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change"
      },
      "id": "604220ec196a670d0ba83dd4"
    },
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-09-01T22:03:08Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.10266,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures you would use the docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures&#x2F;images directory. If the images directory does"
      },
      "id": "604220ec196a67105da83dc2"
    }
  ],
  "/docs/style-guide/quick-reference/bold-or-code-not-italics": [
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "Child account",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "customer vs. user",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-09-01T21:56:16Z",
      "updated_at": "2021-09-01T21:56:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements Child account A parent account contains one or more child accounts. Child accounts were previously referred to as \"sub-accounts\". click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also [mouse over] #mouse-over). collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. customer vs. user When possible, use the second person you to form a sense of connection with the reader. For times when you need a descriptive third-person noun, keep the following guidelines in mind: customer and user are both appropriate depending on context. customer makes more sense when talking about billing, or about a group of people or a business entity. For example, one customer may have one or more individual users who interact with New Relic through the customer's account(s). user makes more sense as a general term for an individual user, or when talking about users as an object in the account model. For example, when discussing account models, it's important to be specific about what constitutes a single person identity in our system. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account We previously used \"master account\" and \"sub-account\" but now we use parent account and child account. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account New Relic organizations can have a parent/child account structure. This is more important for our original account/user model but still plays a role for some behind-the-scenes features on our New Relic One account/user model. Learn more about account structure. Parent accounts were previously referred to as master accounts, and there are still some uses of this in the codebase. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of browser monitoring docs. Often abbreviated as RUM, this is a generic industry term for browser monitoring. New Relic refers to this as page load timing or browser monitoring. Use this term only for SEO or clarification, not to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 435.25336,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>). Don&#x27;t use NR-ONLY or NRONLY or New Relic"
      },
      "id": "60421ec1196a676986a83d87"
    },
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution (callout-caution)",
        "Caution",
        "Important (callout-important)",
        "Important",
        "Tip (callout-tip)",
        "Tip",
        "User-related permissions",
        "Pricing (callout-pricing) Do not use.",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c8337fb61ea2576fe138fe4540929e67d501ce2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/callouts/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-20T14:36:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts Here's an example of the callout format: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy On our Docs site, we use these callout classes: Caution (callout-caution) Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use the callout-caution class. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important (callout-important) Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use the callout-important class. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip (callout-tip) Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use the callout-tip class. At a traffic light, a Tip would be a green light. Tip If you have integrated your New Relic account with a ticketing system such as Lighthouse, Pivotal Tracker, or Atlassian JIRA, you can use the note to file a ticket or story. User-related permissions For recommended wording, see User-related language and styles. Pricing (callout-pricing) Do not use. Pricing callouts let you know that you may need a specific subscription level in order to access the product or feature. Pricing callouts use the callout-pricing class. Typically, pricing callouts appear in the intro of a doc. See the example below for standard verbiage in the callout. With the new pricing model, these are rarely used. Tip Access to this feature depends on your subscription level. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, no watermark is needed–just a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the Docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 324.55994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    },
    {
      "sections": [
        "Buttons",
        "Button breakdown",
        "Button variations"
      ],
      "title": "Buttons",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c755477545c29afb5ae1a309af0f61bbb9091a2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/buttons/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-08T00:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you want to draw someone's attention to a link without putting it in a callout, buttons are an elegant way to do that. Click me! Button breakdown Buttons are created from two React components: <ButtonGroup> and <ButtonLink>. <ButtonGroup> <ButtonLink role=\"button\" to=\"Button URL\" variant=\"primary\" > Button text </ButtonLink> </ButtonGroup> Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button's URL. variant Use the value primary. For alternate button style, use secondary Button variations If you need it, you can put two or more buttons in a row. Simply include additional ButtonLink content within ButtonGroup. Button one Button two Secondary button The source for those buttons looks like this: <ButtonGroup> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button one </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button two </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"secondary\" > Secondary button </ButtonLink> </ButtonGroup> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.91156,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": "=&quot;primary&quot; &gt; Button text &lt;&#x2F;ButtonLink&gt; &lt;&#x2F;ButtonGroup&gt; Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button&#x27;s URL. variant Use the value primary. For alternate button <em>style</em>, use secondary Button variations If you need it, you can put two or more buttons"
      },
      "id": "610f1f1064441f5f2947abfa"
    }
  ],
  "/docs/style-guide/quick-reference/buttons": [
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "Child account",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "customer vs. user",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-09-01T21:56:16Z",
      "updated_at": "2021-09-01T21:56:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements Child account A parent account contains one or more child accounts. Child accounts were previously referred to as \"sub-accounts\". click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also [mouse over] #mouse-over). collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. customer vs. user When possible, use the second person you to form a sense of connection with the reader. For times when you need a descriptive third-person noun, keep the following guidelines in mind: customer and user are both appropriate depending on context. customer makes more sense when talking about billing, or about a group of people or a business entity. For example, one customer may have one or more individual users who interact with New Relic through the customer's account(s). user makes more sense as a general term for an individual user, or when talking about users as an object in the account model. For example, when discussing account models, it's important to be specific about what constitutes a single person identity in our system. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account We previously used \"master account\" and \"sub-account\" but now we use parent account and child account. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account New Relic organizations can have a parent/child account structure. This is more important for our original account/user model but still plays a role for some behind-the-scenes features on our New Relic One account/user model. Learn more about account structure. Parent accounts were previously referred to as master accounts, and there are still some uses of this in the codebase. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of browser monitoring docs. Often abbreviated as RUM, this is a generic industry term for browser monitoring. New Relic refers to this as page load timing or browser monitoring. Use this term only for SEO or clarification, not to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 435.25314,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>). Don&#x27;t use NR-ONLY or NRONLY or New Relic"
      },
      "id": "60421ec1196a676986a83d87"
    },
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution (callout-caution)",
        "Caution",
        "Important (callout-important)",
        "Important",
        "Tip (callout-tip)",
        "Tip",
        "User-related permissions",
        "Pricing (callout-pricing) Do not use.",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c8337fb61ea2576fe138fe4540929e67d501ce2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/callouts/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-20T14:36:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts Here's an example of the callout format: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy On our Docs site, we use these callout classes: Caution (callout-caution) Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use the callout-caution class. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important (callout-important) Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use the callout-important class. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip (callout-tip) Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use the callout-tip class. At a traffic light, a Tip would be a green light. Tip If you have integrated your New Relic account with a ticketing system such as Lighthouse, Pivotal Tracker, or Atlassian JIRA, you can use the note to file a ticket or story. User-related permissions For recommended wording, see User-related language and styles. Pricing (callout-pricing) Do not use. Pricing callouts let you know that you may need a specific subscription level in order to access the product or feature. Pricing callouts use the callout-pricing class. Typically, pricing callouts appear in the intro of a doc. See the example below for standard verbiage in the callout. With the new pricing model, these are rarely used. Tip Access to this feature depends on your subscription level. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, no watermark is needed–just a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the Docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 324.55988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-09-01T21:52:38Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.68669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ", such as a variable or function, then capitalize it exactly as it&#x27;s used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles"
      },
      "id": "60421e50196a67d785a83d97"
    }
  ],
  "/docs/style-guide/quick-reference/callouts": [
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "Child account",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "customer vs. user",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-09-01T21:56:16Z",
      "updated_at": "2021-09-01T21:56:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements Child account A parent account contains one or more child accounts. Child accounts were previously referred to as \"sub-accounts\". click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also [mouse over] #mouse-over). collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. customer vs. user When possible, use the second person you to form a sense of connection with the reader. For times when you need a descriptive third-person noun, keep the following guidelines in mind: customer and user are both appropriate depending on context. customer makes more sense when talking about billing, or about a group of people or a business entity. For example, one customer may have one or more individual users who interact with New Relic through the customer's account(s). user makes more sense as a general term for an individual user, or when talking about users as an object in the account model. For example, when discussing account models, it's important to be specific about what constitutes a single person identity in our system. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account We previously used \"master account\" and \"sub-account\" but now we use parent account and child account. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account New Relic organizations can have a parent/child account structure. This is more important for our original account/user model but still plays a role for some behind-the-scenes features on our New Relic One account/user model. Learn more about account structure. Parent accounts were previously referred to as master accounts, and there are still some uses of this in the codebase. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of browser monitoring docs. Often abbreviated as RUM, this is a generic industry term for browser monitoring. New Relic refers to this as page load timing or browser monitoring. Use this term only for SEO or clarification, not to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 435.25314,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>). Don&#x27;t use NR-ONLY or NRONLY or New Relic"
      },
      "id": "60421ec1196a676986a83d87"
    },
    {
      "sections": [
        "Buttons",
        "Button breakdown",
        "Button variations"
      ],
      "title": "Buttons",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c755477545c29afb5ae1a309af0f61bbb9091a2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/buttons/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-08T00:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you want to draw someone's attention to a link without putting it in a callout, buttons are an elegant way to do that. Click me! Button breakdown Buttons are created from two React components: <ButtonGroup> and <ButtonLink>. <ButtonGroup> <ButtonLink role=\"button\" to=\"Button URL\" variant=\"primary\" > Button text </ButtonLink> </ButtonGroup> Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button's URL. variant Use the value primary. For alternate button style, use secondary Button variations If you need it, you can put two or more buttons in a row. Simply include additional ButtonLink content within ButtonGroup. Button one Button two Secondary button The source for those buttons looks like this: <ButtonGroup> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button one </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button two </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"secondary\" > Secondary button </ButtonLink> </ButtonGroup> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.91153,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": "=&quot;primary&quot; &gt; Button text &lt;&#x2F;ButtonLink&gt; &lt;&#x2F;ButtonGroup&gt; Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button&#x27;s URL. variant Use the value primary. For alternate button <em>style</em>, use secondary Button variations If you need it, you can put two or more buttons"
      },
      "id": "610f1f1064441f5f2947abfa"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-09-01T21:52:38Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.68669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ", such as a variable or function, then capitalize it exactly as it&#x27;s used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles"
      },
      "id": "60421e50196a67d785a83d97"
    }
  ],
  "/docs/style-guide/quick-reference/capitalization": [
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "Child account",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "customer vs. user",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-09-01T21:56:16Z",
      "updated_at": "2021-09-01T21:56:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements Child account A parent account contains one or more child accounts. Child accounts were previously referred to as \"sub-accounts\". click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also [mouse over] #mouse-over). collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. customer vs. user When possible, use the second person you to form a sense of connection with the reader. For times when you need a descriptive third-person noun, keep the following guidelines in mind: customer and user are both appropriate depending on context. customer makes more sense when talking about billing, or about a group of people or a business entity. For example, one customer may have one or more individual users who interact with New Relic through the customer's account(s). user makes more sense as a general term for an individual user, or when talking about users as an object in the account model. For example, when discussing account models, it's important to be specific about what constitutes a single person identity in our system. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account We previously used \"master account\" and \"sub-account\" but now we use parent account and child account. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account New Relic organizations can have a parent/child account structure. This is more important for our original account/user model but still plays a role for some behind-the-scenes features on our New Relic One account/user model. Learn more about account structure. Parent accounts were previously referred to as master accounts, and there are still some uses of this in the codebase. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of browser monitoring docs. Often abbreviated as RUM, this is a generic industry term for browser monitoring. New Relic refers to this as page load timing or browser monitoring. Use this term only for SEO or clarification, not to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 435.25293,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>). Don&#x27;t use NR-ONLY or NRONLY or New Relic"
      },
      "id": "60421ec1196a676986a83d87"
    },
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution (callout-caution)",
        "Caution",
        "Important (callout-important)",
        "Important",
        "Tip (callout-tip)",
        "Tip",
        "User-related permissions",
        "Pricing (callout-pricing) Do not use.",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c8337fb61ea2576fe138fe4540929e67d501ce2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/callouts/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-20T14:36:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts Here's an example of the callout format: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy On our Docs site, we use these callout classes: Caution (callout-caution) Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use the callout-caution class. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important (callout-important) Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use the callout-important class. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip (callout-tip) Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use the callout-tip class. At a traffic light, a Tip would be a green light. Tip If you have integrated your New Relic account with a ticketing system such as Lighthouse, Pivotal Tracker, or Atlassian JIRA, you can use the note to file a ticket or story. User-related permissions For recommended wording, see User-related language and styles. Pricing (callout-pricing) Do not use. Pricing callouts let you know that you may need a specific subscription level in order to access the product or feature. Pricing callouts use the callout-pricing class. Typically, pricing callouts appear in the intro of a doc. See the example below for standard verbiage in the callout. With the new pricing model, these are rarely used. Tip Access to this feature depends on your subscription level. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, no watermark is needed–just a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the Docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 324.55984,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    },
    {
      "sections": [
        "Buttons",
        "Button breakdown",
        "Button variations"
      ],
      "title": "Buttons",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c755477545c29afb5ae1a309af0f61bbb9091a2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/buttons/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-08T00:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you want to draw someone's attention to a link without putting it in a callout, buttons are an elegant way to do that. Click me! Button breakdown Buttons are created from two React components: <ButtonGroup> and <ButtonLink>. <ButtonGroup> <ButtonLink role=\"button\" to=\"Button URL\" variant=\"primary\" > Button text </ButtonLink> </ButtonGroup> Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button's URL. variant Use the value primary. For alternate button style, use secondary Button variations If you need it, you can put two or more buttons in a row. Simply include additional ButtonLink content within ButtonGroup. Button one Button two Secondary button The source for those buttons looks like this: <ButtonGroup> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button one </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button two </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"secondary\" > Secondary button </ButtonLink> </ButtonGroup> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.9115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": "=&quot;primary&quot; &gt; Button text &lt;&#x2F;ButtonLink&gt; &lt;&#x2F;ButtonGroup&gt; Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button&#x27;s URL. variant Use the value primary. For alternate button <em>style</em>, use secondary Button variations If you need it, you can put two or more buttons"
      },
      "id": "610f1f1064441f5f2947abfa"
    }
  ],
  "/docs/style-guide/quick-reference/code-examples": [
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "Child account",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "customer vs. user",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-09-01T21:56:16Z",
      "updated_at": "2021-09-01T21:56:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements Child account A parent account contains one or more child accounts. Child accounts were previously referred to as \"sub-accounts\". click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also [mouse over] #mouse-over). collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. customer vs. user When possible, use the second person you to form a sense of connection with the reader. For times when you need a descriptive third-person noun, keep the following guidelines in mind: customer and user are both appropriate depending on context. customer makes more sense when talking about billing, or about a group of people or a business entity. For example, one customer may have one or more individual users who interact with New Relic through the customer's account(s). user makes more sense as a general term for an individual user, or when talking about users as an object in the account model. For example, when discussing account models, it's important to be specific about what constitutes a single person identity in our system. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account We previously used \"master account\" and \"sub-account\" but now we use parent account and child account. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account New Relic organizations can have a parent/child account structure. This is more important for our original account/user model but still plays a role for some behind-the-scenes features on our New Relic One account/user model. Learn more about account structure. Parent accounts were previously referred to as master accounts, and there are still some uses of this in the codebase. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of browser monitoring docs. Often abbreviated as RUM, this is a generic industry term for browser monitoring. New Relic refers to this as page load timing or browser monitoring. Use this term only for SEO or clarification, not to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 435.25293,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>). Don&#x27;t use NR-ONLY or NRONLY or New Relic"
      },
      "id": "60421ec1196a676986a83d87"
    },
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution (callout-caution)",
        "Caution",
        "Important (callout-important)",
        "Important",
        "Tip (callout-tip)",
        "Tip",
        "User-related permissions",
        "Pricing (callout-pricing) Do not use.",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c8337fb61ea2576fe138fe4540929e67d501ce2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/callouts/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-20T14:36:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts Here's an example of the callout format: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy On our Docs site, we use these callout classes: Caution (callout-caution) Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use the callout-caution class. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important (callout-important) Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use the callout-important class. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip (callout-tip) Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use the callout-tip class. At a traffic light, a Tip would be a green light. Tip If you have integrated your New Relic account with a ticketing system such as Lighthouse, Pivotal Tracker, or Atlassian JIRA, you can use the note to file a ticket or story. User-related permissions For recommended wording, see User-related language and styles. Pricing (callout-pricing) Do not use. Pricing callouts let you know that you may need a specific subscription level in order to access the product or feature. Pricing callouts use the callout-pricing class. Typically, pricing callouts appear in the intro of a doc. See the example below for standard verbiage in the callout. With the new pricing model, these are rarely used. Tip Access to this feature depends on your subscription level. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, no watermark is needed–just a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the Docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 324.55984,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    },
    {
      "sections": [
        "Buttons",
        "Button breakdown",
        "Button variations"
      ],
      "title": "Buttons",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c755477545c29afb5ae1a309af0f61bbb9091a2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/buttons/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-08T00:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you want to draw someone's attention to a link without putting it in a callout, buttons are an elegant way to do that. Click me! Button breakdown Buttons are created from two React components: <ButtonGroup> and <ButtonLink>. <ButtonGroup> <ButtonLink role=\"button\" to=\"Button URL\" variant=\"primary\" > Button text </ButtonLink> </ButtonGroup> Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button's URL. variant Use the value primary. For alternate button style, use secondary Button variations If you need it, you can put two or more buttons in a row. Simply include additional ButtonLink content within ButtonGroup. Button one Button two Secondary button The source for those buttons looks like this: <ButtonGroup> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button one </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button two </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"secondary\" > Secondary button </ButtonLink> </ButtonGroup> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.9115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": "=&quot;primary&quot; &gt; Button text &lt;&#x2F;ButtonLink&gt; &lt;&#x2F;ButtonGroup&gt; Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button&#x27;s URL. variant Use the value primary. For alternate button <em>style</em>, use secondary Button variations If you need it, you can put two or more buttons"
      },
      "id": "610f1f1064441f5f2947abfa"
    }
  ],
  "/docs/style-guide/quick-reference/collapsers": [
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "Child account",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "customer vs. user",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-09-01T21:56:16Z",
      "updated_at": "2021-09-01T21:56:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements Child account A parent account contains one or more child accounts. Child accounts were previously referred to as \"sub-accounts\". click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also [mouse over] #mouse-over). collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. customer vs. user When possible, use the second person you to form a sense of connection with the reader. For times when you need a descriptive third-person noun, keep the following guidelines in mind: customer and user are both appropriate depending on context. customer makes more sense when talking about billing, or about a group of people or a business entity. For example, one customer may have one or more individual users who interact with New Relic through the customer's account(s). user makes more sense as a general term for an individual user, or when talking about users as an object in the account model. For example, when discussing account models, it's important to be specific about what constitutes a single person identity in our system. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account We previously used \"master account\" and \"sub-account\" but now we use parent account and child account. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account New Relic organizations can have a parent/child account structure. This is more important for our original account/user model but still plays a role for some behind-the-scenes features on our New Relic One account/user model. Learn more about account structure. Parent accounts were previously referred to as master accounts, and there are still some uses of this in the codebase. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of browser monitoring docs. Often abbreviated as RUM, this is a generic industry term for browser monitoring. New Relic refers to this as page load timing or browser monitoring. Use this term only for SEO or clarification, not to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 435.25272,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>). Don&#x27;t use NR-ONLY or NRONLY or New Relic"
      },
      "id": "60421ec1196a676986a83d87"
    },
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution (callout-caution)",
        "Caution",
        "Important (callout-important)",
        "Important",
        "Tip (callout-tip)",
        "Tip",
        "User-related permissions",
        "Pricing (callout-pricing) Do not use.",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c8337fb61ea2576fe138fe4540929e67d501ce2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/callouts/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-20T14:36:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts Here's an example of the callout format: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy On our Docs site, we use these callout classes: Caution (callout-caution) Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use the callout-caution class. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important (callout-important) Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use the callout-important class. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip (callout-tip) Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use the callout-tip class. At a traffic light, a Tip would be a green light. Tip If you have integrated your New Relic account with a ticketing system such as Lighthouse, Pivotal Tracker, or Atlassian JIRA, you can use the note to file a ticket or story. User-related permissions For recommended wording, see User-related language and styles. Pricing (callout-pricing) Do not use. Pricing callouts let you know that you may need a specific subscription level in order to access the product or feature. Pricing callouts use the callout-pricing class. Typically, pricing callouts appear in the intro of a doc. See the example below for standard verbiage in the callout. With the new pricing model, these are rarely used. Tip Access to this feature depends on your subscription level. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, no watermark is needed–just a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the Docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 324.55978,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    },
    {
      "sections": [
        "Buttons",
        "Button breakdown",
        "Button variations"
      ],
      "title": "Buttons",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c755477545c29afb5ae1a309af0f61bbb9091a2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/buttons/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-08T00:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you want to draw someone's attention to a link without putting it in a callout, buttons are an elegant way to do that. Click me! Button breakdown Buttons are created from two React components: <ButtonGroup> and <ButtonLink>. <ButtonGroup> <ButtonLink role=\"button\" to=\"Button URL\" variant=\"primary\" > Button text </ButtonLink> </ButtonGroup> Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button's URL. variant Use the value primary. For alternate button style, use secondary Button variations If you need it, you can put two or more buttons in a row. Simply include additional ButtonLink content within ButtonGroup. Button one Button two Secondary button The source for those buttons looks like this: <ButtonGroup> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button one </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button two </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"secondary\" > Secondary button </ButtonLink> </ButtonGroup> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.9115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": "=&quot;primary&quot; &gt; Button text &lt;&#x2F;ButtonLink&gt; &lt;&#x2F;ButtonGroup&gt; Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button&#x27;s URL. variant Use the value primary. For alternate button <em>style</em>, use secondary Button variations If you need it, you can put two or more buttons"
      },
      "id": "610f1f1064441f5f2947abfa"
    }
  ],
  "/docs/style-guide/quick-reference/lists": [
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "Child account",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "customer vs. user",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-09-01T21:56:16Z",
      "updated_at": "2021-09-01T21:56:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements Child account A parent account contains one or more child accounts. Child accounts were previously referred to as \"sub-accounts\". click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also [mouse over] #mouse-over). collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. customer vs. user When possible, use the second person you to form a sense of connection with the reader. For times when you need a descriptive third-person noun, keep the following guidelines in mind: customer and user are both appropriate depending on context. customer makes more sense when talking about billing, or about a group of people or a business entity. For example, one customer may have one or more individual users who interact with New Relic through the customer's account(s). user makes more sense as a general term for an individual user, or when talking about users as an object in the account model. For example, when discussing account models, it's important to be specific about what constitutes a single person identity in our system. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account We previously used \"master account\" and \"sub-account\" but now we use parent account and child account. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account New Relic organizations can have a parent/child account structure. This is more important for our original account/user model but still plays a role for some behind-the-scenes features on our New Relic One account/user model. Learn more about account structure. Parent accounts were previously referred to as master accounts, and there are still some uses of this in the codebase. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of browser monitoring docs. Often abbreviated as RUM, this is a generic industry term for browser monitoring. New Relic refers to this as page load timing or browser monitoring. Use this term only for SEO or clarification, not to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 435.25272,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>). Don&#x27;t use NR-ONLY or NRONLY or New Relic"
      },
      "id": "60421ec1196a676986a83d87"
    },
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution (callout-caution)",
        "Caution",
        "Important (callout-important)",
        "Important",
        "Tip (callout-tip)",
        "Tip",
        "User-related permissions",
        "Pricing (callout-pricing) Do not use.",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c8337fb61ea2576fe138fe4540929e67d501ce2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/callouts/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-20T14:36:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts Here's an example of the callout format: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy On our Docs site, we use these callout classes: Caution (callout-caution) Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use the callout-caution class. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important (callout-important) Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use the callout-important class. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip (callout-tip) Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use the callout-tip class. At a traffic light, a Tip would be a green light. Tip If you have integrated your New Relic account with a ticketing system such as Lighthouse, Pivotal Tracker, or Atlassian JIRA, you can use the note to file a ticket or story. User-related permissions For recommended wording, see User-related language and styles. Pricing (callout-pricing) Do not use. Pricing callouts let you know that you may need a specific subscription level in order to access the product or feature. Pricing callouts use the callout-pricing class. Typically, pricing callouts appear in the intro of a doc. See the example below for standard verbiage in the callout. With the new pricing model, these are rarely used. Tip Access to this feature depends on your subscription level. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, no watermark is needed–just a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the Docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 324.55978,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    },
    {
      "sections": [
        "Buttons",
        "Button breakdown",
        "Button variations"
      ],
      "title": "Buttons",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c755477545c29afb5ae1a309af0f61bbb9091a2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/buttons/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-08T00:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you want to draw someone's attention to a link without putting it in a callout, buttons are an elegant way to do that. Click me! Button breakdown Buttons are created from two React components: <ButtonGroup> and <ButtonLink>. <ButtonGroup> <ButtonLink role=\"button\" to=\"Button URL\" variant=\"primary\" > Button text </ButtonLink> </ButtonGroup> Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button's URL. variant Use the value primary. For alternate button style, use secondary Button variations If you need it, you can put two or more buttons in a row. Simply include additional ButtonLink content within ButtonGroup. Button one Button two Secondary button The source for those buttons looks like this: <ButtonGroup> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button one </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button two </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"secondary\" > Secondary button </ButtonLink> </ButtonGroup> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.9115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": "=&quot;primary&quot; &gt; Button text &lt;&#x2F;ButtonLink&gt; &lt;&#x2F;ButtonGroup&gt; Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button&#x27;s URL. variant Use the value primary. For alternate button <em>style</em>, use secondary Button variations If you need it, you can put two or more buttons"
      },
      "id": "610f1f1064441f5f2947abfa"
    }
  ],
  "/docs/style-guide/quick-reference/tables": [
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "Child account",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "customer vs. user",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-09-01T21:56:16Z",
      "updated_at": "2021-09-01T21:56:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements Child account A parent account contains one or more child accounts. Child accounts were previously referred to as \"sub-accounts\". click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also [mouse over] #mouse-over). collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. customer vs. user When possible, use the second person you to form a sense of connection with the reader. For times when you need a descriptive third-person noun, keep the following guidelines in mind: customer and user are both appropriate depending on context. customer makes more sense when talking about billing, or about a group of people or a business entity. For example, one customer may have one or more individual users who interact with New Relic through the customer's account(s). user makes more sense as a general term for an individual user, or when talking about users as an object in the account model. For example, when discussing account models, it's important to be specific about what constitutes a single person identity in our system. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account We previously used \"master account\" and \"sub-account\" but now we use parent account and child account. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account New Relic organizations can have a parent/child account structure. This is more important for our original account/user model but still plays a role for some behind-the-scenes features on our New Relic One account/user model. Learn more about account structure. Parent accounts were previously referred to as master accounts, and there are still some uses of this in the codebase. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of browser monitoring docs. Often abbreviated as RUM, this is a generic industry term for browser monitoring. New Relic refers to this as page load timing or browser monitoring. Use this term only for SEO or clarification, not to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 435.25272,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>). Don&#x27;t use NR-ONLY or NRONLY or New Relic"
      },
      "id": "60421ec1196a676986a83d87"
    },
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution (callout-caution)",
        "Caution",
        "Important (callout-important)",
        "Important",
        "Tip (callout-tip)",
        "Tip",
        "User-related permissions",
        "Pricing (callout-pricing) Do not use.",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c8337fb61ea2576fe138fe4540929e67d501ce2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/callouts/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-20T14:36:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts Here's an example of the callout format: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy On our Docs site, we use these callout classes: Caution (callout-caution) Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use the callout-caution class. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important (callout-important) Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use the callout-important class. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip (callout-tip) Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use the callout-tip class. At a traffic light, a Tip would be a green light. Tip If you have integrated your New Relic account with a ticketing system such as Lighthouse, Pivotal Tracker, or Atlassian JIRA, you can use the note to file a ticket or story. User-related permissions For recommended wording, see User-related language and styles. Pricing (callout-pricing) Do not use. Pricing callouts let you know that you may need a specific subscription level in order to access the product or feature. Pricing callouts use the callout-pricing class. Typically, pricing callouts appear in the intro of a doc. See the example below for standard verbiage in the callout. With the new pricing model, these are rarely used. Tip Access to this feature depends on your subscription level. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, no watermark is needed–just a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the Docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 324.55978,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    },
    {
      "sections": [
        "Buttons",
        "Button breakdown",
        "Button variations"
      ],
      "title": "Buttons",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c755477545c29afb5ae1a309af0f61bbb9091a2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/buttons/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-08T00:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you want to draw someone's attention to a link without putting it in a callout, buttons are an elegant way to do that. Click me! Button breakdown Buttons are created from two React components: <ButtonGroup> and <ButtonLink>. <ButtonGroup> <ButtonLink role=\"button\" to=\"Button URL\" variant=\"primary\" > Button text </ButtonLink> </ButtonGroup> Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button's URL. variant Use the value primary. For alternate button style, use secondary Button variations If you need it, you can put two or more buttons in a row. Simply include additional ButtonLink content within ButtonGroup. Button one Button two Secondary button The source for those buttons looks like this: <ButtonGroup> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button one </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button two </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"secondary\" > Secondary button </ButtonLink> </ButtonGroup> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.9115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": "=&quot;primary&quot; &gt; Button text &lt;&#x2F;ButtonLink&gt; &lt;&#x2F;ButtonGroup&gt; Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button&#x27;s URL. variant Use the value primary. For alternate button <em>style</em>, use secondary Button variations If you need it, you can put two or more buttons"
      },
      "id": "610f1f1064441f5f2947abfa"
    }
  ],
  "/docs/style-guide/quick-reference/titles": [
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-09-01T19:30:05Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 334.1256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rename or <em>redirect</em> a document",
        "sections": "Rename or <em>redirect</em> a document",
        "body": "This document describes how to change the title of a document and how to create, edit, and delete <em>redirects</em>. Procedures are the same for both standard docs (&quot;basic pages&quot;) and release notes. Caution Changing <em>titles</em> or updating <em>redirects</em> can create issues with finding content. If you need to change"
      },
      "id": "604220ec196a670d0ba83dd4"
    },
    {
      "image": "https://docs.newrelic.com/static/e8d42feaa627a4f1abd362c85a07596d/c1b63/example-doc-in-folder.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/understand-edit-docs-site-structure/",
      "sections": [
        "Understand and edit docs site structure (nav file, sidebar, categories)",
        "Terms",
        "Understand how the docs site structure works",
        "How is the displayed structure related to the actual folders?",
        "What determines a doc's URL?",
        "What does a nav file do?",
        "Where is the docs site structure exposed?",
        "What determines a doc's sidebar?",
        "When you click a sidebar category, what determines how that category view displays?",
        "Nav file format",
        "Tip",
        "Procedures",
        "Add a new category",
        "Add a new nav file",
        "Add a new category to a nav file",
        "Add a doc to sidebar/nav-file",
        "Add doc in multiple sidebar locations",
        "Move docs to other categories",
        "Move docs using nav file",
        "Move docs between folders",
        "Move or delete a folder",
        "Create a \"dummy\" sub-category of docs that don't live in that category",
        "Make a sidebar category heading clickable",
        "Troubleshoot category views not working correctly"
      ],
      "published_at": "2021-09-01T21:52:39Z",
      "title": "Understand and edit docs site structure (nav file, sidebar, categories)",
      "updated_at": "2021-09-01T04:18:46Z",
      "type": "docs",
      "external_id": "5498c89c5d5497ac899f70f86bb8bf0cda4bc840",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc contains information and procedures pertaining to the structure of the docs site, including: the nav files, the sidebar, docs category (index) views, and more. For succinct instructions, see Procedures, but it is highly recommended you understand the general concepts of how the docs site structure works if you will be doing larger docs site projects. Terms When talking about the docs site structure, sometimes people use different words for the same things. Below is a list of terms that can help us communicate about the docs site structure: Nav files: In the github docs site, there are yaml files under the nav folder that are used to determine the docs site structure that we display. This structure is exposed in the docs site left sidebar and when you view docs category views (also known as index views, like this one). Folder: We sometimes use \"folders\" to refer to the actual docs site folder structure (those folders and files in the content section). This is a way to differentiate between the actual folder structure and the displayed structure that's set using the nav files. Sidebar: On public-facing docs, the sidebar is what is visible on the left hand side, showing the structure of that category of docs. The sidebar and index view are both determined by the structure set in the nav file. Category or subcategory: we use these words a bit interchangeably to refer to the various levels of docs site categories. For example, this view shows a list of docs in a specific category, as does this higher level category view. Index: In this context, an \"index\" is sometimes used to refer to a view of a certain category of docs (like this one). \"Index\" and \"category\" can be used a bit interchangably, but the gist is that the \"index\" term refers to a docs category being displayed in a page load. (Note that this is a different, more general use of the term than the index.mdx files that are used to build landing pages.) Understand how the docs site structure works This section will explain some of the logic behind how the docs site structure is determined and how the structure we display to the public relates to the actual docs folder structure. How is the displayed structure related to the actual folders? The actual docs folder structure (the folders and mdx files in the content folder) is entirely separate from the docs site structure that we display (e.g., the structure shown in the sidebar and category views like this one). The displayed structure of the docs site is determined solely by the nav files (the yaml-format files in the nav folder). It's important to understand the above point. The divergence of the docs folder structure and the displayed docs site structure is necessary: we need a way to control the displayed site structure, which is used for the sidebar and category views, without requiring us to keep the folder structure and folder names and doc file names completely parallel and matching. Because these two things are so separate, it means we have some fairly complex behind-the-scenes logic to get them to work together. And this means that there can be fairly unintuitive aspects of how that logic works. We do have procedures for common use cases, but it will help you a lot to understand the specifics below of how the displayed structure is generated. What determines a doc's URL? Where a doc file (mdx file) is located in the content folder, and the associated folder and file names, are the only factors that govern that doc's URL. For example, consider the following doc file automated-user-provisioning-single-sign.mdx: This doc's URL is solely based on its folder location and the names of the folders. In this case, its URL is: docs.newrelic.com/docs/accounts/accounts/automated-user-management/automated-user-provisioning-single-sign Copy This has important implications, including: When you move a doc from one folder to another, its URL changes, and this means that you will have to add a redirect to that doc of its original URL. If you rename an mdx file name or a folder name, that changes its URL, so that means you would have to add a redirect to that doc for its original URL. What does a nav file do? The nav files are quite simple. A nav file controls these things: The docs structure (the various levels of docs) for that category of docs. The category headers, set by title (e.g., \"On-host integrations list\") and path (e.g., \"/docs/integrations/on-host-integrations\"). The doc information, set by title (e.g., \"NGINX integration\") and path (the doc's URL). A category and a doc in a nav file have the same elements: a title and a `path. What separates a category from a doc is that: A category contains docs in the level below it. If a category has a path (which isn't required but should be present for most docs), the path points to a content docs folder that has at least one doc in it. For more on nav file format, see Nav file format Where is the docs site structure exposed? The structure set in the nav files is exposed in two places: The left sidebar of a doc that shows the structure of that category. When a category header in the sidebar is clicked, it shows a view of that docs site category. Doc category views, also sometimes called index views: for example, this view, which shows a particular section of docs. What determines a doc's sidebar? As stated above, the sidebar is just one way that the docs site structure governed by the nav files is exposed. When a doc is loaded, the docs site searches for that URL in the nav files. If it finds a match, it displays that nav file in the sidebar with that doc highlighted. If it finds that doc in more than one nav file, it attempts to find the right nav file by choosing the nav that matches the top level category in the doc URL. For example, if a doc with a relative URL /docs/accounts/accounts-billing/account-setup/create-your-new-relic-account was in two nav files, the docs site code would search to see if one of the nav files has docs/accounts as its first path field. If it finds a match, it uses that nav file. For an example of a doc that is placed in two different nav files, in this category view click the Manage data doc and see how, when it loads, it displays the sidebar for the nav file that better matches its URL. When you click a sidebar category, what determines how that category view displays? When you click on a docs category header in the sidebar and a docs category view loads (like this one), what governs what is displayed there? Here is how this process works: A category header in the sidebar has an associated URL, which is set in the nav file. In the example nav file snippet below, the Get started category view has a path set to /docs/apis/intro-apis. This is what governs the sidebar heading title of \"Get started\" and tells it the URL to use. - title: APIs path: /docs/apis pages: - title: Get started path: /docs/apis/intro-apis pages: - title: New Relic APIs path: /docs/apis/intro-apis/introduction-new-relic-apis - title: API keys path: /docs/apis/intro-apis/new-relic-api-keys Copy If the associated folder of that path has an index mdx file (representing a landing page, like this one), the docs site displays that landing page. If there is no landing page, we check to see if that path matches an actual folder that has at least one mdx file. In other words, if we instead put in a completely arbitrary URL path for a category path, like docs/random-category/random-category-2, it would not work. It requires an existing folder with at least one doc in there. Other aspects to consider: Note that a category doesn't need a path link in the nav file; that is just what tells it to create a link and a URL for that view. If a category in a nav file lacks a path, it won't have a link or associated URL for it (for an example, see the \"New Relic University\" category in this section). Having a category without an associated link/URL can be an acceptable choice if you are creating a category of docs that don't reside in that section and you simply want to give a helpful category view in the sidebar. Note that every URL based on actual folder structure can create a theoretical URL. For example, here's a URL based on an actual folder containing one doc. But because there is no path in a nav file corresponding to that URL, it doesn't display anything. Nav file format Below is a snippet of the agents.yml nav file. Note that the file has indentation that corresponds to the level of the navigation hierarchy. When making changes or creating a new nav file, be sure to use the existing spacing format. yml title: Agents path: /docs/agents pages: - title: Manage APM agents path: /docs/agents/manage-apm-agents pages: - title: Agent data path: /docs/agents/manage-apm-agents/agent-data pages: - title: Real time streaming path: /docs/agents/manage-apm-agents/agent-data/real-time-streaming - title: Custom instrumentation path: /docs/agents/manage-apm-agents/agent-data/custom-instrumentation - title: Agent attributes path: /docs/agents/manage-apm-agents/agent-data/agent-attributes - title: Custom events path: /docs/agents/manage-apm-agents/agent-data/collect-custom-events - title: Custom metrics path: /docs/agents/manage-apm-agents/agent-data/collect-custom-metrics - title: Manage errors path: /docs/agents/manage-apm-agents/agent-data/manage-errors-apm-collect-ignore-or-mark-expected - title: Link Kubernetes path: /docs/agents/manage-apm-agents/agent-data/link-your-applications-kubernetes - title: App naming pages: - title: Name your application path: /docs/agents/manage-apm-agents/app-naming/name-your-application - title: Use multiple names for an app path: /docs/agents/manage-apm-agents/app-naming/use-multiple-names-app Copy Tip Navigation nesting is currently limited to a maximum of six levels deep. Please reach out to the engineering team if that is not enough. Here are important elements of the nav file: Key Required? Description title yes The text shown in the navigation, either of a doc or a category. path yes The URL path to the doc or the category view. Do not use trailing slashes. For docs categories in the nav file, the path is required to create an index view. Without the path, a docs category won't be clickable as a link and won't display a view of those docs. Learn more about index views. rootNav no rootNav controls whether a nav file will be displayed or hidden on the docs site home page. It is enabled by default. If you want to hide a category from the home page (as we do for our style guide docs, for example), you would set this to false, as shown below: title: Style guide path: /docs/style-guide rootNav: false Copy children no This is hardly ever used. It indicates a sub-navigation node. Procedures Below are instructions for several common procedures. It may help you to review the terms we use before starting a procedure. Procedures include: Add a new category Add a doc to sidebar/nav-file Move docs between folders or categories Move or delete folders Create a \"dummy\" category for docs that don’t live in that area Make a category heading clickable Troubleshoot messed up category views Add a new category We'll explain two procedures: adding a subcategory of docs in an existing nav file, and adding an entirely new nav file. Add a new nav file Adding an entirely new nav file should be rare, and something we only do occasionally during large overhauls of site structure. To add an entirely new nav file: Copy an existing file nav file, or create a new nav file. Customize the new nav file with the categories and docs you want, using the structure of existing nav files as a template. For more on structure, see nav format. Tip You need at least one level of nesting inside the nav file. Without that, doc titles in the auto-generated category views will render as H2 headings. For example, src/content/level-one/level-two/doc will work, but src/content/level-one/doc will produce strange formatting. If you don't want your new nav to appear on the main landing page, add rootNav: false to your .yml file. (For an example of this, see src/nav/style-guide.yml.) Add a new category to a nav file To add a new category to a nav file: In an existing nav file, add a new category, represented by its title and path. If you're adding a path for that category (recommended), it must use the URL of an existing folder with at least one mdx file in it. Add the docs you want in that section. Ensure your new content matches the indenting of the surrounding nav file. To learn more about how this works, see: How a doc's sidebar is determined How a doc category view is determined If a category view isn't clickable, see Make category view clickable. Add a doc to sidebar/nav-file Once you create a doc, you need to place it in one or more nav files. To do this: In the nav file location where you want to locate it, add the title (its short title displayed in the sidebar and category views) and the path, which is the doc's URL. Ensure that you've emulated the indenting based on the surrounding nav file content or other nav files. Add doc in multiple sidebar locations To add a doc in more than one sidebar location, simply add that doc (its title and path) wherever you want it to be in the nav file. For more on how the sidebar is determined for docs in multiple nav files, see Sidebar. You can add a doc URL in multiple nav file locations. Move docs to other categories Because the nav file and the actual folder structure aren't connected, there are two different ways to \"move docs\": Move a doc in the nav files: preferred and most common procedure. Move a doc between folders: less frequent, mainly when doing larger projects where we want to do a significant overhaul of the docs structure and want to ensure the folder structure doesn't become too divergent from the nav file structure. Move docs using nav file You would move a doc in the nav file when you want to change its location in the displayed docs site structure (i.e., the sidebar and docs category views). To move a doc from one place to another in the nav file: In the first nav file, copy the two rows representing that doc's entry (the title and path lines) and paste that content into the place you want it to live in the new nav file. In the new nav file section, make sure that new content is aligned properly with the surrounding nav file content. See [#nav-format] for more about nav file structure. Move docs between folders Note that moving docs between the folders should be relatively rare. The main reasons to do this are when the folder structure and nav file structure are becoming very different, which can be bad for a couple reasons: Too much divergence can create issues with category view displays or sidebar actions. Too much divergence can make finding and editing docs harder, so there can be value to keeping things fairly up to date and parallel. When you move a doc between folders or rename a doc, that changes its URL. Similarly, if you rename a folder, that changes the URL of all docs in that area. To move a doc between folders: Get the current URL of the doc you want to move and add that URL to its own list of redirects. Tips: One way to do this in VSCode is to right click the file and click \"Get relative path\". If you are moving many files, ask the team about ways to programmatically add redirects. Remove the trailing slash. Move the doc to the new folder. Update nav files with the new URL. This is easily overlooked but having the correct doc URL in the nav file, and not a redirect, is important. Note that a doc URL may be in more than one nav file so searching the site for that URL can help. Move or delete a folder Sometimes when we are doing a larger restructuring project, we may want to move or delete the actual folders instead of simply editing the nav files. If you are moving an entire folder or multiple folders to another folder, docs and all: Simply move these folders using your preferred method (e.g., using drag and drop) to the new location. Next, because that move changes all the URLs of the docs and categories, you'll need to add redirects: For adding redirects for docs, see the procedures for moving a doc between folders. For category redirects: For the section of the nav file affected by your folder editing, gather all the category URLs (path fields) that relate to the moved or deleted folders. We don't need to redirect all folder-related URL paths: we only need to redirect the nav file paths because those represent the paths that we actually link to in the docs (in other words: we aren't using folder-based URLs if they don't have a nav file path). Add those category path URLs as redirects in specific docs or, if that won't work, in the taxonomy-redirects file. We should aim to add category redirects in specific docs and the reason for this is that the taxonomy-redirects file is hard to use and because it's a better customer experience to land on a doc versus a category if possible. In most cases, you'll be able to find a fitting doc to redirect to but if only a category view makes sense, use the taxonomy redirects file. For larger projects, this can be tough work, so you'll want to check out the build and make sure all the sidebar links and category headers are working as expected. For deleting folders, you'll want to essentially follow the same steps as above: either moving or deleting the docs in those folders first, gathering the affected category path URLs and adding them as redirects, adn then deleting the empty folders. Create a \"dummy\" sub-category of docs that don't live in that category Sometimes you want to create a category of docs that is there to help expose a related doc or set of docs. For example, in this view, we have added a category for 'New Relic University' even though that's not a doc that lives in that section; in this case, it's not even a doc on our site. In the example above, this 'New Relic University' category header is in regular text and not a link, and that's because it doesn't have a path set for it in the nav file. This also means that in the sidebar, this category header is not a clickable link and simply functions as a collapser/expander. This is acceptable if you don't mind it but below we explain how you can get a clickable category if you need it. To create a so-called \"dummy\" category: Add the category structure you want in the nav file. If you're okay not having a clickable category header, your new category doesn't require a path. If you want a clickable category header, you will need to use or create a folder that matches the new category path and that has at least one mdx file in it (details). In the nav file, add the title and path information for the docs you want in that new category. Test your new category to ensure it is working correctly. Make a sidebar category heading clickable If there's a sidebar category that's only acting as an expander/collapser and doesn't have a link, that's because it either a) doesn't have a path set in the nav file, or b) that path goes to a folder that doesn't have a doc in it. For more on this, see the instructions regarding clickable headers in the \"dummy\" category section. Troubleshoot category views not working correctly If a docs category view is not working correctly, review how category views are formed. If this does happen, get another opinion from another tech writer to make sure you're not missing something, as we should rarely have problems. One reason that a category view might not work is specifically for path URLs that are also landing pages. In this case, if that path is used in more than one location in the same nav file, the docs site can be confused about which category view to use. We may fix this with a coding fix but in meantime: consider pointing to other URLs and not that path, so that there's only one use of that path per nav file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.81427,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " between folders. For category <em>redirects</em>: For the section of the nav file affected by your folder editing, gather all the category URLs (<em>path</em> fields) that relate to the moved or deleted folders. We don&#x27;t need to <em>redirect</em> all folder-related URL paths: we only need to <em>redirect</em> the nav file paths because"
      },
      "id": "612eff27e7b9d25b16b6f24c"
    },
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "Child account",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "customer vs. user",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-09-01T21:56:16Z",
      "updated_at": "2021-09-01T21:56:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements Child account A parent account contains one or more child accounts. Child accounts were previously referred to as \"sub-accounts\". click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also [mouse over] #mouse-over). collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. customer vs. user When possible, use the second person you to form a sense of connection with the reader. For times when you need a descriptive third-person noun, keep the following guidelines in mind: customer and user are both appropriate depending on context. customer makes more sense when talking about billing, or about a group of people or a business entity. For example, one customer may have one or more individual users who interact with New Relic through the customer's account(s). user makes more sense as a general term for an individual user, or when talking about users as an object in the account model. For example, when discussing account models, it's important to be specific about what constitutes a single person identity in our system. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account We previously used \"master account\" and \"sub-account\" but now we use parent account and child account. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account New Relic organizations can have a parent/child account structure. This is more important for our original account/user model but still plays a role for some behind-the-scenes features on our New Relic One account/user model. Learn more about account structure. Parent accounts were previously referred to as master accounts, and there are still some uses of this in the codebase. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of browser monitoring docs. Often abbreviated as RUM, this is a generic industry term for browser monitoring. New Relic refers to this as page load timing or browser monitoring. Use this term only for SEO or clarification, not to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.14688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "app name <em>vs</em>. app alias",
        "body": " that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the <em>short</em> name according to the AWS Documentation site. Example: Amazon EC2. app name <em>vs</em>. app alias The &quot;machine name&quot; that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes"
      },
      "id": "60421ec1196a676986a83d87"
    }
  ],
  "/docs/style-guide/quick-reference/ui-paths": [
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "Child account",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "customer vs. user",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-09-01T21:56:16Z",
      "updated_at": "2021-09-01T21:56:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements Child account A parent account contains one or more child accounts. Child accounts were previously referred to as \"sub-accounts\". click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also [mouse over] #mouse-over). collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. customer vs. user When possible, use the second person you to form a sense of connection with the reader. For times when you need a descriptive third-person noun, keep the following guidelines in mind: customer and user are both appropriate depending on context. customer makes more sense when talking about billing, or about a group of people or a business entity. For example, one customer may have one or more individual users who interact with New Relic through the customer's account(s). user makes more sense as a general term for an individual user, or when talking about users as an object in the account model. For example, when discussing account models, it's important to be specific about what constitutes a single person identity in our system. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account We previously used \"master account\" and \"sub-account\" but now we use parent account and child account. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account New Relic organizations can have a parent/child account structure. This is more important for our original account/user model but still plays a role for some behind-the-scenes features on our New Relic One account/user model. Learn more about account structure. Parent accounts were previously referred to as master accounts, and there are still some uses of this in the codebase. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of browser monitoring docs. Often abbreviated as RUM, this is a generic industry term for browser monitoring. New Relic refers to this as page load timing or browser monitoring. Use this term only for SEO or clarification, not to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 435.2525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>). Don&#x27;t use NR-ONLY or NRONLY or New Relic"
      },
      "id": "60421ec1196a676986a83d87"
    },
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution (callout-caution)",
        "Caution",
        "Important (callout-important)",
        "Important",
        "Tip (callout-tip)",
        "Tip",
        "User-related permissions",
        "Pricing (callout-pricing) Do not use.",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c8337fb61ea2576fe138fe4540929e67d501ce2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/callouts/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-20T14:36:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts Here's an example of the callout format: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy On our Docs site, we use these callout classes: Caution (callout-caution) Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use the callout-caution class. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important (callout-important) Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use the callout-important class. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip (callout-tip) Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use the callout-tip class. At a traffic light, a Tip would be a green light. Tip If you have integrated your New Relic account with a ticketing system such as Lighthouse, Pivotal Tracker, or Atlassian JIRA, you can use the note to file a ticket or story. User-related permissions For recommended wording, see User-related language and styles. Pricing (callout-pricing) Do not use. Pricing callouts let you know that you may need a specific subscription level in order to access the product or feature. Pricing callouts use the callout-pricing class. Typically, pricing callouts appear in the intro of a doc. See the example below for standard verbiage in the callout. With the new pricing model, these are rarely used. Tip Access to this feature depends on your subscription level. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, no watermark is needed–just a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the Docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 324.55975,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    },
    {
      "sections": [
        "Buttons",
        "Button breakdown",
        "Button variations"
      ],
      "title": "Buttons",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c755477545c29afb5ae1a309af0f61bbb9091a2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/buttons/",
      "published_at": "2021-09-01T21:51:53Z",
      "updated_at": "2021-08-08T00:02:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you want to draw someone's attention to a link without putting it in a callout, buttons are an elegant way to do that. Click me! Button breakdown Buttons are created from two React components: <ButtonGroup> and <ButtonLink>. <ButtonGroup> <ButtonLink role=\"button\" to=\"Button URL\" variant=\"primary\" > Button text </ButtonLink> </ButtonGroup> Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button's URL. variant Use the value primary. For alternate button style, use secondary Button variations If you need it, you can put two or more buttons in a row. Simply include additional ButtonLink content within ButtonGroup. Button one Button two Secondary button The source for those buttons looks like this: <ButtonGroup> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button one </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"primary\" > Button two </ButtonLink> <ButtonLink role=\"button\" to=\"https://docs.newrelic.com\" variant=\"secondary\" > Secondary button </ButtonLink> </ButtonGroup> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 288.91147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": "=&quot;primary&quot; &gt; Button text &lt;&#x2F;ButtonLink&gt; &lt;&#x2F;ButtonGroup&gt; Copy The ButtonLink component has three fields: Field Description role Use the value button. to The button&#x27;s URL. variant Use the value primary. For alternate button <em>style</em>, use secondary Button variations If you need it, you can put two or more buttons"
      },
      "id": "610f1f1064441f5f2947abfa"
    }
  ]
}